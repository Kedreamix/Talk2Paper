<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-08-20  WebMall -- A Multi-Shop Benchmark for Evaluating Web Agents">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-1cd588f7ea33dc92654d2f58f9f73c0e.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-08-20
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-09-08
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    14.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    58 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-08-20-更新"><a href="#2025-08-20-更新" class="headerlink" title="2025-08-20 更新"></a>2025-08-20 更新</h1><h2 id="WebMall-–-A-Multi-Shop-Benchmark-for-Evaluating-Web-Agents"><a href="#WebMall-–-A-Multi-Shop-Benchmark-for-Evaluating-Web-Agents" class="headerlink" title="WebMall – A Multi-Shop Benchmark for Evaluating Web Agents"></a>WebMall – A Multi-Shop Benchmark for Evaluating Web Agents</h2><p><strong>Authors:Ralph Peeters, Aaron Steiner, Luca Schwarz, Julian Yuya Caspary, Christian Bizer</strong></p>
<p>LLM-based web agents have the potential to automate long-running web tasks, such as finding offers for specific products in multiple online shops and subsequently ordering the cheapest products that meet the users needs. This paper introduces WebMall, a multi-shop online shopping benchmark for evaluating the effectiveness and efficiency of web agents for comparison-shopping. WebMall consists of four simulated online shops populated with authentic product offers sourced from the Common Crawl, alongside a suite of 91 cross-shop tasks. These tasks include basic tasks such as finding specific products in multiple shops, performing price comparisons, adding items to the shopping cart, and completing checkout. Advanced tasks involve searching for products based on vague requirements, identifying suitable substitutes, and finding compatible products. Compared to existing e-commerce benchmarks, such as WebShop or ShoppingBench, WebMall introduces comparison-shopping tasks across multiple shops. Furthermore, the product offers are more heterogeneous, as they originate from hundreds of distinct real-world shops. The tasks in WebMall require longer interaction trajectories than those in WebShop, while remaining representative of real-world shopping behaviors. We evaluate eight baseline agents on WebMall, varying in observation modality, memory utilization, and underlying large language model (GPT 4.1 and Claude Sonnet 4). The best-performing configurations achieve completion rates of 75% and 53%, and F1 scores of 87% and 63%, on the basic and advanced task sets, respectively. WebMall is publicly released to facilitate research on web agents and to promote advancements in navigation, reasoning, and efficiency within e-commerce scenarios. </p>
<blockquote>
<p>基于LLM的Web代理具有自动化长期Web任务的潜力，例如在多间网上商店中寻找特定产品的优惠，然后订购符合用户需求的最低价格产品。本文介绍了WebMall，这是一个用于评估Web代理在比较购物中的有效性和效率的多店在线购物基准测试。WebMall由四个模拟在线商店组成，这些商店充满了来自Common Crawl的真实产品优惠信息，以及一套91个跨店任务。这些任务包括在多个商店中寻找特定产品、进行价格比较、将商品添加到购物车并完成结账等基本任务。高级任务包括根据模糊要求搜索产品、识别合适的替代品和寻找兼容产品。与现有的电子商务基准测试（如WebShop或ShoppingBench）相比，WebMall引入了跨多个商店的比较购物任务。此外，产品优惠更加多样化，因为它们来源于数百个不同的真实商店。WebMall中的任务需要比WebShop更长的交互轨迹，同时仍然代表真实世界的购物行为。我们在WebMall上评估了八种基线代理，它们在观察模式、内存利用和底层大型语言模型（GPT 4.1和Claude Sonnet 4）方面有所不同。表现最佳的配置在基本和高级任务集上的完成率分别为75%和53%，F1分数分别为87%和63%。WebMall公开发布，以促进对Web代理的研究，并推动电子商务场景中的导航、推理和效率方面的进步。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13024v1">PDF</a> </p>
<p><strong>Summary</strong><br>    LLM驱动的Web代理具备自动化长期Web任务的能力，如跨多个在线商店寻找特定产品的优惠并订购符合用户需求的最低价格产品。本文介绍了WebMall，这是一个在线购物基准测试平台，用于评估Web代理的比较购物效果与效率。WebMall包含四个模拟在线商店和91个跨店任务，用于评估代理在基本和高级任务上的表现。与现有电子商务基准测试相比，WebMall引入了跨多个商店的比较购物任务，产品来源更加多样化。我们对使用不同观察模式、记忆利用和大型语言模型（GPT 4.1和Claude Sonnet 4）的八种基准代理进行了评估，最佳配置在基本和高级任务集上的完成率分别为75%和53%，F1分数分别为87%和63%。WebMall已公开发布，以促进对Web代理的研究并推动电子商务场景中导航、推理和效率方面的进展。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM-based web agents具备自动化长期Web任务的能力，如跨多个在线商店进行比较购物。</li>
<li>WebMall是一个多店在线购物基准测试平台，用于评估web代理在比较购物中的效果和效率。</li>
<li>WebMall包含四个模拟在线商店和91个跨店任务，任务包括基本和高级任务，要求更长的交互轨迹。</li>
<li>与现有电子商务基准测试相比，WebMall的产品来源更加多样化，并引入了跨多个商店的比较购物任务。</li>
<li>评估的代理表现差异显著，最佳配置在任务完成率和F1分数方面表现较好。</li>
<li>WebMall已公开发布，以促进对Web代理的研究。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.13024">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-657e1cef1c71a394c94080848a152520.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7800447470596b895e61b5098ce3e00f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fa6432ab39fb1752d487694831927264.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b3981b850f02ef59c49ccbdd1a265ff1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8e55febebe0147ff03bdee88f9c9d38a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-14e939ae0e1c5761564f4fa7243d1ef3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-65d4d8fa0232c9d98845645e86265828.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="An-LLM-Agent-Based-Complex-Semantic-Table-Annotation-Approach"><a href="#An-LLM-Agent-Based-Complex-Semantic-Table-Annotation-Approach" class="headerlink" title="An LLM Agent-Based Complex Semantic Table Annotation Approach"></a>An LLM Agent-Based Complex Semantic Table Annotation Approach</h2><p><strong>Authors:Yilin Geng, Shujing Wang, Chuan Wang, Keqing He, Yanfei Lv, Ying Wang, Zaiwen Feng, Xiaoying Bai</strong></p>
<p>The Semantic Table Annotation (STA) task, which includes Column Type Annotation (CTA) and Cell Entity Annotation (CEA), maps table contents to ontology entities and plays important roles in various semantic applications. However, complex tables often pose challenges such as semantic loss of column names or cell values, strict ontological hierarchy requirements, homonyms, spelling errors, and abbreviations, which hinder annotation accuracy. To address these issues, this paper proposes an LLM-based agent approach for CTA and CEA. We design and implement five external tools with tailored prompts based on the ReAct framework, enabling the STA agent to dynamically select suitable annotation strategies depending on table characteristics. Experiments are conducted on the Tough Tables and BiodivTab datasets from the SemTab challenge, which contain the aforementioned challenges. Our method outperforms existing approaches across various metrics. Furthermore, by leveraging Levenshtein distance to reduce redundant annotations, we achieve a 70% reduction in time costs and a 60% reduction in LLM token usage, providing an efficient and cost-effective solution for STA. </p>
<blockquote>
<p>语义表注解（STA）任务包括列类型注解（CTA）和单元格实体注解（CEA），其将表格内容映射到本体实体并在各种语义应用中扮演着重要角色。然而，复杂的表格往往带来挑战，如列名或单元格值的语义丢失、严格的本体层次结构要求、同义词、拼写错误和缩写，这些都会阻碍注释的准确性。为了解决这些问题，本文提出了一种基于大语言模型（LLM）的CTA和CEA代理方法。基于ReAct框架，我们设计并实现了五个外部工具，并使用针对性的提示使STA代理能够根据表格特性动态选择适当的注释策略。实验是在SemTab挑战中的Tough Tables和BiodivTab数据集上进行的，这些数据集包含了上述挑战。我们的方法在各项指标上均优于现有方法。此外，通过利用莱文斯坦距离减少冗余注释，我们实现了时间成本降低70%和大语言模型令牌使用量减少60%，为STA提供了高效且经济实惠的解决方案。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12868v1">PDF</a> </p>
<p><strong>Summary</strong>：语义表注解任务包括列类型注解和单元格实体注解，它将表内容映射到本体实体上并在多种语义应用中发挥重要作用。针对复杂表格中的语义损失、严格的本体层次结构要求、同音词、拼写错误和缩写等问题，本文提出了一种基于大型语言模型的代理方法用于列类型注解和单元格实体注解。通过设计五个基于ReAct框架的外部工具与定制提示，该代理可以动态选择适合的策略来应对不同的表格特性。实验证明，该方法在SemTab挑战中的Tough Tables和BiodivTab数据集上的表现优于现有方法。此外，通过利用Levenshtein距离减少冗余注释，降低了时间成本和大型语言模型的令牌使用量，提供了一种高效且经济的语义表注解解决方案。</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>语义表注解任务包括列类型注解和单元格实体注解，对表内容映射到本体实体上具有重要意义。</li>
<li>复杂表格存在语义损失、本体层次结构要求严格、同音词等挑战。</li>
<li>基于大型语言模型的代理方法被提出用于解决这些问题，并设计五个外部工具以应对不同表格特性。</li>
<li>在SemTab挑战中的实验证明该方法表现优于现有方法。</li>
<li>通过利用Levenshtein距离减少冗余注释，提高了效率并降低了时间和成本。</li>
<li>该方法提供了一种高效且经济的语义表注解解决方案。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12868">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-cbad4667707eb52d9960188afa15a90f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f9fb63fd6dc6a82aefca9bd0db090e71.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cdf99140ab69a2e9d91a65c260d1dc35.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Scaling-Multi-Agent-Epistemic-Planning-through-GNN-Derived-Heuristics"><a href="#Scaling-Multi-Agent-Epistemic-Planning-through-GNN-Derived-Heuristics" class="headerlink" title="Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics"></a>Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics</h2><p><strong>Authors:Giovanni Briglia, Francesco Fabiano, Stefano Mariani</strong></p>
<p>Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for reasoning about both the physical world and the beliefs of agents, with applications in domains where information flow and awareness among agents are critical. The richness of MEP requires states to be represented as Kripke structures, i.e., directed labeled graphs. This representation limits the applicability of existing heuristics, hindering the scalability of epistemic solvers, which must explore an exponential search space without guidance, resulting often in intractability. To address this, we exploit Graph Neural Networks (GNNs) to learn patterns and relational structures within epistemic states, to guide the planning process. GNNs, which naturally capture the graph-like nature of Kripke models, allow us to derive meaningful estimates of state quality – e.g., the distance from the nearest goal – by generalizing knowledge obtained from previously solved planning instances. We integrate these predictive heuristics into an epistemic planning pipeline and evaluate them against standard baselines, showing significant improvements in the scalability of multi-agent epistemic planning. </p>
<blockquote>
<p>多智能体知识规划（MEP）是一个自主规划框架，能够推理物理世界和智能体的信念，适用于信息流和智能体之间的认知至关重要的领域。MEP的丰富性需要将状态表示为Kripke结构，即带有标签的有向图。这种表示方法限制了现有启发式方法的应用，阻碍了认知求解器的可扩展性，因为必须在没有指导的情况下进行指数搜索空间探索，这通常会导致难以解决。为解决这一问题，我们利用图神经网络（GNNs）学习认知状态中的模式和关系结构，以指导规划过程。图神经网络自然捕捉了Kripke模型的图形特征，允许我们通过推广从先前解决的规划实例中获得的知识来评估状态质量的有意义的估计——例如距离最近的目标的距离。我们将这些预测启发式集成到认知规划管道中，并与标准基线进行评估，显示出多智能体知识规划的扩展性得到了显著改善。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12840v1">PDF</a> </p>
<p><strong>Summary</strong><br>     多主体认知规划（MEP）是一个自主规划框架，能够同时对物理世界和智能体的信念进行推理，在信息流动和智能体之间的意识至关重要的领域有广泛应用。MEP的丰富性需要将状态表示为Kripke结构，即带标签的有向图。这种表示限制了现有启发式方法的应用，阻碍了认知求解器的可扩展性，因为必须在没有指导的情况下进行指数搜索空间的探索，这通常会导致不可解性。为解决这一问题，我们利用图神经网络（GNNs）学习认知状态的模式和关系结构，以指导规划过程。通过捕捉Kripke模型的图形性质，GNNs允许我们从先前解决的规划实例中获得知识来推导有意义的状态质量估计——例如，离最近目标的距离。我们将这些预测性启发式方法整合到认知规划管道中，并进行标准基准测试，显示出多主体认知规划的扩展性得到了显著改善。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MEP是一个用于自主规划的框架，能够处理物理世界和智能体信念的推理。</li>
<li>MEP采用Kripke结构表示状态，限制了现有启发式方法的应用。</li>
<li>GNNs被用来学习认知状态的模式和关系结构，以指导规划过程。</li>
<li>GNNs能够捕捉Kripke模型的图形性质，从先前解决的规划实例中推导状态质量估计。</li>
<li>预测性启发式方法被整合到认知规划管道中。</li>
<li>与标准基准相比，整合后的方法在多主体认知规划的扩展性方面表现出显著改善。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12840">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-64098cd9606fbd3cd49a25cd1bef746d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f4aa9f683ff079d43271b1abb1039fe1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-64be13fbb9b6532e366d504f50c9521b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-334e860a35ec876c17ccd878191a6d16.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5ca7cd051d8e027e34b3c8178d2daf17.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Atom-Searcher-Enhancing-Agentic-Deep-Research-via-Fine-Grained-Atomic-Thought-Reward"><a href="#Atom-Searcher-Enhancing-Agentic-Deep-Research-via-Fine-Grained-Atomic-Thought-Reward" class="headerlink" title="Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic   Thought Reward"></a>Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic   Thought Reward</h2><p><strong>Authors:Yong Deng, Guoqing Wang, Zhenzhe Ying, Xiaofeng Wu, Jinzhen Lin, Wenwen Xiong, Yuqin Dai, Shuo Yang, Zhanwei Zhang, Qiwen Wang, Yang Qin, Changhua Meng</strong></p>
<p>Large language models (LLMs) exhibit remarkable problem-solving abilities, but struggle with complex tasks due to static internal knowledge. Retrieval-Augmented Generation (RAG) enhances access to external information, yet remains limited in multi-hop reasoning and strategic search due to rigid workflows. Recent advancements in agentic deep research empower LLMs to autonomously reason, search, and synthesize information. However, current approaches relying on outcome-based reinforcement learning (RL) face critical issues such as conflicting gradients and reward sparsity, limiting performance gains and training efficiency. To address these, we first propose Atomic Thought, a novel LLM thinking paradigm that decomposes reasoning into fine-grained functional units. These units are supervised by Reasoning Reward Models (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained guidance. Building on this, we propose Atom-Searcher, a novel RL framework for agentic deep research that integrates Atomic Thought and ATR. Atom-Searcher uses a curriculum-inspired reward schedule, prioritizing process-level ATR early and transitioning to outcome rewards, accelerating convergence on effective reasoning paths. Experiments on seven benchmarks show consistent improvements over the state-of-the-art. Key advantages include: (1) Atom-Searcher scales computation at test-time. (2) Atomic Thought provides supervision anchors for RRMs, bridging deep research tasks and RRMs. (3) Atom-Searcher exhibits more interpretable, human-like reasoning patterns. </p>
<blockquote>
<p>大型语言模型（LLM）展现出卓越的解决问题的能力，但由于静态内部知识，它们在处理复杂任务时遇到困难。检索增强生成（RAG）增强了对外部信息的访问，但由于僵化的工作流程，它在多跳推理和战略搜索方面仍然有限制。最近的代理深度研究进展使LLM能够自主推理、搜索和合成信息。然而，当前依赖结果基于强化学习（RL）的方法面临关键挑战，如梯度冲突和奖励稀疏，这限制了性能提升和训练效率。为了解决这些问题，我们首先提出原子思维，这是一种新的LLM思维范式，将推理分解成精细的功能单元。这些单元受到推理奖励模型（RRMs）的监督，为精细指导提供原子思维奖励（ATR）。在此基础上，我们提出了Atom-Searcher，这是一个用于代理深度研究的新型强化学习框架，它结合了原子思维和ATR。Atom-Searcher使用受课程启发的奖励时间表，早期优先提供过程级的ATR，然后过渡到结果奖励，从而加快对有效推理路径的收敛。在七个基准测试上的实验表明，与最新技术相比，它始终表现出一致的优势。主要优势包括：（1）Atom-Searcher在测试时扩展计算规模。（2）原子思维为RRMs提供了监督锚点，桥接了深度研究任务和RRMs。（3）Atom-Searcher展现出更具解释性、更人性化的推理模式。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12800v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）具有出色的解决问题的能力，但由于静态内部知识而难以应对复杂任务。检索增强生成（RAG）提高了对外部信息的访问能力，但由于工作流程僵化，它在多跳推理和战略搜索方面仍存在局限性。最近的深度研究中，赋能LLM自主推理、搜索和合成信息的进步显著。然而，依赖结果强化学习（RL）的方法面临梯度冲突和奖励稀疏等关键问题，限制了性能提升和训练效率。为解决这些问题，我们提出了原子思维这一新型LLM思维范式和基于它的推理奖励模型（RRM），通过精细的奖励引导进行原子思维奖励（ATR）。基于此，我们进一步提出了Atom-Searcher这一新型的深度研究RL框架，融合了原子思维和ATR。Atom-Searcher采用启发式教学奖励计划，早期侧重于过程级ATR，并逐步过渡到结果奖励，以加速在有效推理路径上的收敛。实验结果表明，相较于现有技术，Atom-Searcher具有持续的优势，如计算能力的扩展性、为RRM提供监督锚点以及更可解释的类似人类的推理模式。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLMs）虽具备解决问题的能力，但在复杂任务方面存在由于静态内部知识的局限性。</li>
<li>检索增强生成（RAG）能提高对外部信息的访问，但在多跳推理和战略搜索方面的表现仍然受限。</li>
<li>目前依赖结果强化学习（RL）的方法面临梯度冲突和奖励稀疏的问题。</li>
<li>原子思维（Atomic Thought）是一种新型的LLM思维范式，通过将推理分解为精细的功能单元来提高性能。</li>
<li>推理奖励模型（RRM）用于提供原子思维奖励（ATR），为精细的推理过程提供指导。</li>
<li>Atom-Searcher是一个结合了原子思维和ATR的新型RL框架，采用启发式教学奖励计划以加速收敛有效推理路径。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12800">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-75ef40e8940d1c4fd2b3b0a6b4a96736.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6d71e84c2ed3b992e40dd7cbadded5b4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-847fe97327e36bfe692c937f850560ee.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="A-Taxonomy-of-Hierarchical-Multi-Agent-Systems-Design-Patterns-Coordination-Mechanisms-and-Industrial-Applications"><a href="#A-Taxonomy-of-Hierarchical-Multi-Agent-Systems-Design-Patterns-Coordination-Mechanisms-and-Industrial-Applications" class="headerlink" title="A Taxonomy of Hierarchical Multi-Agent Systems: Design Patterns,   Coordination Mechanisms, and Industrial Applications"></a>A Taxonomy of Hierarchical Multi-Agent Systems: Design Patterns,   Coordination Mechanisms, and Industrial Applications</h2><p><strong>Authors:David J. Moore</strong></p>
<p>Hierarchical multi-agent systems (HMAS) organize collections of agents into layered structures that help manage complexity and scale. These hierarchies can simplify coordination, but they also can introduce trade-offs that are not always obvious. This paper proposes a multi-dimensional taxonomy for HMAS along five axes: control hierarchy, information flow, role and task delegation, temporal layering, and communication structure. The intent is not to prescribe a single “best” design but to provide a lens for comparing different approaches.   Rather than treating these dimensions in isolation, the taxonomy is connected to concrete coordination mechanisms - from the long-standing contract-net protocol for task allocation to more recent work in hierarchical reinforcement learning. Industrial contexts illustrate the framework, including power grids and oilfield operations, where agents at production, maintenance, and supply levels coordinate to diagnose well issues or balance energy demand. These cases suggest that hierarchical structures may achieve global efficiency while preserving local autonomy, though the balance is delicate.   The paper closes by identifying open challenges: making hierarchical decisions explainable to human operators, scaling to very large agent populations, and assessing whether learning-based agents such as large language models can be safely integrated into layered frameworks. This paper presents what appears to be the first taxonomy that unifies structural, temporal, and communication dimensions of hierarchical MAS into a single design framework, bridging classical coordination mechanisms with modern reinforcement learning and large language model agents. </p>
<blockquote>
<p>分层多智能体系统（HMAS）将智能体集合组织成层次结构，有助于管理复杂性和规模。这些层次结构可以简化协调，但它们也可能引入并不总是明显的权衡。本文提出了一个沿着五个轴的多层次多维度分类法：控制层次结构、信息流、角色和任务委派、时间分层和通信结构。其目的并不是规定一个单一的“最佳”设计，而是提供一个比较不同方法的视角。这个分类法不仅孤立地处理这些维度，而且与具体的协调机制相关联——从长期的任务分配合同网协议到最新的分层强化学习工作。工业背景说明了该框架，包括电力网和油田操作，其中生产、维护和供应级别的智能体协调以诊断油井问题或平衡能源需求。这些案例表明，层次结构可能在实现全局效率的同时保留局部自主性，但平衡是微妙的。最后，论文指出了开放挑战：使分层决策对人类操作者具有可解释性、扩展到大量智能体以及评估基于学习的大型语言模型等智能体是否能安全地集成到分层框架中。本文似乎呈现了第一个将层次化MAS的结构、时间和通信维度统一到一个设计框架中的分类法，桥梁古典协调机制与现代的强化学习和大型语言模型智能体。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12683v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了层次化多智能体系统（HMAS）的五维分类方法，包括控制层次结构、信息流动、角色和任务委派、时间分层和通信结构。文章旨在提供一种比较不同层次化多智能体系统设计方法的透镜，旨在通过具体的协调机制实现全局效率和局部自主性的平衡。通过案例分析探讨了HMAS在实际工业环境中的实际应用和挑战。虽然本文提供了层次化决策的分类框架，但仍面临诸多挑战，如提高决策的可解释性、适应大规模智能体数量和评估基于学习模型的智能体的集成等。这看似是多智能体系统研究的重要一步，旨在跨越经典协调机制与当前强化学习和大型语言模型智能体的界限。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>HMAS通过分层结构管理复杂性和规模，简化协调，但也带来权衡。</li>
<li>提出一个五维分类法：控制层次结构、信息流动、角色和任务委派、时间分层和通信结构。</li>
<li>分类法旨在比较不同的HMAS设计方法，并强调具体的协调机制。</li>
<li>HMAS在工业环境中可实现全局效率和局部自主性的平衡。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12683">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-af64e37cae4244643f9b172271ca03b6.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="OS-R1-Agentic-Operating-System-Kernel-Tuning-with-Reinforcement-Learning"><a href="#OS-R1-Agentic-Operating-System-Kernel-Tuning-with-Reinforcement-Learning" class="headerlink" title="OS-R1: Agentic Operating System Kernel Tuning with Reinforcement   Learning"></a>OS-R1: Agentic Operating System Kernel Tuning with Reinforcement   Learning</h2><p><strong>Authors:Hongyu Lin, Yuchen Li, Haoran Luo, Kaichun Yao, Libo Zhang, Mingjie Xing, Yanjun Wu</strong></p>
<p>Linux kernel tuning is essential for optimizing operating system (OS) performance. However, existing methods often face challenges in terms of efficiency, scalability, and generalization. This paper introduces OS-R1, an agentic Linux kernel tuning framework powered by rule-based reinforcement learning (RL). By abstracting the kernel configuration space as an RL environment, OS-R1 facilitates efficient exploration by large language models (LLMs) and ensures accurate configuration modifications. Additionally, custom reward functions are designed to enhance reasoning standardization, configuration modification accuracy, and system performance awareness of the LLMs. Furthermore, we propose a two-phase training process that accelerates convergence and minimizes retraining across diverse tuning scenarios. Experimental results show that OS-R1 significantly outperforms existing baseline methods, achieving up to 5.6% performance improvement over heuristic tuning and maintaining high data efficiency. Notably, OS-R1 is adaptable across various real-world applications, demonstrating its potential for practical deployment in diverse environments. Our dataset and code are publicly available at <a target="_blank" rel="noopener" href="https://github.com/LHY-24/OS-R1">https://github.com/LHY-24/OS-R1</a>. </p>
<blockquote>
<p>Linux内核调优对于优化操作系统性能至关重要。然而，现有方法常常在效率、可扩展性和通用性方面面临挑战。本文介绍了一种名为OS-R1的基于规则的强化学习驱动的Linux内核调优框架。通过将内核配置空间抽象为强化学习环境，OS-R1便于大型语言模型进行高效探索，并确保准确的配置修改。此外，我们设计了自定义奖励函数，以提高大型语言模型的推理标准化、配置修改准确性和系统性能意识。此外，我们提出了一种两阶段训练过程，以加速收敛并减少不同调优场景下的再训练时间。实验结果表明，OS-R1显著优于现有基线方法，在启发式调优的基础上实现了高达5.6%的性能提升，并保持了较高的数据效率。值得注意的是，OS-R1可适应各种实际应用，展示了其在不同环境中实际部署的潜力。我们的数据集和代码可在<a target="_blank" rel="noopener" href="https://github.com/LHY-24/OS-R1%E5%85%AC%E5%BC%80%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/LHY-24/OS-R1公开访问。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12551v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>OS-R1，一个基于规则强化学习的Linux内核调优框架，通过抽象内核配置空间作为RL环境，提高了操作系统性能优化的效率与准确性。它利用大型语言模型进行高效探索，并通过自定义奖励函数增强标准化、修改准确性和系统性能意识。此外，提出的两阶段训练过程可加速收敛并减少不同调优场景下的再训练时间。实验表明，OS-R1显著优于现有方法，在性能上提高了5.6%，且具有良好的数据效率及跨实际应用环境的适应性。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>OS-R1引入了一种新的Linux内核调优框架，该框架结合规则强化学习技术以提高系统性能优化效率。</li>
<li>通过抽象内核配置空间作为强化学习环境，OS-R1使大型语言模型进行高效探索。</li>
<li>自定义奖励函数增强了标准化、配置修改准确性和系统性能意识。</li>
<li>两阶段训练过程加速模型收敛并减少在不同调优场景下的再训练时间。</li>
<li>OS-R1在性能上显著优于现有方法，提高了高达5.6%。</li>
<li>OS-R1具有良好的数据效率，可适应不同的实际应用程序和环境。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12551">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-715461a7028b754f26b2d23c4821ad76.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-609575a06a8826fcfad7acebadf92c18.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b16a43a3726c9e87ef1afc1e1e32249f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1cd588f7ea33dc92654d2f58f9f73c0e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ae885579eff528b54f34d2484a7f12a1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-153fec1be038821acecfe27a6b0ce823.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Dynamic-Multi-Agent-System-with-Stable-Maneuvering-for-Robust-GAIA-Problem-Solving-by-AWorld"><a href="#Dynamic-Multi-Agent-System-with-Stable-Maneuvering-for-Robust-GAIA-Problem-Solving-by-AWorld" class="headerlink" title="Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA   Problem Solving by AWorld"></a>Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA   Problem Solving by AWorld</h2><p><strong>Authors:Zhitian Xie, Qintong Wu, Chengyue Yu, Chenyi Zhuang, Jinjie Gu</strong></p>
<p>The rapid advancement of large language models (LLMs) has empowered intelligent agents to leverage diverse external tools for solving complex real-world problems. However, as agents increasingly depend on multiple tools, they encounter new challenges: extended contexts from disparate sources and noisy or irrelevant tool outputs can undermine system reliability and accuracy. These challenges underscore the necessity for enhanced stability in agent-based systems. To address this, we introduce dynamic supervision and maneuvering mechanisms, constructing a robust and dynamic Multi-Agent System (MAS) architecture within the AWorld framework. In our approach, the Execution Agent invokes the Guard Agent at critical steps to verify and correct the reasoning process, effectively reducing errors arising from noise and bolstering problem-solving robustness. Extensive experiments on the GAIA test dataset reveal that our dynamic maneuvering mechanism significantly improves both the effectiveness and stability of solutions, outperforming single-agent system (SAS) and standard tool-augmented systems. As a result, our dynamic MAS system achieved first place among open-source projects on the prestigious GAIA leaderboard. These findings highlight the practical value of collaborative agent roles in developing more reliable and trustworthy intelligent systems. </p>
<blockquote>
<p>随着大型语言模型（LLM）的快速发展，智能代理能够利用多种外部工具解决复杂的现实世界问题。然而，随着代理越来越依赖于多种工具，它们面临着新的挑战：来自不同来源的扩展上下文和嘈杂或无关的工具输出可能会破坏系统可靠性和准确性。这些挑战强调了提高基于代理的系统的稳定性的必要性。为了解决这一问题，我们引入了动态监督和操作机制，在AWorld框架内构建了一个稳健且动态的多代理系统（MAS）架构。在我们的方法中，执行代理会在关键步骤调用防护代理来验证和纠正推理过程，有效地减少了由噪声引起的错误，增强了解决问题的稳健性。在GAIA测试数据集上的大量实验表明，我们的动态操作机制显著提高了解决方案的有效性和稳定性，优于单代理系统（SAS）和标准工具增强系统。因此，我们的动态MAS系统在著名的GAIA排行榜上获得开源项目第一名。这些发现凸显了协作代理角色在开发更可靠、更值得信赖的智能系统中的实际价值。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.09889v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型的快速发展使得智能代理能够利用多种外部工具解决复杂的现实世界问题。然而，随着代理越来越依赖于多种工具，他们面临新的挑战：来自不同来源的扩展上下文和嘈杂或无关的工具输出可能会破坏系统可靠性和准确性。为解决这些问题，我们引入动态监督和操控机制，在AWorld框架内构建稳健且动态的多代理系统（MAS）架构。执行代理在关键步骤调用守卫代理进行验证和校正推理过程，有效减少噪声引起的错误，增强解决问题的稳健性。在GAIA测试数据集上的广泛实验表明，我们的动态操控机制显著提高了解决方案的有效性和稳定性，优于单代理系统（SAS）和标准工具增强系统。因此，我们的动态MAS系统在著名的GAIA排行榜上获得开源项目第一名。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型的进步促进了智能代理利用外部工具解决复杂问题。</li>
<li>依赖多工具带来挑战，如上下文扩展、嘈杂工具输出影响系统可靠性。</li>
<li>引入动态监督和操控机制，构建多代理系统（MAS）以增强系统稳健性。</li>
<li>执行代理与守卫代理协同工作，减少错误，提高问题解决的稳健性。</li>
<li>在GAIA测试数据集上的实验表明，动态操控机制提高解决方案的有效性和稳定性。</li>
<li>与单代理系统和其他工具增强系统相比，动态MAS系统表现优越。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.09889">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-6572f685bc4f876b23eeac4ee8e4deb3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-deddb3ea5996422094aeaf80bb4e909c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4971518c8d91fbacbc933a3bb909cef4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fdacbd56ed7c3536c5c998d69ed7b66e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4afcabdb16ee890dd11da85902e3501b.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Congestion-Mitigation-Path-Planning-for-Large-Scale-Multi-Agent-Navigation-in-Dense-Environments"><a href="#Congestion-Mitigation-Path-Planning-for-Large-Scale-Multi-Agent-Navigation-in-Dense-Environments" class="headerlink" title="Congestion Mitigation Path Planning for Large-Scale Multi-Agent   Navigation in Dense Environments"></a>Congestion Mitigation Path Planning for Large-Scale Multi-Agent   Navigation in Dense Environments</h2><p><strong>Authors:Takuro Kato, Keisuke Okumura, Yoko Sasaki, Naoya Yokomachi</strong></p>
<p>In high-density environments where numerous autonomous agents move simultaneously in a distributed manner, streamlining global flows to mitigate local congestion is crucial to maintain overall navigation efficiency. This paper introduces a novel path-planning problem, congestion mitigation path planning (CMPP), which embeds congestion directly into the cost function, defined by the usage of incoming edges along agents’ paths. CMPP assigns a flow-based multiplicative penalty to each vertex of a sparse graph, which grows steeply where frequently-traversed paths intersect, capturing the intuition that congestion intensifies where many agents enter the same area from different directions. Minimizing the total cost yields a set of coarse-level, time-independent routes that autonomous agents can follow while applying their own local collision avoidance. We formulate the problem and develop two solvers: (i) an exact mixed-integer nonlinear programming solver for small instances, and (ii) a scalable two-layer search algorithm, A-CMTS, which quickly finds suboptimal solutions for large-scale instances and iteratively refines them toward the optimum. Empirical studies show that augmenting state-of-the-art collision-avoidance planners with CMPP significantly reduces local congestion and enhances system throughput in both discrete- and continuous-space scenarios. These results indicate that CMPP improves the performance of multi-agent systems in real-world applications such as logistics and autonomous-vehicle operations. </p>
<blockquote>
<p>在高密度环境中，众多自主代理以分布式方式同时移动，理顺全局流程以缓解局部拥堵对于维持整体导航效率至关重要。本文引入了一种新的路径规划问题，即拥堵缓解路径规划（CMPP），它将拥堵直接嵌入到成本函数中，该成本函数由代理路径上的传入边使用定义。CMPP为每个稀疏图的顶点分配基于流量的乘法惩罚，该惩罚在频繁穿越的路径交叉处急剧增长，直觉地反映了拥堵的加剧，即许多代理从不同方向进入同一区域。最小化总成本产生了一组粗略的、时间独立的路线，自主代理可以遵循这些路线并应用其自己的本地避障策略。我们制定问题并开发了两个求解器：（i）针对小实例的精确混合整数非线性规划求解器，（ii）可扩展的两层搜索算法A-CMTS，该算法可以快速为大规模实例找到次优解，并迭代地对其进行优化以达到最优。实证研究表明，使用CMPP增强最新的避障规划器可以显著减少局部拥堵，并在离散和连续空间场景中提高系统吞吐量。这些结果表明，CMPP在物流和自动驾驶等实际应用中提高了多代理系统的性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.05253v2">PDF</a> Published in IEEE Robotics and Automation Letters (RA-L), 2025. (C)   2025 IEEE. CC BY 4.0 license. Supplementary videos will be accessible via   IEEE Xplore upon publication</p>
<p><strong>摘要</strong></p>
<p>在存在众多以分布式方式自主移动的智能体的高密度环境中，优化全局流程以缓解局部拥堵对于维持整体导航效率至关重要。本文引入了一种新型路径规划问题——拥堵缓解路径规划（CMPP），它将拥堵直接嵌入到成本函数中，该成本函数由智能体路径上的传入边决定。CMPP为每个稀疏图的顶点分配基于流量的乘法惩罚，这在频繁穿越的路径交汇处急剧增长，捕捉到一个直觉，即当许多智能体从不同方向进入同一区域时，拥堵加剧。最小化总成本产生一组粗略的、时间独立的路线，自主智能体可以在遵循这些路线的同时应用其自身的局部防撞功能。我们建立了这个问题，并开发了两种求解器：（i）一种精确的混合整数非线性规划求解器用于小型实例，（ii）一种快速为大型实例找到次优解决方案的可扩展两层搜索算法A-CMTS，并朝着最优方向迭代改进它们。实证研究表明，通过将最新防撞规划器与CMPP相结合，可在离散空间和连续空间场景中显著降低局部拥堵并提高系统吞吐量。这些结果表明，CMPP在物流和自动驾驶车辆操作等实际应用中提高了多智能体系统的性能。</p>
<p><strong>关键要点</strong></p>
<ul>
<li>在高密度环境中，缓解局部拥堵对维持多智能体系统整体导航效率至关重要。</li>
<li>提出了新型的拥堵缓解路径规划（CMPP）问题，将拥堵直接纳入成本函数。</li>
<li>CMPP为稀疏图的每个顶点分配基于流量的乘法惩罚，在频繁交汇的路径交汇处惩罚更高。</li>
<li>最小化总成本得到自主智能体可遵循的粗略时间独立路线。</li>
<li>开发了两种求解器：一种是精确的非线性规划求解器适用于小规模问题；另一种是快速找到大规模问题的次优解并迭代优化的两层搜索算法A-CMTS。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.05253">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-8474259f11fe613aeebc90da784dd937.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1ca1a9635c99ab451b1039928cb4ac2a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b36b540912b3009c465b093cccc012dd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8a40d8bba8f37fa746ef88a55b640c18.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-105b78936b145e1530d0ee360ddaa8ef.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d2585d8293e1e8fb52c139aa8a3a3101.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="ContestTrade-A-Multi-Agent-Trading-System-Based-on-Internal-Contest-Mechanism"><a href="#ContestTrade-A-Multi-Agent-Trading-System-Based-on-Internal-Contest-Mechanism" class="headerlink" title="ContestTrade: A Multi-Agent Trading System Based on Internal Contest   Mechanism"></a>ContestTrade: A Multi-Agent Trading System Based on Internal Contest   Mechanism</h2><p><strong>Authors:Li Zhao, Rui Sun, Zuoyou Jiang, Bo Yang, Yuxiao Bai, Mengting Chen, Xinyang Wang, Jing Li, Zuo Bai</strong></p>
<p>In financial trading, large language model (LLM)-based agents demonstrate significant potential. However, the high sensitivity to market noise undermines the performance of LLM-based trading systems. To address this limitation, we propose a novel multi-agent system featuring an internal competitive mechanism inspired by modern corporate management structures. The system consists of two specialized teams: (1) Data Team - responsible for processing and condensing massive market data into diversified text factors, ensuring they fit the model’s constrained context. (2) Research Team - tasked with making parallelized multipath trading decisions based on deep research methods. The core innovation lies in implementing a real-time evaluation and ranking mechanism within each team, driven by authentic market feedback. Each agent’s performance undergoes continuous scoring and ranking, with only outputs from top-performing agents being adopted. The design enables the system to adaptively adjust to dynamic environment, enhances robustness against market noise and ultimately delivers superior trading performance. Experimental results demonstrate that our proposed system significantly outperforms prevailing multi-agent systems and traditional quantitative investment methods across diverse evaluation metrics. ContestTrade is open-sourced on GitHub at <a target="_blank" rel="noopener" href="https://github.com/FinStep-AI/ContestTrade">https://github.com/FinStep-AI/ContestTrade</a>. </p>
<blockquote>
<p>在金融交易领域，基于大型语言模型（LLM）的代理展现出了巨大的潜力。然而，对市场噪声的高度敏感性削弱了LLM交易系统的性能。为了解决这一局限性，我们提出了一种新型的多代理系统，该系统以现代企业管理结构为灵感，具备内部竞争机制。该系统由两个专业团队组成：（1）数据团队——负责处理和压缩大量市场数据，形成多样化的文本因素，确保它们符合模型的限制语境。（2）研究团队——根据深度研究方法制定并行多路径交易决策。核心创新在于在每个团队内部实施实时评估和排名机制，以真实的市场反馈为驱动。每个代理的表现都会进行持续评分和排名，只有表现最佳的代理的输出才会被采用。这种设计使系统能够自适应地调整动态环境，增强对市场噪声的稳健性，并最终实现优越的交易性能。实验结果表明，我们提出的系统在多种评价指标上显著优于现有的多代理系统和传统的量化投资方法。ContestTrade已在GitHub上开源，地址为：<a target="_blank" rel="noopener" href="https://github.com/FinStep-AI/ContestTrade%E3%80%82">https://github.com/FinStep-AI/ContestTrade。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00554v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>基于大型语言模型（LLM）的金融交易代理展现出巨大潜力，但易受市场噪音影响。为此，我们提出一种新型多代理系统，该系统由数据团队和研究团队组成，借鉴现代企业管理结构中的竞争机制。通过实时评估和排名机制，系统能够自适应调整环境、增强对市场噪音的稳健性并提升交易性能。该系统已在GitHub上开源，性能优越。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM在金融交易领域展现出巨大潜力。</li>
<li>市场噪音对LLM交易系统性能影响较大。</li>
<li>提出一种新型多代理系统，包含数据团队和研究团队。</li>
<li>系统借鉴现代企业管理结构中的竞争机制。</li>
<li>系统通过实时评估和排名机制自适应调整环境。</li>
<li>系统增强了对市场噪音的稳健性并提升了交易性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00554">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-45566e79db7be45938c04c10fe2ef4ad.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-266868a091c9e99deb2f01f35589ca21.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-364148b71b45242c99c25af292f7d10c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d8281a829e28eaa4cea0e4f596804ed2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a807157e61658624b0937b694ac83a57.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Hierarchical-Multi-Agent-Reinforcement-Learning-with-Control-Barrier-Functions-for-Safety-Critical-Autonomous-Systems"><a href="#Hierarchical-Multi-Agent-Reinforcement-Learning-with-Control-Barrier-Functions-for-Safety-Critical-Autonomous-Systems" class="headerlink" title="Hierarchical Multi-Agent Reinforcement Learning with Control Barrier   Functions for Safety-Critical Autonomous Systems"></a>Hierarchical Multi-Agent Reinforcement Learning with Control Barrier   Functions for Safety-Critical Autonomous Systems</h2><p><strong>Authors:H. M. Sabbir Ahmad, Ehsan Sabouni, Alexander Wasilkoff, Param Budhraja, Zijian Guo, Songyuan Zhang, Chuchu Fan, Christos Cassandras, Wenchao Li</strong></p>
<p>We address the problem of safe policy learning in multi-agent safety-critical autonomous systems. In such systems, it is necessary for each agent to meet the safety requirements at all times while also cooperating with other agents to accomplish the task. Toward this end, we propose a safe Hierarchical Multi-Agent Reinforcement Learning (HMARL) approach based on Control Barrier Functions (CBFs). Our proposed hierarchical approach decomposes the overall reinforcement learning problem into two levels learning joint cooperative behavior at the higher level and learning safe individual behavior at the lower or agent level conditioned on the high-level policy. Specifically, we propose a skill-based HMARL-CBF algorithm in which the higher level problem involves learning a joint policy over the skills for all the agents and the lower-level problem involves learning policies to execute the skills safely with CBFs. We validate our approach on challenging environment scenarios whereby a large number of agents have to safely navigate through conflicting road networks. Compared with existing state of the art methods, our approach significantly improves the safety achieving near perfect (within 5%) success&#x2F;safety rate while also improving performance across all the environments. </p>
<blockquote>
<p>我们解决多智能体安全关键自主系统中的安全策略学习问题。在这种系统中，每个智能体必须随时满足安全要求，同时与其他智能体合作完成任务。为此，我们提出了一种基于控制屏障函数（CBF）的安全分层多智能体强化学习（HMARL）方法。我们提出的分层方法将整体的强化学习问题分解为两个层次的学习：在较高层次上学习联合合作行为，在较低层次或智能体层面上学习以高级策略为条件的安全个体行为。具体来说，我们提出了一种基于技能的HMARL-CBF算法，其中高级问题涉及学习所有智能体的技能联合策略，而低级问题涉及使用CBF安全执行技能的学习策略。我们在具有挑战性的环境场景中验证了我们的方法，其中大量智能体必须通过冲突的道路网络进行安全导航。与现有最先进的相比，我们的方法显著提高了安全性，实现了近完美的（在5%以内）成功&#x2F;安全率，同时提高了所有环境中的性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.14850v2">PDF</a> </p>
<p><strong>Summary</strong><br>安全多智能体强化学习在关键自主系统中的研究。针对此类系统中各智能体需全天候满足安全需求且与其他智能体合作完成任务的问题，提出了一种基于控制屏障函数的安全分层多智能体强化学习（HMARL）方法。该方法将整体强化学习问题分解为两个层次的学习问题：高层学习联合合作行为，低层或智能体层次则在高层策略条件下学习安全个体行为。提出一种基于技能的HMARL-CBF算法，高层问题涉及学习所有智能体的技能联合策略，低层问题则涉及利用CBF学习安全执行技能的政策。在充满挑战的环境中验证了该方法的有效性，大量智能体在冲突道路网络上安全导航，相较于现有方法显著提高安全性，接近完美的成功&#x2F;安全率（在5%以内），同时提高所有环境的性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>该研究解决多智能体安全关键自主系统中的安全策略学习问题。</li>
<li>提出一种基于控制屏障函数的安全分层多智能体强化学习（HMARL）方法。</li>
<li>将整体强化学习问题分解为两个层次的学习问题：联合合作行为和个人安全行为。</li>
<li>提出一种基于技能的HMARL-CBF算法，其中高层学习所有智能体的技能联合策略，低层学习安全执行技能的政策。</li>
<li>在复杂环境中验证了该方法的有效性，大量智能体在冲突道路网络上安全导航。</li>
<li>与现有方法相比，该方法显著提高安全性，达到近乎完美的成功&#x2F;安全率（在5%以内）。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.14850">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-73ccb723e4eead1af3192dd9d53c0031.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dceb02855161e383392d064baa85648b.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Multi-agent-Auditory-Scene-Analysis"><a href="#Multi-agent-Auditory-Scene-Analysis" class="headerlink" title="Multi-agent Auditory Scene Analysis"></a>Multi-agent Auditory Scene Analysis</h2><p><strong>Authors:Caleb Rascon, Luis Gato-Diaz, Eduardo García-Alarcón</strong></p>
<p>Auditory scene analysis (ASA) aims to retrieve information from the acoustic environment, by carrying out three main tasks: sound source location, separation, and classification. These tasks are traditionally executed with a linear data flow, where the sound sources are first located; then, using their location, each source is separated into its own audio stream; from each of which, information is extracted that is relevant to the application scenario (audio event detection, speaker identification, emotion classification, etc.). However, running these tasks linearly increases the overall response time, while making the last tasks (separation and classification) highly sensitive to errors of the first task (location). A considerable amount of effort and computational complexity has been employed in the state-of-the-art to develop techniques that are the least error-prone possible. However, doing so gives rise to an ASA system that is non-viable in many applications that require a small computational footprint and a low response time, such as bioacoustics, hearing-aid design, search and rescue, human-robot interaction, etc. To this effect, in this work, a multi-agent approach is proposed to carry out ASA where the tasks are run in parallel, with feedback loops between them to compensate for local errors, such as: using the quality of the separation output to correct the location error; and using the classification result to reduce the localization’s sensitivity towards interferences. The result is a multi-agent auditory scene analysis (MASA) system that is robust against local errors, without a considerable increase in complexity, and with a low response time. The complete proposed MASA system is provided as a framework that uses open-source tools for sound acquisition and reproduction (JACK) and inter-agent communication (ROS2), allowing users to add their own agents. </p>
<blockquote>
<p>听觉场景分析（ASA）旨在通过执行三个主要任务从声学环境中检索信息：声源定位、分离和分类。这些任务通常是按线性数据流执行的，首先定位声源；然后，利用它们的位置，将每个声源分离成各自的音频流；从每个音频流中提取与应用场景相关的信息（如音频事件检测、说话人识别、情感分类等）。然而，按线性方式运行这些任务会增加总体响应时间，同时使最后的任务（分离和分类）对第一个任务（定位）的错误高度敏感。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02755v2">PDF</a> Submitted to Applied Soft Computing</p>
<p><strong>Summary</strong><br>    多智能体听觉场景分析（MASA）采用并行执行任务的方式，通过反馈环路补偿局部错误，如利用分离质量校正定位误差和利用分类结果减少干扰对定位的影响。MASA系统对局部错误具有鲁棒性，且复杂度增加不大，响应时间快。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>听觉场景分析（ASA）主要从声学环境中提取信息，包括声音源定位、分离和分类三个主要任务。</li>
<li>传统线性执行这些任务的方法会增加总体响应时间，并使后续任务对前面任务的错误更加敏感。</li>
<li>在本研究中，提出了一种多智能体听觉场景分析（MASA）方法，该方法采用并行执行任务，并在任务间建立反馈环路以补偿局部错误。</li>
<li>MASA系统利用分离质量校正定位误差，并使用分类结果来减少干扰对定位的影响，从而增强了对局部错误的鲁棒性。</li>
<li>MASA系统的复杂度增加不大，且具备快速的响应时间，使其适用于对计算足迹和响应时间有严格要求的应用。</li>
<li>MASA系统框架利用开源工具进行声音采集和复制（JACK）以及智能体间通信（ROS2），用户可添加自己的智能体。</li>
<li>MASA系统框架的提供为研究者提供了一个实现多智能体听觉场景分析的平台。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02755">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-a9d6422076805350fa0fc5703c10784c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e48a2984ef6ffc459027c962e81b806a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c06654ef916e1eb3d663e0197a19af70.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e4713f3a75df3f8df6968b4451e0641c.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Policy-Search-Retrieval-and-Composition-via-Task-Similarity-in-Collaborative-Agentic-Systems"><a href="#Policy-Search-Retrieval-and-Composition-via-Task-Similarity-in-Collaborative-Agentic-Systems" class="headerlink" title="Policy Search, Retrieval, and Composition via Task Similarity in   Collaborative Agentic Systems"></a>Policy Search, Retrieval, and Composition via Task Similarity in   Collaborative Agentic Systems</h2><p><strong>Authors:Saptarshi Nath, Christos Peridis, Eseoghene Benjamin, Xinran Liu, Soheil Kolouri, Peter Kinnell, Zexin Li, Cong Liu, Shirin Dora, Andrea Soltoggio</strong></p>
<p>Agentic AI aims to create systems that set their own goals, adapt proactively to change, and refine behavior through continuous experience. Recent advances suggest that, when facing multiple and unforeseen tasks, agents could benefit from sharing machine-learned knowledge and reuse policies that have already been fully or partially learned by other agents. However, how to query, select, and retrieve policies from a pool of agents, and how to integrate such policies remains a largely unexplored area. This study explores how an agent decides what knowledge to select, from whom, and when and how to integrate it in its own policy in order to accelerate its own learning. The proposed algorithm, \emph{Modular Sharing and Composition in Collective Learning} (MOSAIC), improves learning in agentic collectives by combining (1) knowledge selection using performance signals and cosine similarity on Wasserstein task embeddings, (2) modular and transferable neural representations via masks, and (3) policy integration, composition and fine-tuning. MOSAIC outperforms isolated learners and global sharing approaches in both learning speed and overall performance, and in some cases solves tasks that isolated agents cannot. The results also demonstrate that selective, goal-driven reuse leads to less susceptibility to task interference. We also observe the emergence of self-organization, where agents solving simpler tasks accelerate the learning of harder ones through shared knowledge. </p>
<blockquote>
<p>人工智能Agent旨在创建能够自主设定目标、主动适应变化并通过持续经验调整行为的系统。最近的进展表明，在面对多个和未曾预见的任务时，agents可以通过共享机器学习的知识和重用其他agents已经完全或部分学习的策略来获益。然而，如何从多个agents的池中查询、选择和检索策略，以及如何整合这些策略仍然是一个尚未完全探索的领域。本研究探讨了agent如何决定选择哪些知识、从谁那里获取、以及何时以及如何将其整合到自身的策略中，以加速其自身的学习。提出的算法“集体学习中的模块化共享与组合”(MOSAIC)，通过以下三个方面改进了集体学习中的学习：1）使用性能信号和Wasserstein任务嵌入上的余弦相似性进行知识选择；2）通过掩码实现模块化可迁移的神经表征；以及3）策略集成、组合和微调。MOSAIC在学习速度和整体性能上均优于孤立学习者和全局共享方法，在某些情况下，可以解决孤立agents无法解决的问题。结果还表明，选择性、目标驱动的重用降低了对任务干扰的敏感性。我们还观察到自我组织的出现，其中解决简单任务的agents通过共享知识来加速解决更复杂任务的学习。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.05577v2">PDF</a> 25 pages, 20 figures, 6 tables. Preprint</p>
<p><strong>Summary</strong><br>人工智能代理系统通过学习设定自身目标、主动适应变化并通过持续经验优化行为。面对多重和未曾预见的任务时，代理之间共享机器学到的知识和重用其他代理已完全或部分学到的策略可带来好处。然而，如何查询、选择和检索代理池中的策略，以及如何整合这些策略仍是一个待探索的领域。本研究探讨了代理如何决定选择哪些知识、从谁那里获取、以及何时和如何将其整合到自身策略中，以加速自身学习。提出的算法“集体学习中的模块化共享与组合（MOSAIC）”通过结合知识选择、模块化可转移的神经表征和策略整合，提高了代理集体的学习效率。MOSAIC在学习速度和整体性能上超越了孤立学习者和全局共享方法，并在某些情况下解决了孤立代理无法解决的问题。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Agentic AI系统能自主设定目标、适应变化，并通过经验持续优化行为。</li>
<li>面对多重任务时，代理之间共享知识和策略带来益处。</li>
<li>知识选择、模块化可转移的神经表征和策略整合是提高代理学习效率的关键。</li>
<li>MOSAIC算法通过结合性能信号和余弦相似性在Wasserstein任务嵌入中进行知识选择。</li>
<li>MOSAIC在学习速度和整体性能上优于孤立学习者和全局共享方法。</li>
<li>选择性、目标驱动的重用策略减少了任务干扰的易感性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.05577">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-8c55db4e6ce75fb0190a152ed4a30dd4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-735ee25406da0292146d4866399718ae.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d215f8b8cccee93254550fb33c091b2e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1c455281bf12c7d41b2248ca61b4d3ab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aa7af71490d227b7c4a560d2f55f4044.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Explainable-Reinforcement-Learning-Agents-Using-World-Models"><a href="#Explainable-Reinforcement-Learning-Agents-Using-World-Models" class="headerlink" title="Explainable Reinforcement Learning Agents Using World Models"></a>Explainable Reinforcement Learning Agents Using World Models</h2><p><strong>Authors:Madhuri Singh, Amal Alabdulkarim, Gennie Mansi, Mark O. Riedl</strong></p>
<p>Explainable AI (XAI) systems have been proposed to help people understand how AI systems produce outputs and behaviors. Explainable Reinforcement Learning (XRL) has an added complexity due to the temporal nature of sequential decision-making. Further, non-AI experts do not necessarily have the ability to alter an agent or its policy. We introduce a technique for using World Models to generate explanations for Model-Based Deep RL agents. World Models predict how the world will change when actions are performed, allowing for the generation of counterfactual trajectories. However, identifying what a user wanted the agent to do is not enough to understand why the agent did something else. We augment Model-Based RL agents with a Reverse World Model, which predicts what the state of the world should have been for the agent to prefer a given counterfactual action. We show that explanations that show users what the world should have been like significantly increase their understanding of the agent policy. We hypothesize that our explanations can help users learn how to control the agents execution through by manipulating the environment. </p>
<blockquote>
<p>可解释的AI（XAI）系统已经被提出，以帮助人们理解AI系统如何产生输出和行为。由于时序决策的自然属性，可解释的强化学习（XRL）增加了额外的复杂性。此外，非AI专家并不一定具备改变代理或其策略的能力。我们引入了一种使用世界模型来为基于模型的深度强化学习代理生成解释的技术。世界模型预测了当执行动作时世界将如何变化，从而可以生成反事实轨迹。然而，仅仅确定用户希望代理执行的操作并不足以理解为什么代理执行了其他操作。我们用反向世界模型增强基于模型的RL代理，该模型预测世界状态应该是怎样的，才能使代理偏好给定的反事实动作。我们表明，向用户展示世界应该是怎样的样子的解释，能显著提高他们对代理策略的理解。我们假设我们的解释可以帮助用户学习如何通过操纵环境来控制代理的执行。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08073v2">PDF</a> Accepted by Workshop on Explainable Artificial Intelligence (XAI) at   IJCAI 2025</p>
<p><strong>Summary</strong></p>
<p>本摘要介绍了可解释的强化学习（XRL）的复杂性及其对于时序决策制定的挑战。为解决这一问题，我们引入了使用世界模型（World Models）为基于模型的深度强化学习（Model-Based Deep RL）代理生成解释的技术。通过预测世界在执行动作时的变化，世界模型可以生成反事实轨迹。然而，仅仅了解用户希望代理执行的动作并不足以理解代理的实际行为原因。因此，我们增强了基于模型的RL代理的反向世界模型（Reverse World Model），它预测对于代理偏好给定的反事实动作时世界的状态应该是什么样的。实验表明，解释用户看到的世界应该是怎样的，可以显著提高他们对代理策略的理解。我们假设这些解释可以帮助用户学习如何通过操纵环境来控制代理的执行。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>可解释的强化学习（XRL）面临复杂性和挑战，特别是时序决策的问题。</li>
<li>世界模型技术被用来为基于模型的深度强化学习代理生成解释。</li>
<li>世界模型可以生成反事实轨迹，预测世界在执行动作时的变化。</li>
<li>仅知道用户希望代理执行的动作不足以理解代理的实际行为原因。</li>
<li>反向世界模型增强了基于模型的RL代理，预测在给定反事实动作下世界的状态。</li>
<li>显示给用户的世界模型解释能显著提高他们对代理策略的理解。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08073">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-c3cd683b25b5bfea1b24d5ca2ee239f9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0923899977279d8b1126d61573253efd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4ad7ac25e12deafe44ba1f180209a736.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ebf810b87dcf0aa2cfa2a940562f5a11.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d9e6ca13371e27197c450fffc06010f0.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Advancing-AI-Scientist-Understanding-Multi-Agent-LLMs-with-Interpretable-Physics-Reasoning"><a href="#Advancing-AI-Scientist-Understanding-Multi-Agent-LLMs-with-Interpretable-Physics-Reasoning" class="headerlink" title="Advancing AI-Scientist Understanding: Multi-Agent LLMs with   Interpretable Physics Reasoning"></a>Advancing AI-Scientist Understanding: Multi-Agent LLMs with   Interpretable Physics Reasoning</h2><p><strong>Authors:Yinggan Xu, Hana Kimlee, Yijia Xiao, Di Luo</strong></p>
<p>Large Language Models (LLMs) are playing an increasingly important role in physics research by assisting with symbolic manipulation, numerical computation, and scientific reasoning. However, ensuring the reliability, transparency, and interpretability of their outputs remains a major challenge. In this work, we introduce a novel multi-agent LLM physicist framework that fosters collaboration between AI and human scientists through three key modules: a reasoning module, an interpretation module, and an AI-scientist interaction module. Recognizing that effective physics reasoning demands logical rigor, quantitative accuracy, and alignment with established theoretical models, we propose an interpretation module that employs a team of specialized LLM agents-including summarizers, model builders, visualization tools, and testers-to systematically structure LLM outputs into transparent, physically grounded science models. A case study demonstrates that our approach significantly improves interpretability, enables systematic validation, and enhances human-AI collaboration in physics problem-solving and discovery. Our work bridges free-form LLM reasoning with interpretable, executable models for scientific analysis, enabling more transparent and verifiable AI-augmented research. </p>
<blockquote>
<p>大规模语言模型（LLMs）在物理研究中的作用越来越重要，它们可以协助进行符号操作、数值计算和科学推理。然而，确保这些输出的可靠性、透明度和可解释性仍然是一个主要挑战。在这项工作中，我们引入了一个新型的多智能体LLM物理学家框架，该框架通过三个关键模块：推理模块、解释模块和人机互动模块，来培养人工智能与人类科学家之间的协作。我们认识到有效的物理推理需要逻辑严谨、定量准确并与既定的理论模型相符，因此，我们提出了一种解释模块，该模块采用一组专业的LLM智能体，包括摘要撰写者、模型构建者、可视化工具和测试者等，以系统地构建透明的、基于物理的科学模型。一项案例研究表明，我们的方法显著提高了可解释性，实现了系统的验证，并增强了人类在解决物理问题和发现方面的能力。我们的工作将自由的LLM推理与可解释、可执行的模型相结合，用于科学分析，实现了更透明、可验证的人工智能辅助研究。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.01911v2">PDF</a> ICML 2025 Workshop on MAS</p>
<p><strong>Summary</strong>：大型语言模型（LLM）在物理研究中的作用日益重要，可协助进行符号操作、数值计算和科学研究推理。然而，确保输出的可靠性、透明度和可解释性是一大挑战。本研究介绍了一种新型的多智能体LLM物理学家框架，通过推理模块、解释模块和人机互动模块三个核心模块促进人工智能与人类科学家的合作。该框架采用专业LLM智能体团队进行结构化输出，以建立透明、基于物理的科学模型，显著提高了解释性，实现系统验证，并强化了人类与人工智能在解决物理问题和发现方面的合作。该研究将自由形式的LLM推理与可解释、可执行的模型相结合，实现了更透明和可验证的人工智能辅助研究。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>大型语言模型（LLM）在物理研究中发挥着重要作用，涵盖符号操作、数值计算和科学研究推理。</li>
<li>LLM在物理研究中的可靠性、透明度和可解释性仍是挑战。</li>
<li>引入了一种新型的多智能体LLM物理学家框架，包含推理模块、解释模块和人机互动模块。</li>
<li>解释模块采用专业LLM智能体团队进行结构化输出，建立透明、基于物理的科学模型。</li>
<li>该框架提高了LLM输出的解释性，实现了系统验证。</li>
<li>强化了人类与人工智能在解决物理问题和发现方面的合作。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.01911">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-63e1f5e589c03155ad47d210c09ebf2d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19721a7c2d576c4a7e2b2fa5d2872c4f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0b77115cfdfeba2f9218113cfc54da95.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-119b65bcc6a791307759da1c231ed8e4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-59e2854b466de7c280e5747da02a87df.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff5c5880c23248ba832a92df916a3d97.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-998f9e594ceee451f7545df9e7de4744.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-20/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-20/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-20/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-1cd6df32adbbf757cd796674a163d818.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-08-20  MAGNeT Multimodal Adaptive Gaussian Networks for Intent Inference in   Moving Target Selection across Complex Scenarios
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-20
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-20/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-14e939ae0e1c5761564f4fa7243d1ef3.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-08-20  RepreGuard Detecting LLM-Generated Text by Revealing Hidden   Representation Patterns
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-20
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">29997.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
