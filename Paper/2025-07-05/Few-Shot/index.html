<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-07-05  No time to train! Training-Free Reference-Based Instance Segmentation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-34ef610aa985554711ae9ea98c2158ba.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-07-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-07-07
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    7.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    29 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-07-05-更新"><a href="#2025-07-05-更新" class="headerlink" title="2025-07-05 更新"></a>2025-07-05 更新</h1><h2 id="No-time-to-train-Training-Free-Reference-Based-Instance-Segmentation"><a href="#No-time-to-train-Training-Free-Reference-Based-Instance-Segmentation" class="headerlink" title="No time to train! Training-Free Reference-Based Instance Segmentation"></a>No time to train! Training-Free Reference-Based Instance Segmentation</h2><p><strong>Authors:Miguel Espinosa, Chenhongyi Yang, Linus Ericsson, Steven McDonagh, Elliot J. Crowley</strong></p>
<p>The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP). </p>
<blockquote>
<p>历史上，图像分割模型的性能一直受到收集大规模标注数据的高成本的限制。Segment Anything Model（SAM）通过可提示的、与语义无关的分割范式缓解了这一原始问题，但仍然存在需要手动视觉提示或复杂的域相关提示生成规则来处理新图像的问题。为了减轻这一新负担，我们的工作研究了在仅提供一小组参考图像的情况下进行目标分割的任务。我们的关键见解是利用基础模型学到的强大语义先验知识，来识别参考图像和目标图像之间的对应区域。我们发现这种对应关系能够自动生成用于下游任务的实例级分割掩码，并通过一个多阶段、无需训练的方法实现我们的想法，该方法包括（1）构建内存银行；（2）表示聚合和（3）语义感知特征匹配。我们的实验显示，在分割指标上取得了显著改进，达到了COCO FSOD（nAP 36.8%）、PASCAL VOC少镜头（nAP50 71.2%）的先进水平，并在跨域FSOD基准测试上超越了现有的无需训练的方法（nAP 22.4%）。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02798v1">PDF</a> Preprint</p>
<p><strong>Summary</strong></p>
<p>本文提出一种基于少量参考图像进行物体分割的方法。通过利用强大的语义先验知识，结合基础模型学习到的特征，实现在目标图像与参考图像间对应区域的自动识别和实例级分割掩模的生成。实验结果在COCO FSOD等数据集上表现出显著的改进，并达到了业界领先水平。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Segment Anything Model (SAM) 解决了大规模标注数据收集成本高昂的问题，但仍需手动视觉提示或复杂的领域相关提示生成规则来处理新图像。</li>
<li>研究提出了一种基于少量参考图像进行物体分割的新方法。</li>
<li>利用强大的语义先验知识，结合基础模型，在目标图像和参考图像之间识别对应区域。</li>
<li>通过自动生成实例级分割掩模，促进下游任务的应用。</li>
<li>实现了多阶段、无需训练的方法，包括建立内存库、表示聚合和语义感知特征匹配。</li>
<li>在COCO FSOD、PASCAL VOC Few-Shot等数据集上的实验结果显著，表现出优越性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02798">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-74e6e77ec342ce3937f6f5fbad310cf6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a43ed67f609bc84c9ae609956c3b7949.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34ef610aa985554711ae9ea98c2158ba.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4a286991d15d5b81e95cb8d8dcb2551e.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Learning-few-step-posterior-samplers-by-unfolding-and-distillation-of-diffusion-models"><a href="#Learning-few-step-posterior-samplers-by-unfolding-and-distillation-of-diffusion-models" class="headerlink" title="Learning few-step posterior samplers by unfolding and distillation of   diffusion models"></a>Learning few-step posterior samplers by unfolding and distillation of   diffusion models</h2><p><strong>Authors:Charlesquin Kemajou Mbakam, Jonathan Spence, Marcelo Pereyra</strong></p>
<p>Diffusion models (DMs) have emerged as powerful image priors in Bayesian computational imaging. Two primary strategies have been proposed for leveraging DMs in this context: Plug-and-Play methods, which are zero-shot and highly flexible but rely on approximations; and specialized conditional DMs, which achieve higher accuracy and faster inference for specific tasks through supervised training. In this work, we introduce a novel framework that integrates deep unfolding and model distillation to transform a DM image prior into a few-step conditional model for posterior sampling. A central innovation of our approach is the unfolding of a Markov chain Monte Carlo (MCMC) algorithm - specifically, the recently proposed LATINO Langevin sampler (Spagnoletti et al., 2025) - representing the first known instance of deep unfolding applied to a Monte Carlo sampling scheme. We demonstrate our proposed unfolded and distilled samplers through extensive experiments and comparisons with the state of the art, where they achieve excellent accuracy and computational efficiency, while retaining the flexibility to adapt to variations in the forward model at inference time. </p>
<blockquote>
<p>扩散模型（DMs）在贝叶斯计算成像中已作为强大的图像先验项出现。在此上下文中，已经提出了两种主要策略来利用DMs：即插即用方法，它们是零射击且高度灵活但依赖于近似值；以及通过监督训练针对特定任务实现更高精度和更快推理的专用条件DMs。在这项工作中，我们引入了一个新型框架，该框架集成了深度展开和模型蒸馏，将DM图像先验项转化为用于后采样的一步式条件模型。我们的方法的一个核心创新之处在于展开马尔可夫链蒙特卡洛（MCMC）算法——特别是最近提出的LATINO Langevin采样器（Spagnoletti等人，2025）——这代表了已知第一个用于蒙特卡洛采样方案的深度展开实例。我们通过大量实验以及与最新技术的比较来证明我们提出的展开和蒸馏采样器具有出色的准确性和计算效率，同时在推理时间保持适应正向模型变化的能力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02686v1">PDF</a> 28 pages, 16 figures, 10 tables</p>
<p><strong>摘要</strong></p>
<p>扩散模型（DMs）在贝叶斯计算成像中作为图像先验具有强大的能力。本研究介绍了一种结合深度展开和模型蒸馏的新框架，将扩散模型图像先验转化为用于后采样分析的几步条件模型。核心创新在于马尔可夫链蒙特卡罗算法的展开，特别是最近提出的LATINO Langevin采样器，代表了深度展开首次应用于蒙特卡罗采样方案。实验证明，与现有技术相比，所提出的展开和蒸馏采样器具有出色的准确性和计算效率，同时保留了适应前向模型变化的能力。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>扩散模型（DMs）作为贝叶斯计算成像中的图像先验具有强大的能力。</li>
<li>引入了一种结合深度展开和模型蒸馏的新框架，用于转化扩散模型图像先验为条件模型进行后采样分析。</li>
<li>展开马尔可夫链蒙特卡罗算法在研究中占据核心地位，特别是应用了LATINO Langevin采样器。</li>
<li>此框架是深度展开首次应用于蒙特卡罗采样方案的实例。</li>
<li>与现有技术相比，所提出的采样器具有出色的准确性和计算效率。</li>
<li>提出的框架能够在推理时适应前向模型的变异。</li>
<li>该研究为贝叶斯计算成像中的扩散模型应用提供了新的视角和方法论支持。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02686">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-ece5f8def27a63ef1b6b4e3face95067.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b18d1fd0cf7fadde1d207267175b8e80.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MAGIC-Mask-Guided-Diffusion-Inpainting-with-Multi-Level-Perturbations-and-Context-Aware-Alignment-for-Few-Shot-Anomaly-Generation"><a href="#MAGIC-Mask-Guided-Diffusion-Inpainting-with-Multi-Level-Perturbations-and-Context-Aware-Alignment-for-Few-Shot-Anomaly-Generation" class="headerlink" title="MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations   and Context-Aware Alignment for Few-Shot Anomaly Generation"></a>MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations   and Context-Aware Alignment for Few-Shot Anomaly Generation</h2><p><strong>Authors:JaeHyuck Choi, MinJun Kim, JeHyeong Hong</strong></p>
<p>Few-shot anomaly generation is emerging as a practical solution for augmenting the scarce anomaly data in industrial quality control settings. An ideal generator would meet three demands at once, namely (i) keep the normal background intact, (ii) inpaint anomalous regions to tightly overlap with the corresponding anomaly masks, and (iii) generate anomalous regions in a semantically valid location, while still producing realistic, diverse appearances from only a handful of real examples. Existing diffusion-based methods usually satisfy at most two of these requirements: global anomaly generators corrupt the background, whereas mask-guided ones often falter when the mask is imprecise or misplaced. We propose MAGIC–Mask-guided inpainting with multi-level perturbations and Context-aware alignment–to resolve all three issues. At its core, MAGIC fine-tunes a Stable Diffusion inpainting backbone that preserves normal regions and ensures strict adherence of the synthesized anomaly to the supplied mask, directly addressing background corruption and misalignment. To offset the diversity loss that fine-tuning can cause, MAGIC adds two complementary perturbation strategies: (i) Gaussian prompt-level perturbation applied during fine-tuning and inference that broadens the global appearance of anomalies while avoiding low-fidelity textual appearances, and (ii) mask-guided spatial noise injection that enriches local texture variations. Additionally, the context-aware mask alignment module forms semantic correspondences and relocates masks so that every anomaly remains plausibly contained within the host object, eliminating out-of-boundary artifacts. Under a consistent identical evaluation protocol on the MVTec-AD dataset, MAGIC outperforms previous state-of-the-arts in downstream anomaly tasks. </p>
<blockquote>
<p>少数镜头异常生成（Few-shot anomaly generation）作为一种实用解决方案，正逐渐崭露头角，用于在工业质量控制环境中扩充稀缺的异常数据。理想的生成器需要同时满足三个要求，即（i）保持正常背景不变，（ii）将异常区域填充以紧密覆盖对应的异常掩膜，（iii）在语义有效的位置生成异常区域，同时仅使用少量真实示例即可产生真实且多样化的外观。现有的基于扩散的方法最多只能满足其中两个要求：全局异常生成器会破坏背景，而掩膜引导的方法在掩膜不精确或错位时往往会遇到困难。我们提出了MAGIC方法——一种带有多级扰动和上下文感知对齐的掩膜引导填充法来解决这三个问题。MAGIC的核心是微调Stable Diffusion填充骨干网，以保留正常区域并确保合成异常严格遵循提供的掩膜，直接解决了背景破坏和对齐不精确的问题。为了弥补微调可能导致的多样性损失，MAGIC增加了两种互补的扰动策略：（i）在微调期间和推理期间应用高斯提示级扰动，以扩大异常的总体外观，同时避免低保真度的文本外观；（ii）掩膜引导的空间噪声注入丰富了局部纹理变化。此外，上下文感知的掩膜对齐模块形成了语义对应关系并重新定位了掩膜，使每个异常都合理地包含在主体对象中，消除了边界外的伪影。在MVTec-AD数据集上采用一致相同的评估协议，MAGIC在下游异常任务中的表现超过了以前的最先进方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02314v1">PDF</a> 10 pages, 6 figures</p>
<p><strong>Summary</strong><br>    本文提出了一种名为MAGIC的少数样本异常生成方法，用于工业质量控制设置中异常数据的增强。该方法通过微调Stable Diffusion模型作为核心，解决背景破坏和不匹配问题，同时通过两种互补的扰动策略增强异常多样性，且上下文感知的掩膜对齐模块使异常区域语义上更合理。在MVTec-AD数据集上的评估表明，MAGIC在下游异常任务中表现优于先前技术。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>少数样本异常生成是解决工业质量控制中异常数据稀缺问题的实用方法。</li>
<li>理想的生成器需满足三个需求：保持正常背景、精确覆盖异常区域以及生成语义合理的异常地点。</li>
<li>现有扩散方法通常最多满足两个要求，全球异常生成器会破坏背景，而掩膜引导的生成器在掩膜不精确或错位时经常失效。</li>
<li>MAGIC方法通过微调Stable Diffusion模型解决背景破坏和不匹配问题。</li>
<li>MAGIC通过两种互补的扰动策略增强异常多样性：高斯提示级别扰动和掩膜引导的空间噪声注入。</li>
<li>上下文感知的掩膜对齐模块使异常区域语义上更合理，避免了边界外的伪影。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02314">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-ec4f33981b962a7d897afec11f436cf6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-89e94bef23373798e52db88ac11fc486.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c62ff6dcca77bdc9e02fa203b7c54120.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3c0bf3ad11975ff46ae929829d4433b4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-20755c3100328bc94775cf660ea35a33.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="ViRefSAM-Visual-Reference-Guided-Segment-Anything-Model-for-Remote-Sensing-Segmentation"><a href="#ViRefSAM-Visual-Reference-Guided-Segment-Anything-Model-for-Remote-Sensing-Segmentation" class="headerlink" title="ViRefSAM: Visual Reference-Guided Segment Anything Model for Remote   Sensing Segmentation"></a>ViRefSAM: Visual Reference-Guided Segment Anything Model for Remote   Sensing Segmentation</h2><p><strong>Authors:Hanbo Bi, Yulong Xu, Ya Li, Yongqiang Mao, Boyuan Tong, Chongyang Li, Chunbo Lang, Wenhui Diao, Hongqi Wang, Yingchao Feng, Xian Sun</strong></p>
<p>The Segment Anything Model (SAM), with its prompt-driven paradigm, exhibits strong generalization in generic segmentation tasks. However, applying SAM to remote sensing (RS) images still faces two major challenges. First, manually constructing precise prompts for each image (e.g., points or boxes) is labor-intensive and inefficient, especially in RS scenarios with dense small objects or spatially fragmented distributions. Second, SAM lacks domain adaptability, as it is pre-trained primarily on natural images and struggles to capture RS-specific semantics and spatial characteristics, especially when segmenting novel or unseen classes. To address these issues, inspired by few-shot learning, we propose ViRefSAM, a novel framework that guides SAM utilizing only a few annotated reference images that contain class-specific objects. Without requiring manual prompts, ViRefSAM enables automatic segmentation of class-consistent objects across RS images. Specifically, ViRefSAM introduces two key components while keeping SAM’s original architecture intact: (1) a Visual Contextual Prompt Encoder that extracts class-specific semantic clues from reference images and generates object-aware prompts via contextual interaction with target images; and (2) a Dynamic Target Alignment Adapter, integrated into SAM’s image encoder, which mitigates the domain gap by injecting class-specific semantics into target image features, enabling SAM to dynamically focus on task-relevant regions. Extensive experiments on three few-shot segmentation benchmarks, including iSAID-5$^i$, LoveDA-2$^i$, and COCO-20$^i$, demonstrate that ViRefSAM enables accurate and automatic segmentation of unseen classes by leveraging only a few reference images and consistently outperforms existing few-shot segmentation methods across diverse datasets. </p>
<blockquote>
<p>Segment Anything Model（SAM）以其基于提示的范式在通用分割任务中展现出强大的泛化能力。然而，将SAM应用于遥感（RS）图像仍然面临两大挑战。首先，手动为每张图像构建精确提示（例如点或框）是劳动密集型的，且效率低下，特别是在具有密集小目标或空间碎片分布的遥感场景中。其次，SAM缺乏领域适应性，因为它主要是在自然图像上进行预训练的，在捕获遥感特定的语义和空间特征方面存在困难，尤其是在分割新颖或未见类别时。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02294v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>该论文介绍了Segment Anything Model（SAM）在处理遥感图像时面临的挑战，并提出了ViRefSAM框架来解决这些问题。ViRefSAM利用少量标注的参考图像，通过视觉上下文提示编码器和动态目标对齐适配器两个关键组件，实现了对遥感图像中类一致性对象的自动分割。这一框架在多个数据集上的实验结果表明，它能够在仅使用少量参考图像的情况下实现对未见类的准确自动分割，并一致优于现有的少样本分割方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Segment Anything Model (SAM)面临在遥感图像分割中的两大挑战：手动构建精确提示的劳动密集型和低效性，以及缺乏针对遥感图像特定语义和空间特性的域适应性。</li>
<li>ViRefSAM框架通过利用少量标注的参考图像来解决这些问题，这些参考图像包含特定类别的对象。</li>
<li>ViRefSAM框架包含两个关键组件：视觉上下文提示编码器和动态目标对齐适配器。</li>
<li>视觉上下文提示编码器从参考图像中提取特定类别的语义线索，并通过与目标图像的上下文交互生成对象感知提示。</li>
<li>动态目标对齐适配器被集成到SAM的图像编码器中，通过注入特定类别的语义信息来缩小域差距，使SAM能够动态关注任务相关区域。</li>
<li>在多个数据集上的实验结果表明，ViRefSAM能够利用少量参考图像实现对未见类的准确自动分割。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02294">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-8587e56bcc110111ee537931f59e5790.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-10906a9bebcbf2fafb73f1fe4ecc1783.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f9d8ebbbd6871b06099933dc3c3ddc80.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4427e3b3ed91425082664d70ca51c668.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-01312cf89c27121c9a9a8ad5366d3a00.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Symbolic-or-Numerical-Understanding-Physics-Problem-Solving-in-Reasoning-LLMs"><a href="#Symbolic-or-Numerical-Understanding-Physics-Problem-Solving-in-Reasoning-LLMs" class="headerlink" title="Symbolic or Numerical? Understanding Physics Problem Solving in   Reasoning LLMs"></a>Symbolic or Numerical? Understanding Physics Problem Solving in   Reasoning LLMs</h2><p><strong>Authors:Nifu Dan, Yujun Cai, Yiwei Wang</strong></p>
<p>Navigating the complexities of physics reasoning has long been a difficult task for Large Language Models (LLMs), requiring a synthesis of profound conceptual understanding and adept problem-solving techniques. In this study, we investigate the application of advanced instruction-tuned reasoning models, such as Deepseek-R1, to address a diverse spectrum of physics problems curated from the challenging SciBench benchmark. Our comprehensive experimental evaluation reveals the remarkable capabilities of reasoning models. Not only do they achieve state-of-the-art accuracy in answering intricate physics questions, but they also generate distinctive reasoning patterns that emphasize on symbolic derivation. Furthermore, our findings indicate that even for these highly sophisticated reasoning models, the strategic incorporation of few-shot prompting can still yield measurable improvements in overall accuracy, highlighting the potential for continued performance gains. </p>
<blockquote>
<p>长期以来，对于大型语言模型（LLM）来说，应对复杂的物理推理是一项艰巨的任务，它要求有深刻的概念理解和熟练的问题解决技巧的综合应用。在这项研究中，我们研究了先进指令调优推理模型（如Deepseek-R1）在应对从具有挑战性的SciBench基准测试中精选出的各种物理问题时的应用。我们的综合实验评估展示了推理模型的卓越能力。这些模型不仅在回答复杂物理问题时达到了最先进的准确性，而且产生了强调符号推导的独特推理模式。此外，我们的研究还发现，即使是对于这些高度复杂的推理模型，通过战略性地融入少量提示（few-shot prompting），仍然可以提高总体准确性，这突显了未来性能提升的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.01334v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本研究探讨了先进的指令调优推理模型（如Deepseek-R1）在解决一系列来自SciBench基准测试的物理问题时的应用。实验表明，这些模型不仅在回答复杂物理问题方面达到了最新技术水平，还展现出独特的强调符号推导的推理模式。此外，研究还发现，即使是这些高度复杂的推理模型，通过战略性地引入少量提示，仍可实现总体准确性的显著提高，显示出潜在的性能提升空间。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>先进的指令调优推理模型在解决物理问题方面表现出卓越的能力。</li>
<li>这些模型能够通过符号推导来强调独特的推理模式。</li>
<li>在高度复杂的推理模型中，通过引入少量提示，可以显著提高总体准确性。</li>
<li>这些模型在回答复杂物理问题时达到了最新技术水平。</li>
<li>研究表明，持续的性能提升具有潜在可能性。</li>
<li>Deepseek-R1等模型在物理问题解答方面具有广泛应用前景。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.01334">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-aab02320fa33366802e367f7a5388eef.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-43ee0b3af7d989529f628567f903df25.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-372b906d2927d0b416cf3711220ee157.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bce1c83d5c44a0ac7c57117747866cef.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-39a106965c2a43254c57b5354cd250ca.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Task-Adapter-Task-specific-Adaptation-with-Order-aware-Alignment-for-Few-shot-Action-Recognition"><a href="#Task-Adapter-Task-specific-Adaptation-with-Order-aware-Alignment-for-Few-shot-Action-Recognition" class="headerlink" title="Task-Adapter++: Task-specific Adaptation with Order-aware Alignment for   Few-shot Action Recognition"></a>Task-Adapter++: Task-specific Adaptation with Order-aware Alignment for   Few-shot Action Recognition</h2><p><strong>Authors:Congqi Cao, Peiheng Han, Yueran zhang, Yating Yu, Qinyi Lv, Lingtong Min, Yanning zhang</strong></p>
<p>Large-scale pre-trained models have achieved remarkable success in language and image tasks, leading an increasing number of studies to explore the application of pre-trained image models, such as CLIP, in the domain of few-shot action recognition (FSAR). However, current methods generally suffer from several problems: 1) Direct fine-tuning often undermines the generalization capability of the pre-trained model; 2) The exploration of task-specific information is insufficient in the visual tasks; 3) The semantic order information is typically overlooked during text modeling; 4) Existing cross-modal alignment techniques ignore the temporal coupling of multimodal information. To address these, we propose Task-Adapter++, a parameter-efficient dual adaptation method for both image and text encoders. Specifically, to make full use of the variations across different few-shot learning tasks, we design a task-specific adaptation for the image encoder so that the most discriminative information can be well noticed during feature extraction. Furthermore, we leverage large language models (LLMs) to generate detailed sequential sub-action descriptions for each action class, and introduce semantic order adapters into the text encoder to effectively model the sequential relationships between these sub-actions. Finally, we develop an innovative fine-grained cross-modal alignment strategy that actively maps visual features to reside in the same temporal stage as semantic descriptions. Extensive experiments fully demonstrate the effectiveness and superiority of the proposed method, which achieves state-of-the-art performance on 5 benchmarks consistently. The code is open-sourced at <a target="_blank" rel="noopener" href="https://github.com/Jaulin-Bage/Task-Adapter-pp">https://github.com/Jaulin-Bage/Task-Adapter-pp</a>. </p>
<blockquote>
<p>大规模预训练模型在语言和图像任务中取得了显著的成功，引发越来越多的研究探索预训练图像模型，如CLIP，在少样本动作识别（FSAR）领域的应用。然而，当前的方法普遍存在以下问题：1）直接微调往往会削弱预训练模型的泛化能力；2）视觉任务中特定任务信息的探索不足；3）文本建模时通常忽略了语义顺序信息；4）现有的跨模态对齐技术忽略了多模态信息的时序耦合。为了解决这些问题，我们提出了Task-Adapter++，这是一种参数高效的图像和文本编码器的双重适应方法。具体来说，为了充分利用不同少样本学习任务之间的差异，我们为图像编码器设计了特定任务的适应方法，以便在特征提取过程中充分注意到最具区分性的信息。此外，我们利用大型语言模型（LLM）为每个动作类别生成详细的序列子动作描述，并在文本编码器中引入语义顺序适配器，以有效地建模这些子动作之间的序列关系。最后，我们开发了一种创新的精细跨模态对齐策略，该策略能够主动将视觉特征映射到与语义描述相同的时序阶段。大量的实验充分证明了所提方法的有效性和优越性，该方法在5个基准测试上均达到了最新性能水平。代码已开源在<a target="_blank" rel="noopener" href="https://github.com/Jaulin-Bage/Task-Adapter-pp">https://github.com/Jaulin-Bage/Task-Adapter-pp</a>。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.06002v2">PDF</a> extended work of Task-Adapter</p>
<p><strong>Summary</strong></p>
<p>大规模预训练模型在语言和图像任务中取得了显著的成功，引发了对预训练图像模型如CLIP在少镜头动作识别（FSAR）领域应用的探索。针对现有方法存在的问题，如直接微调影响模型泛化能力、视觉任务中特定信息探索不足、文本建模时忽略语义顺序信息以及跨模态对齐技术忽略多模态信息的时序耦合等，我们提出了Task-Adapter++，一种参数高效的图像和文本编码器的双重适应方法。该方法通过设计任务特定适应的图像编码器，利用大型语言模型生成每个动作类的详细序列子动作描述，并在文本编码器中引入语义顺序适配器，有效建模这些子动作之间的序列关系。此外，我们开发了一种创新的精细跨模态对齐策略，积极将视觉特征映射到与语义描述相同的时序阶段。该方法在五个基准测试上均达到了最先进的性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大规模预训练模型在语言和图像任务中表现出色，推动了少镜头动作识别（FSAR）领域的研究。</li>
<li>当前方法存在直接微调影响模型泛化能力、视觉任务中特定信息探索不足等问题。</li>
<li>Task-Adapter++是一种参数高效的图像和文本编码器的双重适应方法，旨在解决这些问题。</li>
<li>该方法利用大型语言模型生成每个动作类的详细序列子动作描述。</li>
<li>Task-Adapter++引入了语义顺序适配器，以有效建模子动作之间的序列关系。</li>
<li>开发了一种创新的精细跨模态对齐策略，实现视觉特征和语义描述的积极映射。</li>
<li>该方法在五个基准测试上均达到了最先进的性能，并公开了代码。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.06002">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-10d24c654ab7d340c690cc0ca71a9070.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f3da678737c6977821609635c7d33144.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Optimal-strategies-to-perform-multilingual-analysis-of-social-content-for-a-novel-dataset-in-the-tourism-domain"><a href="#Optimal-strategies-to-perform-multilingual-analysis-of-social-content-for-a-novel-dataset-in-the-tourism-domain" class="headerlink" title="Optimal strategies to perform multilingual analysis of social content   for a novel dataset in the tourism domain"></a>Optimal strategies to perform multilingual analysis of social content   for a novel dataset in the tourism domain</h2><p><strong>Authors:Maxime Masson, Rodrigo Agerri, Christian Sallaberry, Marie-Noelle Bessagnet, Annig Le Parc Lacayrelle, Philippe Roose</strong></p>
<p>The rising influence of social media platforms in various domains, including tourism, has highlighted the growing need for efficient and automated Natural Language Processing (NLP) strategies to take advantage of this valuable resource. However, the transformation of multilingual, unstructured, and informal texts into structured knowledge still poses significant challenges, most notably the never-ending requirement for manually annotated data to train deep learning classifiers. In this work, we study different NLP techniques to establish the best ones to obtain competitive performances while keeping the need for training annotated data to a minimum. To do so, we built the first publicly available multilingual dataset (French, English, and Spanish) for the tourism domain, composed of tourism-related tweets. The dataset includes multilayered, manually revised annotations for Named Entity Recognition (NER) for Locations and Fine-grained Thematic Concepts Extraction mapped to the Thesaurus of Tourism and Leisure Activities of the World Tourism Organization, as well as for Sentiment Analysis at the tweet level. Extensive experimentation comparing various few-shot and fine-tuning techniques with modern language models demonstrate that modern few-shot techniques allow us to obtain competitive results for all three tasks with very little annotation data: 5 tweets per label (15 in total) for Sentiment Analysis, 30 tweets for Named Entity Recognition of Locations and 1K tweets annotated with fine-grained thematic concepts, a highly fine-grained sequence labeling task based on an inventory of 315 classes. We believe that our results, grounded in a novel dataset, pave the way for applying NLP to new domain-specific applications, reducing the need for manual annotations and circumventing the complexities of rule-based, ad-hoc solutions. </p>
<blockquote>
<p>随着社交媒体平台在包括旅游在内的各个领域影响力的不断提升，高效且自动化的自然语言处理（NLP）策略的需求也日益增长，以便充分利用这一宝贵资源。然而，将多语言、非结构化和非正式文本转化为结构化知识仍然面临重大挑战，其中最显著的是对用于训练深度学习分类器的手动注释数据的无止境需求。在这项工作中，我们研究了不同的NLP技术，以找出表现最佳的方案，同时尽量减少对训练注释数据的依赖。为此，我们构建了首个面向旅游领域的公开可用多语言数据集（包括法语、英语和西班牙语），数据集由旅游相关的推文组成。该数据集包含针对地点命名实体识别（NER）的分层手动修订注释，以及精细主题概念提取映射到世界旅游组织休闲活动词典的注释，还有推文级别的情感分析注释。通过广泛实验比较各种少样本和微调技术与现代语言模型，结果表明现代少样本技术只需很少量的注释数据即可在所有三项任务中获得具有竞争力的结果：情感分析仅需每标签5条推文（总计1s条），地点命名实体识别需要30条推文，而基于精细概念集的序列标注任务则需要精细粒度注释的1K条推文（共包含315个类别）。我们相信，基于新数据集的结果为将NLP应用于新的特定领域应用铺平了道路，减少了对手动注释的需求，避免了基于规则的临时解决方案的复杂性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.14727v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文研究了社交媒体平台在旅游等领域的影响日益突出背景下，如何利用高效的自然语言处理（NLP）策略实现旅游领域的多语种数据的有效利用。为了解决如何从多元、非结构化及非正式文本中提炼结构化知识的问题，研究建立了一个涵盖旅游相关的多元数据集，通过对比不同的NLP技术发现现代少数学习技巧只需极少的人工标注数据即可实现优秀的表现。本研究为将NLP应用于新的领域特定应用提供了可能，减少了人工标注的需求，避免了基于规则和临时解决方案的复杂性。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>社会媒体平台对旅游等领域的影响力增长，凸显了需要有效的自然语言处理策略。</li>
<li>当前从多语种、非结构化及非正式文本中转化结构知识是一大挑战。</li>
<li>研究建立了首个针对旅游领域的多语种数据集，包含地点命名实体识别、精细主题概念提取和情绪分析。</li>
<li>利用现代少数学习技巧在极少人工标注数据下取得出色的表现。如情感分析仅需要五个标注数据点，地点命名实体识别需要三十个标注数据点，精细主题概念提取则需要一千个标注数据点。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2311.14727">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-a65a63d021aebea2fa1323909b75a8c5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a5d153d9526a14a05888fa8f1c03d92a.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-05/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-05/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-05/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-09e5dbbb28ce4e1cda02f246b4384498.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation 方向最新论文已更新，请持续关注 Update in 2025-07-05  Unsupervised Cardiac Video Translation Via Motion Feature Guided   Diffusion Model
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-05/Agent/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-a70bb736c160c30d6ef975b026e1bd2c.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent 方向最新论文已更新，请持续关注 Update in 2025-07-05  Establishing Best Practices for Building Rigorous Agentic Benchmarks
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">22950.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
