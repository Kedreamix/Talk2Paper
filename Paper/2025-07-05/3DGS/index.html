<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-05  HyperGaussians High-Dimensional Gaussian Splatting for High-Fidelity   Animatable Face Avatars">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-42bc17fa39ad06cd6cb26dab7c9fad37.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-17
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    15.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    63 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-07-05-æ›´æ–°"><a href="#2025-07-05-æ›´æ–°" class="headerlink" title="2025-07-05 æ›´æ–°"></a>2025-07-05 æ›´æ–°</h1><h2 id="HyperGaussians-High-Dimensional-Gaussian-Splatting-for-High-Fidelity-Animatable-Face-Avatars"><a href="#HyperGaussians-High-Dimensional-Gaussian-Splatting-for-High-Fidelity-Animatable-Face-Avatars" class="headerlink" title="HyperGaussians: High-Dimensional Gaussian Splatting for High-Fidelity   Animatable Face Avatars"></a>HyperGaussians: High-Dimensional Gaussian Splatting for High-Fidelity   Animatable Face Avatars</h2><p><strong>Authors:Gent Serifi, Marcel C. BÃ¼hler</strong></p>
<p>We introduce HyperGaussians, a novel extension of 3D Gaussian Splatting for high-quality animatable face avatars. Creating such detailed face avatars from videos is a challenging problem and has numerous applications in augmented and virtual reality. While tremendous successes have been achieved for static faces, animatable avatars from monocular videos still fall in the uncanny valley. The de facto standard, 3D Gaussian Splatting (3DGS), represents a face through a collection of 3D Gaussian primitives. 3DGS excels at rendering static faces, but the state-of-the-art still struggles with nonlinear deformations, complex lighting effects, and fine details. While most related works focus on predicting better Gaussian parameters from expression codes, we rethink the 3D Gaussian representation itself and how to make it more expressive. Our insights lead to a novel extension of 3D Gaussians to high-dimensional multivariate Gaussians, dubbed â€˜HyperGaussiansâ€™. The higher dimensionality increases expressivity through conditioning on a learnable local embedding. However, splatting HyperGaussians is computationally expensive because it requires inverting a high-dimensional covariance matrix. We solve this by reparameterizing the covariance matrix, dubbed the â€˜inverse covariance trickâ€™. This trick boosts the efficiency so that HyperGaussians can be seamlessly integrated into existing models. To demonstrate this, we plug in HyperGaussians into the state-of-the-art in fast monocular face avatars: FlashAvatar. Our evaluation on 19 subjects from 4 face datasets shows that HyperGaussians outperform 3DGS numerically and visually, particularly for high-frequency details like eyeglass frames, teeth, complex facial movements, and specular reflections. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†HyperGaussiansï¼Œè¿™æ˜¯3Dé«˜æ–¯è´´å›¾çš„ä¸€ç§æ–°å‹æ‰©å±•ï¼Œç”¨äºåˆ›å»ºé«˜è´¨é‡çš„å¯åŠ¨ç”»é¢éƒ¨åŒ–èº«ã€‚ä»è§†é¢‘ä¸­åˆ›å»ºå¦‚æ­¤è¯¦ç»†çš„é¢éƒ¨åŒ–èº«æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œå¹¶ä¸”åœ¨å¢å¼ºå’Œè™šæ‹Ÿç°å®ä¸­æœ‰è®¸å¤šåº”ç”¨ã€‚è™½ç„¶é™æ€é¢å­”å·²ç»å–å¾—äº†å·¨å¤§çš„æˆåŠŸï¼Œä½†ä»å•ç›®è§†é¢‘ä¸­åˆ›å»ºçš„å¯åŠ¨ç”»åŒ–èº«ä»ç„¶å¤„äºä¸çœŸå®ä¸çœŸå®ä¹‹é—´çš„å¢ƒåœ°ã€‚ç°è¡Œæ ‡å‡†3Dé«˜æ–¯è´´å›¾ï¼ˆ3DGSï¼‰é€šè¿‡ä¸€ç»„3Dé«˜æ–¯åŸå§‹æ•°æ®è¡¨ç¤ºé¢éƒ¨ã€‚3DGSåœ¨å‘ˆç°é™æ€é¢å­”æ–¹é¢éå¸¸å‡ºè‰²ï¼Œä½†æœ€æ–°æŠ€æœ¯ä»ç„¶éš¾ä»¥å¤„ç†éçº¿æ€§å˜å½¢ã€å¤æ‚çš„ç¯å…‰æ•ˆæœå’Œç²¾ç»†ç»†èŠ‚ã€‚å¤§å¤šæ•°ç›¸å…³ä½œå“éƒ½ä¸“æ³¨äºä»è¡¨æƒ…ä»£ç ä¸­é¢„æµ‹æ›´å¥½çš„é«˜æ–¯å‚æ•°ï¼Œè€Œæˆ‘ä»¬é‡æ–°æ€è€ƒäº†3Dé«˜æ–¯è¡¨ç¤ºæœ¬èº«ä»¥åŠå¦‚ä½•ä½¿å…¶æ›´å…·è¡¨ç°åŠ›ã€‚æˆ‘ä»¬çš„è§è§£å¯¼è‡´å°†3Dé«˜æ–¯æ‰©å±•åˆ°äº†é«˜ç»´å¤šå…ƒé«˜æ–¯ï¼Œç§°ä¸ºâ€œHyperGaussiansâ€ã€‚æ›´é«˜çš„ç»´åº¦é€šè¿‡ä»¥å¯å­¦ä¹ å±€éƒ¨åµŒå…¥ä¸ºæ¡ä»¶æ¥å¢åŠ è¡¨ç°åŠ›ã€‚ç„¶è€Œï¼Œç»˜åˆ¶HyperGaussiansçš„è®¡ç®—æˆæœ¬å¾ˆé«˜ï¼Œå› ä¸ºå®ƒéœ€è¦åè½¬é«˜ç»´åæ–¹å·®çŸ©é˜µã€‚æˆ‘ä»¬é€šè¿‡é‡æ–°å‚æ•°åŒ–åæ–¹å·®çŸ©é˜µè§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œç§°ä¸ºâ€œé€†åæ–¹å·®æŠ€å·§â€ã€‚è¿™ç§æŠ€å·§æé«˜äº†æ•ˆç‡ï¼Œä½¿å¾—HyperGaussianså¯ä»¥æ— ç¼åœ°é›†æˆåˆ°ç°æœ‰æ¨¡å‹ä¸­ã€‚ä¸ºäº†è¯æ˜è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°†HyperGaussiansæ’å…¥åˆ°ç°æœ‰å¿«é€Ÿå•ç›®é¢éƒ¨åŒ–èº«æŠ€æœ¯çš„æœ€æ–°æˆæœä¸­ï¼šFlashAvatarã€‚æˆ‘ä»¬å¯¹æ¥è‡ªå››ä¸ªé¢éƒ¨æ•°æ®é›†çš„19ä¸ªä¸»é¢˜è¿›è¡Œçš„è¯„ä¼°è¡¨æ˜ï¼ŒHyperGaussiansåœ¨æ•°å€¼å’Œè§†è§‰ä¸Šå‡ä¼˜äº3DGSï¼Œå°¤å…¶æ˜¯åœ¨çœ¼é•œæ¡†ã€ç‰™é½¿ã€å¤æ‚é¢éƒ¨è¿åŠ¨å’Œé•œé¢åå°„ç­‰é«˜é¢‘ç»†èŠ‚æ–¹é¢ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02803v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://gserifi.github.io/HyperGaussians">https://gserifi.github.io/HyperGaussians</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†HyperGaussiansï¼Œè¿™æ˜¯ä¸€ç§åŸºäºä¸‰ç»´é«˜æ–¯æ··è‰²çš„æ–°å‹æ‰©å±•æŠ€æœ¯ï¼Œç”¨äºåˆ›å»ºé«˜è´¨é‡çš„å¯åŠ¨ç”»é¢éƒ¨åŒ–èº«ã€‚è¯¥æŠ€æœ¯å¯¹äºä»è§†é¢‘åˆ›å»ºè¯¦ç»†çš„é¢éƒ¨åŒ–èº«å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œä½†åœ¨å¢å¼ºå’Œè™šæ‹Ÿç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›åº”ç”¨ã€‚å°½ç®¡é™æ€é¢éƒ¨æ¸²æŸ“å·²ç»å–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä½†ä»å•ç›®è§†é¢‘ä¸­åˆ›å»ºçš„å¯åŠ¨ç”»åŒ–èº«ä»ç„¶åœ¨â€œå°´å°¬ä¹‹è°·â€é˜¶æ®µã€‚æœ¬æ–‡æå‡ºçš„HyperGaussiansé€šè¿‡å¼•å…¥é«˜ç»´å¤šå…ƒé«˜æ–¯åˆ†å¸ƒï¼Œæ‰©å±•äº†ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºæ³•ï¼Œæé«˜äº†å…¶è¡¨ç°åŠ›ã€‚åŒæ—¶ï¼Œä¸ºè§£å†³æ··è‰²HyperGaussiansæ‰€éœ€çš„é«˜ç»´åæ–¹å·®çŸ©é˜µè®¡ç®—æˆæœ¬è¾ƒé«˜çš„é—®é¢˜ï¼Œé‡‡ç”¨åæ–¹å·®çŸ©é˜µé‡æ–°å‚æ•°åŒ–çš„æ–¹æ³•ï¼ˆâ€œé€†åæ–¹å·®æŠ€å·§â€ï¼‰ï¼Œæé«˜äº†è®¡ç®—æ•ˆç‡ï¼Œä½¿HyperGaussiansèƒ½å¤Ÿæ— ç¼é›†æˆåˆ°ç°æœ‰æ¨¡å‹ä¸­ã€‚å°†HyperGaussiansåº”ç”¨äºå½“å‰å…ˆè¿›çš„å¿«é€Ÿå•ç›®é¢éƒ¨åŒ–èº«æŠ€æœ¯FlashAvatarä¸­ï¼Œå¯¹å››ä¸ªé¢éƒ¨æ•°æ®é›†çš„19åä¸»ä½“çš„è¯„ä¼°æ˜¾ç¤ºï¼ŒHyperGaussiansåœ¨æ•°å€¼å’Œè§†è§‰ä¸Šå‡ä¼˜äºä¸‰ç»´é«˜æ–¯æ··è‰²æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨çœ¼é•œæ¡†ã€ç‰™é½¿ã€å¤æ‚é¢éƒ¨åŠ¨ä½œå’Œé•œé¢åå°„ç­‰é«˜é¢‘ç»†èŠ‚æ–¹é¢è¡¨ç°æ›´å‡ºè‰²ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ä»‹ç»äº†ä¸€ç§æ–°å‹æŠ€æœ¯HyperGaussiansï¼Œè¯¥æŠ€æœ¯æ‰©å±•äº†ä¸‰ç»´é«˜æ–¯æ··è‰²æŠ€æœ¯ä»¥åˆ›å»ºæ›´è¯¦ç»†çš„å¯åŠ¨ç”»é¢éƒ¨åŒ–èº«ã€‚</li>
<li>HyperGaussiansé€šè¿‡å¼•å…¥é«˜ç»´å¤šå…ƒé«˜æ–¯åˆ†å¸ƒæé«˜äº†è¡¨ç°åŠ›ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è§£å†³HyperGaussiansæ··è‰²è®¡ç®—æˆæœ¬é«˜çš„æ–¹æ³•â€”â€”â€œé€†åæ–¹å·®æŠ€å·§â€ï¼Œæé«˜äº†è®¡ç®—æ•ˆç‡ã€‚</li>
<li>å°†HyperGaussiansé›†æˆåˆ°ç°æœ‰æ¨¡å‹ï¼ˆå¦‚FlashAvatarï¼‰ä¸­ï¼Œä»¥æ”¹è¿›é¢éƒ¨åŒ–èº«çš„è´¨é‡ã€‚</li>
<li>HyperGaussiansåœ¨å¤æ‚é¢éƒ¨åŠ¨ä½œå’Œé«˜é¢‘ç»†èŠ‚ï¼ˆå¦‚çœ¼é•œæ¡†å’Œç‰™é½¿ï¼‰çš„æ¸²æŸ“ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>å¯¹å¤šä¸ªæ•°æ®é›†è¿›è¡Œçš„è¯„ä¼°è¡¨æ˜ï¼ŒHyperGaussiansåœ¨æ•°å€¼å’Œè§†è§‰ä¸Šå‡ä¼˜äºç°æœ‰æŠ€æœ¯ï¼ˆå¦‚ä¸‰ç»´é«˜æ–¯æ··è‰²ï¼‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02803">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9e733f4b7900d962afc9d76566455a9d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4d08312a1c6545c4754165ab6ae10e45.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-49e2aeb6534ccdd9e43a4397170f7846.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c6729f068a39236f40a3778df8c91343.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-239841382d5b91846d0380efed18d723.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1d9fbe9edf3b53ba2b1d486dd22d7fa0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="ArtGS-3D-Gaussian-Splatting-for-Interactive-Visual-Physical-Modeling-and-Manipulation-of-Articulated-Objects"><a href="#ArtGS-3D-Gaussian-Splatting-for-Interactive-Visual-Physical-Modeling-and-Manipulation-of-Articulated-Objects" class="headerlink" title="ArtGS:3D Gaussian Splatting for Interactive Visual-Physical Modeling and   Manipulation of Articulated Objects"></a>ArtGS:3D Gaussian Splatting for Interactive Visual-Physical Modeling and   Manipulation of Articulated Objects</h2><p><strong>Authors:Qiaojun Yu, Xibin Yuan, Yu jiang, Junting Chen, Dongzhe Zheng, Ce Hao, Yang You, Yixing Chen, Yao Mu, Liu Liu, Cewu Lu</strong></p>
<p>Articulated object manipulation remains a critical challenge in robotics due to the complex kinematic constraints and the limited physical reasoning of existing methods. In this work, we introduce ArtGS, a novel framework that extends 3D Gaussian Splatting (3DGS) by integrating visual-physical modeling for articulated object understanding and interaction. ArtGS begins with multi-view RGB-D reconstruction, followed by reasoning with a vision-language model (VLM) to extract semantic and structural information, particularly the articulated bones. Through dynamic, differentiable 3DGS-based rendering, ArtGS optimizes the parameters of the articulated bones, ensuring physically consistent motion constraints and enhancing the manipulation policy. By leveraging dynamic Gaussian splatting, cross-embodiment adaptability, and closed-loop optimization, ArtGS establishes a new framework for efficient, scalable, and generalizable articulated object modeling and manipulation. Experiments conducted in both simulation and real-world environments demonstrate that ArtGS significantly outperforms previous methods in joint estimation accuracy and manipulation success rates across a variety of articulated objects. Additional images and videos are available on the project website: <a target="_blank" rel="noopener" href="https://sites.google.com/view/artgs/home">https://sites.google.com/view/artgs/home</a> </p>
<blockquote>
<p>å…³èŠ‚å¼å¯¹è±¡æ“ä½œä»ç„¶æ˜¯æœºå™¨äººæŠ€æœ¯ä¸­çš„ä¸€é¡¹å…³é”®æŒ‘æˆ˜ï¼Œå› ä¸ºå­˜åœ¨å¤æ‚çš„è¿åŠ¨å­¦çº¦æŸå’Œç°æœ‰æ–¹æ³•çš„ç‰©ç†æ¨ç†æœ‰é™ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ArtGSï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡æ•´åˆè§†è§‰ç‰©ç†å»ºæ¨¡æ¥æ‰©å±•ä¸‰ç»´é«˜æ–¯è´´ç‰‡æŠ€æœ¯ï¼ˆ3DGSï¼‰çš„æ–°å‹æ¡†æ¶ï¼Œç”¨äºå…³èŠ‚å¼å¯¹è±¡çš„ç†è§£å’Œäº¤äº’ã€‚ArtGSå§‹äºå¤šè§†è§’RGB-Dé‡å»ºï¼Œéšååˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è¿›è¡Œæ¨ç†ï¼Œä»¥æå–è¯­ä¹‰å’Œç»“æ„ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯å…³èŠ‚éª¨éª¼ã€‚é€šè¿‡åŸºäºåŠ¨æ€ã€å¯åŒºåˆ†3DGSçš„æ¸²æŸ“ï¼ŒArtGSä¼˜åŒ–äº†å…³èŠ‚éª¨éª¼çš„å‚æ•°ï¼Œç¡®ä¿ç‰©ç†ä¸€è‡´çš„åŠ¨æ€çº¦æŸï¼Œå¹¶å¢å¼ºäº†æ“ä½œç­–ç•¥ã€‚é€šè¿‡åˆ©ç”¨åŠ¨æ€é«˜æ–¯è´´ç‰‡æŠ€æœ¯ã€è·¨ä½“æ€é€‚åº”æ€§å’Œé—­ç¯ä¼˜åŒ–ï¼ŒArtGSå»ºç«‹äº†ä¸€ä¸ªé«˜æ•ˆã€å¯æ‰©å±•å’Œé€šç”¨çš„å…³èŠ‚å¼å¯¹è±¡å»ºæ¨¡å’Œæ“ä½œçš„æ–°æ¡†æ¶ã€‚åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸­æ‰€è¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒArtGSåœ¨å…³èŠ‚ä¼°è®¡å‡†ç¡®æ€§å’Œæ“ä½œæˆåŠŸç‡æ–¹é¢å¤§å¤§ä¼˜äºä»¥å‰çš„æ–¹æ³•ï¼Œé€‚ç”¨äºå„ç§å…³èŠ‚å¼å¯¹è±¡ã€‚æ›´å¤šå›¾ç‰‡å’Œè§†é¢‘å¯åœ¨é¡¹ç›®ç½‘ç«™æŸ¥çœ‹ï¼š<a target="_blank" rel="noopener" href="https://sites.google.com/view/artgs/home">https://sites.google.com/view/artgs/home</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02600v1">PDF</a> Accepted by IROS 2025</p>
<p><strong>Summary</strong><br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºArtGSçš„æ–°æ¡†æ¶ï¼Œé€šè¿‡é›†æˆè§†è§‰ç‰©ç†å»ºæ¨¡æ¥å®ç°å…³èŠ‚å¯åŠ¨å¯¹è±¡çš„æ“æ§å’Œäº¤äº’ï¼Œä½¿ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹æå–è¯­ä¹‰å’Œç»“æ„ä¿¡æ¯ï¼Œå¹¶åˆ©ç”¨åŠ¨æ€å¯å¾®åˆ†çš„3DGSæ¸²æŸ“æŠ€æœ¯ä¼˜åŒ–å…³èŠ‚å‚æ•°ï¼Œç¡®ä¿ç‰©ç†ä¸€è‡´æ€§è¿åŠ¨çº¦æŸï¼Œæé«˜äº†æ“æ§ç­–ç•¥ã€‚åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸­è¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒArtGSåœ¨å…³èŠ‚ä¼°è®¡å‡†ç¡®æ€§å’Œæ“æ§æˆåŠŸç‡æ–¹é¢æ˜¾è‘—ä¼˜äºå…ˆå‰çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ArtGSæ˜¯ä¸€ä¸ªåŸºäºè§†è§‰ç‰©ç†å»ºæ¨¡çš„æ¡†æ¶ï¼Œç”¨äºå…³èŠ‚å¯åŠ¨å¯¹è±¡çš„æ“æ§å’Œäº¤äº’ã€‚</li>
<li>åˆ©ç”¨å¤šè§†è§’RGB-Dé‡å»ºè¿›è¡Œåˆæ­¥å¯¹è±¡ç†è§£ã€‚</li>
<li>é€šè¿‡ç»“åˆè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰æå–è¯­ä¹‰å’Œç»“æ„ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯å…³èŠ‚éª¨ä¿¡æ¯ã€‚</li>
<li>ä½¿ç”¨åŠ¨æ€ã€å¯å¾®åˆ†çš„3DGSæ¸²æŸ“æŠ€æœ¯è¿›è¡Œå…³èŠ‚å‚æ•°ä¼˜åŒ–ã€‚</li>
<li>å¼•å…¥åŠ¨æ€é«˜æ–¯è’™ç‰ˆã€è·¨åµŒå…¥é€‚åº”æ€§å’Œé—­ç¯ä¼˜åŒ–æœºåˆ¶æå‡æ¡†æ¶æ•ˆç‡ã€‚</li>
<li>ArtGSåœ¨å…³èŠ‚ä¼°è®¡å‡†ç¡®æ€§å’Œæ“æ§æˆåŠŸç‡ä¸Šè¶…è¶Šå…ˆå‰æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02600">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-19306d84afdf2ad525578ded6641a000.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-82149cf648e10c65999d8b82245f0e70.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c09f202400fa5ea8ef8ff84ed9a0c7f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8522b2f228986f325a3f851f05808ac2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d503646dc1cadc42402b7d3d52481021.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Reconstructing-Close-Human-Interaction-with-Appearance-and-Proxemics-Reasoning"><a href="#Reconstructing-Close-Human-Interaction-with-Appearance-and-Proxemics-Reasoning" class="headerlink" title="Reconstructing Close Human Interaction with Appearance and Proxemics   Reasoning"></a>Reconstructing Close Human Interaction with Appearance and Proxemics   Reasoning</h2><p><strong>Authors:Buzhen Huang, Chen Li, Chongyang Xu, Dongyue Lu, Jinnan Chen, Yangang Wang, Gim Hee Lee</strong></p>
<p>Due to visual ambiguities and inter-person occlusions, existing human pose estimation methods cannot recover plausible close interactions from in-the-wild videos. Even state-of-the-art large foundation models~(\eg, SAM) cannot accurately distinguish human semantics in such challenging scenarios. In this work, we find that human appearance can provide a straightforward cue to address these obstacles. Based on this observation, we propose a dual-branch optimization framework to reconstruct accurate interactive motions with plausible body contacts constrained by human appearances, social proxemics, and physical laws. Specifically, we first train a diffusion model to learn the human proxemic behavior and pose prior knowledge. The trained network and two optimizable tensors are then incorporated into a dual-branch optimization framework to reconstruct human motions and appearances. Several constraints based on 3D Gaussians, 2D keypoints, and mesh penetrations are also designed to assist the optimization. With the proxemics prior and diverse constraints, our method is capable of estimating accurate interactions from in-the-wild videos captured in complex environments. We further build a dataset with pseudo ground-truth interaction annotations, which may promote future research on pose estimation and human behavior understanding. Experimental results on several benchmarks demonstrate that our method outperforms existing approaches. The code and data are available at <a target="_blank" rel="noopener" href="https://www.buzhenhuang.com/works/CloseApp.html">https://www.buzhenhuang.com/works/CloseApp.html</a>. </p>
<blockquote>
<p>ç”±äºè§†è§‰æ¨¡ç³Šå’Œäººä¸äººä¹‹é—´çš„ç›¸äº’é®æŒ¡ï¼Œç°æœ‰çš„äººä½“å§¿æ€ä¼°è®¡æ–¹æ³•æ— æ³•ä»é‡ç”Ÿè§†é¢‘ä¸­æ¢å¤å‡ºåˆç†çš„ç´§å¯†äº¤äº’ã€‚å³ä½¿æ˜¯æœ€å…ˆè¿›çš„å¤§å‹åŸºç¡€æ¨¡å‹ï¼ˆä¾‹å¦‚SAMï¼‰ä¹Ÿæ— æ³•åœ¨è¿™ç§å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸­å‡†ç¡®åŒºåˆ†äººä½“è¯­ä¹‰ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å‘ç°äººçš„å¤–è§‚å¯ä»¥æä¾›ä¸€ç§ç›´æ¥çš„çº¿ç´¢æ¥è§£å†³è¿™äº›éšœç¢ã€‚åŸºäºè¿™ä¸€è§‚å¯Ÿï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŒåˆ†æ”¯ä¼˜åŒ–æ¡†æ¶ï¼Œé€šè¿‡äººä½“å¤–è§‚ã€ç¤¾äº¤ç©ºé—´å­¦ï¼ˆproxemicsï¼‰å’Œç‰©ç†å®šå¾‹çš„çº¦æŸæ¥é‡å»ºå‡†ç¡®çš„äº¤äº’åŠ¨ä½œå’Œåˆç†çš„èº«ä½“æ¥è§¦ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆå¯¹æ‰©æ•£æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ äººç±»çš„ç©ºé—´è¡Œä¸ºå­¦å’Œå§¿æ€å…ˆéªŒçŸ¥è¯†ã€‚ç„¶åå°†è®­ç»ƒå¥½çš„ç½‘ç»œå’Œä¸¤ä¸ªå¯ä¼˜åŒ–çš„å¼ é‡çº³å…¥åŒåˆ†æ”¯ä¼˜åŒ–æ¡†æ¶ä¸­ï¼Œä»¥é‡å»ºäººä½“åŠ¨ä½œå’Œå¤–è§‚ã€‚è¿˜è®¾è®¡äº†åŸºäº3Dé«˜æ–¯åˆ†å¸ƒã€2Då…³é”®ç‚¹ä»¥åŠç½‘æ ¼ç©¿é€çš„å¤šç§çº¦æŸæ¥å¸®åŠ©ä¼˜åŒ–ã€‚å‡­å€Ÿç©ºé—´å­¦å…ˆéªŒçŸ¥è¯†å’Œå¤šæ ·åŒ–çš„çº¦æŸæ¡ä»¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿä»å¤æ‚ç¯å¢ƒä¸­æ•è·çš„é‡ç”Ÿè§†é¢‘ä¸­ä¼°è®¡å‡ºå‡†ç¡®çš„äººä½“äº¤äº’åŠ¨ä½œã€‚æˆ‘ä»¬è¿˜å»ºç«‹äº†ä¸€ä¸ªå¸¦æœ‰ä¼ªåœ°é¢çœŸå®äº¤äº’æ³¨é‡Šçš„æ•°æ®é›†ï¼Œè¿™å¯èƒ½æœ‰åŠ©äºæ¨åŠ¨æœªæ¥åœ¨å§¿æ€ä¼°è®¡å’Œäººç±»è¡Œä¸ºç†è§£æ–¹é¢çš„ç ”ç©¶ã€‚åœ¨å‡ ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://www.buzhenhuang.com/works/CloseApp.html%E6%89%BE%E5%88%B0%E3%80%82">https://www.buzhenhuang.com/works/CloseApp.htmlæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02565v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡é’ˆå¯¹äººç±»å§¿æ€ä¼°è®¡åœ¨å¤æ‚ç¯å¢ƒä¸­çš„éš¾ç‚¹è¿›è¡Œäº†æ·±å…¥ç ”ç©¶ï¼Œå‘ç°äººç±»å¤–è§‚æ˜¯çªç ´è¿™ä¸€é—®é¢˜çš„å…³é”®çº¿ç´¢ã€‚å› æ­¤æå‡ºä¸€ä¸ªåŸºäºäººä½“å¤–è§‚ã€ç¤¾äº¤è·ç¦»å’Œäººç±»è¡Œä¸ºçº¦æŸçš„åŒåˆ†æ”¯ä¼˜åŒ–æ¡†æ¶æ¥å‡†ç¡®é‡å»ºäººç±»è¿åŠ¨ã€‚ç»“åˆæ‰©æ•£æ¨¡å‹è¿›è¡Œå­¦ä¹ å’Œè®­ç»ƒç½‘ç»œï¼Œåœ¨æ¨¡æ‹Ÿä¸åŒå¤æ‚ç¯å¢ƒä¸‹çš„åœºæ™¯ï¼Œå¯ä»¥æœ‰æ•ˆåœ°ä¼°è®¡äººç±»äº¤äº’åŠ¨ä½œã€‚è¯¥ç ”ç©¶è¿˜å»ºç«‹äº†ä¸€ä¸ªåŒ…å«ä¼ªçœŸå®äº¤äº’æ³¨é‡Šçš„æ•°æ®é›†ï¼Œä¿ƒè¿›äº†å§¿æ€ä¼°è®¡å’Œäººç±»è¡Œä¸ºç†è§£çš„ç ”ç©¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰çš„äººç±»å§¿æ€ä¼°è®¡æ–¹æ³•åœ¨å¤„ç†å¤æ‚ç¯å¢ƒä¸­çš„ç´§å¯†äº¤äº’æ—¶å­˜åœ¨å›°éš¾ã€‚</li>
<li>äººç±»å¤–è§‚ä¿¡æ¯æ˜¯è§£å†³è¿™ä¸€é—®é¢˜çš„å…³é”®çº¿ç´¢ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºäººä½“å¤–è§‚ã€ç¤¾äº¤è·ç¦»å’Œäººç±»è¡Œä¸ºçº¦æŸçš„åŒåˆ†æ”¯ä¼˜åŒ–æ¡†æ¶æ¥é‡å»ºå‡†ç¡®çš„äººç±»è¿åŠ¨ã€‚</li>
<li>åˆ©ç”¨æ‰©æ•£æ¨¡å‹å­¦ä¹ äººç±»è¡Œä¸ºæ¨¡å¼å’Œå§¿æ€å…ˆéªŒçŸ¥è¯†ã€‚</li>
<li>é€šè¿‡å¤šç§çº¦æŸï¼ˆå¦‚3Dé«˜æ–¯åˆ†å¸ƒã€2Då…³é”®ç‚¹ã€ç½‘æ ¼ç©¿é€ç­‰ï¼‰è¾…åŠ©ä¼˜åŒ–è¿‡ç¨‹ã€‚</li>
<li>å»ºç«‹äº†ä¸€ä¸ªåŒ…å«ä¼ªçœŸå®äº¤äº’æ³¨é‡Šçš„æ•°æ®é›†ï¼Œæœ‰åŠ©äºæ¨åŠ¨å§¿æ€ä¼°è®¡å’Œäººç±»è¡Œä¸ºç†è§£çš„ç ”ç©¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02565">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-42bc17fa39ad06cd6cb26dab7c9fad37.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e13336ff5e3373bf1c2748676e1565ea.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d19eb1174d90cea03009525b6f1425fd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-77be3bfc211df6a2b17d27843b78e17d.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="AvatarMakeup-Realistic-Makeup-Transfer-for-3D-Animatable-Head-Avatars"><a href="#AvatarMakeup-Realistic-Makeup-Transfer-for-3D-Animatable-Head-Avatars" class="headerlink" title="AvatarMakeup: Realistic Makeup Transfer for 3D Animatable Head Avatars"></a>AvatarMakeup: Realistic Makeup Transfer for 3D Animatable Head Avatars</h2><p><strong>Authors:Yiming Zhong, Xiaolin Zhang, Ligang Liu, Yao Zhao, Yunchao Wei</strong></p>
<p>Similar to facial beautification in real life, 3D virtual avatars require personalized customization to enhance their visual appeal, yet this area remains insufficiently explored. Although current 3D Gaussian editing methods can be adapted for facial makeup purposes, these methods fail to meet the fundamental requirements for achieving realistic makeup effects: 1) ensuring a consistent appearance during drivable expressions, 2) preserving the identity throughout the makeup process, and 3) enabling precise control over fine details. To address these, we propose a specialized 3D makeup method named AvatarMakeup, leveraging a pretrained diffusion model to transfer makeup patterns from a single reference photo of any individual. We adopt a coarse-to-fine idea to first maintain the consistent appearance and identity, and then to refine the details. In particular, the diffusion model is employed to generate makeup images as supervision. Due to the uncertainties in diffusion process, the generated images are inconsistent across different viewpoints and expressions. Therefore, we propose a Coherent Duplication method to coarsely apply makeup to the target while ensuring consistency across dynamic and multiview effects. Coherent Duplication optimizes a global UV map by recoding the averaged facial attributes among the generated makeup images. By querying the global UV map, it easily synthesizes coherent makeup guidance from arbitrary views and expressions to optimize the target avatar. Given the coarse makeup avatar, we further enhance the makeup by incorporating a Refinement Module into the diffusion model to achieve high makeup quality. Experiments demonstrate that AvatarMakeup achieves state-of-the-art makeup transfer quality and consistency throughout animation. </p>
<blockquote>
<p>ç±»ä¼¼äºç°å®ç”Ÿæ´»ä¸­çš„é¢éƒ¨ç¾å®¹ï¼Œ3Dè™šæ‹Ÿè§’è‰²éœ€è¦ä¸ªæ€§åŒ–å®šåˆ¶ä»¥å¢å¼ºå…¶è§†è§‰å¸å¼•åŠ›ï¼Œä½†è¿™ä¸ªé¢†åŸŸä»ç„¶æ²¡æœ‰å¾—åˆ°è¶³å¤Ÿçš„æ¢ç´¢ã€‚å°½ç®¡å½“å‰çš„3Dé«˜æ–¯ç¼–è¾‘æ–¹æ³•å¯ä»¥é€‚åº”é¢éƒ¨åŒ–å¦†çš„ç›®çš„ï¼Œä½†è¿™äº›æ–¹æ³•æœªèƒ½æ»¡è¶³å®ç°çœŸå®åŒ–å¦†æ•ˆæœçš„åŸºæœ¬éœ€æ±‚ï¼š1ï¼‰åœ¨å¯é©±åŠ¨çš„è¡¨æƒ…ä¸­ç¡®ä¿ä¸€è‡´çš„å¤–è§‚ï¼Œ2ï¼‰åœ¨åŒ–å¦†è¿‡ç¨‹ä¸­ä¿ç•™èº«ä»½ç‰¹å¾ï¼Œä»¥åŠ3ï¼‰å¯¹ç»†èŠ‚è¿›è¡Œç²¾ç¡®æ§åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸“é—¨çš„3DåŒ–å¦†æ–¹æ³•ï¼Œåä¸ºAvatarMakeupï¼Œå®ƒåˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä»ä»»ä½•ä¸ªäººçš„å•å¼ å‚è€ƒç…§ç‰‡ä¸­è½¬ç§»åŒ–å¦†æ¨¡å¼ã€‚æˆ‘ä»¬é‡‡ç”¨ç”±ç²—åˆ°ç»†çš„ç†å¿µï¼Œé¦–å…ˆä¿æŒå¤–è§‚å’Œèº«ä»½çš„ä¸€è‡´æ€§ï¼Œç„¶åç»†åŒ–ç»†èŠ‚ã€‚ç‰¹åˆ«æ˜¯ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”ŸæˆåŒ–å¦†å›¾åƒä½œä¸ºç›‘ç£ã€‚ç”±äºæ‰©æ•£è¿‡ç¨‹ä¸­çš„ä¸ç¡®å®šæ€§ï¼Œç”Ÿæˆçš„å›¾åƒåœ¨ä¸åŒçš„è§†è§’å’Œè¡¨æƒ…ä¸Šå­˜åœ¨å·®å¼‚ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è¿è´¯å¤åˆ¶æ–¹æ³•ï¼Œå°†åŒ–å¦†ç²—ç•¥åœ°åº”ç”¨åˆ°ç›®æ ‡ä¸Šï¼ŒåŒæ—¶ç¡®ä¿åŠ¨æ€å’Œå¤šè§†è§’æ•ˆæœçš„ä¸€è‡´æ€§ã€‚è¿è´¯å¤åˆ¶é€šè¿‡é‡æ–°ç¼–ç ç”ŸæˆåŒ–å¦†å›¾åƒä¹‹é—´çš„å¹³å‡é¢éƒ¨å±æ€§æ¥ä¼˜åŒ–å…¨å±€UVæ˜ å°„ã€‚é€šè¿‡æŸ¥è¯¢å…¨å±€UVæ˜ å°„ï¼Œå®ƒå¾ˆå®¹æ˜“åˆæˆæ¥è‡ªä»»æ„è§†è§’å’Œè¡¨æƒ…çš„è¿è´¯åŒ–å¦†æŒ‡å¯¼ï¼Œä»¥ä¼˜åŒ–ç›®æ ‡è§’è‰²ã€‚ç»™å®šç²—ç•¥çš„åŒ–å¦†è§’è‰²ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡å°†ç»†åŒ–æ¨¡å—èå…¥åˆ°æ‰©æ•£æ¨¡å‹ä¸­ï¼Œä»¥æé«˜åŒ–å¦†å“è´¨é‡ã€‚å®éªŒè¡¨æ˜ï¼ŒAvatarMakeupåœ¨åŠ¨ç”»è¿‡ç¨‹ä¸­å®ç°äº†å…ˆè¿›çš„åŒ–å¦†è½¬ç§»è´¨é‡å’Œä¸€è‡´æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02419v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºAvatarMakeupçš„3Dè™šæ‹Ÿè§’è‰²åŒ–å¦†æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä»å•ä¸€å‚è€ƒç…§ç‰‡è½¬ç§»å¦†å®¹ã€‚é‡‡ç”¨ç”±ç²—åˆ°ç»†çš„ç­–ç•¥ï¼Œå…ˆä¿æŒå¤–è§‚å’Œèº«ä»½çš„è¿ç»­æ€§ï¼Œå†ç»†åŒ–ç»†èŠ‚ã€‚ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¦†å®¹å›¾åƒä½œä¸ºç›‘ç£ï¼Œå¹¶æå‡ºCoherent Duplicationæ–¹æ³•ç¡®ä¿åŠ¨æ€å’Œå¤šè§†è§’ä¸‹çš„å¦†å®¹ä¸€è‡´æ€§ã€‚é€šè¿‡ä¼˜åŒ–å…¨å±€UVæ˜ å°„ï¼Œåˆæˆä»»æ„è§†è§’å’Œè¡¨æƒ…ä¸‹çš„è¿è´¯å¦†å®¹æŒ‡å¯¼ã€‚è¿›ä¸€æ­¥é€šè¿‡å¼•å…¥ç»†åŒ–æ¨¡å—æå‡å¦†å®¹è´¨é‡ã€‚å®éªŒè¡¨æ˜ï¼ŒAvatarMakeupåœ¨åŒ–å¦†è½¬ç§»è´¨é‡å’ŒåŠ¨ç”»ä¸€è‡´æ€§æ–¹é¢è¾¾åˆ°é¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3Dè™šæ‹Ÿè§’è‰²éœ€è¦ä¸ªæ€§åŒ–å®šåˆ¶ä»¥å¢å¼ºå…¶è§†è§‰å¸å¼•åŠ›ï¼Œä½†å½“å‰æ–¹æ³•æ— æ³•æ»¡è¶³çœŸå®å¦†å®¹æ•ˆæœçš„è¦æ±‚ã€‚</li>
<li>æå‡ºäº†AvatarMakeupæ–¹æ³•ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä»å•ä¸€å‚è€ƒç…§ç‰‡è½¬ç§»å¦†å®¹ã€‚</li>
<li>é‡‡ç”¨ç”±ç²—åˆ°ç»†çš„ç­–ç•¥ï¼Œå…ˆä¿è¯å¤–è§‚å’Œèº«ä»½çš„è¿ç»­æ€§ï¼Œå†ç»†åŒ–ç»†èŠ‚ã€‚</li>
<li>ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¦†å®¹å›¾åƒä½œä¸ºç›‘ç£ï¼Œä½†å­˜åœ¨ä¸ç¡®å®šæ€§é—®é¢˜ã€‚</li>
<li>æå‡ºCoherent Duplicationæ–¹æ³•ï¼Œä¼˜åŒ–å…¨å±€UVæ˜ å°„ï¼Œç¡®ä¿åŠ¨æ€å’Œå¤šè§†è§’ä¸‹çš„å¦†å®¹ä¸€è‡´æ€§ã€‚</li>
<li>å¼•å…¥ç»†åŒ–æ¨¡å—æå‡å¦†å®¹è´¨é‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02419">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-bc87e0924f6be6ebe0fd48bebca87ff2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d7aa1481255c0157df1d6ec2b1ba125f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-66fda79a028a957be39888e65417c685.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e8a6e4afb0f824163399f06eff68027c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8163a2160dd5abd48450c8e3796778c3.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="LocalDyGS-Multi-view-Global-Dynamic-Scene-Modeling-via-Adaptive-Local-Implicit-Feature-Decoupling"><a href="#LocalDyGS-Multi-view-Global-Dynamic-Scene-Modeling-via-Adaptive-Local-Implicit-Feature-Decoupling" class="headerlink" title="LocalDyGS: Multi-view Global Dynamic Scene Modeling via Adaptive Local   Implicit Feature Decoupling"></a>LocalDyGS: Multi-view Global Dynamic Scene Modeling via Adaptive Local   Implicit Feature Decoupling</h2><p><strong>Authors:Jiahao Wu, Rui Peng, Jianbo Jiao, Jiayu Yang, Luyang Tang, Kaiqiang Xiong, Jie Liang, Jinbo Yan, Runling Liu, Ronggang Wang</strong></p>
<p>Due to the complex and highly dynamic motions in the real world, synthesizing dynamic videos from multi-view inputs for arbitrary viewpoints is challenging. Previous works based on neural radiance field or 3D Gaussian splatting are limited to modeling fine-scale motion, greatly restricting their application. In this paper, we introduce LocalDyGS, which consists of two parts to adapt our method to both large-scale and fine-scale motion scenes: 1) We decompose a complex dynamic scene into streamlined local spaces defined by seeds, enabling global modeling by capturing motion within each local space. 2) We decouple static and dynamic features for local space motion modeling. A static feature shared across time steps captures static information, while a dynamic residual field provides time-specific features. These are combined and decoded to generate Temporal Gaussians, modeling motion within each local space. As a result, we propose a novel dynamic scene reconstruction framework to model highly dynamic real-world scenes more realistically. Our method not only demonstrates competitive performance on various fine-scale datasets compared to state-of-the-art (SOTA) methods, but also represents the first attempt to model larger and more complex highly dynamic scenes. Project page: <a target="_blank" rel="noopener" href="https://wujh2001.github.io/LocalDyGS/">https://wujh2001.github.io/LocalDyGS/</a>. </p>
<blockquote>
<p>ç”±äºç°å®ä¸–ç•Œä¸­å¤æ‚ä¸”é«˜åº¦åŠ¨æ€çš„åŠ¨æ€ï¼Œä»å¤šè§†è§’è¾“å…¥åˆæˆä»»æ„è§†è§’çš„åŠ¨æ€è§†é¢‘æ˜¯ä¸€é¡¹æŒ‘æˆ˜ã€‚ä¹‹å‰åŸºäºç¥ç»è¾å°„åœºæˆ–3Dé«˜æ–¯è´´å›¾çš„å·¥ä½œä»…é™äºå¯¹ç²¾ç»†åŠ¨ä½œçš„å»ºæ¨¡ï¼Œæå¤§åœ°é™åˆ¶äº†å…¶åº”ç”¨ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†LocalDyGSï¼Œå®ƒç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼Œä½¿æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿé€‚åº”å¤§è§„æ¨¡å’Œç²¾ç»†åŠ¨ä½œçš„åœºæ™¯ï¼š1ï¼‰æˆ‘ä»¬å°†å¤æ‚çš„åŠ¨æ€åœºæ™¯åˆ†è§£ä¸ºç”±ç§å­å®šä¹‰çš„æµçº¿å‹å±€éƒ¨ç©ºé—´ï¼Œé€šè¿‡æ•æ‰æ¯ä¸ªå±€éƒ¨ç©ºé—´å†…çš„è¿åŠ¨æ¥è¿›è¡Œå…¨å±€å»ºæ¨¡ã€‚2ï¼‰æˆ‘ä»¬å°†é™æ€å’ŒåŠ¨æ€ç‰¹å¾è§£è€¦ï¼Œç”¨äºå±€éƒ¨ç©ºé—´è¿åŠ¨å»ºæ¨¡ã€‚ä¸€ä¸ªè·¨æ—¶é—´æ­¥å…±äº«çš„é™æ€ç‰¹å¾æ•æ‰é™æ€ä¿¡æ¯ï¼Œè€Œä¸€ä¸ªåŠ¨æ€æ®‹å·®åœºæä¾›ç‰¹å®šæ—¶é—´çš„ç‰¹å¾ã€‚è¿™äº›ç‰¹å¾ç›¸ç»“åˆå¹¶è§£ç ï¼Œç”Ÿæˆæ—¶åºé«˜æ–¯ï¼Œæ¨¡æ‹Ÿæ¯ä¸ªå±€éƒ¨ç©ºé—´å†…çš„è¿åŠ¨ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„åŠ¨æ€åœºæ™¯é‡å»ºæ¡†æ¶ï¼Œä»¥æ›´çœŸå®çš„æ–¹å¼å¯¹é«˜åº¦åŠ¨æ€çš„ç°å®ä¸–ç•Œåœºæ™¯è¿›è¡Œå»ºæ¨¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…åœ¨å„ç§ç²¾ç»†æ•°æ®é›†ä¸Šå±•ç°å‡ºä¸æœ€æ–°æŠ€æœ¯ç›¸ç«äº‰çš„æ€§èƒ½ï¼Œè€Œä¸”è¿˜é¦–æ¬¡å°è¯•å¯¹æ›´å¤§ã€æ›´å¤æ‚çš„åŠ¨æ€åœºæ™¯è¿›è¡Œå»ºæ¨¡ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://wujh2001.github.io/LocalDyGS/%E3%80%82">https://wujh2001.github.io/LocalDyGS/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02363v1">PDF</a> Accepted by ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºLocalDyGSçš„æ–°æ–¹æ³•ï¼Œç”¨äºåˆæˆåŠ¨æ€è§†é¢‘ã€‚è¯¥æ–¹æ³•é€šè¿‡åˆ†è§£å¤æ‚åŠ¨æ€åœºæ™¯ã€è§£æ„é™æ€ä¸åŠ¨æ€ç‰¹å¾ï¼Œå»ºç«‹å±€éƒ¨ç©ºé—´è¿åŠ¨æ¨¡å‹ï¼Œä»¥åº”å¯¹çœŸå®ä¸–ç•Œä¸­å¤æ‚ä¸”é«˜åº¦åŠ¨æ€çš„è¿åŠ¨ã€‚æ­¤æ¡†æ¶ä¸ä»…åœ¨ç²¾ç»†å°ºåº¦æ•°æ®é›†ä¸Šè¡¨ç°å“è¶Šï¼Œæ›´æ˜¯é¦–æ¬¡å°è¯•æ¨¡æ‹Ÿæ›´å¤§ã€æ›´å¤æ‚çš„åœºæ™¯è¿åŠ¨ã€‚è¯¦æƒ…è¯·å‚è§é¡¹ç›®ç½‘é¡µã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LocalDyGSæ–¹æ³•èƒ½å¤„ç†çœŸå®ä¸–ç•Œä¸­çš„å¤æ‚ä¸”é«˜åº¦åŠ¨æ€çš„è¿åŠ¨åœºæ™¯ã€‚</li>
<li>æ–¹æ³•é€šè¿‡åˆ†è§£å¤æ‚åŠ¨æ€åœºæ™¯åˆ°å±€éƒ¨ç©ºé—´è¿›è¡Œå»ºæ¨¡ï¼Œä»¥åº”å¯¹å¤§è§„æ¨¡è¿åŠ¨åœºæ™¯ã€‚</li>
<li>é™æ€å’ŒåŠ¨æ€ç‰¹å¾è¢«è§£è€¦ï¼Œä»¥ä¾¿æ›´å‡†ç¡®åœ°æ•æ‰å±€éƒ¨ç©ºé—´çš„è¿åŠ¨ç‰¹æ€§ã€‚</li>
<li>é€šè¿‡ç»“åˆé™æ€ç‰¹å¾å’ŒåŠ¨æ€æ®‹å·®åœºï¼Œç”Ÿæˆæ—¶é—´é«˜æ–¯æ¨¡å‹ï¼Œä»¥æ¨¡æ‹Ÿå±€éƒ¨ç©ºé—´çš„è¿åŠ¨ã€‚</li>
<li>LocalDyGSä¸ä»…åœ¨ç²¾ç»†å°ºåº¦æ•°æ®é›†ä¸Šçš„æ€§èƒ½å…·æœ‰ç«äº‰åŠ›ï¼Œè€Œä¸”èƒ½å¤Ÿæ¨¡æ‹Ÿæ›´å¤§ã€æ›´å¤æ‚çš„åœºæ™¯è¿åŠ¨ã€‚</li>
<li>é¡¹ç›®ç½‘é¡µæä¾›äº†æ›´å¤šå…³äºLocalDyGSæ–¹æ³•çš„è¯¦ç»†ä¿¡æ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02363">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3081ecf13671adcdfd22f22fbcf9e856.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2c08eecf660c741dd5021cf74a99305.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f1e303bb91bdef2ea5454b3c8f4a05bb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b89ee60a50eaa45e72e6e5ed7faf2fd6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8d44c5724d9804024e315f6126094b53.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Gbake-Baking-3D-Gaussian-Splats-into-Reflection-Probes"><a href="#Gbake-Baking-3D-Gaussian-Splats-into-Reflection-Probes" class="headerlink" title="Gbake: Baking 3D Gaussian Splats into Reflection Probes"></a>Gbake: Baking 3D Gaussian Splats into Reflection Probes</h2><p><strong>Authors:Stephen Pasch, Joel K. Salzman, Changxi Zheng</strong></p>
<p>The growing popularity of 3D Gaussian Splatting has created the need to integrate traditional computer graphics techniques and assets in splatted environments. Since 3D Gaussian primitives encode lighting and geometry jointly as appearance, meshes are relit improperly when inserted directly in a mixture of 3D Gaussians and thus appear noticeably out of place. We introduce GBake, a specialized tool for baking reflection probes from Gaussian-splatted scenes that enables realistic reflection mapping of traditional 3D meshes in the Unity game engine. </p>
<blockquote>
<p>éšç€ä¸‰ç»´é«˜æ–¯æ··åˆæŠ€æœ¯çš„æ—¥ç›Šæ™®åŠï¼Œéœ€è¦åœ¨æ··åˆç¯å¢ƒä¸­é›†æˆä¼ ç»Ÿçš„è®¡ç®—æœºå›¾å½¢æŠ€æœ¯å’Œèµ„æºã€‚ç”±äºä¸‰ç»´é«˜æ–¯åŸºæœ¬ä½“å°†å…‰ç…§å’Œå‡ ä½•ç»“æ„å…±åŒç¼–ç ä¸ºå¤–è§‚ï¼Œå› æ­¤å½“ç›´æ¥æ’å…¥æ··åˆçš„ä¸‰ç»´é«˜æ–¯ä¸­æ—¶ï¼Œç½‘æ ¼ä¼šé‡æ–°ç…§æ˜ä¸å½“ï¼Œä»è€Œæ˜¾å¾—æ ¼æ ¼ä¸å…¥ã€‚æˆ‘ä»¬å¼•å…¥äº†GBakeï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºä»é«˜æ–¯æ··åˆåœºæ™¯ä¸­çƒ˜ç„™åå°„æ¢é’ˆçš„ä¸“ç”¨å·¥å…·ï¼Œå®ƒèƒ½å¤Ÿåœ¨Unityæ¸¸æˆå¼•æ“ä¸­å®ç°ä¼ ç»Ÿä¸‰ç»´ç½‘æ ¼çš„çœŸå®åå°„æ˜ å°„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02257v1">PDF</a> SIGGRAPH 2025 Posters</p>
<p><strong>Summary</strong></p>
<p>éšç€ä¸‰ç»´é«˜æ–¯æ··åˆæŠ€æœ¯çš„æ™®åŠï¼Œéœ€è¦å°†ä¼ ç»Ÿè®¡ç®—æœºå›¾å½¢æŠ€æœ¯èµ„äº§èå…¥æ··åˆç¯å¢ƒã€‚ç”±äºé«˜æ–¯åŸå§‹æ•°æ®åŒæ—¶ç¼–ç å…‰ç…§å’Œå‡ ä½•å¤–è§‚ï¼Œç›´æ¥æ’å…¥æ··åˆé«˜æ–¯ä¸­çš„ç½‘æ ¼ä¼šé‡æ–°ç…§æ˜ä¸å½“ï¼Œå¯¼è‡´çªå…€æ„Ÿã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†GBakeå·¥å…·ï¼Œå®ƒèƒ½ä»é«˜æ–¯æ··åˆåœºæ™¯ä¸­çƒ˜ç„™åå°„æ¢é’ˆï¼Œå®ç°åœ¨Unityæ¸¸æˆå¼•æ“ä¸­ä¼ ç»Ÿä¸‰ç»´ç½‘æ ¼çš„çœŸå®åå°„æ˜ å°„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸‰ç»´é«˜æ–¯æ··åˆæŠ€æœ¯çš„æ™®åŠå¸¦æ¥äº†å¯¹ä¼ ç»Ÿè®¡ç®—æœºå›¾å½¢æŠ€æœ¯èµ„äº§æ•´åˆçš„éœ€æ±‚ã€‚</li>
<li>3D Gaussian primitivesè”åˆç¼–ç å…‰ç…§å’Œå‡ ä½•å¤–è§‚ï¼Œå¯¼è‡´ç›´æ¥æ’å…¥æ··åˆé«˜æ–¯ç¯å¢ƒä¸­çš„ç½‘æ ¼ç…§æ˜å‡ºç°é—®é¢˜ã€‚</li>
<li>é«˜æ–¯ç¯å¢ƒä¸‹çš„ç½‘æ ¼éœ€è¦é‡æ–°ç…§æ˜ä»¥é¿å…çªå…€æ„Ÿã€‚</li>
<li>GBakeå·¥å…·æ˜¯ä¸ºäº†è§£å†³åœ¨Unityæ¸¸æˆå¼•æ“ä¸­ä¼ ç»Ÿä¸‰ç»´ç½‘æ ¼åœ¨é«˜æ–¯æ··åˆåœºæ™¯ä¸­çš„çœŸå®åå°„æ˜ å°„é—®é¢˜è€Œå¼€å‘çš„ã€‚</li>
<li>GBakeå·¥å…·èƒ½ä»é«˜æ–¯æ··åˆåœºæ™¯ä¸­çƒ˜ç„™åå°„æ¢é’ˆã€‚</li>
<li>é€šè¿‡ä½¿ç”¨GBakeå·¥å…·ï¼Œå¯ä»¥å®ç°åœ¨Unityæ¸¸æˆå¼•æ“ä¸­æ›´çœŸå®çš„æ¸²æŸ“æ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02257">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-e5ef49662025aa95e91853d5fdf5b47c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-639829e00245204fa509b3bf0d8fb577.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6928f7d99de7cd57cf64e1a706c43885.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9fc9297b3f94e4d810a3dca992d529cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fba6fdd60c213dcc1c15cdc97bedfba0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-928213e960387f486e50224b7f68fcdc.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="3D-Gaussian-Splatting-Driven-Multi-View-Robust-Physical-Adversarial-Camouflage-Generation"><a href="#3D-Gaussian-Splatting-Driven-Multi-View-Robust-Physical-Adversarial-Camouflage-Generation" class="headerlink" title="3D Gaussian Splatting Driven Multi-View Robust Physical Adversarial   Camouflage Generation"></a>3D Gaussian Splatting Driven Multi-View Robust Physical Adversarial   Camouflage Generation</h2><p><strong>Authors:Tianrui Lou, Xiaojun Jia, Siyuan Liang, Jiawei Liang, Ming Zhang, Yanjun Xiao, Xiaochun Cao</strong></p>
<p>Physical adversarial attack methods expose the vulnerabilities of deep neural networks and pose a significant threat to safety-critical scenarios such as autonomous driving. Camouflage-based physical attack is a more promising approach compared to the patch-based attack, offering stronger adversarial effectiveness in complex physical environments. However, most prior work relies on mesh priors of the target object and virtual environments constructed by simulators, which are time-consuming to obtain and inevitably differ from the real world. Moreover, due to the limitations of the backgrounds in training images, previous methods often fail to produce multi-view robust adversarial camouflage and tend to fall into sub-optimal solutions. Due to these reasons, prior work lacks adversarial effectiveness and robustness across diverse viewpoints and physical environments. We propose a physical attack framework based on 3D Gaussian Splatting (3DGS), named PGA, which provides rapid and precise reconstruction with few images, along with photo-realistic rendering capabilities. Our framework further enhances cross-view robustness and adversarial effectiveness by preventing mutual and self-occlusion among Gaussians and employing a min-max optimization approach that adjusts the imaging background of each viewpoint, helping the algorithm filter out non-robust adversarial features. Extensive experiments validate the effectiveness and superiority of PGA. Our code is available at:<a target="_blank" rel="noopener" href="https://github.com/TRLou/PGA">https://github.com/TRLou/PGA</a>. </p>
<blockquote>
<p>ç‰©ç†å¯¹æŠ—æ”»å‡»æ–¹æ³•æ­ç¤ºäº†æ·±åº¦ç¥ç»ç½‘ç»œçš„è„†å¼±æ€§ï¼Œå¹¶å¯¹è‡ªåŠ¨é©¾é©¶ç­‰å®‰å…¨å…³é”®åœºæ™¯æ„æˆäº†é‡å¤§å¨èƒã€‚ä¸åŸºäºè¡¥ä¸çš„æ”»å‡»ç›¸æ¯”ï¼ŒåŸºäºä¼ªè£…æ”»å‡»çš„ç‰©æ”»å‡»æ–¹æ³•æ˜¯ä¸€ç§æ›´æœ‰å‰é€”çš„æ–¹æ³•ï¼Œåœ¨å¤æ‚çš„ç‰©ç†ç¯å¢ƒä¸­å…·æœ‰æ›´å¼ºçš„å¯¹æŠ—æ•ˆæœã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°æ—©æœŸçš„ç ”ç©¶ä¾èµ–äºç›®æ ‡ç‰©ä½“çš„ç½‘æ ¼å…ˆéªŒå’Œæ¨¡æ‹Ÿå™¨æ„å»ºçš„è™šæ‹Ÿç¯å¢ƒï¼Œè¿™äº›éƒ½éœ€è¦è€—è´¹å¤§é‡æ—¶é—´ä¸”ä¸å¯é¿å…åœ°ä¸çœŸå®ä¸–ç•Œå­˜åœ¨å·®å¼‚ã€‚æ­¤å¤–ï¼Œç”±äºè®­ç»ƒå›¾åƒèƒŒæ™¯çš„é™åˆ¶ï¼Œä¹‹å‰çš„æ–¹æ³•å¾€å¾€æ— æ³•ç”Ÿæˆå¤šè§†è§’ç¨³å¥çš„å¯¹æŠ—ä¼ªè£…ï¼Œå¹¶å€¾å‘äºé™·å…¥æ¬¡ä¼˜è§£ã€‚ç”±äºè¿™äº›åŸå› ï¼Œæ—©æœŸçš„ç ”ç©¶åœ¨è·¨è¶Šä¸åŒè§†è§’å’Œç‰©ç†ç¯å¢ƒæ–¹é¢çš„å¯¹æŠ—æ•ˆæœå’Œç¨³å¥æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰çš„ç‰©ç†æ”»å‡»æ¡†æ¶ï¼Œåä¸ºPGAã€‚è¯¥æ¡†æ¶å…·æœ‰å¿«é€Ÿç²¾ç¡®é‡å»ºå°‘é‡å›¾åƒçš„èƒ½åŠ›ä»¥åŠé€¼çœŸçš„æ¸²æŸ“èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æ¡†æ¶é€šè¿‡é˜²æ­¢é«˜æ–¯ä¹‹é—´çš„ç›¸äº’å’Œè‡ªé®æŒ¡å¹¶é‡‡ç”¨æœ€å°æœ€å¤§ä¼˜åŒ–æ–¹æ³•è°ƒæ•´æ¯ä¸ªè§†è§’çš„æˆåƒèƒŒæ™¯ï¼Œè¿›ä¸€æ­¥æé«˜äº†è·¨è§†è§’çš„ç¨³å¥æ€§å’Œå¯¹æŠ—æ•ˆæœï¼Œå¸®åŠ©ç®—æ³•è¿‡æ»¤æ‰éç¨³å¥çš„å¯¹æŠ—ç‰¹å¾ã€‚å¤§é‡å®éªŒéªŒè¯äº†PGAçš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/TRLou/PGA%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/TRLou/PGAè®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.01367v1">PDF</a> Accepted by ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>åŸºäºç‰©ç†çš„æ”»å‡»æ–¹æ³•æ­ç¤ºäº†æ·±åº¦ç¥ç»ç½‘ç»œçš„å®‰å…¨æ¼æ´ï¼Œç‰¹åˆ«æ˜¯åœ¨è‡ªåŠ¨é©¾é©¶ç­‰å®‰å…¨å…³é”®åœºæ™¯ä¸­æ„æˆäº†é‡å¤§å¨èƒã€‚ç›¸æ¯”äºåŸºäºè¡¥ä¸çš„æ”»å‡»æ–¹æ³•ï¼Œä¼ªè£…æ”»å‡»æ˜¯ä¸€ç§æ›´æœ‰å‰æ™¯çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚çš„ç‰©ç†ç¯å¢ƒä¸­å®ç°æ›´å¼ºçš„å¯¹æŠ—æ€§æ•ˆæœã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°å…ˆå‰çš„ç ”ç©¶ä¾èµ–äºç›®æ ‡ç‰©ä½“çš„ç½‘æ ¼å…ˆéªŒå’Œç”±æ¨¡æ‹Ÿå™¨æ„å»ºçš„è™šæ‹Ÿç¯å¢ƒï¼Œè¿™äº›ç¯å¢ƒè€—æ—¶ä¸”ä¸å¯é¿å…åœ°ä¸çœŸå®ä¸–ç•Œå­˜åœ¨å·®å¼‚ã€‚æ­¤å¤–ï¼Œç”±äºè®­ç»ƒå›¾åƒèƒŒæ™¯çš„é™åˆ¶ï¼Œå…ˆå‰çš„æ–¹æ³•å¾€å¾€éš¾ä»¥ç”Ÿæˆå¤šè§†è§’çš„é²æ£’å¯¹æŠ—ä¼ªè£…ï¼Œå¹¶å®¹æ˜“é™·å…¥æ¬¡ä¼˜è§£å†³æ–¹æ¡ˆã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰çš„ç‰©ç†æ”»å‡»æ¡†æ¶â€”â€”PGAã€‚è¯¥æ¡†æ¶å…·æœ‰å¿«é€Ÿç²¾ç¡®é‡å»ºå’Œé€¼çœŸçš„æ¸²æŸ“èƒ½åŠ›ã€‚é€šè¿‡é˜²æ­¢é«˜æ–¯ä¹‹é—´çš„äº’ç›¸é®æŒ¡å’Œè‡ªæˆ‘é®æŒ¡ä»¥åŠé‡‡ç”¨è°ƒæ•´æ¯ä¸ªè§†ç‚¹æˆåƒèƒŒæ™¯çš„minmaxä¼˜åŒ–æ–¹æ³•ï¼Œè¯¥æ¡†æ¶å¢å¼ºäº†è·¨è§†è§’çš„é²æ£’æ€§å’Œå¯¹æŠ—æ€§æ•ˆæœï¼Œä½¿ç®—æ³•èƒ½å¤Ÿè¿‡æ»¤æ‰éé²æ£’çš„å¯¹æŠ—ç‰¹å¾ã€‚å®éªŒè¯æ˜PGAçš„æœ‰æ•ˆæ€§ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚æˆ‘ä»¬çš„ä»£ç å¯é€šè¿‡é“¾æ¥è®¿é—®ï¼š[é“¾æ¥åœ°å€]ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç‰©ç†å¯¹æŠ—æ”»å‡»æ–¹æ³•æ­ç¤ºäº†æ·±åº¦ç¥ç»ç½‘ç»œçš„å®‰å…¨æ¼æ´ï¼Œç‰¹åˆ«æ˜¯åœ¨è‡ªåŠ¨é©¾é©¶ç­‰å®‰å…¨å…³é”®åœºæ™¯ä¸­ã€‚</li>
<li>ä¼ªè£…æ”»å‡»æ˜¯ä¸€ç§åœ¨å¤æ‚ç‰©ç†ç¯å¢ƒä¸­å®ç°æ›´å¼ºå¯¹æŠ—æ€§æ•ˆæœçš„æœ‰å‰æ™¯çš„æ–¹æ³•ã€‚</li>
<li>å¤§å¤šæ•°å…ˆå‰ç ”ç©¶ä¾èµ–äºè™šæ‹Ÿç¯å¢ƒï¼Œè¿™äº›ç¯å¢ƒä¸çœŸå®ä¸–ç•Œå­˜åœ¨å·®å¼‚ã€‚</li>
<li>è®­ç»ƒå›¾åƒèƒŒæ™¯çš„é™åˆ¶å¯¼è‡´å…ˆå‰æ–¹æ³•éš¾ä»¥ç”Ÿæˆå¤šè§†è§’çš„é²æ£’å¯¹æŠ—ä¼ªè£…ã€‚</li>
<li>æå‡ºçš„åŸºäºä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰çš„ç‰©ç†æ”»å‡»æ¡†æ¶PGAå…·æœ‰å¿«é€Ÿç²¾ç¡®é‡å»ºå’Œé€¼çœŸçš„æ¸²æŸ“èƒ½åŠ›ã€‚</li>
<li>PGAé€šè¿‡é˜²æ­¢é«˜æ–¯ä¹‹é—´çš„äº’ç›¸é®æŒ¡å’Œè‡ªæˆ‘é®æŒ¡ä»¥åŠé‡‡ç”¨minmaxä¼˜åŒ–æ–¹æ³•å¢å¼ºäº†è·¨è§†è§’çš„é²æ£’æ€§å’Œå¯¹æŠ—æ€§æ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.01367">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-44deda9972e1204140a4e1abbf956124.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dcbcc4d220811732b4e339d428bda9db.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6f74e4e5477d3a8509967dea6f0e494f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cde9389c287b2f88fc1e844fd1f0e301.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="VISTA-Open-Vocabulary-Task-Relevant-Robot-Exploration-with-Online-Semantic-Gaussian-Splatting"><a href="#VISTA-Open-Vocabulary-Task-Relevant-Robot-Exploration-with-Online-Semantic-Gaussian-Splatting" class="headerlink" title="VISTA: Open-Vocabulary, Task-Relevant Robot Exploration with Online   Semantic Gaussian Splatting"></a>VISTA: Open-Vocabulary, Task-Relevant Robot Exploration with Online   Semantic Gaussian Splatting</h2><p><strong>Authors:Keiko Nagami, Timothy Chen, Javier Yu, Ola Shorinwa, Maximilian Adang, Carlyn Dougherty, Eric Cristofalo, Mac Schwager</strong></p>
<p>We present VISTA (Viewpoint-based Image selection with Semantic Task Awareness), an active exploration method for robots to plan informative trajectories that improve 3D map quality in areas most relevant for task completion. Given an open-vocabulary search instruction (e.g., â€œfind a personâ€), VISTA enables a robot to explore its environment to search for the object of interest, while simultaneously building a real-time semantic 3D Gaussian Splatting reconstruction of the scene. The robot navigates its environment by planning receding-horizon trajectories that prioritize semantic similarity to the query and exploration of unseen regions of the environment. To evaluate trajectories, VISTA introduces a novel, efficient viewpoint-semantic coverage metric that quantifies both the geometric view diversity and task relevance in the 3D scene. On static datasets, our coverage metric outperforms state-of-the-art baselines, FisherRF and Bayesâ€™ Rays, in computation speed and reconstruction quality. In quadrotor hardware experiments, VISTA achieves 6x higher success rates in challenging maps, compared to baseline methods, while matching baseline performance in less challenging maps. Lastly, we show that VISTA is platform-agnostic by deploying it on a quadrotor drone and a Spot quadruped robot. Open-source code will be released upon acceptance of the paper. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºVISTAï¼ˆåŸºäºè§†ç‚¹å›¾åƒé€‰æ‹©å¹¶å…·æœ‰è¯­ä¹‰ä»»åŠ¡æ„ŸçŸ¥èƒ½åŠ›ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æœºå™¨äººä¸»åŠ¨æ¢ç´¢æ–¹æ³•ï¼Œç”¨äºè§„åˆ’èƒ½å¤Ÿæ”¹å–„ä»»åŠ¡å®Œæˆç›¸å…³åŒºåŸŸçš„ä¸‰ç»´åœ°å›¾è´¨é‡çš„è½¨è¿¹ã€‚ç»™å®šå¼€æ”¾è¯æ±‡æœç´¢æŒ‡ä»¤ï¼ˆä¾‹å¦‚ï¼Œâ€œå¯»æ‰¾ä¸€ä¸ªäººâ€ï¼‰ï¼ŒVISTAå…è®¸æœºå™¨äººåœ¨æ¢ç´¢ç¯å¢ƒä»¥å¯»æ‰¾æ„Ÿå…´è¶£å¯¹è±¡çš„åŒæ—¶ï¼Œå®æ—¶æ„å»ºåœºæ™¯çš„è¯­ä¹‰ä¸‰ç»´é«˜æ–¯å–·æº…é‡å»ºã€‚æœºå™¨äººé€šè¿‡è§„åˆ’å…·æœ‰ä¼˜å…ˆè¯­ä¹‰ç›¸ä¼¼æ€§å’Œæ¢ç´¢æœªçŸ¥åŒºåŸŸçš„æœªæ¥åœ°å¹³çº¿è½¨è¿¹æ¥å¯¼èˆªç¯å¢ƒã€‚ä¸ºäº†è¯„ä¼°è½¨è¿¹ï¼ŒVISTAå¼•å…¥äº†ä¸€ç§æ–°çš„é«˜æ•ˆè§†ç‚¹è¯­ä¹‰è¦†ç›–åº¦é‡æ ‡å‡†ï¼Œè¯¥æ ‡å‡†å¯ä»¥é‡åŒ–ä¸‰ç»´åœºæ™¯ä¸­çš„å‡ ä½•è§†å›¾å¤šæ ·æ€§å’Œä»»åŠ¡ç›¸å…³æ€§ã€‚åœ¨é™æ€æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„è¦†ç›–åº¦é‡æ ‡å‡†åœ¨è®¡ç®—é€Ÿåº¦å’Œé‡å»ºè´¨é‡æ–¹é¢ä¼˜äºæœ€æ–°åŸºçº¿FisherRFå’Œè´å¶æ–¯å°„çº¿ã€‚åœ¨å››æ—‹ç¿¼ç¡¬ä»¶å®éªŒä¸­ï¼Œä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒVISTAåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°å›¾ä¸Šå®ç°äº†é«˜è¾¾å…­å€çš„æˆåŠŸç‡æå‡ï¼ŒåŒæ—¶åœ¨ä¸å¤ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°å›¾ä¸Šä¿æŒåŸºçº¿æ€§èƒ½ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡å°†å…¶éƒ¨ç½²åœ¨å››æ—‹ç¿¼æ— äººæœºå’ŒSpotå››è¶³æœºå™¨äººä¸Šè¯æ˜äº†VISTAå…·æœ‰å¹³å°ä¸­ç«‹æ€§ã€‚è®ºæ–‡è¢«æ¥å—åå°†å‘å¸ƒå¼€æºä»£ç ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.01125v1">PDF</a> 9 pages, 4 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºVISTAçš„æœºå™¨äººä¸»åŠ¨æ¢ç´¢æ–¹æ³•ï¼Œç”¨äºè§„åˆ’ä¿¡æ¯è½¨è¿¹ä»¥æé«˜3Dåœ°å›¾è´¨é‡ï¼Œé‡ç‚¹å…³æ³¨ä¸ä»»åŠ¡å®Œæˆç›¸å…³çš„åŒºåŸŸã€‚VISTAå¯å¤„ç†å¼€æ”¾å¼è¯æ±‡æœç´¢æŒ‡ä»¤ï¼Œä½¿æœºå™¨äººåœ¨æ¢ç´¢ç¯å¢ƒå¯»æ‰¾ç›®æ ‡å¯¹è±¡çš„åŒæ—¶ï¼Œå®æ—¶æ„å»ºåœºæ™¯çš„è¯­ä¹‰3Dé«˜æ–¯æ··åˆé‡å»ºæ¨¡å‹ã€‚é€šè¿‡è§„åˆ’ä¸æ–­æ¥è¿‘åœ°å¹³çº¿çš„è½¨è¿¹ï¼Œæœºå™¨äººèƒ½å¤Ÿä¼˜å…ˆè€ƒè™‘åˆ°æŸ¥è¯¢çš„è¯­ä¹‰ç›¸ä¼¼æ€§å’Œå¯¹æœªè§‚æµ‹åŒºåŸŸçš„æ¢ç´¢ã€‚VISTAå¼•å…¥äº†ä¸€ç§æ–°çš„ã€é«˜æ•ˆçš„è§†ç‚¹è¯­ä¹‰è¦†ç›–åº¦é‡æ ‡å‡†ï¼Œä»¥é‡åŒ–ä¸‰ç»´åœºæ™¯ä¸­çš„å‡ ä½•è§†å›¾å¤šæ ·æ€§å’Œä»»åŠ¡ç›¸å…³æ€§ã€‚åœ¨é™æ€æ•°æ®é›†ä¸Šï¼Œå…¶è¦†ç›–åº¦é‡åœ¨è®¡ç®—é€Ÿåº¦å’Œé‡å»ºè´¨é‡ä¸Šä¼˜äºæœ€æ–°åŸºçº¿FisherRFå’ŒBayeså°„çº¿ã€‚åœ¨æ— äººæœºçš„ç¡¬ä»¶å®éªŒä¸­ï¼Œä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒVISTAåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°å›¾ä¸ŠæˆåŠŸç‡æé«˜äº†å…­å€ï¼ŒåŒæ—¶åœ¨ä¸å¤ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°å›¾ä¸Šä¿æŒäº†åŸºçº¿æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å±•ç¤ºäº†VISTAçš„å¹³å°æ— å…³æ€§ï¼Œå¯ä»¥åœ¨æ— äººæœºå’ŒSpotå››è¶³æœºå™¨äººä¸Šéƒ¨ç½²ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VISTAæ˜¯ä¸€ç§æœºå™¨äººä¸»åŠ¨æ¢ç´¢æ–¹æ³•ï¼Œç”¨äºè§„åˆ’ä¿¡æ¯è½¨è¿¹ä»¥æé«˜3Dåœ°å›¾è´¨é‡ã€‚</li>
<li>VISTAå¯å¤„ç†å¼€æ”¾å¼è¯æ±‡æœç´¢æŒ‡ä»¤ï¼Œç»“åˆè¯­ä¹‰æ¢ç´¢å’Œå®æ—¶3Dé‡å»ºã€‚</li>
<li>æœºå™¨äººé€šè¿‡è§„åˆ’ä¸æ–­æ¥è¿‘åœ°å¹³çº¿çš„è½¨è¿¹æ¥å¹³è¡¡æŸ¥è¯¢çš„è¯­ä¹‰ç›¸ä¼¼æ€§å’Œå¯¹æœªè§‚æµ‹åŒºåŸŸçš„æ¢ç´¢ã€‚</li>
<li>VISTAå¼•å…¥äº†ä¸€ç§æ–°çš„è§†ç‚¹è¯­ä¹‰è¦†ç›–åº¦é‡æ ‡å‡†ï¼Œä»¥é‡åŒ–ä¸‰ç»´åœºæ™¯ä¸­çš„å‡ ä½•è§†å›¾å¤šæ ·æ€§å’Œä»»åŠ¡ç›¸å…³æ€§ã€‚</li>
<li>åœ¨é™æ€æ•°æ®é›†ä¸Šï¼ŒVISTAçš„è¦†ç›–åº¦é‡åœ¨è®¡ç®—é€Ÿåº¦å’Œé‡å»ºè´¨é‡æ–¹é¢ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
<li>åœ¨ç¡¬ä»¶å®éªŒä¸­ï¼ŒVISTAåœ¨æŒ‘æˆ˜æ€§åœ°å›¾ä¸Šè¡¨ç°å‡ºæ›´é«˜çš„æˆåŠŸç‡ï¼ŒåŒæ—¶åœ¨ä¸å¤ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°å›¾ä¸Šä¿æŒäº†åŸºçº¿æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.01125">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-913e2b8e8f37562e40265d2df28d783a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ac3b8829ffe4dceab36baf5db547448c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5d28fdf275388d246e0c1df4a250a1df.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-473b4dda75125b31cbbe75a2ac05788d.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Masks-make-discriminative-models-great-again"><a href="#Masks-make-discriminative-models-great-again" class="headerlink" title="Masks make discriminative models great again!"></a>Masks make discriminative models great again!</h2><p><strong>Authors:Tianshi Cao, Marie-Julie Rakotosaona, Ben Poole, Federico Tombari, Michael Niemeyer</strong></p>
<p>We present Image2GS, a novel approach that addresses the challenging problem of reconstructing photorealistic 3D scenes from a single image by focusing specifically on the image-to-3D lifting component of the reconstruction process. By decoupling the lifting problem (converting an image to a 3D model representing what is visible) from the completion problem (hallucinating content not present in the input), we create a more deterministic task suitable for discriminative models. Our method employs visibility masks derived from optimized 3D Gaussian splats to exclude areas not visible from the source view during training. This masked training strategy significantly improves reconstruction quality in visible regions compared to strong baselines. Notably, despite being trained only on masked regions, Image2GS remains competitive with state-of-the-art discriminative models trained on full target images when evaluated on complete scenes. Our findings highlight the fundamental struggle discriminative models face when fitting unseen regions and demonstrate the advantages of addressing image-to-3D lifting as a distinct problem with specialized techniques. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†Image2GSè¿™ä¸€æ–°æ–¹æ³•ï¼Œä¸“æ³¨äºè§£å†³ä»å•ä¸€å›¾åƒé‡å»ºå†™å®é£æ ¼çš„3Dåœºæ™¯è¿™ä¸€éš¾é¢˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡ç‚¹ç ”ç©¶é‡å»ºè¿‡ç¨‹ä¸­çš„å›¾åƒåˆ°3Dè½¬æ¢ç¯èŠ‚ã€‚é€šè¿‡è§£é™¤æå‡é—®é¢˜ï¼ˆå°†å›¾åƒè½¬æ¢ä¸ºè¡¨ç¤ºå¯è§å†…å®¹çš„3Dæ¨¡å‹ï¼‰ä¸è¡¥å…¨é—®é¢˜ï¼ˆå‡­ç©ºæƒ³è±¡è¾“å…¥ä¸­ä¸å­˜åœ¨çš„éƒ¨åˆ†ï¼‰ä¹‹é—´çš„è€¦åˆå…³ç³»ï¼Œæˆ‘ä»¬åˆ›é€ äº†ä¸€ä¸ªæ›´ç¡®å®šæ€§çš„ä»»åŠ¡ï¼Œæ›´é€‚åˆåˆ¤åˆ«æ¨¡å‹æ¥å¤„ç†ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨ç”±ä¼˜åŒ–åçš„3Dé«˜æ–¯å±•å¸ƒæ´¾ç”Ÿçš„å¯è§æ€§æ©ç ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ’é™¤æºè§†è§’ä¸å¯è§çš„åŒºåŸŸã€‚ä¸å¼ºå¤§çš„åŸºçº¿ç›¸æ¯”ï¼Œè¿™ç§æ©ç è®­ç»ƒç­–ç•¥åœ¨å¯è§åŒºåŸŸçš„é‡å»ºè´¨é‡æ–¹é¢æ˜¾è‘—æé«˜ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå°½ç®¡ä»…åœ¨æ©ç åŒºåŸŸä¸Šè¿›è¡Œè®­ç»ƒï¼Œä½†å½“åœ¨å®Œæ•´åœºæ™¯ä¸Šè¯„ä¼°æ—¶ï¼ŒImage2GSä»ä¸åœ¨å®Œæ•´ç›®æ ‡å›¾åƒä¸Šè®­ç»ƒçš„æœ€æ–°åˆ¤åˆ«æ¨¡å‹ç«äº‰ã€‚æˆ‘ä»¬çš„ç ”ç©¶çªå‡ºäº†åˆ¤åˆ«æ¨¡å‹åœ¨é¢å¯¹æœªçŸ¥åŒºåŸŸæ‹Ÿåˆæ—¶çš„åŸºæœ¬æŒ‘æˆ˜ï¼Œå¹¶å±•ç¤ºäº†å°†å›¾åƒåˆ°3Dè½¬æ¢ä½œä¸ºä¸€ä¸ªå…·æœ‰ä¸“é—¨æŠ€æœ¯çš„é—®é¢˜æ¥è§£å†³çš„ä¼˜ç‚¹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.00916v1">PDF</a> </p>
<p><strong>Summary</strong><br>å›¾åƒé‡å»ºä¸­çš„å•å¹…å›¾åƒåˆ°ä¸‰ç»´åœºæ™¯çš„è½¬æ¢é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡é‡‡ç”¨ä¸“é—¨çš„å›¾åƒåˆ°ä¸‰ç»´æå‡æŠ€æœ¯æ¥è§£å†³ã€‚æœ¬æ–‡æå‡ºä¸€ç§åä¸ºImage2GSçš„æ–°æ–¹æ³•ï¼Œé€šè¿‡å°†æå‡é—®é¢˜å’Œå®Œæˆé—®é¢˜åˆ†ç¦»ï¼Œå®ç°äº†ä»å›¾åƒåˆ°ä¸‰ç»´æ¨¡å‹çš„è½¬æ¢ã€‚é‡‡ç”¨åŸºäºä¼˜åŒ–çš„ä¸‰ç»´é«˜æ–¯æ©æ¨¡è¿›è¡Œè®­ç»ƒï¼Œæ˜¾è‘—æé«˜å¯è§åŒºåŸŸçš„é‡å»ºè´¨é‡ã€‚Image2GSæ–¹æ³•è¡¨ç°å‡ºç‹¬ç‰¹çš„ä¼˜åŠ¿ï¼Œåœ¨è§£å†³ç‰¹å®šé—®é¢˜æ—¶å±•ç°äº†è¾ƒé«˜çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Image2GSä¸“æ³¨äºä»å•å¹…å›¾åƒé‡å»ºä¸‰ç»´åœºæ™¯çš„æå‡é—®é¢˜ï¼Œåˆ†ç¦»äº†æå‡é—®é¢˜å’Œå®Œæˆé—®é¢˜ã€‚</li>
<li>ä½¿ç”¨ä¼˜åŒ–çš„ä¸‰ç»´é«˜æ–¯æ©æ¨¡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ’é™¤æºè§†å›¾ä¸å¯è§åŒºåŸŸï¼Œä»è€Œæé«˜å¯è§åŒºåŸŸçš„é‡å»ºè´¨é‡ã€‚</li>
<li>Image2GSåœ¨è®­ç»ƒæ—¶ä»…é’ˆå¯¹æ©æ¨¡åŒºåŸŸè¿›è¡Œè®­ç»ƒï¼Œä½†åœ¨å®Œæ•´åœºæ™¯è¯„ä¼°æ—¶ä»ä¸å…¨ç›®æ ‡å›¾åƒè®­ç»ƒçš„æœ€æ–°åˆ¤åˆ«æ¨¡å‹ç«äº‰ã€‚</li>
<li>è¯¥æ–¹æ³•å¼ºè°ƒäº†åˆ¤åˆ«æ¨¡å‹åœ¨æ‹Ÿåˆæœªè§åŒºåŸŸæ—¶çš„åŸºæœ¬æŒ‘æˆ˜ï¼Œå¹¶å±•ç¤ºäº†é‡‡ç”¨ä¸“é—¨æŠ€æœ¯çš„å›¾åƒåˆ°ä¸‰ç»´æå‡é—®é¢˜çš„ä¼˜åŠ¿ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.00916">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-23332aba3a4f6d7924df6f9cf74231c4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc2dbf7781b29f8d30fffee64395f30b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e7581ba4d4a5aa83439c5c5cc67dd4db.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-023a5cb73bc8f41d465996d91b5318d0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="LOD-GS-Level-of-Detail-Sensitive-3D-Gaussian-Splatting-for-Detail-Conserved-Anti-Aliasing"><a href="#LOD-GS-Level-of-Detail-Sensitive-3D-Gaussian-Splatting-for-Detail-Conserved-Anti-Aliasing" class="headerlink" title="LOD-GS: Level-of-Detail-Sensitive 3D Gaussian Splatting for Detail   Conserved Anti-Aliasing"></a>LOD-GS: Level-of-Detail-Sensitive 3D Gaussian Splatting for Detail   Conserved Anti-Aliasing</h2><p><strong>Authors:Zhenya Yang, Bingchen Gong, Kai Chen, Qi Dou</strong></p>
<p>Despite the advancements in quality and efficiency achieved by 3D Gaussian Splatting (3DGS) in 3D scene rendering, aliasing artifacts remain a persistent challenge. Existing approaches primarily rely on low-pass filtering to mitigate aliasing. However, these methods are not sensitive to the sampling rate, often resulting in under-filtering and over-smoothing renderings. To address this limitation, we propose LOD-GS, a Level-of-Detail-sensitive filtering framework for Gaussian Splatting, which dynamically predicts the optimal filtering strength for each 3D Gaussian primitive. Specifically, we introduce a set of basis functions to each Gaussian, which take the sampling rate as input to model appearance variations, enabling sampling-rate-sensitive filtering. These basis function parameters are jointly optimized with the 3D Gaussian in an end-to-end manner. The sampling rate is influenced by both focal length and camera distance. However, existing methods and datasets rely solely on down-sampling to simulate focal length changes for anti-aliasing evaluation, overlooking the impact of camera distance. To enable a more comprehensive assessment, we introduce a new synthetic dataset featuring objects rendered at varying camera distances. Extensive experiments on both public datasets and our newly collected dataset demonstrate that our method achieves SOTA rendering quality while effectively eliminating aliasing. The code and dataset have been open-sourced. </p>
<blockquote>
<p>å°½ç®¡ä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰åœ¨ä¸‰ç»´åœºæ™¯æ¸²æŸ“ä¸­å–å¾—äº†è´¨é‡å’Œæ•ˆç‡çš„æå‡ï¼Œä½†æ··å ä¼ªå½±ä»ç„¶æ˜¯ä¸€ä¸ªæŒç»­å­˜åœ¨çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–ä½é€šæ»¤æ³¢æ¥å‡è½»æ··å ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¯¹é‡‡æ ·ç‡ä¸å¤Ÿæ•æ„Ÿï¼Œé€šå¸¸ä¼šå¯¼è‡´æ»¤æ³¢ä¸è¶³å’Œè¿‡åº¦å¹³æ»‘çš„æ¸²æŸ“ç»“æœã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†LOD-GSï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºé«˜æ–¯æ‹¼è´´çš„ç»†èŠ‚å±‚æ¬¡æ•æ„Ÿæ»¤æ³¢æ¡†æ¶ï¼Œèƒ½å¤ŸåŠ¨æ€é¢„æµ‹æ¯ä¸ªä¸‰ç»´é«˜æ–¯åŸºå…ƒçš„æœ€ä½³æ»¤æ³¢å¼ºåº¦ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸ªé«˜æ–¯å¼•å…¥äº†ä¸€ç»„åŸºå‡½æ•°ï¼Œä»¥é‡‡æ ·ç‡ä½œä¸ºè¾“å…¥æ¥æ¨¡æ‹Ÿå¤–è§‚å˜åŒ–ï¼Œä»è€Œå®ç°é‡‡æ ·ç‡æ•æ„Ÿæ»¤æ³¢ã€‚è¿™äº›åŸºå‡½æ•°çš„å‚æ•°ä¸ä¸‰ç»´é«˜æ–¯ä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼è¿›è¡Œè”åˆä¼˜åŒ–ã€‚é‡‡æ ·ç‡å—åˆ°ç„¦è·å’Œç›¸æœºè·ç¦»çš„å½±å“ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å’Œæ•°æ®é›†ä»…é€šè¿‡ä¸‹é‡‡æ ·æ¥æ¨¡æ‹Ÿç„¦è·å˜åŒ–ä»¥è¿›è¡ŒæŠ—æ··å è¯„ä¼°ï¼Œå¿½ç•¥äº†ç›¸æœºè·ç¦»çš„å½±å“ã€‚ä¸ºäº†è¿›è¡Œæ›´å…¨é¢çš„è¯„ä¼°ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ–°çš„åˆæˆæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«åœ¨ä¸åŒç›¸æœºè·ç¦»ä¸‹å‘ˆç°çš„å¯¹è±¡ã€‚åœ¨å…¬å…±æ•°æ®é›†å’Œæˆ‘ä»¬æ–°æ”¶é›†çš„æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ï¼ŒåŒæ—¶æœ‰æ•ˆåœ°æ¶ˆé™¤äº†æ··å ã€‚ç›¸å…³ä»£ç å’Œæ•°æ®é›†å·²å¼€æºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.00554v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹3Dåœºæ™¯æ¸²æŸ“ä¸­çš„æŠ—é”¯é½¿é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºLevel-of-Detailï¼ˆLODï¼‰æ•æ„Ÿæ€§çš„é«˜æ–¯Splattingï¼ˆLOD-GSï¼‰æ»¤æ³¢æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡åŠ¨æ€é¢„æµ‹æ¯ä¸ª3Dé«˜æ–¯åŸºå…ƒçš„æœ€ä½³æ»¤æ³¢å¼ºåº¦æ¥è§£å†³ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€‚åŒæ—¶å¼•å…¥äº†ä¸€å¥—åŸºç¡€å‡½æ•°ï¼Œç”¨äºå¯¹é‡‡æ ·ç‡è¿›è¡Œå»ºæ¨¡ï¼Œå®ç°é‡‡æ ·ç‡æ•æ„Ÿæ»¤æ³¢ã€‚é€šè¿‡ä¼˜åŒ–åŸºç¡€å‡½æ•°å‚æ•°å’Œ3Dé«˜æ–¯å‚æ•°ï¼Œè¾¾åˆ°å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ï¼Œæœ‰æ•ˆæ¶ˆé™¤é”¯é½¿æ•ˆåº”ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†ä¸€ä¸ªæ–°çš„åˆæˆæ•°æ®é›†ï¼Œç”¨äºå…¨é¢è¯„ä¼°ä¸åŒç›¸æœºè·ç¦»ä¸‹çš„æŠ—é”¯é½¿æ•ˆæœã€‚ä»£ç å’Œæ•°æ®é›†å·²å¼€æºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°æœ‰çš„åŸºäºä½é€šæ»¤æ³¢çš„æŠ—é”¯é½¿æ–¹æ³•å› ç¼ºä¹é‡‡æ ·ç‡çš„æ•æ„Ÿæ€§ï¼Œå¯èƒ½å¯¼è‡´è¿‡æ»¤ä¸è¶³å’Œè¿‡åº¦å¹³æ»‘çš„æ¸²æŸ“ç»“æœã€‚</li>
<li>LOD-GSæ»¤æ³¢æ¡†æ¶é€šè¿‡åŠ¨æ€é¢„æµ‹æ¯ä¸ª3Dé«˜æ–¯åŸºå…ƒçš„æœ€ä½³æ»¤æ³¢å¼ºåº¦æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>LOD-GSå¼•å…¥äº†åŸºç¡€å‡½æ•°æ¥å»ºæ¨¡é‡‡æ ·ç‡çš„å˜åŒ–ï¼ŒåŒ…æ‹¬ç›¸æœºç„¦è·å’Œè·ç¦»çš„å½±å“ã€‚</li>
<li>ä»…ä¾èµ–é™é‡‡æ ·æ¨¡æ‹Ÿç„¦è·å˜åŒ–çš„ç°æœ‰æ–¹æ³•å’Œæ•°æ®é›†æ— æ³•å…¨é¢è¯„ä¼°æŠ—é”¯é½¿æ•ˆæœï¼Œå¿½è§†äº†ç›¸æœºè·ç¦»çš„å½±å“ã€‚ä¸ºæ­¤å¼•å…¥äº†æ–°çš„åˆæˆæ•°æ®é›†ç”¨äºå…¨é¢è¯„ä¼°æ€§èƒ½ã€‚å®éªŒè¡¨æ˜LOD-GSå¯æœ‰æ•ˆæ¶ˆé™¤é”¯é½¿å¹¶è¾¾åˆ°é¢†å…ˆçš„æ¸²æŸ“è´¨é‡ã€‚æ•°æ®å’Œä»£ç å·²ç»å¼€æºä»¥ä¾›ç ”ç©¶ä½¿ç”¨ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.00554">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ca616831399626a0e1c9de66930a1785.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9f70979b4f369c36529216b28aa50d70.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-62141399150fea7a898457057d6d3446.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-89fec2c82b2a96e79ecf2f0fd70bdff0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-759d9d60017bcf11345b45d5b9d5ee26.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="GDGS-3D-Gaussian-Splatting-Via-Geometry-Guided-Initialization-And-Dynamic-Density-Control"><a href="#GDGS-3D-Gaussian-Splatting-Via-Geometry-Guided-Initialization-And-Dynamic-Density-Control" class="headerlink" title="GDGS: 3D Gaussian Splatting Via Geometry-Guided Initialization And   Dynamic Density Control"></a>GDGS: 3D Gaussian Splatting Via Geometry-Guided Initialization And   Dynamic Density Control</h2><p><strong>Authors:Xingjun Wang, Lianlei Shan</strong></p>
<p>We propose a method to enhance 3D Gaussian Splatting (3DGS)~\cite{Kerbl2023}, addressing challenges in initialization, optimization, and density control. Gaussian Splatting is an alternative for rendering realistic images while supporting real-time performance, and it has gained popularity due to its explicit 3D Gaussian representation. However, 3DGS heavily depends on accurate initialization and faces difficulties in optimizing unstructured Gaussian distributions into ordered surfaces, with limited adaptive density control mechanism proposed so far. Our first key contribution is a geometry-guided initialization to predict Gaussian parameters, ensuring precise placement and faster convergence. We then introduce a surface-aligned optimization strategy to refine Gaussian placement, improving geometric accuracy and aligning with the surface normals of the scene. Finally, we present a dynamic adaptive density control mechanism that adjusts Gaussian density based on regional complexity, for visual fidelity. These innovations enable our method to achieve high-fidelity real-time rendering and significant improvements in visual quality, even in complex scenes. Our method demonstrates comparable or superior results to state-of-the-art methods, rendering high-fidelity images in real time. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ”¹è¿›3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰çš„æ–¹æ³•\cite{Kerbl2023}ï¼Œä»¥è§£å†³åˆå§‹åŒ–ã€ä¼˜åŒ–å’Œå¯†åº¦æ§åˆ¶æ–¹é¢çš„æŒ‘æˆ˜ã€‚é«˜æ–¯æ‹¼è´´æ˜¯ä¸€ç§ç”¨äºå‘ˆç°çœŸå®å›¾åƒçš„æŠ€æœ¯ï¼Œæ”¯æŒå®æ—¶æ€§èƒ½ï¼Œç”±äºå…¶æ˜ç¡®çš„3Dé«˜æ–¯è¡¨ç¤ºè€Œå¹¿å—æ¬¢è¿ã€‚ç„¶è€Œï¼Œ3DGSä¸¥é‡ä¾èµ–äºå‡†ç¡®çš„åˆå§‹åŒ–ï¼Œå¹¶ä¸”åœ¨å°†æ— åºçš„é«˜æ–¯åˆ†å¸ƒä¼˜åŒ–ä¸ºæœ‰åºçš„æ›²é¢æ—¶é¢ä¸´å›°éš¾ï¼Œç›®å‰æå‡ºçš„è‡ªé€‚åº”å¯†åº¦æ§åˆ¶æœºåˆ¶æœ‰é™ã€‚æˆ‘ä»¬çš„ç¬¬ä¸€é¡¹å…³é”®è´¡çŒ®æ˜¯é€šè¿‡å‡ ä½•å¼•å¯¼åˆå§‹åŒ–æ¥é¢„æµ‹é«˜æ–¯å‚æ•°ï¼Œç¡®ä¿ç²¾ç¡®æ”¾ç½®å’Œæ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ã€‚ç„¶åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ä¸æ›²é¢å¯¹é½çš„ä¼˜åŒ–ç­–ç•¥ï¼Œä»¥ç»†åŒ–é«˜æ–¯æ”¾ç½®ï¼Œæé«˜å‡ ä½•ç²¾åº¦å¹¶ä¸åœºæ™¯çš„è¡¨é¢æ³•çº¿å¯¹é½ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŠ¨æ€è‡ªé€‚åº”å¯†åº¦æ§åˆ¶æœºåˆ¶ï¼Œæ ¹æ®åŒºåŸŸå¤æ‚æ€§è°ƒæ•´é«˜æ–¯å¯†åº¦ï¼Œä»¥æé«˜è§†è§‰ä¿çœŸåº¦ã€‚è¿™äº›åˆ›æ–°ä½¿æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿå®ç°é«˜ä¿çœŸå®æ—¶æ¸²æŸ“å’Œè§†è§‰è´¨é‡çš„æ˜¾ç€æé«˜ï¼Œå³ä½¿åœ¨å¤æ‚çš„åœºæ™¯ä¸­ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”ï¼Œå‘ˆç°å‡ºç›¸å½“æˆ–æ›´å¥½çš„ç»“æœï¼Œèƒ½å¤Ÿå®æ—¶å‘ˆç°é«˜ä¿çœŸå›¾åƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.00363v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¢å¼º3Dé«˜æ–¯ç»˜åˆ¶ï¼ˆ3DGSï¼‰æ–¹æ³•ï¼Œè§£å†³åˆå§‹åŒ–ã€ä¼˜åŒ–å’Œå¯†åº¦æ§åˆ¶æ–¹é¢çš„æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•é€šè¿‡å‡ ä½•å¼•å¯¼åˆå§‹åŒ–é¢„æµ‹é«˜æ–¯å‚æ•°ï¼Œç¡®ä¿ç²¾ç¡®æ”¾ç½®å’Œæ›´å¿«æ”¶æ•›ï¼›å¼•å…¥è¡¨é¢å¯¹é½ä¼˜åŒ–ç­–ç•¥ï¼Œæé«˜å‡ ä½•ç²¾åº¦å’Œåœºæ™¯è¡¨é¢æ³•çº¿å¯¹é½ï¼›æå‡ºåŠ¨æ€è‡ªé€‚åº”å¯†åº¦æ§åˆ¶æœºåˆ¶ï¼Œæ ¹æ®åŒºåŸŸå¤æ‚æ€§è°ƒæ•´é«˜æ–¯å¯†åº¦ï¼Œä»¥æé«˜è§†è§‰ä¿çœŸåº¦ã€‚è¿™äº›åˆ›æ–°ä½¿è¯¥æ–¹æ³•å®ç°é«˜ä¿çœŸå®æ—¶æ¸²æŸ“ï¼Œåœ¨å¤æ‚åœºæ™¯ä¸­æ˜¾è‘—æé«˜è§†è§‰è´¨é‡ï¼Œä¸æœ€æ–°æ–¹æ³•ç›¸æ¯”å…·æœ‰ç›¸å½“æˆ–æ›´ä¼˜çš„ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºå¢å¼º3Dé«˜æ–¯ç»˜åˆ¶ï¼ˆ3DGSï¼‰æ–¹æ³•ï¼Œè§£å†³åˆå§‹åŒ–ã€ä¼˜åŒ–å’Œå¯†åº¦æ§åˆ¶çš„æŒ‘æˆ˜ã€‚</li>
<li>é€šè¿‡å‡ ä½•å¼•å¯¼åˆå§‹åŒ–é¢„æµ‹é«˜æ–¯å‚æ•°ï¼Œç¡®ä¿ç²¾ç¡®æ”¾ç½®å’Œæ›´å¿«æ”¶æ•›ã€‚</li>
<li>å¼•å…¥è¡¨é¢å¯¹é½ä¼˜åŒ–ç­–ç•¥ï¼Œæé«˜å‡ ä½•ç²¾åº¦å’Œåœºæ™¯è¡¨é¢æ³•çº¿å¯¹é½ã€‚</li>
<li>æå‡ºåŠ¨æ€è‡ªé€‚åº”å¯†åº¦æ§åˆ¶æœºåˆ¶ï¼Œæ ¹æ®åŒºåŸŸå¤æ‚æ€§è°ƒæ•´é«˜æ–¯å¯†åº¦ã€‚</li>
<li>å®ç°é«˜ä¿çœŸå®æ—¶æ¸²æŸ“ï¼Œæ˜¾è‘—æé«˜è§†è§‰è´¨é‡ã€‚</li>
<li>æ–¹æ³•åœ¨å¤æ‚åœºæ™¯ä¸­è¡¨ç°è‰¯å¥½ã€‚</li>
<li>ä¸æœ€æ–°æ–¹æ³•ç›¸æ¯”ï¼Œå…·æœ‰ç›¸å½“æˆ–æ›´ä¼˜çš„ç»“æœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.00363">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-71d2e084295bd7363e8238f5fafc542a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4802c1343006395686514ba2ab72a576.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-04816cb8dce23a39750384813c8b46b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ec69e8b559229bea4ed3fb2557c37be7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d70951868f492301eb96e086644332f7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1264527f138ee53e31f14d8c8ceaf1a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dde21d871e3e5d15aaff6c7c5782e978.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="RGE-GS-Reward-Guided-Expansive-Driving-Scene-Reconstruction-via-Diffusion-Priors"><a href="#RGE-GS-Reward-Guided-Expansive-Driving-Scene-Reconstruction-via-Diffusion-Priors" class="headerlink" title="RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via   Diffusion Priors"></a>RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via   Diffusion Priors</h2><p><strong>Authors:Sicong Du, Jiarun Liu, Qifeng Chen, Hao-Xiang Chen, Tai-Jiang Mu, Sheng Yang</strong></p>
<p>A single-pass driving clip frequently results in incomplete scanning of the road structure, making reconstructed scene expanding a critical requirement for sensor simulators to effectively regress driving actions. Although contemporary 3D Gaussian Splatting (3DGS) techniques achieve remarkable reconstruction quality, their direct extension through the integration of diffusion priors often introduces cumulative physical inconsistencies and compromises training efficiency. To address these limitations, we present RGE-GS, a novel expansive reconstruction framework that synergizes diffusion-based generation with reward-guided Gaussian integration. The RGE-GS framework incorporates two key innovations: First, we propose a reward network that learns to identify and prioritize consistently generated patterns prior to reconstruction phases, thereby enabling selective retention of diffusion outputs for spatial stability. Second, during the reconstruction process, we devise a differentiated training strategy that automatically adjust Gaussian optimization progress according to scene converge metrics, which achieving better convergence than baseline methods. Extensive evaluations of publicly available datasets demonstrate that RGE-GS achieves state-of-the-art performance in reconstruction quality. Our source-code will be made publicly available at <a target="_blank" rel="noopener" href="https://github.com/CN-ADLab/RGE-GS">https://github.com/CN-ADLab/RGE-GS</a>. </p>
<blockquote>
<p>å•é€šé“é©¾é©¶è§†é¢‘å‰ªè¾‘ç»å¸¸å¯¼è‡´å¯¹é“è·¯ç»“æ„çš„ä¸å®Œå…¨æ‰«æï¼Œè¿™ä½¿å¾—é‡å»ºåœºæ™¯æˆä¸ºä¼ æ„Ÿå™¨æ¨¡æ‹Ÿå™¨æœ‰æ•ˆå›å½’é©¾é©¶åŠ¨ä½œçš„å…³é”®è¦æ±‚ã€‚å°½ç®¡å½“å‰çš„3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æŠ€æœ¯å®ç°äº†ä»¤äººå°è±¡æ·±åˆ»çš„é‡å»ºè´¨é‡ï¼Œä½†å…¶é€šè¿‡é›†æˆæ‰©æ•£å…ˆéªŒå€¼çš„ç›´æ¥æ‰©å±•å¸¸å¸¸ä¼šå¼•å…¥ç´¯ç§¯çš„ç‰©ç†ä¸ä¸€è‡´æ€§å¹¶å½±å“è®­ç»ƒæ•ˆç‡ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†RGE-GSï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹æ‰©å±•é‡å»ºæ¡†æ¶ï¼Œå®ƒååŒåŸºäºæ‰©æ•£çš„ç”Ÿæˆä¸å¥–åŠ±å¼•å¯¼çš„é«˜æ–¯ç§¯åˆ†ã€‚RGE-GSæ¡†æ¶åŒ…å«ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¥–åŠ±ç½‘ç»œï¼Œè¯¥ç½‘ç»œåœ¨é‡å»ºé˜¶æ®µä¹‹å‰å­¦ä¹ è¯†åˆ«å’Œä¼˜å…ˆç”Ÿæˆä¸€è‡´çš„æ¨¡å¼ï¼Œä»è€Œèƒ½å¤Ÿæœ‰é€‰æ‹©åœ°ä¿ç•™æ‰©æ•£è¾“å‡ºä»¥å®ç°ç©ºé—´ç¨³å®šæ€§ã€‚å…¶æ¬¡ï¼Œåœ¨é‡å»ºè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åˆ¶å®šäº†ä¸€ç§å·®å¼‚åŒ–çš„è®­ç»ƒç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯æ ¹æ®åœºæ™¯æ”¶æ•›æŒ‡æ ‡è‡ªåŠ¨è°ƒæ•´é«˜æ–¯ä¼˜åŒ–è¿›åº¦ï¼Œä»è€Œå®ç°æ¯”åŸºçº¿æ–¹æ³•æ›´å¥½çš„æ”¶æ•›æ•ˆæœã€‚å¯¹å…¬å¼€å¯ç”¨æ•°æ®é›†çš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒRGE-GSåœ¨é‡å»ºè´¨é‡æ–¹é¢è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚æˆ‘ä»¬çš„æºä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/CN-ADLab/RGE-GS%E4%B8%8A%E5%85%AC%E5%BC%80%E3%80%82">https://github.com/CN-ADLab/RGE-GSä¸Šå…¬å¼€ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.22800v2">PDF</a> </p>
<p><strong>Summary</strong><br>     åŸºäºå•é€šé“é©¾é©¶ç‰‡æ®µå¸¸å¸¸å¯¼è‡´é“è·¯ç»“æ„æ‰«æä¸å®Œæ•´çš„é—®é¢˜ï¼Œç ”ç©¶è€…æå‡ºä¸€ç§æ–°å‹é‡å»ºæ¡†æ¶RGE-GSï¼Œè¯¥æ¡†æ¶ç»“åˆäº†æ‰©æ•£ç”Ÿæˆä¸å¥–åŠ±å¼•å¯¼çš„é«˜æ–¯ç§¯åˆ†æŠ€æœ¯ã€‚å…¶ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬å¥–åŠ±ç½‘ç»œçš„å¼•å…¥å’Œå·®å¼‚åŒ–è®­ç»ƒç­–ç•¥çš„è®¾è®¡ã€‚å¥–åŠ±ç½‘ç»œèƒ½å¤Ÿè¯†åˆ«å¹¶ä¼˜å…ˆä¿ç•™é‡å»ºé˜¶æ®µçš„ä¸€è‡´æ€§ç”Ÿæˆæ¨¡å¼ï¼Œä»è€Œå®ç°æ‰©æ•£è¾“å‡ºçš„é€‰æ‹©æ€§ä¿ç•™ï¼Œæé«˜ç©ºé—´ç¨³å®šæ€§ï¼›å·®å¼‚åŒ–è®­ç»ƒç­–ç•¥åˆ™æ ¹æ®åœºæ™¯æ”¶æ•›æŒ‡æ ‡è‡ªåŠ¨è°ƒæ•´é«˜æ–¯ä¼˜åŒ–è¿›ç¨‹ï¼Œä»¥å®ç°æ›´é«˜çš„æ”¶æ•›æ•ˆæœã€‚RGE-GSæ¡†æ¶åœ¨å…¬å¼€æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœå±•ç°å‡ºå…¶é‡å»ºè´¨é‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ç›¸å…³æºä»£ç å°†åœ¨GitHubä¸Šå…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å•é€šé“é©¾é©¶ç‰‡æ®µå¯¼è‡´é“è·¯ç»“æ„æ‰«æä¸å®Œæ•´çš„é—®é¢˜ã€‚</li>
<li>RGE-GSæ˜¯ä¸€ç§æ–°å‹é‡å»ºæ¡†æ¶ï¼Œç»“åˆäº†æ‰©æ•£ç”Ÿæˆä¸å¥–åŠ±å¼•å¯¼çš„é«˜æ–¯ç§¯åˆ†æŠ€æœ¯ã€‚</li>
<li>å¥–åŠ±ç½‘ç»œèƒ½å¤Ÿè¯†åˆ«å¹¶ä¼˜å…ˆä¿ç•™ä¸€è‡´æ€§ç”Ÿæˆæ¨¡å¼ï¼Œæé«˜ç©ºé—´ç¨³å®šæ€§ã€‚</li>
<li>å·®å¼‚åŒ–è®­ç»ƒç­–ç•¥èƒ½å¤Ÿæ ¹æ®åœºæ™¯æ”¶æ•›æŒ‡æ ‡è‡ªåŠ¨è°ƒæ•´é«˜æ–¯ä¼˜åŒ–è¿›ç¨‹ã€‚</li>
<li>RGE-GSæ¡†æ¶åœ¨å…¬å¼€æ•°æ®é›†ä¸Šçš„é‡å»ºè´¨é‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>è¯¥ç ”ç©¶çš„æºä»£ç å°†åœ¨GitHubä¸Šå…¬å¼€ï¼Œä¾¿äºä»–äººå‚è€ƒå’Œä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.22800">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-511bdf6d28b5f4925c6376f0a24d4003.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1dc5887293733c727875ceffbd312327.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a61f77cef6f2fad62c6db945607a6710.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cab6026585490bb0e4c0e44ab4c64ed8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1f97898b913f2623f1c2e953da890eb8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-331841ae066036511fc1fb6939f94a70.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3aa49ebc0ed0f569c5990a35c8a6d8d2.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="DeGauss-Dynamic-Static-Decomposition-with-Gaussian-Splatting-for-Distractor-free-3D-Reconstruction"><a href="#DeGauss-Dynamic-Static-Decomposition-with-Gaussian-Splatting-for-Distractor-free-3D-Reconstruction" class="headerlink" title="DeGauss: Dynamic-Static Decomposition with Gaussian Splatting for   Distractor-free 3D Reconstruction"></a>DeGauss: Dynamic-Static Decomposition with Gaussian Splatting for   Distractor-free 3D Reconstruction</h2><p><strong>Authors:Rui Wang, Quentin Lohmeyer, Mirko Meboldt, Siyu Tang</strong></p>
<p>Reconstructing clean, distractor-free 3D scenes from real-world captures remains a significant challenge, particularly in highly dynamic and cluttered settings such as egocentric videos. To tackle this problem, we introduce DeGauss, a simple and robust self-supervised framework for dynamic scene reconstruction based on a decoupled dynamic-static Gaussian Splatting design. DeGauss models dynamic elements with foreground Gaussians and static content with background Gaussians, using a probabilistic mask to coordinate their composition and enable independent yet complementary optimization. DeGauss generalizes robustly across a wide range of real-world scenarios, from casual image collections to long, dynamic egocentric videos, without relying on complex heuristics or extensive supervision. Experiments on benchmarks including NeRF-on-the-go, ADT, AEA, Hot3D, and EPIC-Fields demonstrate that DeGauss consistently outperforms existing methods, establishing a strong baseline for generalizable, distractor-free 3D reconstructionin highly dynamic, interaction-rich environments. Project page: <a target="_blank" rel="noopener" href="https://batfacewayne.github.io/DeGauss.io/">https://batfacewayne.github.io/DeGauss.io/</a> </p>
<blockquote>
<p>ä»ç°å®ä¸–ç•Œæ•æ‰ä¸­é‡å»ºå¹²å‡€ã€æ— å¹²æ‰°ç‰©çš„3Dåœºæ™¯ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜åº¦åŠ¨æ€å’Œæ‚ä¹±çš„ç¯å¢ƒä¸­ï¼Œå¦‚ç¬¬ä¸€äººç§°è§†é¢‘ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†DeGaussï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•è€Œç¨³å¥çš„åŸºäºè§£è€¦åŠ¨æ€é™æ€é«˜æ–¯æ¶‚å¸ƒè®¾è®¡çš„åŠ¨æ€åœºæ™¯é‡å»ºè‡ªç›‘ç£æ¡†æ¶ã€‚DeGaussä½¿ç”¨å‰æ™¯é«˜æ–¯å¯¹åŠ¨æ€å…ƒç´ è¿›è¡Œå»ºæ¨¡ï¼Œä½¿ç”¨èƒŒæ™¯é«˜æ–¯å¯¹é™æ€å†…å®¹è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶ä½¿ç”¨æ¦‚ç‡æ©è†œæ¥åè°ƒå®ƒä»¬çš„ç»„åˆï¼Œå®ç°ç‹¬ç«‹ä½†äº’è¡¥çš„ä¼˜åŒ–ã€‚DeGaussåœ¨å¤šç§çœŸå®åœºæ™¯ä¸­å…·æœ‰ç¨³å¥çš„æ³›åŒ–èƒ½åŠ›ï¼Œä»éšæ„çš„å›¾åƒé›†åˆåˆ°å†—é•¿ã€åŠ¨æ€çš„ç¬¬ä¸€äººç§°è§†é¢‘ï¼Œæ— éœ€ä¾èµ–å¤æ‚çš„å¯å‘å¼æ–¹æ³•æˆ–å¹¿æ³›çš„ç›‘ç£ã€‚åœ¨åŒ…æ‹¬NeRF-on-the-goã€ADTã€AEAã€Hot3Då’ŒEPIC-Fieldsç­‰åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒDeGausså§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºåœ¨é«˜åº¦åŠ¨æ€ã€äº¤äº’ä¸°å¯Œçš„ç¯å¢ƒä¸­çš„é€šç”¨æ— å¹²æ‰°ç‰©3Dé‡å»ºå»ºç«‹äº†å¼ºå¤§çš„åŸºå‡†çº¿ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://batfacewayne.github.io/DeGauss.io/">https://batfacewayne.github.io/DeGauss.io/</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13176v2">PDF</a> Accepted by ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºDeGaussçš„ç®€æ´ã€ç¨³å¥çš„è‡ªç›‘ç£åŠ¨æ€åœºæ™¯é‡å»ºæ¡†æ¶ï¼Œç”¨äºä»çœŸå®ä¸–ç•Œæ•æ‰ä¸­é‡å»ºæ— å¹²æ‰°ç‰©çš„3Dåœºæ™¯ã€‚è¯¥æ¡†æ¶åŸºäºåŠ¨æ€é™æ€é«˜æ–¯æ–‘ç‚¹è®¾è®¡çš„è§£è€¦è®¾è®¡ï¼Œä½¿ç”¨æ¦‚ç‡æ©è†œåè°ƒåŠ¨æ€å…ƒç´ å’Œé™æ€å†…å®¹çš„ç»„åˆï¼Œä½¿å®ƒä»¬èƒ½å¤Ÿç‹¬ç«‹ä½†äº’è¡¥åœ°è¿›è¡Œä¼˜åŒ–ã€‚DeGaussèƒ½å¤Ÿå¹¿æ³›åº”ç”¨äºå„ç§çœŸå®åœºæ™¯ï¼Œä»éšæœºå›¾åƒé›†åˆåˆ°é•¿çš„åŠ¨æ€ç¬¬ä¸€äººç§°è§†é¢‘ï¼Œä¸”æ— éœ€ä¾èµ–å¤æ‚çš„å¯å‘å¼æ–¹æ³•æˆ–å¹¿æ³›çš„ç›‘ç£ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDeGaussåœ¨é«˜åº¦åŠ¨æ€ã€äº¤äº’ä¸°å¯Œçš„ç¯å¢ƒä¸­ï¼Œåœ¨æ— å¹²æ‰°ç‰©çš„3Dé‡å»ºæ–¹é¢å§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºé€šç”¨åŒ–çš„3Dé‡å»ºå»ºç«‹äº†å¼ºå¤§çš„åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DeGaussæ˜¯ä¸€ä¸ªè‡ªç›‘ç£çš„åŠ¨æ€åœºæ™¯é‡å»ºæ¡†æ¶ï¼Œèƒ½å¤Ÿå¤„ç†çœŸå®ä¸–ç•Œæ•æ‰çš„æ— å¹²æ‰°ç‰©3Dåœºæ™¯é‡å»ºã€‚</li>
<li>æ¡†æ¶é‡‡ç”¨åŠ¨æ€é™æ€é«˜æ–¯æ–‘ç‚¹è®¾è®¡çš„è§£è€¦è®¾è®¡ï¼Œåˆ†åˆ«å»ºæ¨¡åŠ¨æ€å…ƒç´ å’Œé™æ€å†…å®¹ã€‚</li>
<li>ä½¿ç”¨æ¦‚ç‡æ©è†œåè°ƒåŠ¨æ€å’Œé™æ€å†…å®¹çš„ç»„åˆï¼Œå®ç°ç‹¬ç«‹ä¸”äº’è¡¥çš„ä¼˜åŒ–ã€‚</li>
<li>DeGaussé€‚ç”¨äºå¤šç§çœŸå®åœºæ™¯ï¼Œä»éšæœºå›¾åƒé›†åˆåˆ°é•¿åŠ¨æ€ç¬¬ä¸€äººç§°è§†é¢‘ã€‚</li>
<li>è¯¥æ¡†æ¶æ— éœ€å¤æ‚çš„å¯å‘å¼æ–¹æ³•æˆ–å¹¿æ³›çš„ç›‘ç£å³å¯å®ç°è‰¯å¥½çš„æ€§èƒ½ã€‚</li>
<li>åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šï¼ŒDeGaussçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨é«˜åº¦åŠ¨æ€ã€äº¤äº’ä¸°å¯Œçš„ç¯å¢ƒä¸­çš„è¡¨ç°æ›´ä¸ºå‡ºè‰²ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13176">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-29ea926948ae864003e61fd5d9ac3d28.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-52abc34ee50baeec82082d5a0b0a39dd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7e7ca9349c5c917b61361a49ba3a2b90.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dd25e5aad263e01ba35748e113a06ea1.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Grounding-Creativity-in-Physics-A-Brief-Survey-of-Physical-Priors-in-AIGC"><a href="#Grounding-Creativity-in-Physics-A-Brief-Survey-of-Physical-Priors-in-AIGC" class="headerlink" title="Grounding Creativity in Physics: A Brief Survey of Physical Priors in   AIGC"></a>Grounding Creativity in Physics: A Brief Survey of Physical Priors in   AIGC</h2><p><strong>Authors:Siwei Meng, Yawei Luo, Ping Liu</strong></p>
<p>Recent advancements in AI-generated content have significantly improved the realism of 3D and 4D generation. However, most existing methods prioritize appearance consistency while neglecting underlying physical principles, leading to artifacts such as unrealistic deformations, unstable dynamics, and implausible objects interactions. Incorporating physics priors into generative models has become a crucial research direction to enhance structural integrity and motion realism. This survey provides a review of physics-aware generative methods, systematically analyzing how physical constraints are integrated into 3D and 4D generation. First, we examine recent works in incorporating physical priors into static and dynamic 3D generation, categorizing methods based on representation types, including vision-based, NeRF-based, and Gaussian Splatting-based approaches. Second, we explore emerging techniques in 4D generation, focusing on methods that model temporal dynamics with physical simulations. Finally, we conduct a comparative analysis of major methods, highlighting their strengths, limitations, and suitability for different materials and motion dynamics. By presenting an in-depth analysis of physics-grounded AIGC, this survey aims to bridge the gap between generative models and physical realism, providing insights that inspire future research in physically consistent content generation. </p>
<blockquote>
<p>è¿‘æœŸäººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹çš„è¿›å±•æå¤§åœ°æé«˜äº†3Då’Œ4Dç”Ÿæˆçš„é€¼çœŸåº¦ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æ–¹æ³•ä¼˜å…ˆè€ƒè™‘å¤–è§‚çš„ä¸€è‡´æ€§ï¼Œå´å¿½ç•¥äº†åŸºæœ¬çš„ç‰©ç†åŸç†ï¼Œå¯¼è‡´å‡ºç°ä¸çœŸå®çš„å˜å½¢ã€ä¸ç¨³å®šçš„åŠ¨æ€ä»¥åŠä¸åˆç†çš„ç‰©ä½“äº¤äº’ç­‰ä¼ªå½±ã€‚å°†ç‰©ç†å…ˆéªŒçŸ¥è¯†èå…¥ç”Ÿæˆæ¨¡å‹å·²æˆä¸ºå¢å¼ºç»“æ„å®Œæ•´æ€§å’Œè¿åŠ¨é€¼çœŸåº¦çš„é‡è¦ç ”ç©¶æ–¹å‘ã€‚æœ¬æ–‡ç»¼è¿°äº†ç‰©ç†æ„ŸçŸ¥çš„ç”Ÿæˆæ–¹æ³•ï¼Œç³»ç»Ÿåˆ†æäº†å¦‚ä½•å°†ç‰©ç†çº¦æŸèå…¥3Då’Œ4Dç”Ÿæˆã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ç ”ç©¶äº†å°†ç‰©ç†å…ˆéªŒçŸ¥è¯†èå…¥é™æ€å’ŒåŠ¨æ€3Dç”Ÿæˆçš„æœ€æ–°å·¥ä½œï¼ŒæŒ‰è¡¨ç¤ºç±»å‹å¯¹æ–¹æ³•è¿›è¡Œåˆ†ç±»ï¼ŒåŒ…æ‹¬åŸºäºè§†è§‰çš„ã€åŸºäºNeRFçš„å’ŒåŸºäºé«˜æ–¯æ‹¼è´´çš„æ–¹æ³•ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æ¢ç´¢äº†4Dç”Ÿæˆçš„æ–°å…´æŠ€æœ¯ï¼Œé‡ç‚¹å…³æ³¨ä½¿ç”¨ç‰©ç†æ¨¡æ‹Ÿå¯¹æ—¶é—´åŠ¨æ€è¿›è¡Œå»ºæ¨¡çš„æ–¹æ³•ã€‚æœ€åï¼Œæˆ‘ä»¬å¯¹ä¸»è¦æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒåˆ†æï¼Œçªå‡ºäº†å®ƒä»¬å„è‡ªçš„ä¼˜åŠ¿ã€å±€é™æ€§å’Œåœ¨ä¸åŒææ–™å’Œè¿åŠ¨åŠ¨åŠ›å­¦æ–¹é¢çš„é€‚ç”¨æ€§ã€‚é€šè¿‡å¯¹åŸºäºç‰©ç†åŸç†çš„äººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹çš„æ·±å…¥åˆ†æï¼Œæœ¬æ–‡æ—¨åœ¨å¼¥åˆç”Ÿæˆæ¨¡å‹å’Œç‰©ç†é€¼çœŸä¹‹é—´çš„é¸¿æ²Ÿï¼Œæä¾›èƒ½æ¿€å‘æœªæ¥åœ¨ç‰©ç†ä¸€è‡´æ€§å†…å®¹ç”Ÿæˆæ–¹é¢ç ”ç©¶çš„è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.07007v3">PDF</a> Accepted by IJCAI 2025 Survey Track</p>
<p><strong>Summary</strong><br>     è¿‘æœŸäººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹çš„æŠ€æœ¯è¿›æ­¥å·²æ˜¾è‘—æé«˜3Då’Œ4Dç”Ÿæˆçš„é€¼çœŸåº¦ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¤šæ³¨é‡å¤–è§‚ä¸€è‡´æ€§ï¼Œå¿½è§†åº•å±‚ç‰©ç†åŸç†ï¼Œå¯¼è‡´ç”Ÿæˆå†…å®¹å‡ºç°ä¸çœŸå®å˜å½¢ã€åŠ¨æ€ä¸ç¨³å®šã€ç‰©ä½“äº¤äº’ä¸åˆç†ç­‰é—®é¢˜ã€‚èå…¥ç‰©ç†å…ˆéªŒçŸ¥è¯†åˆ°ç”Ÿæˆæ¨¡å‹å·²æˆä¸ºå¢å¼ºç»“æ„å®Œæ•´æ€§å’Œè¿åŠ¨é€¼çœŸåº¦çš„å…³é”®ç ”ç©¶æ–¹å‘ã€‚æœ¬æ–‡ç»¼è¿°äº†ç‰©ç†æ„ŸçŸ¥ç”Ÿæˆæ–¹æ³•ï¼Œç³»ç»Ÿåˆ†æå¦‚ä½•å°†ç‰©ç†çº¦æŸèå…¥3Då’Œ4Dç”Ÿæˆã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ç ”ç©¶äº†å°†ç‰©ç†å…ˆéªŒçŸ¥è¯†èå…¥é™æ€å’ŒåŠ¨æ€3Dç”Ÿæˆçš„æœ€æ–°å·¥ä½œï¼ŒæŒ‰è¡¨ç°å½¢å¼åˆ†ç±»ï¼ŒåŒ…æ‹¬åŸºäºè§†è§‰ã€NeRFå’ŒGaussian Splattingçš„æ–¹æ³•ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æ¢è®¨äº†4Dç”Ÿæˆçš„æ–°å…´æŠ€æœ¯ï¼Œé‡ç‚¹å…³æ³¨é€šè¿‡ç‰©ç†æ¨¡æ‹Ÿå¯¹æ—¶é—´åŠ¨æ€è¿›è¡Œå»ºæ¨¡çš„æ–¹æ³•ã€‚æœ€åï¼Œæˆ‘ä»¬å¯¹ä¸»è¦æ–¹æ³•è¿›è¡Œäº†å¯¹æ¯”åˆ†æï¼Œçªå‡ºå…¶ä¼˜åŠ¿ã€å±€é™æ€§å’Œåœ¨ä¸åŒææ–™å’Œè¿åŠ¨åŠ¨åŠ›å­¦æ–¹é¢çš„é€‚ç”¨æ€§ã€‚æœ¬æ–‡æ—¨åœ¨å¡«è¡¥ç”Ÿæˆæ¨¡å‹ä¸ç‰©ç†ç°å®ä¸»ä¹‰ä¹‹é—´çš„é¸¿æ²Ÿï¼Œä¸ºç‰©ç†ä¸€è‡´çš„å†…å®¹ç”Ÿæˆæä¾›æ´å¯Ÿï¼Œæ¿€å‘æœªæ¥ç ”ç©¶çµæ„Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIç”Ÿæˆçš„3Då’Œ4Då†…å®¹åœ¨é€¼çœŸåº¦ä¸Šæœ‰äº†æ˜¾è‘—æå‡ï¼Œä½†å­˜åœ¨ä¸çœŸå®å˜å½¢ã€åŠ¨æ€ä¸ç¨³å®šç­‰é—®é¢˜ã€‚</li>
<li>èå…¥ç‰©ç†å…ˆéªŒçŸ¥è¯†åˆ°ç”Ÿæˆæ¨¡å‹æ˜¯å¢å¼ºç»“æ„å®Œæ•´æ€§å’Œè¿åŠ¨é€¼çœŸåº¦çš„å…³é”®ã€‚</li>
<li>é™æ€å’ŒåŠ¨æ€3Dç”Ÿæˆçš„æœ€æ–°å·¥ä½œæŒ‰è¡¨ç°å½¢å¼åˆ†ç±»ï¼ŒåŒ…æ‹¬åŸºäºè§†è§‰ã€NeRFå’ŒGaussian Splattingçš„æ–¹æ³•ã€‚</li>
<li>4Dç”ŸæˆæŠ€æœ¯æ­£å…³æ³¨é€šè¿‡ç‰©ç†æ¨¡æ‹Ÿå¯¹æ—¶é—´åŠ¨æ€è¿›è¡Œå»ºæ¨¡çš„æ–¹æ³•ã€‚</li>
<li>ç‰©ç†æ„ŸçŸ¥ç”Ÿæˆæ–¹æ³•åœ¨ä¸åŒææ–™å’Œè¿åŠ¨åŠ¨åŠ›å­¦æ–¹é¢æœ‰ä¸åŒçš„é€‚ç”¨æ€§å’Œå±€é™æ€§ã€‚</li>
<li>æœ¬æ–‡æ—¨åœ¨å¡«è¡¥ç”Ÿæˆæ¨¡å‹ä¸ç‰©ç†ç°å®ä¸»ä¹‰ä¹‹é—´çš„é¸¿æ²Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.07007">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8316847a61ca9ce8a873eb8dcbaa3c8a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fc02149aac6500706268cff41d86f7d9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dcb9ba7838cf34365a0566c3c008fea1.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Instruct-4DGS-Efficient-Dynamic-Scene-Editing-via-4D-Gaussian-based-Static-Dynamic-Separation"><a href="#Instruct-4DGS-Efficient-Dynamic-Scene-Editing-via-4D-Gaussian-based-Static-Dynamic-Separation" class="headerlink" title="Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based   Static-Dynamic Separation"></a>Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based   Static-Dynamic Separation</h2><p><strong>Authors:Joohyun Kwon, Hanbyel Cho, Junmo Kim</strong></p>
<p>Recent 4D dynamic scene editing methods require editing thousands of 2D images used for dynamic scene synthesis and updating the entire scene with additional training loops, resulting in several hours of processing to edit a single dynamic scene. Therefore, these methods are not scalable with respect to the temporal dimension of the dynamic scene (i.e., the number of timesteps). In this work, we propose Instruct-4DGS, an efficient dynamic scene editing method that is more scalable in terms of temporal dimension. To achieve computational efficiency, we leverage a 4D Gaussian representation that models a 4D dynamic scene by combining static 3D Gaussians with a Hexplane-based deformation field, which captures dynamic information. We then perform editing solely on the static 3D Gaussians, which is the minimal but sufficient component required for visual editing. To resolve the misalignment between the edited 3D Gaussians and the deformation field, which may arise from the editing process, we introduce a refinement stage using a score distillation mechanism. Extensive editing results demonstrate that Instruct-4DGS is efficient, reducing editing time by more than half compared to existing methods while achieving high-quality edits that better follow user instructions. Code and results: <a target="_blank" rel="noopener" href="https://hanbyelcho.info/instruct-4dgs/">https://hanbyelcho.info/instruct-4dgs/</a> </p>
<blockquote>
<p>æœ€è¿‘çš„4DåŠ¨æ€åœºæ™¯ç¼–è¾‘æ–¹æ³•éœ€è¦å¯¹ç”¨äºåŠ¨æ€åœºæ™¯åˆæˆçš„æ•°åƒå¼ 2Då›¾åƒè¿›è¡Œç¼–è¾‘ï¼Œå¹¶é€šè¿‡é¢å¤–çš„è®­ç»ƒå¾ªç¯æ›´æ–°æ•´ä¸ªåœºæ™¯ï¼Œå¯¼è‡´ç¼–è¾‘å•ä¸ªåŠ¨æ€åœºæ™¯éœ€è¦æ•°å°æ—¶çš„å¤„ç†æ—¶é—´ã€‚å› æ­¤ï¼Œè¿™äº›æ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯çš„æ—¶ç©ºç»´åº¦ä¸Šï¼ˆå³æ—¶åºæ•°é‡ï¼‰å¹¶ä¸å…·å¤‡å¯æ‰©å±•æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†Instruct-4DGSï¼Œä¸€ç§é«˜æ•ˆçš„åŠ¨æ€åœºæ™¯ç¼–è¾‘æ–¹æ³•ï¼Œåœ¨æ—¶ç©ºç»´åº¦ä¸Šæ›´å…·å¯æ‰©å±•æ€§ã€‚ä¸ºäº†å®ç°è®¡ç®—æ•ˆç‡ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§4Dé«˜æ–¯è¡¨ç¤ºæ³•ï¼Œé€šè¿‡ç»“åˆé™æ€3Dé«˜æ–¯å’ŒåŸºäºHexplaneçš„å˜å½¢åœºæ¥æ¨¡æ‹Ÿä¸€ä¸ª4DåŠ¨æ€åœºæ™¯ï¼Œå…¶ä¸­å˜å½¢åœºæ•æ‰åŠ¨æ€ä¿¡æ¯ã€‚ç„¶åï¼Œæˆ‘ä»¬ä»…åœ¨é™æ€çš„3Dé«˜æ–¯ä¸Šè¿›è¡Œç¼–è¾‘ï¼Œè¿™æ˜¯è§†è§‰ç¼–è¾‘æ‰€éœ€çš„æœ€å°ä½†è¶³å¤Ÿçš„ç»„ä»¶ã€‚ä¸ºäº†è§£å†³ç¼–è¾‘åçš„3Dé«˜æ–¯å’Œå˜å½¢åœºä¹‹é—´å¯èƒ½å‡ºç°çš„é”™ä½é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªä½¿ç”¨è¯„åˆ†è’¸é¦æœºåˆ¶çš„ä¼˜åŒ–é˜¶æ®µã€‚å¤§é‡çš„ç¼–è¾‘ç»“æœè¡¨æ˜ï¼ŒInstruct-4DGSæ˜¯é«˜æ•ˆçš„ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œç¼–è¾‘æ—¶é—´å‡å°‘äº†è¶…è¿‡ä¸€åŠï¼ŒåŒæ—¶å®ç°äº†é«˜è´¨é‡çš„ç¼–è¾‘ï¼Œæ›´å¥½åœ°éµå¾ªäº†ç”¨æˆ·çš„æŒ‡ä»¤ã€‚ç›¸å…³ä»£ç å’Œç»“æœå¯é€šè¿‡<a target="_blank" rel="noopener" href="https://hanbyelcho.info/instruct-4dgs/%E6%9F%A5%E7%9C%8B%E3%80%82">https://hanbyelcho.info/instruct-4dgs/æŸ¥çœ‹ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.02091v3">PDF</a> Accepted to CVPR 2025. The first two authors contributed equally</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå½“å‰å››ç»´åŠ¨æ€åœºæ™¯ç¼–è¾‘æ–¹æ³•éœ€è¦å¤„ç†æ•°åƒå¼ äºŒç»´å›¾åƒç”¨äºåŠ¨æ€åœºæ™¯åˆæˆï¼Œå¹¶ä¸”éœ€è¦é¢å¤–çš„è®­ç»ƒå¾ªç¯æ¥æ›´æ–°æ•´ä¸ªåœºæ™¯ï¼Œç¼–è¾‘å•ä¸ªåŠ¨æ€åœºæ™¯éœ€è¦æ•°å°æ—¶çš„å¤„ç†æ—¶é—´ã€‚å› æ­¤ï¼Œè¿™äº›æ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯çš„æ—¶ç©ºç»´åº¦ä¸Šå¹¶ä¸å…·å¤‡å¯æ‰©å±•æ€§ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„å››ç»´åŠ¨æ€åœºæ™¯ç¼–è¾‘æ–¹æ³•â€”â€”Instruct-4DGSï¼Œè¯¥æ–¹æ³•åœ¨æ—¶ç©ºç»´åº¦ä¸Šæ›´å…·å¯æ‰©å±•æ€§ã€‚ä¸ºæå‡è®¡ç®—æ•ˆç‡ï¼Œæœ¬ç ”ç©¶é‡‡ç”¨å››ç»´é«˜æ–¯è¡¨ç¤ºæ³•ï¼Œç»“åˆé™æ€ä¸‰ç»´é«˜æ–¯ä¸åŸºäºå…­å¹³é¢çš„å˜å½¢åœºæ¥æ¨¡æ‹Ÿå››ç»´åŠ¨æ€åœºæ™¯ã€‚ç¼–è¾‘è¿‡ç¨‹ä»…é’ˆå¯¹é™æ€ä¸‰ç»´é«˜æ–¯è¿›è¡Œï¼Œè¿™æ˜¯è§†è§‰ç¼–è¾‘æ‰€éœ€çš„æœ€å°ä¸”å……åˆ†çš„ç»„ä»¶ã€‚ä¸ºè§£å†³ç¼–è¾‘è¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„ç¼–è¾‘åçš„ä¸‰ç»´é«˜æ–¯ä¸å˜å½¢åœºä¹‹é—´çš„ä¸åŒ¹é…é—®é¢˜ï¼Œå¼•å…¥äº†ä¸€ç§åŸºäºåˆ†æ•°è’¸é¦çš„ç»†åŒ–é˜¶æ®µã€‚å¤§é‡çš„ç¼–è¾‘ç»“æœè¯æ˜ï¼ŒInstruct-4DGSæ–¹æ³•é«˜æ•ˆï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œç¼–è¾‘æ—¶é—´å‡å°‘äº†ä¸€åŠä»¥ä¸Šï¼ŒåŒæ—¶å®ç°äº†é«˜è´¨é‡çš„ç¼–è¾‘ï¼Œæ›´å¥½åœ°éµå¾ªäº†ç”¨æˆ·çš„æŒ‡ä»¤ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰å››ç»´åŠ¨æ€åœºæ™¯ç¼–è¾‘æ–¹æ³•å­˜åœ¨å¤„ç†æ—¶é—´é•¿ã€ä¸ä¾¿äºç¼–è¾‘å¤§é‡åŠ¨æ€åœºæ™¯çš„é—®é¢˜ã€‚</li>
<li>Instruct-4DGSæ–¹æ³•è¢«æå‡ºï¼Œä»¥æé«˜å››ç»´åŠ¨æ€åœºæ™¯ç¼–è¾‘çš„æ•ˆç‡ä¸æ—¶ç©ºç»´åº¦çš„å¯æ‰©å±•æ€§ã€‚</li>
<li>Instruct-4DGSé‡‡ç”¨å››ç»´é«˜æ–¯è¡¨ç¤ºæ³•ï¼Œç»“åˆé™æ€ä¸‰ç»´é«˜æ–¯ä¸åŸºäºå…­å¹³é¢çš„å˜å½¢åœºæ¥æ¨¡æ‹Ÿå’Œç¼–è¾‘å››ç»´åŠ¨æ€åœºæ™¯ã€‚</li>
<li>ç¼–è¾‘è¿‡ç¨‹ä¸»è¦é’ˆå¯¹é™æ€ä¸‰ç»´é«˜æ–¯è¿›è¡Œï¼Œè¿™æ˜¯è§†è§‰ç¼–è¾‘çš„æœ€å°ä¸”å……åˆ†ç»„ä»¶ã€‚</li>
<li>ä¸ºè§£å†³ç¼–è¾‘åå¯èƒ½å‡ºç°çš„ä¸‰ç»´é«˜æ–¯ä¸å˜å½¢åœºä¸åŒ¹é…é—®é¢˜ï¼Œå¼•å…¥äº†åŸºäºåˆ†æ•°è’¸é¦çš„ç»†åŒ–é˜¶æ®µã€‚</li>
<li>Instruct-4DGSæ–¹æ³•å¤§å¤§å‡å°‘äº†ç¼–è¾‘æ—¶é—´ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”æ•ˆç‡æé«˜ä¸€å€ä»¥ä¸Šã€‚</li>
<li>Instruct-4DGSå®ç°äº†é«˜è´¨é‡çš„ç¼–è¾‘ï¼Œæ›´å¥½åœ°éµå¾ªäº†ç”¨æˆ·çš„æŒ‡ä»¤ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.02091">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-e1dd46c4fa181424ce7db384ecef1e94.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d06d97a6a06d81f3261bfb33b2ed4644.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d373dba2b2e0eaced75c9e267c6117fd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6d0a47a1eecb653cfabe528e0b375132.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="GLS-Geometry-aware-3D-Language-Gaussian-Splatting"><a href="#GLS-Geometry-aware-3D-Language-Gaussian-Splatting" class="headerlink" title="GLS: Geometry-aware 3D Language Gaussian Splatting"></a>GLS: Geometry-aware 3D Language Gaussian Splatting</h2><p><strong>Authors:Jiaxiong Qiu, Liu Liu, Xinjie Wang, Tianwei Lin, Wei Sui, Zhizhong Su</strong></p>
<p>Recently, 3D Gaussian Splatting (3DGS) has achieved impressive performance on indoor surface reconstruction and 3D open-vocabulary segmentation. This paper presents GLS, a unified framework of 3D surface reconstruction and open-vocabulary segmentation based on 3DGS. GLS extends two fields by improving their sharpness and smoothness. For indoor surface reconstruction, we introduce surface normal prior as a geometric cue to guide the rendered normal, and use the normal error to optimize the rendered depth. For 3D open-vocabulary segmentation, we employ 2D CLIP features to guide instance features and enhance the surface smoothness, then utilize DEVA masks to maintain their view consistency. Extensive experiments demonstrate the effectiveness of jointly optimizing surface reconstruction and 3D open-vocabulary segmentation, where GLS surpasses state-of-the-art approaches of each task on MuSHRoom, ScanNet++ and LERF-OVS datasets. Project webpage: <a target="_blank" rel="noopener" href="https://jiaxiongq.github.io/GLS_ProjectPage">https://jiaxiongq.github.io/GLS_ProjectPage</a>. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œ3Dé«˜æ–¯è´´å›¾ï¼ˆ3DGSï¼‰åœ¨å®¤å†…è¡¨é¢é‡å»ºå’Œ3Då¼€æ”¾è¯æ±‡åˆ†å‰²æ–¹é¢å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ã€‚æœ¬æ–‡æå‡ºäº†åŸºäº3DGSçš„GLSï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„3Dè¡¨é¢é‡å»ºå’Œå¼€æ”¾è¯æ±‡åˆ†å‰²æ¡†æ¶ã€‚GLSé€šè¿‡æé«˜é”åº¦å’Œå¹³æ»‘åº¦æ¥æ‰©å±•è¿™ä¸¤ä¸ªé¢†åŸŸã€‚å¯¹äºå®¤å†…è¡¨é¢é‡å»ºï¼Œæˆ‘ä»¬å¼•å…¥è¡¨é¢æ³•çº¿å…ˆéªŒä½œä¸ºå‡ ä½•çº¿ç´¢æ¥å¼•å¯¼æ¸²æŸ“æ³•çº¿ï¼Œå¹¶ä½¿ç”¨æ³•çº¿è¯¯å·®æ¥ä¼˜åŒ–æ¸²æŸ“æ·±åº¦ã€‚å¯¹äº3Då¼€æ”¾è¯æ±‡åˆ†å‰²ï¼Œæˆ‘ä»¬é‡‡ç”¨2D CLIPç‰¹å¾æ¥å¼•å¯¼å®ä¾‹ç‰¹å¾å¹¶å¢å¼ºè¡¨é¢å¹³æ»‘åº¦ï¼Œç„¶åä½¿ç”¨DEVAé®ç½©æ¥ä¿æŒè§†å›¾ä¸€è‡´æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œè”åˆä¼˜åŒ–è¡¨é¢é‡å»ºå’Œ3Då¼€æ”¾è¯æ±‡åˆ†å‰²æ˜¯æœ‰æ•ˆçš„ï¼Œå…¶ä¸­GLSåœ¨MuSHRoomã€ScanNet++å’ŒLERF-OVSæ•°æ®é›†ä¸Šè¶…è¶Šäº†æ¯ä¸ªä»»åŠ¡çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚é¡¹ç›®ç½‘é¡µï¼š<a target="_blank" rel="noopener" href="https://jiaxiongq.github.io/GLS_ProjectPage%E3%80%82">https://jiaxiongq.github.io/GLS_ProjectPageã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.18066v2">PDF</a> Technical Report</p>
<p><strong>Summary</strong></p>
<p>åŸºäºä¸‰ç»´é«˜æ–¯æ‹¼è´´æŠ€æœ¯ï¼ˆ3DGSï¼‰ï¼Œæœ¬æ–‡æå‡ºäº†GLSç»Ÿä¸€æ¡†æ¶ï¼Œç”¨äºå®¤å†…è¡¨é¢é‡å»ºå’Œä¸‰ç»´å¼€æ”¾è¯æ±‡åˆ†å‰²ã€‚åœ¨å®¤å†…è¡¨é¢é‡å»ºæ–¹é¢ï¼Œå¼•å…¥æ³•çº¿å…ˆéªŒä½œä¸ºå‡ ä½•çº¿ç´¢æ¥æŒ‡å¯¼æ¸²æŸ“æ³•çº¿ï¼Œå¹¶åˆ©ç”¨æ³•çº¿è¯¯å·®ä¼˜åŒ–æ¸²æŸ“æ·±åº¦ã€‚åœ¨ä¸‰ç»´å¼€æ”¾è¯æ±‡åˆ†å‰²æ–¹é¢ï¼Œé‡‡ç”¨äºŒç»´CLIPç‰¹å¾å¼•å¯¼å®ä¾‹ç‰¹å¾å¹¶å¢å¼ºè¡¨é¢å¹³æ»‘åº¦ï¼Œåˆ©ç”¨DEVAæ©è†œä¿æŒè§†å›¾ä¸€è‡´æ€§ã€‚é€šè¿‡è”åˆä¼˜åŒ–è¡¨é¢é‡å»ºå’Œä¸‰ç»´å¼€æ”¾è¯æ±‡åˆ†å‰²ï¼ŒGLSåœ¨MuSHRoomã€ScanNet++å’ŒLERF-OVSæ•°æ®é›†ä¸Šçš„æ€§èƒ½è¶…è¶Šäº†å„ä»»åŠ¡çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä»‹ç»äº†åŸºäºä¸‰ç»´é«˜æ–¯æ‹¼è´´æŠ€æœ¯ï¼ˆ3DGSï¼‰çš„GLSç»Ÿä¸€æ¡†æ¶ï¼Œç”¨äºå®¤å†…è¡¨é¢é‡å»ºå’Œä¸‰ç»´å¼€æ”¾è¯æ±‡åˆ†å‰²ã€‚</li>
<li>åœ¨å®¤å†…è¡¨é¢é‡å»ºä¸­ï¼Œå¼•å…¥æ³•çº¿å…ˆéªŒä½œä¸ºå‡ ä½•çº¿ç´¢æŒ‡å¯¼æ¸²æŸ“æ³•çº¿ï¼Œå¹¶é€šè¿‡æ³•çº¿è¯¯å·®ä¼˜åŒ–æ¸²æŸ“æ·±åº¦ã€‚</li>
<li>é‡‡ç”¨äºŒç»´CLIPç‰¹å¾å¼•å¯¼å®ä¾‹ç‰¹å¾ï¼Œå¢å¼ºè¡¨é¢å¹³æ»‘åº¦ï¼Œå¹¶åˆ©ç”¨DEVAæ©è†œä¿æŒè§†å›¾ä¸€è‡´æ€§ã€‚</li>
<li>é€šè¿‡è”åˆä¼˜åŒ–è¡¨é¢é‡å»ºå’Œä¸‰ç»´å¼€æ”¾è¯æ±‡åˆ†å‰²ä»»åŠ¡ï¼ŒGLSåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„æ€§èƒ½è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚</li>
<li>GLSæ¡†æ¶æé«˜äº†ä¸¤ä¸ªé¢†åŸŸçš„æ¸…æ™°åº¦ä¸å¹³æ»‘åº¦ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.18066">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cae79a3f8826f4d9890ae02490f0f798.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-59c8f6e20226ebc1114941036502cd3d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e6d5e781e9fea9eaa5b7add8b69187c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a52dfcace7c2e4032d8f76e6ecd4f54d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bf52afaa2da9ba4f54dcec6e785977b0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0a7a81ad9d62cddff4435fb8258b824c.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-05/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-05/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-05/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-16256fb252544fb37bdf6def48db78c7.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-05  LocalDyGS Multi-view Global Dynamic Scene Modeling via Adaptive Local   Implicit Feature Decoupling
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-05/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-9e733f4b7900d962afc9d76566455a9d.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-05  HyperGaussians High-Dimensional Gaussian Splatting for High-Fidelity   Animatable Face Avatars
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">26024.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
