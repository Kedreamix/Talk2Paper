<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Vision Transformer">
    <meta name="description" content="Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-17  Change State Space Models for Remote Sensing Change Detection">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Vision Transformer | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-8f7b8a174a6d280d01c68d4b3cd9918d.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Vision Transformer</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Vision-Transformer/">
                                <span class="chip bg-color">Vision Transformer</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                Vision Transformer
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-17
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    5.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    22 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-17-æ›´æ–°"><a href="#2025-04-17-æ›´æ–°" class="headerlink" title="2025-04-17 æ›´æ–°"></a>2025-04-17 æ›´æ–°</h1><h2 id="Change-State-Space-Models-for-Remote-Sensing-Change-Detection"><a href="#Change-State-Space-Models-for-Remote-Sensing-Change-Detection" class="headerlink" title="Change State Space Models for Remote Sensing Change Detection"></a>Change State Space Models for Remote Sensing Change Detection</h2><p><strong>Authors:Elman Ghazaei, Erchan Aptoula</strong></p>
<p>Despite their frequent use for change detection, both ConvNets and Vision transformers (ViT) exhibit well-known limitations, namely the former struggle to model long-range dependencies while the latter are computationally inefficient, rendering them challenging to train on large-scale datasets. Vision Mamba, an architecture based on State Space Models has emerged as an alternative addressing the aforementioned deficiencies and has been already applied to remote sensing change detection, though mostly as a feature extracting backbone. In this article the Change State Space Model is introduced, that has been specifically designed for change detection by focusing on the relevant changes between bi-temporal images, effectively filtering out irrelevant information. By concentrating solely on the changed features, the number of network parameters is reduced, enhancing significantly computational efficiency while maintaining high detection performance and robustness against input degradation. The proposed model has been evaluated via three benchmark datasets, where it outperformed ConvNets, ViTs, and Mamba-based counterparts at a fraction of their computational complexity. The implementation will be made available at <a target="_blank" rel="noopener" href="https://github.com/Elman295/CSSM">https://github.com/Elman295/CSSM</a> upon acceptance. </p>
<blockquote>
<p>å°½ç®¡å·ç§¯ç¥ç»ç½‘ç»œï¼ˆConvNetsï¼‰å’Œè§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰ç»å¸¸ç”¨äºå˜åŒ–æ£€æµ‹ï¼Œä½†å®ƒä»¬éƒ½è¡¨ç°å‡ºäº†ä¸€äº›ä¼—æ‰€å‘¨çŸ¥çš„å±€é™æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œå‰è€…éš¾ä»¥å»ºæ¨¡é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œè€Œåè€…è®¡ç®—æ•ˆç‡ä½ä¸‹ï¼Œéš¾ä»¥åœ¨å¤§å‹æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚åŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹çš„Vision Mambaæ¶æ„ä½œä¸ºæ›¿ä»£æ–¹æ¡ˆåº”è¿è€Œç”Ÿï¼Œè§£å†³äº†ä¸Šè¿°ç¼ºé™·ï¼Œå¹¶å·²åº”ç”¨äºé¥æ„Ÿå˜åŒ–æ£€æµ‹ï¼Œä½†å¤§å¤šä½œä¸ºç‰¹å¾æå–çš„éª¨å¹²ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸“ä¸ºå˜åŒ–æ£€æµ‹è€Œè®¾è®¡çš„å˜åŒ–çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆChange State Space Modelï¼‰ã€‚è¯¥æ¨¡å‹å…³æ³¨åŒæ—¶æ€å›¾åƒä¹‹é—´çš„ç›¸å…³å˜åŒ–ï¼Œæœ‰æ•ˆåœ°è¿‡æ»¤äº†æ— å…³ä¿¡æ¯ã€‚é€šè¿‡ä¸“æ³¨äºå˜åŒ–ç‰¹å¾ï¼Œå‡å°‘äº†ç½‘ç»œå‚æ•°çš„æ•°é‡ï¼Œåœ¨ä¿æŒé«˜æ£€æµ‹æ€§èƒ½å’Œå¯¹æŠ—è¾“å…¥é€€åŒ–ç¨³å¥æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜äº†è®¡ç®—æ•ˆç‡ã€‚æ‰€æå‡ºçš„æ¨¡å‹é€šè¿‡ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†è¿›è¡Œäº†è¯„ä¼°ï¼Œåœ¨è®¡ç®—å¤æ‚åº¦è¾ƒä½çš„æƒ…å†µä¸‹ï¼Œå…¶æ€§èƒ½ä¼˜äºConvNetsã€ViTså’ŒåŸºäºMambaçš„åŒç±»æ¨¡å‹ã€‚ä»£ç å®ç°å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/Elman295/CSSM%EF%BC%88%E6%8E%A5%E5%8F%97%E5%90%8E%EF%BC%89%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/Elman295/CSSMï¼ˆæ¥å—åï¼‰æä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11080v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹å˜åŒ–æ£€æµ‹ä»»åŠ¡çš„æ–°å‹è§†è§‰æ¨¡å‹â€”â€”å˜åŒ–çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆCSSMï¼‰ã€‚è¯¥æ¨¡å‹åŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹è®¾è®¡ï¼Œæ—¨åœ¨è§£å†³å·ç§¯ç¥ç»ç½‘ç»œï¼ˆConvNetsï¼‰å’Œè§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰åœ¨å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†æ—¶çš„å±€é™æ€§ã€‚é€šè¿‡ä¸“æ³¨äºåŒæ—¶æ€å›¾åƒä¹‹é—´çš„ç›¸å…³å˜åŒ–ï¼ŒCSSMæœ‰æ•ˆè¿‡æ»¤æ‰æ— å…³ä¿¡æ¯ï¼Œå‡å°‘ç½‘ç»œå‚æ•°æ•°é‡ï¼Œæ˜¾è‘—æé«˜è®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶ä¿æŒè‰¯å¥½çš„æ£€æµ‹æ€§èƒ½å’ŒæŠ—è¾“å…¥å¹²æ‰°çš„é²æ£’æ€§ã€‚åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒCSSMåœ¨æ€§èƒ½ä¸Šä¼˜äºConvNetsã€ViTså’ŒåŸºäºMambaçš„æ¨¡å‹ï¼ŒåŒæ—¶è®¡ç®—å¤æ‚åº¦å¤§å¹…é™ä½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å˜åŒ–çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆCSSMï¼‰æ˜¯ä¸€ç§é’ˆå¯¹å˜åŒ–æ£€æµ‹ä»»åŠ¡çš„æ–°å‹è§†è§‰æ¨¡å‹ã€‚</li>
<li>CSSMè§£å†³äº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆConvNetsï¼‰å’Œè§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰åœ¨å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†æ—¶çš„å±€é™æ€§ã€‚</li>
<li>CSSMä¸“æ³¨äºåŒæ—¶æ€å›¾åƒä¹‹é—´çš„ç›¸å…³å˜åŒ–ï¼Œè¿‡æ»¤æ‰æ— å…³ä¿¡æ¯ã€‚</li>
<li>CSSMé€šè¿‡å‡å°‘ç½‘ç»œå‚æ•°æ•°é‡ï¼Œæ˜¾è‘—æé«˜äº†è®¡ç®—æ•ˆç‡ã€‚</li>
<li>CSSMåœ¨å˜åŒ–æ£€æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½å’ŒæŠ—è¾“å…¥å¹²æ‰°çš„é²æ£’æ€§ã€‚</li>
<li>åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒCSSMä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œå¦‚ConvNetsã€ViTså’ŒåŸºäºMambaçš„æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11080">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-e3782194bfd1ad99f41189f1eac62bff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-29aed1d18876211ccd99a301df1ddc0e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4b6bca0d15507cd5c258fbb78fa21745.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1d6251757da9ad7f137faba1c3474b19.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Embedding-Radiomics-into-Vision-Transformers-for-Multimodal-Medical-Image-Classification"><a href="#Embedding-Radiomics-into-Vision-Transformers-for-Multimodal-Medical-Image-Classification" class="headerlink" title="Embedding Radiomics into Vision Transformers for Multimodal Medical   Image Classification"></a>Embedding Radiomics into Vision Transformers for Multimodal Medical   Image Classification</h2><p><strong>Authors:Zhenyu Yang, Haiming Zhu, Rihui Zhang, Haipeng Zhang, Jianliang Wang, Chunhao Wang, Minbin Chen, Fang-Fang Yin</strong></p>
<p>Background: Deep learning has significantly advanced medical image analysis, with Vision Transformers (ViTs) offering a powerful alternative to convolutional models by modeling long-range dependencies through self-attention. However, ViTs are inherently data-intensive and lack domain-specific inductive biases, limiting their applicability in medical imaging. In contrast, radiomics provides interpretable, handcrafted descriptors of tissue heterogeneity but suffers from limited scalability and integration into end-to-end learning frameworks. In this work, we propose the Radiomics-Embedded Vision Transformer (RE-ViT) that combines radiomic features with data-driven visual embeddings within a ViT backbone.   Purpose: To develop a hybrid RE-ViT framework that integrates radiomics and patch-wise ViT embeddings through early fusion, enhancing robustness and performance in medical image classification.   Methods: Following the standard ViT pipeline, images were divided into patches. For each patch, handcrafted radiomic features were extracted and fused with linearly projected pixel embeddings. The fused representations were normalized, positionally encoded, and passed to the ViT encoder. A learnable [CLS] token aggregated patch-level information for classification. We evaluated RE-ViT on three public datasets (including BUSI, ChestXray2017, and Retinal OCT) using accuracy, macro AUC, sensitivity, and specificity. RE-ViT was benchmarked against CNN-based (VGG-16, ResNet) and hybrid (TransMed) models.   Results: RE-ViT achieved state-of-the-art results: on BUSI, AUC&#x3D;0.950+&#x2F;-0.011; on ChestXray2017, AUC&#x3D;0.989+&#x2F;-0.004; on Retinal OCT, AUC&#x3D;0.986+&#x2F;-0.001, which outperforms other comparison models.   Conclusions: The RE-ViT framework effectively integrates radiomics with ViT architectures, demonstrating improved performance and generalizability across multimodal medical image classification tasks. </p>
<blockquote>
<p>èƒŒæ™¯ï¼šæ·±åº¦å­¦ä¹ å·²ç»æ˜¾è‘—æ¨è¿›äº†åŒ»å­¦å›¾åƒåˆ†æçš„å‘å±•ã€‚é€šè¿‡è‡ªæ³¨æ„åŠ›è¿›è¡Œé•¿è·ç¦»ä¾èµ–å»ºæ¨¡ï¼ŒVision Transformerï¼ˆViTï¼‰ä¸ºå·ç§¯æ¨¡å‹æä¾›äº†å¼ºå¤§çš„æ›¿ä»£æ–¹æ¡ˆã€‚ç„¶è€Œï¼ŒViTæœ¬è´¨ä¸Šéœ€è¦å¤§é‡çš„æ•°æ®ï¼Œå¹¶ä¸”ç¼ºä¹ç‰¹å®šé¢†åŸŸçš„å½’çº³åè§ï¼Œè¿™åœ¨åŒ»å­¦å½±åƒä¸­é™åˆ¶äº†å…¶é€‚ç”¨æ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ”¾å°„ç»„å­¦æä¾›äº†å¯è§£é‡Šçš„ç»„ç»‡å¼‚è´¨æ€§æ‰‹å·¥æè¿°ç¬¦ï¼Œä½†å—é™äºå¯æ‰©å±•æ€§å’Œæ•´åˆåˆ°ç«¯åˆ°ç«¯å­¦ä¹ æ¡†æ¶çš„èƒ½åŠ›ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†Radiomics-Embedded Vision Transformerï¼ˆRE-ViTï¼‰ï¼Œå®ƒå°†æ”¾å°„ç»„å­¦ç‰¹å¾ä¸æ•°æ®é©±åŠ¨çš„è§†è§‰åµŒå…¥ç›¸ç»“åˆåœ¨ä¸€ä¸ªViTä¸»å¹²ä¸­ã€‚ç›®çš„ï¼šä¸ºäº†å¼€å‘ä¸€ä¸ªæ··åˆRE-ViTæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡æ—©æœŸèåˆæ•´åˆæ”¾å°„ç»„å­¦å’Œè¡¥ä¸å¼ViTåµŒå…¥ï¼Œæé«˜åœ¨åŒ»å­¦å›¾åƒåˆ†ç±»ä¸­çš„ç¨³å¥æ€§å’Œæ€§èƒ½ã€‚æ–¹æ³•ï¼šéµå¾ªæ ‡å‡†çš„ViTç®¡é“ï¼Œå›¾åƒè¢«åˆ†æˆè¡¥ä¸ã€‚å¯¹äºæ¯ä¸ªè¡¥ä¸ï¼Œæ‰‹å·¥æå–æ”¾å°„ç»„å­¦ç‰¹å¾å¹¶ä¸çº¿æ€§æŠ•å½±çš„åƒç´ åµŒå…¥èåˆã€‚èåˆåçš„è¡¨ç¤ºè¢«å½’ä¸€åŒ–ã€ä½ç½®ç¼–ç å¹¶ä¼ é€’ç»™ViTç¼–ç å™¨ã€‚ä¸€ä¸ªå¯å­¦ä¹ çš„[CLS]æ ‡è®°èšåˆäº†è¡¥ä¸çº§åˆ«çš„ä¿¡æ¯ç”¨äºåˆ†ç±»ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªå…¬å…±æ•°æ®é›†ï¼ˆåŒ…æ‹¬BUSIã€ChestXray2017å’ŒRetinal OCTï¼‰ä¸Šè¯„ä¼°äº†RE-ViTï¼Œä½¿ç”¨å‡†ç¡®åº¦ã€å®AUCã€çµæ•åº¦å’Œç‰¹å¼‚æ€§ã€‚RE-ViTä¸åŸºäºCNNï¼ˆVGG-16ã€ResNetï¼‰çš„æ¨¡å‹å’Œæ··åˆï¼ˆTransMedï¼‰æ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒã€‚ç»“æœï¼šRE-ViTè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æˆæœï¼šåœ¨BUSIä¸Šï¼ŒAUC&#x3D;0.950Â±0.011ï¼›åœ¨ChestXray2017ä¸Šï¼ŒAUC&#x3D;0.989Â±0.004ï¼›åœ¨è§†ç½‘è†œOCTä¸Šï¼ŒAUC&#x3D;0.986Â±0.001ï¼Œè¿™è¶…è¿‡äº†å…¶ä»–å¯¹æ¯”æ¨¡å‹çš„è¡¨ç°ã€‚ç»“è®ºï¼šRE-ViTæ¡†æ¶æœ‰æ•ˆåœ°å°†æ”¾å°„ç»„å­¦ä¸ViTæ¶æ„ç›¸ç»“åˆï¼Œæ˜¾ç¤ºå‡ºåœ¨å¤šæ¨¡æ€åŒ»å­¦å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­æ”¹è¿›çš„æ€§èƒ½å’Œé€šç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.10916v1">PDF</a> 27 pages, 3 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§èåˆæ”¾å°„ç»„å­¦ä¸Vision Transformerï¼ˆViTï¼‰çš„æ··åˆæ¡†æ¶RE-ViTï¼Œæ—¨åœ¨æé«˜åŒ»ç–—å›¾åƒåˆ†ç±»çš„ç¨³å¥æ€§å’Œæ€§èƒ½ã€‚RE-ViTç»“åˆäº†æ”¾å°„ç»„å­¦ç‰¹å¾å’Œæ•°æ®é©±åŠ¨çš„è§†è§‰åµŒå…¥ï¼Œé€šè¿‡æ—©æœŸèåˆç­–ç•¥å¢å¼ºåŒ»ç–—å›¾åƒåˆ†ç±»çš„é²æ£’æ€§å’Œæ€§èƒ½ã€‚åœ¨ä¸‰ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒRE-ViTè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶åœ¨ä¸åŒåŒ»ç–—å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­å±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RE-ViTç»“åˆäº†æ”¾å°„ç»„å­¦ç‰¹å¾ï¼ˆæ‰‹å·¥è‰ºå“ç‰¹å¾ï¼‰ä¸Vision Transformerï¼ˆViTï¼‰è¿›è¡Œæ•°æ®é©±åŠ¨çš„è§†è§‰åµŒå…¥ï¼Œå½¢æˆæ··åˆæ¡†æ¶ã€‚</li>
<li>RE-ViTé€šè¿‡æ—©æœŸèåˆç­–ç•¥ï¼Œå°†æ”¾å°„ç»„å­¦ç‰¹å¾ä¸ViTåµŒå…¥ç»“åˆï¼Œä»¥æé«˜åŒ»ç–—å›¾åƒåˆ†ç±»çš„ç¨³å¥æ€§å’Œæ€§èƒ½ã€‚</li>
<li>å®éªŒåœ¨ä¸‰ä¸ªå…¬å…±æ•°æ®é›†ä¸Šè¿›è¡Œï¼ŒåŒ…æ‹¬BUSIã€ChestXray2017å’ŒRetinal OCTï¼Œä½¿ç”¨å‡†ç¡®æ€§ã€å®è§‚AUCã€æ•æ„Ÿæ€§å’Œç‰¹å¼‚æ€§è¿›è¡Œè¯„ä¼°ã€‚</li>
<li>RE-ViTè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¡¨ç°å‡ºè¾ƒé«˜çš„åˆ†ç±»å‡†ç¡®æ€§ã€‚</li>
<li>RE-ViTæ¡†æ¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œé€‚ç”¨äºå¤šç§åŒ»ç–—å›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚</li>
<li>ä¸CNNå’Œæ··åˆæ¨¡å‹ç›¸æ¯”ï¼ŒRE-ViTå±•ç°å‡ºæ›´å¥½çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.10916">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-505f84406278995760475bf6673646d8.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="LPViT-Low-Power-Semi-structured-Pruning-for-Vision-Transformers"><a href="#LPViT-Low-Power-Semi-structured-Pruning-for-Vision-Transformers" class="headerlink" title="LPViT: Low-Power Semi-structured Pruning for Vision Transformers"></a>LPViT: Low-Power Semi-structured Pruning for Vision Transformers</h2><p><strong>Authors:Kaixin Xu, Zhe Wang, Chunyun Chen, Xue Geng, Jie Lin, Mohamed M. Sabry Aly, Xulei Yang, Min Wu, Xiaoli Li, Weisi Lin</strong></p>
<p>Vision transformers have emerged as a promising alternative to convolutional neural networks for various image analysis tasks, offering comparable or superior performance. However, one significant drawback of ViTs is their resource-intensive nature, leading to increased memory footprint, computation complexity, and power consumption. To democratize this high-performance technology and make it more environmentally friendly, it is essential to compress ViT models, reducing their resource requirements while maintaining high performance. In this paper, we introduce a new block-structured pruning to address the resource-intensive issue for ViTs, offering a balanced trade-off between accuracy and hardware acceleration. Unlike unstructured pruning or channel-wise structured pruning, block pruning leverages the block-wise structure of linear layers, resulting in more efficient matrix multiplications. To optimize this pruning scheme, our paper proposes a novel hardware-aware learning objective that simultaneously maximizes speedup and minimizes power consumption during inference, tailored to the block sparsity structure. This objective eliminates the need for empirical look-up tables and focuses solely on reducing parametrized layer connections. Moreover, our paper provides a lightweight algorithm to achieve post-training pruning for ViTs, utilizing second-order Taylor approximation and empirical optimization to solve the proposed hardware-aware objective. Extensive experiments on ImageNet are conducted across various ViT architectures, including DeiT-B and DeiT-S, demonstrating competitive performance with other pruning methods and achieving a remarkable balance between accuracy preservation and power savings. Especially, we achieve 3.93x speedup on dedicated hardware and GPUs respectively for DeiT-B, and a power reduction by 1.4x on GPUs. Code released to <a target="_blank" rel="noopener" href="https://github.com/Akimoto-Cris/LPViT">https://github.com/Akimoto-Cris/LPViT</a>. </p>
<blockquote>
<p>è§†è§‰è½¬æ¢å™¨ï¼ˆVision Transformersï¼‰ä½œä¸ºä¸€ç§æœ‰å‰æ™¯çš„æ›¿ä»£å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„æ–¹æ³•ï¼Œåœ¨å„ç§å›¾åƒåˆ†æä»»åŠ¡ä¸­å±•ç°å‡ºç›¸å½“æˆ–æ›´ä¼˜è¶Šçš„æ€§èƒ½ã€‚ç„¶è€Œï¼ŒViTsçš„ä¸€ä¸ªé‡å¤§ç¼ºç‚¹æ˜¯å®ƒä»¬èµ„æºå¯†é›†å‹çš„ç‰¹ç‚¹ï¼Œå¯¼è‡´å†…å­˜å ç”¨å¢åŠ ã€è®¡ç®—å¤æ‚æ€§å’ŒåŠŸè€—å¢åŠ ã€‚ä¸ºäº†æ™®åŠè¿™ç§é«˜æ€§èƒ½æŠ€æœ¯å¹¶ä½¿å…¶æ›´åŠ ç¯ä¿ï¼Œå‹ç¼©ViTæ¨¡å‹è‡³å…³é‡è¦ï¼Œåœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶å‡å°‘å…¶èµ„æºéœ€æ±‚ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„å—ç»“æ„åŒ–å‰ªææ¥è§£å†³ViTsçš„èµ„æºå¯†é›†é—®é¢˜ï¼Œåœ¨å‡†ç¡®åº¦å’Œç¡¬ä»¶åŠ é€Ÿä¹‹é—´å®ç°äº†å¹³è¡¡ã€‚ä¸ä¼ ç»Ÿçš„éç»“æ„åŒ–å‰ªææˆ–é€šé“ç»“æ„åŒ–å‰ªæä¸åŒï¼Œå—å‰ªæåˆ©ç”¨çº¿æ€§å±‚çš„å—ç»“æ„ï¼Œä»è€Œå®ç°æ›´æœ‰æ•ˆçš„çŸ©é˜µä¹˜æ³•ã€‚ä¸ºäº†ä¼˜åŒ–è¿™ç§å‰ªææ–¹æ¡ˆï¼Œæˆ‘ä»¬çš„è®ºæ–‡æå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„ç¡¬ä»¶æ„ŸçŸ¥å­¦ä¹ ç›®æ ‡ï¼ŒåŒæ—¶æœ€å¤§åŒ–æ¨ç†é€Ÿåº¦å¹¶æœ€å°åŒ–åŠŸè€—ï¼Œé’ˆå¯¹å—ç¨€ç–ç»“æ„è¿›è¡Œå®šåˆ¶ã€‚è¿™ä¸€ç›®æ ‡æ¶ˆé™¤äº†å¯¹ç»éªŒæŸ¥æ‰¾è¡¨çš„éœ€æ±‚ï¼Œå¹¶ä¸“æ³¨äºå‡å°‘å‚æ•°åŒ–å±‚è¿æ¥ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„è®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§è½»é‡çº§çš„ç®—æ³•æ¥å®ç°ViTsçš„è®­ç»ƒåå‰ªæï¼Œåˆ©ç”¨äºŒé˜¶æ³°å‹’è¿‘ä¼¼å’Œå®è¯ä¼˜åŒ–æ¥è§£å†³æ‰€æå‡ºçš„ç¡¬ä»¶æ„ŸçŸ¥ç›®æ ‡ã€‚åœ¨ImageNetä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œæ¶µç›–äº†å„ç§ViTæ¶æ„ï¼ŒåŒ…æ‹¬DeiT-Bå’ŒDeiT-Sï¼Œä¸ç°æœ‰å‰ªææ–¹æ³•ç›¸æ¯”å±•ç°å‡ºç«äº‰åŠ›ï¼Œå¹¶åœ¨ä¿æŒå‡†ç¡®åº¦å’ŒèŠ‚çœåŠŸè€—ä¹‹é—´å–å¾—äº†æ˜¾è‘—å¹³è¡¡ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬åœ¨ä¸“ç”¨ç¡¬ä»¶å’ŒGPUä¸Šä¸ºDeiT-Bå®ç°äº†3.93å€çš„åŠ é€Ÿï¼Œå¹¶åœ¨GPUä¸Šå®ç°äº†1.4å€çš„åŠŸè€—é™ä½ã€‚ä»£ç å·²å‘å¸ƒè‡³<a target="_blank" rel="noopener" href="https://github.com/Akimoto-Cris/LPViT%E3%80%82">https://github.com/Akimoto-Cris/LPViTã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.02068v5">PDF</a> </p>
<p><strong>Summary</strong><br>     è§†è§‰è½¬æ¢å™¨ï¼ˆVision Transformerï¼ŒViTï¼‰å·²æˆä¸ºå·ç§¯ç¥ç»ç½‘ç»œåœ¨å„ç§å›¾åƒåˆ†æä»»åŠ¡ä¸­çš„æœ‰å‰é€”çš„æ›¿ä»£å“ï¼Œå…¶æ€§èƒ½ç›¸å½“æˆ–æ›´ä¼˜è¶Šã€‚ç„¶è€Œï¼ŒViTçš„ä¸€å¤§ç¼ºç‚¹æ˜¯èµ„æºå¯†é›†ï¼Œå¯¼è‡´å†…å­˜å ç”¨ã€è®¡ç®—å¤æ‚æ€§å’ŒåŠŸè€—å¢åŠ ã€‚ä¸ºäº†æ™®åŠè¿™ç§é«˜æ€§èƒ½æŠ€æœ¯å¹¶ä½¿å…¶æ›´åŠ ç¯ä¿ï¼Œå‹ç¼©ViTæ¨¡å‹è‡³å…³é‡è¦ï¼Œéœ€è¦åœ¨å‡å°‘èµ„æºéœ€æ±‚çš„åŒæ—¶ä¿æŒé«˜æ€§èƒ½ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„å—ç»“æ„å‰ªææ¥è§£å†³ViTçš„èµ„æºå¯†é›†é—®é¢˜ï¼Œåœ¨å‡†ç¡®æ€§å’Œç¡¬ä»¶åŠ é€Ÿä¹‹é—´æä¾›äº†å¹³è¡¡ã€‚ä¸æ— ç»“æ„å‰ªææˆ–é€šé“ç»“æ„åŒ–å‰ªæä¸åŒï¼Œå—å‰ªæåˆ©ç”¨çº¿æ€§å±‚çš„å—ç»“æ„ï¼Œå®ç°æ›´æœ‰æ•ˆçš„çŸ©é˜µä¹˜æ³•ã€‚ä¸ºäº†ä¼˜åŒ–è¿™ç§å‰ªææ–¹æ¡ˆï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„ç¡¬ä»¶æ„ŸçŸ¥å­¦ä¹ ç›®æ ‡ï¼Œæ—¨åœ¨æœ€å¤§åŒ–é€Ÿåº¦å¹¶æœ€å°åŒ–æ¨ç†è¿‡ç¨‹ä¸­çš„åŠŸè€—ï¼Œé’ˆå¯¹å—ç¨€ç–ç»“æ„ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡æä¾›äº†ä¸€ç§è½»é‡çº§çš„ç®—æ³•ï¼Œç”¨äºåœ¨è®­ç»ƒåå¯¹ViTè¿›è¡Œå‰ªæï¼Œåˆ©ç”¨äºŒé˜¶æ³°å‹’è¿‘ä¼¼å’Œå®è¯ä¼˜åŒ–æ¥è§£å†³æ‰€æå‡ºçš„ç¡¬ä»¶æ„ŸçŸ¥ç›®æ ‡ã€‚åœ¨ImageNetä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œåœ¨å„ç§ViTæ¶æ„ä¸Šï¼ŒåŒ…æ‹¬DeiT-Bå’ŒDeiT-Sï¼Œè¯¥æ–¹æ³•åœ¨ç«äº‰æ¿€çƒˆçš„å‰ªææ–¹æ³•ä¸­è¡¨ç°å‡ºç«äº‰åŠ›ï¼Œå¹¶åœ¨ä¿æŒå‡†ç¡®æ€§å’ŒèŠ‚çœç”µåŠ›æ–¹é¢å–å¾—äº†æ˜¾è‘—å¹³è¡¡ã€‚ä»£ç å·²å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/Akimoto-Cris/LPViT%E3%80%82">https://github.com/Akimoto-Cris/LPViTã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è§†è§‰è½¬æ¢å™¨ï¼ˆVision Transformer, ViTï¼‰å·²æˆä¸ºå›¾åƒåˆ†æä»»åŠ¡ä¸­çš„æœ‰å‰é€”çš„CNNæ›¿ä»£å“ã€‚</li>
<li>ViTå­˜åœ¨èµ„æºå¯†é›†çš„é—®é¢˜ï¼Œå¯¼è‡´å†…å­˜å ç”¨ã€è®¡ç®—å¤æ‚æ€§å’ŒåŠŸè€—å¢åŠ ã€‚</li>
<li>å¼•å…¥æ–°çš„å—ç»“æ„å‰ªææ–¹æ³•æ¥è§£å†³ViTçš„èµ„æºå¯†é›†é—®é¢˜ï¼Œå®ç°å‡†ç¡®æ€§ä¸ç¡¬ä»¶åŠ é€Ÿä¹‹é—´çš„å¹³è¡¡ã€‚</li>
<li>å—å‰ªæåˆ©ç”¨çº¿æ€§å±‚çš„å—ç»“æ„ï¼Œä¸åŒäºæ— ç»“æ„å‰ªææˆ–é€šé“ç»“æ„åŒ–å‰ªæï¼Œæ›´åŠ é«˜æ•ˆã€‚</li>
<li>æå‡ºç¡¬ä»¶æ„ŸçŸ¥å­¦ä¹ ç›®æ ‡ï¼Œæ—¨åœ¨æœ€å¤§åŒ–é€Ÿåº¦å¹¶æœ€å°åŒ–æ¨ç†è¿‡ç¨‹ä¸­çš„åŠŸè€—ã€‚</li>
<li>æä¾›äº†ä¸€ç§è½»é‡çº§ç®—æ³•è¿›è¡Œè®­ç»ƒåå‰ªæï¼Œç»“åˆäºŒé˜¶æ³°å‹’è¿‘ä¼¼å’Œå®è¯ä¼˜åŒ–æ¥è§£å†³ç¡¬ä»¶æ„ŸçŸ¥ç›®æ ‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.02068">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8f8804e65a1d6e56b18052a13d1397c9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d879519260382cd6896916ff47e1a073.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="UniRGB-IR-A-Unified-Framework-for-Visible-Infrared-Semantic-Tasks-via-Adapter-Tuning"><a href="#UniRGB-IR-A-Unified-Framework-for-Visible-Infrared-Semantic-Tasks-via-Adapter-Tuning" class="headerlink" title="UniRGB-IR: A Unified Framework for Visible-Infrared Semantic Tasks via   Adapter Tuning"></a>UniRGB-IR: A Unified Framework for Visible-Infrared Semantic Tasks via   Adapter Tuning</h2><p><strong>Authors:Maoxun Yuan, Bo Cui, Tianyi Zhao, Jiayi Wang, Shan Fu, Xue Yang, Xingxing Wei</strong></p>
<p>Semantic analysis on visible (RGB) and infrared (IR) images has gained significant attention due to their enhanced accuracy and robustness under challenging conditions including low-illumination and adverse weather. However, due to the lack of pre-trained foundation models on the large-scale infrared image datasets, existing methods prefer to design task-specific frameworks and directly fine-tune them with pre-trained foundation models on their RGB-IR semantic relevance datasets, which results in poor scalability and limited generalization. To address these limitations, we propose UniRGB-IR, a scalable and efficient framework for RGB-IR semantic tasks that introduces a novel adapter mechanism to effectively incorporate rich multi-modal features into pre-trained RGB-based foundation models. Our framework comprises three key components: a vision transformer (ViT) foundation model, a Multi-modal Feature Pool (MFP) module, and a Supplementary Feature Injector (SFI) module. The MFP and SFI modules cooperate with each other as an adpater to effectively complement the ViT features with the contextual multi-scale features. During training process, we freeze the entire foundation model to inherit prior knowledge and only optimize the MFP and SFI modules. Furthermore, to verify the effectiveness of our framework, we utilize the ViT-Base as the pre-trained foundation model to perform extensive experiments. Experimental results on various RGB-IR semantic tasks demonstrate that our method can achieve state-of-the-art performance. The source code and results are available at <a target="_blank" rel="noopener" href="https://github.com/PoTsui99/UniRGB-IR.git">https://github.com/PoTsui99/UniRGB-IR.git</a>. </p>
<blockquote>
<p>é’ˆå¯¹å¯è§å…‰ï¼ˆRGBï¼‰å’Œçº¢å¤–ï¼ˆIRï¼‰å›¾åƒçš„è¯­ä¹‰åˆ†æå› å…¶èƒ½åœ¨ä½å…‰ç…§å’Œæ¶åŠ£å¤©æ°”ç­‰æŒ‘æˆ˜æ€§æ¡ä»¶ä¸‹æé«˜å‡†ç¡®æ€§å’Œç¨³å¥æ€§è€Œå—åˆ°å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹å¤§è§„æ¨¡çº¢å¤–å›¾åƒæ•°æ®é›†ä¸Šçš„é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹ï¼Œç°æœ‰æ–¹æ³•æ›´å€¾å‘äºè®¾è®¡é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„æ¡†æ¶ï¼Œå¹¶ä½¿ç”¨é¢„è®­ç»ƒçš„RGB-IRè¯­ä¹‰ç›¸å…³æ€§æ•°æ®é›†å¯¹å…¶è¿›è¡Œå¾®è°ƒï¼Œè¿™å¯¼è‡´äº†è¾ƒå·®çš„å¯æ‰©å±•æ€§å’Œæœ‰é™çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†UniRGB-IRï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºRGB-IRè¯­ä¹‰ä»»åŠ¡çš„å¯æ‰©å±•ä¸”é«˜æ•ˆçš„æ¡†æ¶ï¼Œå®ƒå¼•å…¥äº†ä¸€ç§æ–°çš„é€‚é…å™¨æœºåˆ¶ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å°†ä¸°å¯Œçš„å¤šæ¨¡å¼ç‰¹å¾èå…¥åˆ°åŸºäºé¢„è®­ç»ƒRGBçš„åŸºç¡€æ¨¡å‹ä¸­ã€‚æˆ‘ä»¬çš„æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šè§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰åŸºç¡€æ¨¡å‹ã€å¤šæ¨¡å¼ç‰¹å¾æ± ï¼ˆMFPï¼‰æ¨¡å—å’Œè¡¥å……ç‰¹å¾æ³¨å…¥å™¨ï¼ˆSFIï¼‰æ¨¡å—ã€‚MFPå’ŒSFIæ¨¡å—ç›¸äº’åä½œï¼Œä½œä¸ºé€‚é…å™¨ï¼Œæœ‰æ•ˆåœ°å°†ä¸Šä¸‹æ–‡å¤šå°ºåº¦ç‰¹å¾ä¸ViTç‰¹å¾ç›¸ç»“åˆã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å†»ç»“æ•´ä¸ªåŸºç¡€æ¨¡å‹ä»¥ç»§æ‰¿å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶ä»…ä¼˜åŒ–MFPå’ŒSFIæ¨¡å—ã€‚æ­¤å¤–ï¼Œä¸ºäº†éªŒè¯æˆ‘ä»¬æ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬åˆ©ç”¨ViT-Baseä½œä¸ºé¢„è®­ç»ƒåŸºç¡€æ¨¡å‹è¿›è¡Œäº†å¤§é‡å®éªŒã€‚åœ¨å„ç§RGB-IRè¯­ä¹‰ä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥è¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æºä»£ç å’Œç»“æœå¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/PoTsui99/UniRGB-IR.git">https://github.com/PoTsui99/UniRGB-IR.git</a>è·å¾—ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.17360v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§é’ˆå¯¹RGB-IRè¯­ä¹‰ä»»åŠ¡çš„å¯æ‰©å±•ä¸”é«˜æ•ˆçš„æ¡†æ¶UniRGB-IRï¼Œé€šè¿‡å¼•å…¥æ–°å‹é€‚é…å™¨æœºåˆ¶ï¼Œæœ‰æ•ˆæ•´åˆå¤šæ¨¡æ€ç‰¹å¾åˆ°é¢„è®­ç»ƒçš„RGBåŸºç¡€æ¨¡å‹ä¸­ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šè§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰åŸºç¡€æ¨¡å‹ã€å¤šæ¨¡æ€ç‰¹å¾æ± ï¼ˆMFPï¼‰æ¨¡å—å’Œè¡¥å……ç‰¹å¾æ³¨å…¥å™¨ï¼ˆSFIï¼‰æ¨¡å—ã€‚é€šè¿‡å†»ç»“åŸºç¡€æ¨¡å‹ï¼Œä»…ä¼˜åŒ–MFPå’ŒSFIæ¨¡å—ï¼Œå®ç°çŸ¥è¯†çš„ç»§æ‰¿ä¸å¤šå°ºåº¦ç‰¹å¾çš„ä¸Šä¸‹æ–‡è¡¥å……ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§RGB-IRè¯­ä¹‰ä»»åŠ¡ä¸Šè¾¾åˆ°å…ˆè¿›æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>UniRGB-IRæ˜¯ä¸€ä¸ªé’ˆå¯¹RGB-IRè¯­ä¹‰ä»»åŠ¡çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹çº¢å¤–å›¾åƒæ—¶çš„å¯æ‰©å±•æ€§å’Œæ³›åŒ–èƒ½åŠ›é—®é¢˜ã€‚</li>
<li>è¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ç§æ–°å‹é€‚é…å™¨æœºåˆ¶ï¼Œé€šè¿‡å¤šæ¨¡æ€ç‰¹å¾æ± ï¼ˆMFPï¼‰å’Œè¡¥å……ç‰¹å¾æ³¨å…¥å™¨ï¼ˆSFIï¼‰æ¨¡å—ï¼Œæœ‰æ•ˆæ•´åˆRGBå’Œçº¢å¤–å›¾åƒçš„å¤šæ¨¡æ€ç‰¹å¾ã€‚</li>
<li>UniRGB-IRé‡‡ç”¨é¢„è®­ç»ƒçš„RGBåŸºç¡€æ¨¡å‹ï¼Œå¦‚ViT-Baseï¼Œå¹¶é€šè¿‡å†»ç»“åŸºç¡€æ¨¡å‹ï¼Œåªä¼˜åŒ–MFPå’ŒSFIæ¨¡å—ï¼Œå®ç°çŸ¥è¯†çš„ç»§æ‰¿ä¸ä¼˜åŒ–ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒUniRGB-IRåœ¨å¤šç§RGB-IRè¯­ä¹‰ä»»åŠ¡ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>è¯¥æ¡†æ¶çš„æºä»£ç å’Œå®éªŒç»“æœå·²å…¬å¼€ï¼Œä¾¿äºåç»­ç ”ç©¶ä¸åº”ç”¨ã€‚</li>
<li>UniRGB-IRæ¡†æ¶é€‚ç”¨äºä½å…‰ç…§å’Œæ¶åŠ£å¤©æ°”ç­‰æŒ‘æˆ˜æ¡ä»¶ä¸‹çš„å›¾åƒè¯­ä¹‰åˆ†æã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.17360">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-41e8bde89f49d9ffa54a124f15a53fdb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-80edde3f2b07e552c96c68249a8661c9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-caee71a514f3d084c4b8dbd22d314f4d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f23370227642587eeddbe429715ca33.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d5c9e6f430e7650b4cf199a86311ac19.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-598ee1091ca014a2f7d8d14d6eb5b700.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="MIMIR-Masked-Image-Modeling-for-Mutual-Information-based-Adversarial-Robustness"><a href="#MIMIR-Masked-Image-Modeling-for-Mutual-Information-based-Adversarial-Robustness" class="headerlink" title="MIMIR: Masked Image Modeling for Mutual Information-based Adversarial   Robustness"></a>MIMIR: Masked Image Modeling for Mutual Information-based Adversarial   Robustness</h2><p><strong>Authors:Xiaoyun Xu, Shujian Yu, Zhuoran Liu, Stjepan Picek</strong></p>
<p>Vision Transformers (ViTs) have emerged as a fundamental architecture and serve as the backbone of modern vision-language models. Despite their impressive performance, ViTs exhibit notable vulnerability to evasion attacks, necessitating the development of specialized Adversarial Training (AT) strategies tailored to their unique architecture. While a direct solution might involve applying existing AT methods to ViTs, our analysis reveals significant incompatibilities, particularly with state-of-the-art (SOTA) approaches such as Generalist (CVPR 2023) and DBAT (USENIX Security 2024). This paper presents a systematic investigation of adversarial robustness in ViTs and provides a novel theoretical Mutual Information (MI) analysis in its autoencoder-based self-supervised pre-training. Specifically, we show that MI between the adversarial example and its latent representation in ViT-based autoencoders should be constrained via derived MI bounds. Building on this insight, we propose a self-supervised AT method, MIMIR, that employs an MI penalty to facilitate adversarial pre-training by masked image modeling with autoencoders. Extensive experiments on CIFAR-10, Tiny-ImageNet, and ImageNet-1K show that MIMIR can consistently provide improved natural and robust accuracy, where MIMIR outperforms SOTA AT results on ImageNet-1K. Notably, MIMIR demonstrates superior robustness against unforeseen attacks and common corruption data and can also withstand adaptive attacks where the adversary possesses full knowledge of the defense mechanism. </p>
<blockquote>
<p>è§†è§‰è½¬æ¢å™¨ï¼ˆViTsï¼‰å·²ç»æˆä¸ºä¸€ç§åŸºæœ¬æ¶æ„ï¼Œå¹¶ä½œä¸ºç°ä»£è§†è§‰è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒã€‚å°½ç®¡ViTsæ€§èƒ½ä»¤äººå°è±¡æ·±åˆ»ï¼Œä½†å®ƒä»¬å¯¹é€ƒé¿æ”»å‡»è¡¨ç°å‡ºæ˜æ˜¾çš„è„†å¼±æ€§ï¼Œå› æ­¤éœ€è¦é’ˆå¯¹å…¶ç‹¬ç‰¹æ¶æ„å¼€å‘ä¸“é—¨çš„å¯¹æŠ—æ€§è®­ç»ƒï¼ˆATï¼‰ç­–ç•¥ã€‚è™½ç„¶ç›´æ¥è§£å†³æ–¹æ¡ˆå¯èƒ½æ¶‰åŠå°†ç°æœ‰ATæ–¹æ³•åº”ç”¨äºViTsï¼Œä½†æˆ‘ä»¬çš„åˆ†ææ­ç¤ºäº†é‡å¤§ä¸å…¼å®¹é—®é¢˜ï¼Œå°¤å…¶æ˜¯ä¸æœ€æ–°ï¼ˆSOTAï¼‰æ–¹æ³•å¦‚Generalistï¼ˆCVPR 2023ï¼‰å’ŒDBATï¼ˆUSENIX Security 2024ï¼‰ã€‚æœ¬æ–‡ç³»ç»Ÿåœ°ç ”ç©¶äº†ViTsä¸­çš„å¯¹æŠ—æ€§ç¨³å¥æ€§ï¼Œå¹¶åœ¨å…¶åŸºäºè‡ªç¼–ç å™¨çš„è‡ªç›‘ç£é¢„è®­ç»ƒä¸­æä¾›äº†æ–°å‹ç†è®ºä¸Šçš„äº’ä¿¡æ¯ï¼ˆMIï¼‰åˆ†æã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è¡¨æ˜ï¼ŒViTåŸºè‡ªç¼–ç å™¨ä¸­çš„å¯¹æŠ—æ ·æœ¬ä¸å…¶æ½œåœ¨è¡¨ç¤ºçš„äº’ä¿¡æ¯åº”é€šè¿‡æ¨å¯¼çš„MIè¾¹ç•Œæ¥çº¦æŸã€‚åŸºäºè¿™ä¸€è§è§£ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è‡ªç›‘ç£ATæ–¹æ³•MIMIRï¼Œè¯¥æ–¹æ³•é‡‡ç”¨MIæƒ©ç½šæªæ–½ï¼Œé€šè¿‡å¸¦æœ‰è‡ªç¼–ç å™¨çš„æ©ç å›¾åƒå»ºæ¨¡æ¥ä¿ƒè¿›å¯¹æŠ—æ€§é¢„è®­ç»ƒã€‚åœ¨CIFAR-10ã€Tiny-ImageNetå’ŒImageNet-1Kä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒMIMIRå¯ä»¥æŒç»­æä¾›æ”¹è¿›çš„è‡ªç„¶å’Œç¨³å¥ç²¾åº¦ï¼Œå¹¶ä¸”åœ¨ImageNet-1Kä¸ŠMIMIRè¶…è¶Šäº†SOTA ATçš„ç»“æœã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒMIMIRåœ¨åº”å¯¹æœªæ›¾é¢„è§åˆ°çš„æ”»å‡»å’Œå¸¸è§è…è´¥æ•°æ®æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„ç¨³å¥æ€§ï¼Œå¹¶ä¸”èƒ½å¤Ÿåœ¨å¯¹æ‰‹å®Œå…¨äº†è§£é˜²å¾¡æœºåˆ¶çš„æƒ…å†µä¸‹æŠµå¾¡é€‚åº”æ€§æ”»å‡»ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.04960v4">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ç ”ç©¶äº†Vision Transformersï¼ˆViTsï¼‰åœ¨é¢ä¸´å¯¹æŠ—æ€§æ”»å‡»æ—¶çš„è„†å¼±æ€§ï¼Œå¹¶æå‡ºäº†ä¸€ç§é’ˆå¯¹ViTsçš„è‡ªç›‘ç£å¯¹æŠ—è®­ç»ƒï¼ˆMIMIRï¼‰æ–¹æ³•ã€‚è¯¥æ–¹æ³•åŸºäºäº’ä¿¡æ¯ï¼ˆMIï¼‰ç†è®ºï¼Œé€šè¿‡çº¦æŸå¯¹æŠ—æ ·æœ¬ä¸ViTè‡ªç¼–ç å™¨æ½œè¡¨å¾ä¹‹é—´çš„äº’ä¿¡æ¯ï¼Œæé«˜äº†æ¨¡å‹çš„é²æ£’æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒMIMIRåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šèƒ½æ˜¾è‘—æé«˜è‡ªç„¶å’Œé²æ£’ç²¾åº¦ï¼Œå¹¶å¯¹æœªçŸ¥æ”»å‡»å’Œå¸¸è§è…è´¥æ•°æ®å…·æœ‰ä¼˜ç§€æŠ—æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Vision Transformers (ViTs) é¢ä¸´å¯¹æŠ—æ€§æ”»å‡»çš„å¨èƒï¼Œéœ€è¦ä¸“é—¨çš„å¯¹æŠ—è®­ç»ƒï¼ˆATï¼‰ç­–ç•¥ã€‚</li>
<li>ç°æœ‰å…ˆè¿›ï¼ˆSOTAï¼‰çš„ATæ–¹æ³•åœ¨ä¸ViTsç»“åˆæ—¶å­˜åœ¨ä¸å…¼å®¹é—®é¢˜ã€‚</li>
<li>è®ºæ–‡æå‡ºé€šè¿‡çº¦æŸå¯¹æŠ—æ ·æœ¬ä¸ViTè‡ªç¼–ç å™¨æ½œè¡¨å¾ä¹‹é—´çš„äº’ä¿¡æ¯ï¼ˆMIï¼‰æ¥æé«˜ViTsçš„é²æ£’æ€§ã€‚</li>
<li>åŸºäºæ­¤ç†è®ºï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§è‡ªç›‘ç£çš„ATæ–¹æ³•MIMIRã€‚</li>
<li>MIMIRåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®éªŒï¼Œè¡¨ç°ä¼˜äºSOTAçš„ATç»“æœã€‚</li>
<li>MIMIRå¯¹æœªçŸ¥æ”»å‡»å’Œå¸¸è§è…è´¥æ•°æ®å…·æœ‰ä¼˜ç§€æŠ—æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.04960">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-8f7b8a174a6d280d01c68d4b3cd9918d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a53f0ad6e4f5226ce2b052fe11d0aa19.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dbecefac981833635773952f2f5707e5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6cbc0c3c1d426ad95876c28940e6b837.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-875c355639c9fcc2b2acbbdae45940ba.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df7a703d08900e8f8ad29aca87e9aba8.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-17/Vision%20Transformer/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-17/Vision%20Transformer/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Vision-Transformer/">
                                    <span class="chip bg-color">Vision Transformer</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-17/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-d9abc869a1d60e0447e6d590f9dddba9.jpg" class="responsive-img" alt="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
                        
                        <span class="card-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-17  Mamba as a Bridge Where Vision Foundation Models Meet Vision Language   Models for Domain-Generalized Semantic Segmentation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-17
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                    æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                        <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-17/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-1a660aeef8fff09fd8610328845bcb27.jpg" class="responsive-img" alt="è§†é¢‘ç†è§£">
                        
                        <span class="card-title">è§†é¢‘ç†è§£</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            è§†é¢‘ç†è§£ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-17  PVUW 2025 Challenge Report Advances in Pixel-level Understanding of   Complex Videos in the Wild
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-17
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/" class="post-category">
                                    è§†é¢‘ç†è§£
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                        <span class="chip bg-color">è§†é¢‘ç†è§£</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32102k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
