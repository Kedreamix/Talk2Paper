<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-19  Prompt-Guided Spatial Understanding with RGB-D Transformers for   Fine-Grained Object Relation Reasoning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-e6ae81fb6af72e956905e01558e482dc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812539&auth_key=1760812539-0-0-59beb2fc73107975a8ede6dc09e6a3fc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-19
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-05
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    20.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    82 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-19-æ›´æ–°"><a href="#2025-10-19-æ›´æ–°" class="headerlink" title="2025-10-19 æ›´æ–°"></a>2025-10-19 æ›´æ–°</h1><h2 id="Prompt-Guided-Spatial-Understanding-with-RGB-D-Transformers-for-Fine-Grained-Object-Relation-Reasoning"><a href="#Prompt-Guided-Spatial-Understanding-with-RGB-D-Transformers-for-Fine-Grained-Object-Relation-Reasoning" class="headerlink" title="Prompt-Guided Spatial Understanding with RGB-D Transformers for   Fine-Grained Object Relation Reasoning"></a>Prompt-Guided Spatial Understanding with RGB-D Transformers for   Fine-Grained Object Relation Reasoning</h2><p><strong>Authors:Tanner Muturi, Blessing Agyei Kyem, Joshua Kofi Asamoah, Neema Jakisa Owor, Richard Dyzinela, Andrews Danyo, Yaw Adu-Gyamfi, Armstrong Aboah</strong></p>
<p>Spatial reasoning in large-scale 3D environments such as warehouses remains a significant challenge for vision-language systems due to scene clutter, occlusions, and the need for precise spatial understanding. Existing models often struggle with generalization in such settings, as they rely heavily on local appearance and lack explicit spatial grounding. In this work, we introduce a dedicated spatial reasoning framework for the Physical AI Spatial Intelligence Warehouse dataset introduced in the Track 3 2025 AI City Challenge. Our approach enhances spatial comprehension by embedding mask dimensions in the form of bounding box coordinates directly into the input prompts, enabling the model to reason over object geometry and layout. We fine-tune the framework across four question categories namely: Distance Estimation, Object Counting, Multi-choice Grounding, and Spatial Relation Inference using task-specific supervision. To further improve consistency with the evaluation system, normalized answers are appended to the GPT response within the training set. Our comprehensive pipeline achieves a final score of 73.0606, placing 4th overall on the public leaderboard. These results demonstrate the effectiveness of structured prompt enrichment and targeted optimization in advancing spatial reasoning for real-world industrial environments. </p>
<blockquote>
<p>åœ¨å¤§è§„æ¨¡ä¸‰ç»´ç¯å¢ƒï¼ˆå¦‚ä»“åº“ï¼‰ä¸­ï¼Œç©ºé—´æ¨ç†å¯¹äºè§†è§‰è¯­è¨€ç³»ç»Ÿæ¥è¯´ä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ï¼Œå› ä¸ºåœºæ™¯æ‚ä¹±ã€é®æŒ¡å’Œéœ€è¦ç²¾ç¡®çš„ç©ºé—´ç†è§£ã€‚ç°æœ‰æ¨¡å‹å¾€å¾€åœ¨è¿™æ ·çš„ç¯å¢ƒä¸­éš¾ä»¥è¿›è¡Œæ³›åŒ–ï¼Œå› ä¸ºå®ƒä»¬è¿‡äºä¾èµ–å±€éƒ¨å¤–è§‚ï¼Œå¹¶ä¸”ç¼ºä¹æ˜ç¡®çš„ç©ºé—´å®šä½ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é’ˆå¯¹Physical AI Spatial Intelligence Warehouseæ•°æ®é›†ï¼ˆè¯¥æ•°æ®é›†åœ¨2025å¹´AIåŸå¸‚æŒ‘æˆ˜èµ›Track 3ä¸­å¼•å…¥ï¼‰è®¾è®¡äº†ä¸€ä¸ªä¸“ç”¨çš„ç©ºé—´æ¨ç†æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡åµŒå…¥é®æŒ¡ç»´åº¦çš„æ–¹å¼ï¼ˆä»¥è¾¹ç•Œæ¡†åæ ‡çš„å½¢å¼ï¼‰ç›´æ¥åµŒå…¥åˆ°è¾“å…¥æç¤ºä¸­ï¼Œä»è€Œæé«˜ç©ºé—´ç†è§£èƒ½åŠ›ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ¨ç†ç‰©ä½“çš„å‡ ä½•å½¢çŠ¶å’Œå¸ƒå±€ã€‚æˆ‘ä»¬é’ˆå¯¹å››ç§é—®é¢˜ç±»åˆ«å¯¹æ¡†æ¶è¿›è¡Œäº†å¾®è°ƒï¼Œåˆ†åˆ«æ˜¯ï¼šè·ç¦»ä¼°è®¡ã€å¯¹è±¡è®¡æ•°ã€å¤šé€‰æ‹©å®šä½ä»¥åŠç©ºé—´å…³ç³»æ¨ç†ï¼Œé‡‡ç”¨äº†ç‰¹å®šä»»åŠ¡çš„ç›‘ç£æ–¹å¼ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜ä¸è¯„ä¼°ç³»ç»Ÿçš„ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒé›†ä¸­å°†æ ‡å‡†åŒ–ç­”æ¡ˆé™„åŠ åˆ°GPTå“åº”ä¸­ã€‚æˆ‘ä»¬çš„ç»¼åˆç®¡é“æœ€ç»ˆå¾—åˆ†73.0606ï¼Œåœ¨å…¬å¼€æ’è¡Œæ¦œä¸Šæ’åç¬¬å››ã€‚è¿™äº›ç»“æœè¯æ˜äº†ç»“æ„åŒ–æç¤ºä¸°å¯Œå’Œé’ˆå¯¹æ€§ä¼˜åŒ–åœ¨æ¨åŠ¨ç°å®ä¸–ç•Œå·¥ä¸šç¯å¢ƒä¸­çš„ç©ºé—´æ¨ç†æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.11996v1">PDF</a> The paper was accepted at ICCV Conference 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬å·¥ä½œé’ˆå¯¹å¤§è§„æ¨¡ä¸‰ç»´ç¯å¢ƒï¼ˆå¦‚ä»“åº“ï¼‰ä¸­çš„ç©ºé—´æ¨ç†æå‡ºäº†ä¸€ä¸ªä¸“ç”¨ç©ºé—´æ¨ç†æ¡†æ¶ï¼Œè§£å†³äº†åœºæ™¯æ‚ä¹±ã€é®æŒ¡å’Œç²¾ç¡®ç©ºé—´ç†è§£çš„éœ€æ±‚ç­‰æŒ‘æˆ˜ã€‚é€šè¿‡åµŒå…¥æ©æ¨¡ç»´åº¦ï¼ˆä»¥è¾¹ç•Œæ¡†åæ ‡çš„å½¢å¼ï¼‰åˆ°è¾“å…¥æç¤ºä¸­ï¼Œå¢å¼ºäº†æ¨¡å‹å¯¹ç‰©ä½“å‡ ä½•å’Œå¸ƒå±€çš„ç†è§£èƒ½åŠ›ã€‚é€šè¿‡é’ˆå¯¹å››ç§é—®é¢˜ç±»åˆ«è¿›è¡Œå¾®è°ƒï¼ŒåŒ…æ‹¬è·ç¦»ä¼°è®¡ã€å¯¹è±¡è®¡æ•°ã€å¤šé€‰æ‹©å®šä½ä»¥åŠç©ºé—´å…³ç³»æ¨ç†ç­‰ä»»åŠ¡ç‰¹å®šç›‘ç£æ–¹æ³•ï¼Œå¹¶ç»“åˆè¯„ä»·ç³»ç»Ÿçš„æ ‡å‡†åŒ–ç­”æ¡ˆè¿›è¡Œè®­ç»ƒé›†å†…çš„å“åº”è¾“å‡ºä¼˜åŒ–ã€‚è¯¥æ–¹æ³•åœ¨å·¥ä¸šç¯å¢ƒä¸­å…·æœ‰æ˜¾è‘—çš„å®è·µåº”ç”¨æ½œåŠ›ã€‚æœ¬ç ”ç©¶è·å¾—äº†æ˜¾è‘—æˆæ•ˆï¼Œå…¬å¼€æ’è¡Œæ¦œä¸­ä½å±…ç¬¬å››åï¼Œå±•ç¤ºç»“æ„æç¤ºä¸°å¯Œå’Œé’ˆå¯¹æ€§ä¼˜åŒ–çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹æ˜¯æ–‡ä¸­å…³äºç©ºé—´æ¨ç†çš„ä¸ƒä¸ªå…³é”®è¦ç‚¹ï¼š</p>
<ul>
<li>é’ˆå¯¹ä»“åº“ç­‰å¤§å‹ä¸‰ç»´ç¯å¢ƒä¸­çš„ç©ºé—´æ¨ç†å¯¹è§†è§‰è¯­è¨€ç³»ç»Ÿä»æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚è¿™æ˜¯å› ä¸ºå­˜åœ¨åœºæ™¯æ··ä¹±ã€é®æŒ¡ç­‰é—®é¢˜éœ€è¦ç²¾ç¡®çš„çš„ç©ºé—´ç†è§£èƒ½åŠ›ã€‚</li>
<li>è®¸å¤šç°æœ‰çš„æ¨¡å‹åœ¨é¢å¯¹æ­¤ç±»ç¯å¢ƒæ—¶æ— æ³•æœ‰æ•ˆè¿›è¡Œæ¨å¹¿ï¼Œå› ä¸ºå®ƒä»¬ä¾èµ–äºå±€éƒ¨å¤–è§‚å¹¶ç¼ºä¹æ˜ç¡®çš„ç©ºé—´å®šä½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.11996">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-9f3eebe47c7d465d01f232b2a833dfdc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812320&auth_key=1760812320-0-0-72bc39b87c133dc8802dc5d16cbd8c75&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2114d5d08afa1fa61e79b063f681ceeb~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812327&auth_key=1760812327-0-0-04fa25eb5246bf361702b13d54e02684&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3815a7e7db2d0c65f18377d09a7995ce~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812334&auth_key=1760812334-0-0-a2d149e97d1c57fe55253c086310c905&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3361423a62b8f377ef84912923949314~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812340&auth_key=1760812340-0-0-1e1f2d0a10bfe031b96349281056dd92&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7fa971e86100bf97b40fe2761a27824b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812346&auth_key=1760812346-0-0-9b0c5f7bef1d9090aa69779a2fbd8792&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-277f8e511247fb3589a470a2ce6f283f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812353&auth_key=1760812353-0-0-2bd5a33ddc76b2fbdc0290628e8ef4e8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-53c789f6e8c17d4eeb81800cee2d771c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812360&auth_key=1760812360-0-0-16155a6a5be372a0b6ab59313472cee7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Indoor-Localization-using-Compact-Telemetry-Agnostic-Transfer-Learning-Enabled-Decoder-Only-Transformer"><a href="#Indoor-Localization-using-Compact-Telemetry-Agnostic-Transfer-Learning-Enabled-Decoder-Only-Transformer" class="headerlink" title="Indoor Localization using Compact, Telemetry-Agnostic, Transfer-Learning   Enabled Decoder-Only Transformer"></a>Indoor Localization using Compact, Telemetry-Agnostic, Transfer-Learning   Enabled Decoder-Only Transformer</h2><p><strong>Authors:Nayan Sanjay Bhatia, Pranay Kocheta, Russell Elliott, Harikrishna S. Kuttivelil, Katia Obraczka</strong></p>
<p>Indoor Wi-Fi positioning remains a challenging problem due to the high sensitivity of radio signals to environmental dynamics, channel propagation characteristics, and hardware heterogeneity. Conventional fingerprinting and model-based approaches typically require labor-intensive calibration and suffer rapid performance degradation when devices, channel or deployment conditions change. In this paper, we introduce Locaris, a decoder-only large language model (LLM) for indoor localization. Locaris treats each access point (AP) measurement as a token, enabling the ingestion of raw Wi-Fi telemetry without pre-processing. By fine-tuning its LLM on different Wi-Fi datasets, Locaris learns a lightweight and generalizable mapping from raw signals directly to device location. Our experimental study comparing Locaris with state-of-the-art methods consistently shows that Locaris matches or surpasses existing techniques for various types of telemetry. Our results demonstrate that compact LLMs can serve as calibration-free regression models for indoor localization, offering scalable and robust cross-environment performance in heterogeneous Wi-Fi deployments. Few-shot adaptation experiments, using only a handful of calibration points per device, further show that Locaris maintains high accuracy when applied to previously unseen devices and deployment scenarios. This yields sub-meter accuracy with just a few hundred samples, robust performance under missing APs and supports any and all available telemetry. Our findings highlight the practical viability of Locaris for indoor positioning in the real-world scenarios, particularly in large-scale deployments where extensive calibration is infeasible. </p>
<blockquote>
<p>å®¤å†…Wi-Fiå®šä½ä»ç„¶æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œå› ä¸ºæ— çº¿ç”µä¿¡å·å¯¹ç¯å¢ƒåŠ¨æ€ã€ä¿¡é“ä¼ æ’­ç‰¹æ€§å’Œç¡¬ä»¶å¼‚è´¨æ€§çš„æ•æ„Ÿåº¦å¾ˆé«˜ã€‚ä¼ ç»Ÿçš„æŒ‡çº¹æ³•å’ŒåŸºäºæ¨¡å‹çš„æ–¹æ³•é€šå¸¸éœ€è¦å¯†é›†çš„æ ¡å‡†å·¥ä½œï¼Œå¹¶ä¸”åœ¨è®¾å¤‡ã€ä¿¡é“æˆ–éƒ¨ç½²æ¡ä»¶å‘ç”Ÿå˜åŒ–æ—¶ï¼Œæ€§èƒ½ä¼šè¿…é€Ÿä¸‹é™ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†Locarisï¼Œè¿™æ˜¯ä¸€ç§ä»…ç”¨äºå®¤å†…å®šä½çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è§£ç å™¨ã€‚Locariså°†æ¯ä¸ªæ¥å…¥ç‚¹ï¼ˆAPï¼‰çš„æµ‹é‡å€¼è§†ä¸ºä¸€ä¸ªä»¤ç‰Œï¼Œèƒ½å¤Ÿç›´æ¥å¤„ç†åŸå§‹Wi-Fié¥æµ‹æ•°æ®ï¼Œæ— éœ€é¢„å…ˆå¤„ç†ã€‚é€šè¿‡å¯¹ä¸åŒçš„Wi-Fiæ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼ŒLocariså­¦ä¹ ä»åŸå§‹ä¿¡å·ç›´æ¥æ˜ å°„åˆ°è®¾å¤‡ä½ç½®çš„è½»é‡çº§å’Œé€šç”¨æ˜ å°„ã€‚æˆ‘ä»¬çš„å®éªŒç ”ç©¶è¡¨æ˜ï¼Œä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”ï¼ŒLocarisåœ¨å„ç§ç±»å‹çš„é¥æµ‹æ•°æ®ä¸Šè¡¨ç°ä¸€è‡´æˆ–è¶…è¶Šç°æœ‰æŠ€æœ¯ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œç´§å‡‘çš„LLMå¯ä»¥ä½œä¸ºæ— éœ€æ ¡å‡†çš„å›å½’æ¨¡å‹ç”¨äºå®¤å†…å®šä½ï¼Œåœ¨å¼‚è´¨çš„Wi-Fiéƒ¨ç½²ä¸­æä¾›å¯æ‰©å±•å’Œç¨³å¥çš„è·¨ç¯å¢ƒæ€§èƒ½ã€‚ä»…ä½¿ç”¨æ¯ä¸ªè®¾å¤‡çš„ä¸€äº›æ ¡å‡†ç‚¹çš„å°‘æ•°é•œå¤´é€‚åº”å®éªŒè¿›ä¸€æ­¥è¡¨æ˜ï¼Œå½“åº”ç”¨äºä»¥å‰æœªè§è¿‡çš„è®¾å¤‡å’Œéƒ¨ç½²åœºæ™¯æ—¶ï¼ŒLocarisä»èƒ½ä¿æŒé«˜ç²¾åº¦ã€‚è¿™åªéœ€æ•°ç™¾ä¸ªæ ·æœ¬å³å¯å®ç°äºšç±³çº§ç²¾åº¦ï¼Œåœ¨ç¼ºå°‘APçš„æƒ…å†µä¸‹è¡¨ç°ç¨³å¥ï¼Œå¹¶æ”¯æŒæ‰€æœ‰å¯ç”¨çš„é¥æµ‹æ•°æ®ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒLocarisåœ¨çœŸå®ä¸–ç•Œçš„å®¤å†…å®šä½åœºæ™¯ä¸­å…·æœ‰å¾ˆå¼ºçš„å®ç”¨æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§è§„æ¨¡éƒ¨ç½²ä¸­ï¼Œå…¨é¢æ ¡å‡†æ˜¯ä¸å¯è¡Œçš„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.11926v1">PDF</a> 11 pages, 12 Figures</p>
<p><strong>Summary</strong></p>
<p>å®¤å†…Wi-Fiå®šä½æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œå› ä¸ºæ— çº¿ç”µä¿¡å·å¯¹ç¯å¢ƒåŠ¨æ€ã€ä¿¡é“ä¼ æ’­ç‰¹æ€§å’Œç¡¬ä»¶å¼‚è´¨æ€§çš„é«˜åº¦æ•æ„Ÿæ€§ã€‚ä¼ ç»ŸæŒ‡çº¹æ³•å’Œæ¨¡å‹æ³•éœ€è¦å¤§é‡æ ¡å‡†å·¥ä½œï¼Œä¸”åœ¨è®¾å¤‡ã€ä¿¡é“æˆ–éƒ¨ç½²æ¡ä»¶å‘ç”Ÿå˜åŒ–æ—¶æ€§èƒ½è¿…é€Ÿä¸‹é™ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºLocarisçš„å®¤å†…å®šä½è§£ç å™¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚Locariså°†æ¯ä¸ªæ¥å…¥ç‚¹ï¼ˆAPï¼‰çš„æµ‹é‡å€¼è§†ä¸ºä¸€ä¸ªä»¤ç‰Œï¼Œèƒ½å¤Ÿç›´æ¥å¤„ç†åŸå§‹Wi-Fié¥æµ‹æ•°æ®ï¼Œæ— éœ€é¢„å…ˆå¤„ç†ã€‚é€šè¿‡å¯¹ä¸åŒWi-Fiæ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼ŒLocarisèƒ½å¤Ÿå­¦ä¹ ä»åŸå§‹ä¿¡å·åˆ°è®¾å¤‡ä½ç½®çš„è½»é‡åŒ–é€šç”¨æ˜ å°„ã€‚å®éªŒç ”ç©¶è¡¨æ˜ï¼Œç›¸è¾ƒäºæœ€æ–°çš„å®šä½æŠ€æœ¯ï¼ŒLocarisåœ¨ä¸åŒç±»å‹çš„é¥æµ‹æ•°æ®ä¸­è¡¨ç°è‰¯å¥½ç”šè‡³æ›´å‡ºè‰²ã€‚å®éªŒç»“æœæ˜¾ç¤ºå‡ºå¤§è§„æ¨¡LLMä½œä¸ºä¸€ç§æ— æ ¡å‡†å›å½’æ¨¡å‹åœ¨WiFiéƒ¨ç½²å®¤å†…å®šä½ä¸­çš„åº”ç”¨æ½œåŠ›ï¼Œå±•ç°äº†åœ¨å¼‚è´¨çš„Wi-Fiéƒ¨ç½²ä¸­çš„è·¨ç¯å¢ƒæ€§èƒ½å’Œç¨³å¥æ€§ã€‚å°‘é‡çš„æ ·æœ¬å°±èƒ½è¾¾åˆ°å­ç±³çº§åˆ«çš„ç²¾åº¦ï¼Œåœ¨ç¼ºå¤±æ¥å…¥ç‚¹çš„æƒ…å†µä¸‹æ€§èƒ½ç¨³å®šï¼Œæ”¯æŒæ‰€æœ‰å¯ç”¨çš„é¥æµ‹æ•°æ®ã€‚è¿™ä¸ºLocarisåœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­çš„å®¤å†…å®šä½æä¾›äº†å®é™…å¯è¡Œæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§è§„æ¨¡éƒ¨ç½²ä¸­æ— æ³•è¿›è¡Œå…¨é¢æ ¡å‡†çš„æƒ…å†µä¸‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å®¤å†…Wi-Fiå®šä½æ˜¯ä¸€ä¸ªæ•æ„Ÿçš„é—®é¢˜ï¼Œé¢ä¸´å¤šç§æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬ç¯å¢ƒåŠ¨æ€ã€ä¿¡é“ä¼ æ’­ç‰¹æ€§å’Œç¡¬ä»¶å·®å¼‚ç­‰å› ç´ ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•éœ€è¦æ˜‚è´µçš„æ ¡å‡†å·¥ä½œï¼Œä¸”åœ¨æ¡ä»¶å˜åŒ–æ—¶æ€§èƒ½ä¸ç¨³å®šã€‚</li>
<li>Locarisæ˜¯ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å®¤å†…å®šä½è§£ç å™¨ï¼Œå¯ä»¥ç›´æ¥å¤„ç†åŸå§‹Wi-Fié¥æµ‹æ•°æ®ï¼Œæ— éœ€é¢„å¤„ç†æ­¥éª¤ã€‚</li>
<li>Locarisé€šè¿‡åœ¨ä¸åŒWi-Fiæ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒï¼Œèƒ½å¤Ÿå­¦ä¹ ä»åŸå§‹ä¿¡å·åˆ°è®¾å¤‡ä½ç½®çš„è½»é‡åŒ–é€šç”¨æ˜ å°„ã€‚</li>
<li>å®éªŒè¡¨æ˜Locarisç›¸è¾ƒäºå…¶ä»–æœ€æ–°æŠ€æœ¯æœ‰æ›´å¥½çš„æ€§èƒ½è¡¨ç°ï¼Œå°¤å…¶åœ¨å¤„ç†ä¸åŒç±»å‹çš„é¥æµ‹æ•°æ®æ—¶ã€‚</li>
<li>Locariså…·æœ‰å¼ºå¤§çš„è·¨ç¯å¢ƒæ€§èƒ½ï¼Œå³ä½¿åœ¨ç¼ºå°‘æ¥å…¥ç‚¹çš„æƒ…å†µä¸‹ä¹Ÿèƒ½ä¿æŒç¨³å®šçš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.11926">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-7eb1851b1908026d11d744ade8807a8e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812367&auth_key=1760812367-0-0-588a2835ca1c2aa5f673e3e08907c1ae&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-36db4d15781cf90d63146d64ada22dca~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812375&auth_key=1760812375-0-0-02c5fb7da6eb1c749b855e29b6bbac63&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-88ab834cafef1f7452064182f2250267~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812382&auth_key=1760812382-0-0-f269bf9ad6a3ab4ac5cdba2a65944b6b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e484a06c8d4af411de7662fe856ce59b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812388&auth_key=1760812388-0-0-29172b828b24efbd41a3405ad5613c96&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6d4d77ae49c8ff2ee455d7339a3945f0~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812395&auth_key=1760812395-0-0-8dcb8e1d3aff631333a1397bb0f5ebfe&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f88b4047a83b7505cd9f2899b66cc9f5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812401&auth_key=1760812401-0-0-335e7daad777d2dd5ad014200044dfa6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Who-are-you-ChatGPT-Personality-and-Demographic-Style-in-LLM-Generated-Content"><a href="#Who-are-you-ChatGPT-Personality-and-Demographic-Style-in-LLM-Generated-Content" class="headerlink" title="Who are you, ChatGPT? Personality and Demographic Style in LLM-Generated   Content"></a>Who are you, ChatGPT? Personality and Demographic Style in LLM-Generated   Content</h2><p><strong>Authors:Dana Sotto Porat, Ella Rabinovich</strong></p>
<p>Generative large language models (LLMs) have become central to everyday life, producing human-like text across diverse domains. A growing body of research investigates whether these models also exhibit personality- and demographic-like characteristics in their language. In this work, we introduce a novel, data-driven methodology for assessing LLM personality without relying on self-report questionnaires, applying instead automatic personality and gender classifiers to model replies on open-ended questions collected from Reddit. Comparing six widely used models to human-authored responses, we find that LLMs systematically express higher Agreeableness and lower Neuroticism, reflecting cooperative and stable conversational tendencies. Gendered language patterns in model text broadly resemble those of human writers, though with reduced variation, echoing prior findings on automated agents. We contribute a new dataset of human and model responses, along with large-scale comparative analyses, shedding new light on the topic of personality and demographic patterns of generative AI. </p>
<blockquote>
<p>ç”Ÿæˆå¼å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²ç»æˆä¸ºæ—¥å¸¸ç”Ÿæ´»çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒé¢†åŸŸäº§ç”Ÿç±»ä¼¼äººç±»çš„æ–‡æœ¬ã€‚è¶Šæ¥è¶Šå¤šçš„ç ”ç©¶å¼€å§‹æ¢ç©¶è¿™äº›æ¨¡å‹çš„è¯­è¨€ä¸­æ˜¯å¦ä¹Ÿè¡¨ç°å‡ºä¸ªæ€§å’Œäººå£ç»Ÿè®¡ç‰¹å¾ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹çš„æ•°æ®é©±åŠ¨æ–¹æ³•ï¼Œç”¨äºè¯„ä¼°LLMçš„ä¸ªæ€§ï¼Œè€Œæ— éœ€ä¾èµ–è‡ªæˆ‘æŠ¥å‘Šé—®å·ã€‚æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯è‡ªåŠ¨ä¸ªæ€§å’Œæ€§åˆ«åˆ†ç±»å™¨ï¼Œå¯¹ä»Redditæ”¶é›†çš„å¼€æ”¾æ€§é—®é¢˜å›å¤è¿›è¡Œå»ºæ¨¡ã€‚æˆ‘ä»¬å°†å…­ä¸ªå¹¿å—æ¬¢è¿çš„æ¨¡å‹ä¸äººç±»åˆ›ä½œçš„å›å¤è¿›è¡Œæ¯”è¾ƒï¼Œå‘ç°LLMç³»ç»Ÿæ€§åœ°è¡¨ç°å‡ºæ›´é«˜çš„å®œäººæ€§ï¼ˆAgreeablenessï¼‰å’Œæ›´ä½çš„ç¥ç»è´¨ï¼ˆNeuroticismï¼‰ï¼Œåæ˜ äº†åˆä½œå’Œç¨³å®šçš„å¯¹è¯å€¾å‘ã€‚æ¨¡å‹æ–‡æœ¬ä¸­çš„æ€§åˆ«è¯­è¨€æ¨¡å¼å¤§è‡´ä¸äººç±»ä½œè€…ç›¸ä¼¼ï¼Œä½†å˜åŒ–è¾ƒå°‘ï¼Œè¿™ä¸ä¹‹å‰å…³äºè‡ªåŠ¨åŒ–ä»£ç†çš„ç ”ç©¶ç»“æœç›¸å‘¼åº”ã€‚æˆ‘ä»¬æä¾›äº†äººç±»å’Œæ¨¡å‹å“åº”çš„æ–°æ•°æ®é›†ä»¥åŠå¤§è§„æ¨¡æ¯”è¾ƒåˆ†æï¼Œä¸ºç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„ä¸ªæ€§ç‰¹å¾å’Œäººå£ç»Ÿè®¡æ¨¡å¼æä¾›äº†æ–°çš„è§†è§’ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.11434v1">PDF</a> ECAI2025 (Identity-Aware AI workshop)</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹ç”Ÿæˆå¼è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­çš„é‡è¦æ€§æ—¥ç›Šå‡¸æ˜¾ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒé¢†åŸŸç”Ÿæˆç±»ä¼¼äººç±»çš„æ–‡æœ¬ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹çš„æ•°æ®é©±åŠ¨æ–¹æ³•ï¼Œæ— éœ€ä¾èµ–è‡ªæˆ‘æŠ¥å‘Šé—®å·å³å¯è¯„ä¼°LLMçš„äººæ ¼ç‰¹å¾ã€‚é€šè¿‡è‡ªåŠ¨äººæ ¼å’Œæ€§åˆ«åˆ†ç±»å™¨å¯¹Redditä¸Šæ”¶é›†çš„å¼€æ”¾æ€§é—®é¢˜å›å¤è¿›è¡Œå»ºæ¨¡ï¼Œæˆ‘ä»¬å°†å…­ç§å¹¿æ³›ä½¿ç”¨çš„æ¨¡å‹ä¸äººç±»åˆ›ä½œçš„å›å¤è¿›è¡Œæ¯”è¾ƒï¼Œå‘ç°LLMçš„è¡¨è¾¾æ›´å…·åˆä½œæ€§å’Œç¨³å®šæ€§ï¼Œè¡¨ç°å‡ºæ›´é«˜çš„å®œäººæ€§åŠè¾ƒä½ç¥ç»è´¨ã€‚æ¨¡å‹æ–‡æœ¬ä¸­çš„æ€§åˆ«è¯­è¨€æ¨¡å¼å¤§ä½“ä¸Šç±»ä¼¼äºäººç±»ä½œè€…ï¼Œä½†å˜åŒ–æ€§æœ‰æ‰€å‡å°‘ã€‚æœ¬ç ”ç©¶ä¸ºäººå·¥æ™ºèƒ½çš„äººæ ¼å’Œäººå£ç»Ÿè®¡ç‰¹å¾ç ”ç©¶æä¾›äº†æ–°çš„æ•°æ®é›†å’Œå¤§è§„æ¨¡å¯¹æ¯”åˆ†æã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹ç”Ÿæˆå¼è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²èå…¥æ—¥å¸¸ç”Ÿæ´»ï¼Œå¯åœ¨ä¸åŒé¢†åŸŸç”Ÿæˆç±»ä¼¼äººç±»çš„æ–‡æœ¬ã€‚</li>
<li>æå‡ºä¸€ç§æ–°å‹æ•°æ®é©±åŠ¨æ–¹æ³•è¯„ä¼°LLMçš„äººæ ¼ç‰¹å¾ï¼Œæ— éœ€ä¾èµ–è‡ªæˆ‘æŠ¥å‘Šé—®å·ã€‚</li>
<li>LLMçš„è¡¨è¾¾æ›´å…·åˆä½œæ€§å’Œç¨³å®šæ€§ï¼Œè¡¨ç°å‡ºè¾ƒé«˜çš„å®œäººæ€§åŠè¾ƒä½çš„ç¥ç»è´¨ã€‚</li>
<li>LLMçš„å›å¤ä¸­æ€§åˆ«è¯­è¨€æ¨¡å¼ç±»ä¼¼äºäººç±»ä½œè€…ï¼Œä½†å˜åŒ–æ€§æœ‰æ‰€å‡å°‘ã€‚</li>
<li>æœ¬ç ”ç©¶ä¸ºäººå·¥æ™ºèƒ½çš„äººæ ¼ç‰¹å¾ç ”ç©¶æä¾›äº†æ–°çš„æ•°æ®é›†ã€‚</li>
<li>å¯¹æ¯”åˆ†æäº†å…­ç§å¹¿æ³›ä½¿ç”¨çš„æ¨¡å‹ä¸äººç±»åˆ›ä½œçš„å›å¤ï¼Œä¸ºç†è§£LLMçš„ç‰¹å¾æä¾›äº†å¤§è§„æ¨¡æ•°æ®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.11434">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-0d8969e944f9ceea5a7063ebc727e4d1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812409&auth_key=1760812409-0-0-30053aa91ba7803b97deaefbc7db59b6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8c7543b279f22293e0b1c23fb7915f64~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812416&auth_key=1760812416-0-0-6da46109e0804f16a5844cf57e1515f6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-983d4b44cdeb68604559536d30a46e5c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812423&auth_key=1760812423-0-0-314798fc503763000942f925dc2e06db&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Towards-Real-Time-Fake-News-Detection-under-Evidence-Scarcity"><a href="#Towards-Real-Time-Fake-News-Detection-under-Evidence-Scarcity" class="headerlink" title="Towards Real-Time Fake News Detection under Evidence Scarcity"></a>Towards Real-Time Fake News Detection under Evidence Scarcity</h2><p><strong>Authors:Guangyu Wei, Ke Han, Yueming Lyu, Yu Luo, Yue Jiang, Caifeng Shan, Nicu Sebe</strong></p>
<p>Fake news detection becomes particularly challenging in real-time scenarios, where emerging events often lack sufficient supporting evidence. Existing approaches often rely heavily on external evidence and therefore struggle to generalize under evidence scarcity. To address this issue, we propose Evaluation-Aware Selection of Experts (EASE), a novel framework for real-time fake news detection that dynamically adapts its decision-making process according to the assessed sufficiency of available evidence. EASE introduces a sequential evaluation mechanism comprising three independent perspectives: (1) Evidence-based evaluation, which assesses evidence and incorporates it into decision-making only when the evidence is sufficiently supportive; (2) Reasoning-based evaluation, which leverages the world knowledge of large language models (LLMs) and applies them only when their reliability is adequately established; and (3) Sentiment-based fallback, which integrates sentiment cues when neither evidence nor reasoning is reliable. To enhance the accuracy of evaluation processes, EASE employs instruction tuning with pseudo labels to guide each evaluator in justifying its perspective-specific knowledge through interpretable reasoning. Furthermore, the expert modules integrate the evaluatorsâ€™ justified assessments with the news content to enable evaluation-aware decision-making, thereby enhancing overall detection accuracy. Moreover, we introduce RealTimeNews-25, a new benchmark comprising recent news for evaluating model generalization on emerging news with limited evidence. Extensive experiments demonstrate that EASE not only achieves state-of-the-art performance across multiple benchmarks, but also significantly improves generalization to real-time news. The code and dataset are available: <a target="_blank" rel="noopener" href="https://github.com/wgyhhhh/EASE">https://github.com/wgyhhhh/EASE</a>. </p>
<blockquote>
<p>å®æ—¶åœºæ™¯ä¸­è™šå‡æ–°é—»æ£€æµ‹å˜å¾—å°¤å…¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºæ–°å…´äº‹ä»¶å¾€å¾€ç¼ºä¹è¶³å¤Ÿçš„æ”¯æŒè¯æ®ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¸¥é‡ä¾èµ–äºå¤–éƒ¨è¯æ®ï¼Œå› æ­¤åœ¨è¯æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹å¾ˆéš¾æ¨å¹¿ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†â€œåŸºäºè¯„ä¼°çš„ä¸“å®¶é€‰æ‹©â€ï¼ˆEASEï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå®æ—¶è™šå‡æ–°é—»æ£€æµ‹çš„æ–°å‹æ¡†æ¶ï¼Œå®ƒå¯ä»¥æ ¹æ®ç°æœ‰è¯æ®çš„å……è¶³æ€§æ¥åŠ¨æ€è°ƒæ•´å…¶å†³ç­–è¿‡ç¨‹ã€‚EASEå¼•å…¥äº†ä¸€ç§é¡ºåºè¯„ä¼°æœºåˆ¶ï¼ŒåŒ…æ‹¬ä¸‰ä¸ªç‹¬ç«‹çš„è§’åº¦ï¼šï¼ˆ1ï¼‰åŸºäºè¯æ®çš„è¯„ä»·ï¼Œå®ƒåªåœ¨è¯æ®è¶³å¤Ÿæ”¯æŒæ—¶è¯„ä¼°è¯æ®å¹¶å°†å…¶çº³å…¥å†³ç­–è¿‡ç¨‹ï¼›ï¼ˆ2ï¼‰åŸºäºæ¨ç†çš„è¯„ä»·ï¼Œå®ƒåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä¸–ç•ŒçŸ¥è¯†ï¼Œåªåœ¨å¯é æ€§å¾—åˆ°å……åˆ†è¯æ˜æ—¶åº”ç”¨ï¼›ï¼ˆ3ï¼‰åŸºäºæƒ…æ„Ÿçš„åå¤‡ç­–ç•¥ï¼Œå½“è¯æ®å’Œæ¨ç†éƒ½ä¸å¯é æ—¶ï¼Œå®ƒæ•´åˆæƒ…æ„Ÿçº¿ç´¢ã€‚ä¸ºäº†æé«˜è¯„ä¼°è¿‡ç¨‹çš„å‡†ç¡®æ€§ï¼ŒEASEä½¿ç”¨ä¼ªæ ‡ç­¾è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒï¼Œä»¥å¼•å¯¼æ¯ä¸ªè¯„ä¼°è€…é€šè¿‡å¯è§£é‡Šçš„ç†ç”±æ¥è¯æ˜å…¶ç‰¹å®šè§’åº¦çš„çŸ¥è¯†ã€‚æ­¤å¤–ï¼Œä¸“å®¶æ¨¡å—å°†è¯„ä¼°è€…çš„åˆç†è¯„ä¼°ä¸æ–°é—»å†…å®¹ç›¸ç»“åˆï¼Œä»¥å®ç°åŸºäºè¯„ä¼°çš„å†³ç­–åˆ¶å®šï¼Œä»è€Œæé«˜æ•´ä½“æ£€æµ‹å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†RealTimeNews-25ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«æœ€è¿‘çš„æ–°é—»ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨è¯æ®æœ‰é™çš„æ–°å…´æ–°é—»ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒEASEä¸ä»…åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œè€Œä¸”åœ¨å®æ—¶æ–°é—»ä¸­çš„æ³›åŒ–èƒ½åŠ›ä¹Ÿå¾—åˆ°äº†æ˜¾ç€æé«˜ã€‚ç›¸å…³ä»£ç å’Œæ•°æ®é›†å¯é€šè¿‡ä»¥ä¸‹é“¾æ¥è·å–ï¼š<a target="_blank" rel="noopener" href="https://github.com/wgyhhhh/EASE">é“¾æ¥</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.11277v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>å®æ—¶åœºæ™¯ä¸­å‡æ–°é—»æ£€æµ‹é¢ä¸´ç‰¹åˆ«æŒ‘æˆ˜ï¼Œå› ä¸ºæ–°å…´äº‹ä»¶å¾€å¾€ç¼ºä¹è¶³å¤Ÿçš„æ”¯æŒè¯æ®ã€‚ç°æœ‰æ–¹æ³•è¿‡äºä¾èµ–å¤–éƒ¨è¯æ®ï¼Œå› æ­¤åœ¨è¯æ®ä¸è¶³çš„æƒ…å†µä¸‹éš¾ä»¥æ¨å¹¿ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºâ€œåŸºäºè¯„ä¼°çš„ä¸“å®¶é€‰æ‹©â€ï¼ˆEASEï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯åŠ¨æ€è°ƒæ•´å†³ç­–è¿‡ç¨‹ä»¥é€‚åº”ç°æœ‰è¯æ®çš„å¯è¯„ä¼°å……åˆ†æ€§ï¼Œç”¨äºå®æ—¶å‡æ–°é—»æ£€æµ‹ã€‚EASEå¼•å…¥äº†ä¸€ç§åŒ…å«ä¸‰ä¸ªç‹¬ç«‹è§†è§’çš„è¿ç»­è¯„ä¼°æœºåˆ¶ï¼šï¼ˆ1ï¼‰åŸºäºè¯æ®çš„è¯„ä»·ï¼Œä»…åœ¨è¯æ®å……è¶³æ—¶è¯„ä¼°è¯æ®å¹¶å°†å…¶çº³å…¥å†³ç­–è¿‡ç¨‹ï¼›ï¼ˆ2ï¼‰åŸºäºæ¨ç†çš„è¯„ä»·ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä¸–ç•ŒçŸ¥è¯†ï¼Œåœ¨å¯é æ€§å¾—åˆ°éªŒè¯æ—¶åŠ ä»¥åº”ç”¨ï¼›ï¼ˆ3ï¼‰åŸºäºæƒ…æ„Ÿçš„å¤‡ç”¨æ–¹æ³•ï¼Œåœ¨è¯æ®å’Œæ¨ç†å‡ä¸å¯é æ—¶æ•´åˆæƒ…æ„Ÿçº¿ç´¢ã€‚ä¸ºæé«˜è¯„ä¼°è¿‡ç¨‹çš„å‡†ç¡®æ€§ï¼ŒEASEé‡‡ç”¨æŒ‡ä»¤å¾®è°ƒä¸ä¼ªæ ‡ç­¾ç›¸ç»“åˆçš„æ–¹å¼ï¼ŒæŒ‡å¯¼è¯„ä¼°è€…é€šè¿‡å¯è§£é‡Šæ¨ç†æ¥è¯æ˜å…¶ç‰¹å®šè§†è§’çš„çŸ¥è¯†ã€‚æ­¤å¤–ï¼Œä¸“å®¶æ¨¡å—æ•´åˆè¯„ä¼°è€…çš„åˆç†è¯„ä¼°ä¸æ–°é—»å†…å®¹ï¼Œå®ç°åŸºäºè¯„ä¼°çš„å†³ç­–åˆ¶å®šï¼Œä»è€Œæé«˜æ•´ä½“æ£€æµ‹å‡†ç¡®æ€§ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†RealTimeNews-25åŸºå‡†æµ‹è¯•é›†ï¼ŒåŒ…å«æœ€æ–°æ–°é—»ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨è¯æ®æœ‰é™çš„æ–°å…´æ–°é—»ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒEASEä¸ä»…åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•é›†ä¸Šè¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œè€Œä¸”åœ¨å®æ—¶æ–°é—»ä¸Šçš„æ³›åŒ–èƒ½åŠ›æ˜¾è‘—æé«˜ã€‚ç›¸å…³ä»£ç å’Œæ•°æ®é›†å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/wgyhhhh/EASE%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/wgyhhhh/EASEè·å–ã€‚</a></p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å®æ—¶åœºæ™¯ä¸­çš„å‡æ–°é—»æ£€æµ‹é¢ä¸´æŒ‘æˆ˜ï¼Œå› ä¸ºæ–°å…´äº‹ä»¶ç¼ºä¹è¶³å¤Ÿçš„æ”¯æŒè¯æ®ã€‚</li>
<li>ç°æœ‰æ–¹æ³•è¿‡äºä¾èµ–å¤–éƒ¨è¯æ®ï¼Œåœ¨è¯æ®ä¸è¶³æ—¶éš¾ä»¥æ¨å¹¿ã€‚</li>
<li>EASEæ¡†æ¶é€šè¿‡åŠ¨æ€é€‚åº”ç°æœ‰è¯æ®çš„å¯è¯„ä¼°å……åˆ†æ€§æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</li>
<li>EASEå¼•å…¥äº†ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªç‹¬ç«‹è§†è§’çš„è¿ç»­è¯„ä¼°æœºåˆ¶ï¼šåŸºäºè¯æ®çš„è¯„ä»·ã€åŸºäºæ¨ç†çš„è¯„ä»·å’ŒåŸºäºæƒ…æ„Ÿçš„å¤‡ç”¨æ–¹æ³•ã€‚</li>
<li>EASEé‡‡ç”¨æŒ‡ä»¤å¾®è°ƒä¸ä¼ªæ ‡ç­¾ç›¸ç»“åˆçš„æ–¹å¼æé«˜è¯„ä¼°è¿‡ç¨‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>ä¸“å®¶æ¨¡å—æ•´åˆè¯„ä¼°è€…çš„åˆç†è¯„ä¼°ä¸æ–°é—»å†…å®¹ï¼Œæé«˜æ•´ä½“æ£€æµ‹å‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.11277">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-f4611a551b59bd6265bf9046b71670b4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812430&auth_key=1760812430-0-0-a924c6ad9d22f78af8410628549114d2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6142d4972f6e619dea755119b6cd020f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812437&auth_key=1760812437-0-0-a50a4bae7fcca7ff74ac1065ee95dc09&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-adf5d4ea7e5223b89fb5980c3c758d91~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812444&auth_key=1760812444-0-0-56adc86234c4c97c76778c123eedb650&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-39e1462b0500bb69559fa526630f44f6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812451&auth_key=1760812451-0-0-b50b5605969df5b07892f9e20674ec4b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Fairness-Metric-Design-Exploration-in-Multi-Domain-Moral-Sentiment-Classification-using-Transformer-Based-Models"><a href="#Fairness-Metric-Design-Exploration-in-Multi-Domain-Moral-Sentiment-Classification-using-Transformer-Based-Models" class="headerlink" title="Fairness Metric Design Exploration in Multi-Domain Moral Sentiment   Classification using Transformer-Based Models"></a>Fairness Metric Design Exploration in Multi-Domain Moral Sentiment   Classification using Transformer-Based Models</h2><p><strong>Authors:Battemuulen Naranbat, Seyed Sahand Mohammadi Ziabari, Yousuf Nasser Al Husaini, Ali Mohammed Mansoor Alsahag</strong></p>
<p>Ensuring fairness in natural language processing for moral sentiment classification is challenging, particularly under cross-domain shifts where transformer models are increasingly deployed. Using the Moral Foundations Twitter Corpus (MFTC) and Moral Foundations Reddit Corpus (MFRC), this work evaluates BERT and DistilBERT in a multi-label setting with in-domain and cross-domain protocols. Aggregate performance can mask disparities: we observe pronounced asymmetry in transfer, with Twitter-&gt;Reddit degrading micro-F1 by 14.9% versus only 1.5% for Reddit-&gt;Twitter. Per-label analysis reveals fairness violations hidden by overall scores; notably, the authority label exhibits Demographic Parity Differences of 0.22-0.23 and Equalized Odds Differences of 0.40-0.41. To address this gap, we introduce the Moral Fairness Consistency (MFC) metric, which quantifies the cross-domain stability of moral foundation detection. MFC shows strong empirical validity, achieving a perfect negative correlation with Demographic Parity Difference (rho &#x3D; -1.000, p &lt; 0.001) while remaining independent of standard performance metrics. Across labels, loyalty demonstrates the highest consistency (MFC &#x3D; 0.96) and authority the lowest (MFC &#x3D; 0.78). These findings establish MFC as a complementary, diagnosis-oriented metric for fairness-aware evaluation of moral reasoning models, enabling more reliable deployment across heterogeneous linguistic contexts. . </p>
<blockquote>
<p>ç¡®ä¿è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„å…¬å¹³æ€§å¯¹äºé“å¾·æƒ…æ„Ÿåˆ†ç±»æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨éƒ¨ç½²è¶Šæ¥è¶Šå¤šçš„è½¬æ¢å™¨æ¨¡å‹æ—¶ï¼Œé¢ä¸´è·¨é¢†åŸŸå˜åŒ–çš„æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶ä½¿ç”¨é“å¾·åŸºç¡€æ¨ç‰¹è¯­æ–™åº“ï¼ˆMFTCï¼‰å’Œé“å¾·åŸºç¡€Redditè¯­æ–™åº“ï¼ˆMFRCï¼‰ï¼Œåœ¨å…·æœ‰åŸŸå†…å’Œè·¨åŸŸåè®®çš„å¤šæ ‡ç­¾è®¾ç½®ä¸­è¯„ä¼°BERTå’ŒDistilBERTã€‚æ€»ä½“æ€§èƒ½å¯èƒ½ä¼šæ©ç›–ä¸å¹³ç­‰ç°è±¡ï¼šæˆ‘ä»¬è§‚å¯Ÿåˆ°æ˜æ˜¾çš„è½¬ç§»ä¸å¯¹ç§°æ€§ï¼ŒTwitterè½¬å‘Redditçš„å¾®F1å€¼ä¸‹é™14.9ï¼…ï¼Œè€ŒRedditè½¬å‘Twitterä»…ä¸‹é™1.5ï¼…ã€‚æŒ‰æ ‡ç­¾åˆ†ææ­ç¤ºäº†æ€»ä½“åˆ†æ•°éšè—çš„å…¬å¹³æ€§é—®é¢˜;å°¤å…¶æ˜¯æƒå¨æ ‡ç­¾æ˜¾ç¤ºå‡ºæ˜æ˜¾çš„äººå£ç»Ÿè®¡å¹³è¡¡å·®å¼‚åœ¨0.22åˆ°0.23ä¹‹é—´ï¼Œå‡è¡¡æœºä¼šå·®å¼‚åœ¨0.40åˆ°0.41ä¹‹é—´ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†é“å¾·å…¬å¹³ä¸€è‡´æ€§ï¼ˆMFCï¼‰æŒ‡æ ‡ï¼Œè¯¥æŒ‡æ ‡é‡åŒ–äº†é“å¾·åŸºç¡€æ£€æµ‹è·¨åŸŸçš„ç¨³å®šæ€§ã€‚MFCå…·æœ‰å¾ˆå¼ºçš„å®è¯æœ‰æ•ˆæ€§ï¼Œä¸äººå£ç»Ÿè®¡å¹³è¡¡å·®å¼‚å®ç°å®Œç¾çš„è´Ÿç›¸å…³ï¼ˆrho&#x3D;-1.000ï¼Œp&lt;0.001ï¼‰ï¼ŒåŒæ—¶ç‹¬ç«‹äºæ ‡å‡†æ€§èƒ½æŒ‡æ ‡ã€‚åœ¨æ‰€æœ‰æ ‡ç­¾ä¸­ï¼Œå¿ è¯šè¡¨ç°å‡ºæœ€é«˜çš„ä¸€è‡´æ€§ï¼ˆMFC&#x3D;0.96ï¼‰ï¼Œè€Œæƒå¨è¡¨ç°å‡ºæœ€ä½çš„ä¸€è‡´æ€§ï¼ˆMFC&#x3D;0.78ï¼‰ã€‚è¿™äº›å‘ç°ç¡®ç«‹äº†MFCä½œä¸ºä¸€ä¸ªé¢å‘è¯Šæ–­çš„è¡¥å……æŒ‡æ ‡ï¼Œç”¨äºå…¬å¹³è¯„ä¼°é“å¾·æ¨ç†æ¨¡å‹ï¼Œä½¿å…¶åœ¨å¼‚è´¨çš„è¯­è¨€ç¯å¢ƒä¸­éƒ¨ç½²æ›´åŠ å¯é ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.11222v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š</p>
<p>è¯¥ç ”ç©¶è¯„ä¼°äº†BERTå’ŒDistilBERTåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„å…¬å¹³æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨é“å¾·æƒ…æ„Ÿåˆ†ç±»æ–¹é¢çš„è·¨åŸŸè½¬ç§»å­¦ä¹ æ€§èƒ½ã€‚ç ”ç©¶ä½¿ç”¨äº†é“å¾·åŸºç¡€Twitterè¯­æ–™åº“å’ŒRedditè¯­æ–™åº“ï¼Œå¹¶å‘ç°è·¨åŸŸè½¬ç§»å­¦ä¹ å­˜åœ¨ä¸å¯¹ç§°æ€§ï¼ŒTwitteråˆ°Redditçš„è½¬ç§»å­¦ä¹ æ€§èƒ½ä¸‹é™å¹…åº¦è¾ƒå¤§ã€‚æ­¤å¤–ï¼Œè¿˜å‘ç°æŸäº›æ ‡ç­¾çš„å…¬å¹³æ€§å­˜åœ¨å·®è·ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œè¯¥ç ”ç©¶å¼•å…¥äº†é“å¾·å…¬å¹³æ€§ä¸€è‡´æ€§ï¼ˆMFCï¼‰æŒ‡æ ‡æ¥è¡¡é‡é“å¾·åŸºç¡€æ£€æµ‹åœ¨è·¨åŸŸä¸­çš„ç¨³å®šæ€§ã€‚MFCä¸äººå£ç»Ÿè®¡å…¬å¹³å·®å¼‚å‘ˆç°å¼ºè´Ÿç›¸å…³ï¼Œå¹¶å…·æœ‰ç‹¬ç«‹çš„è¯„ä¼°ä»·å€¼ã€‚å¿ è¯šæ ‡ç­¾æ˜¾ç¤ºæœ€é«˜çš„é“å¾·å…¬å¹³æ€§ä¸€è‡´æ€§ï¼Œè€Œæƒå¨æ ‡ç­¾åˆ™æœ€ä½ã€‚è¿™ä¸€ç ”ç©¶ä¸ºå…¬å¹³æ€§è¯„ä»·æä¾›äº†ä¸€ç§å¯é çš„è¯Šæ–­å’Œè¯„ä¼°æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>BERTå’ŒDistilBERTåœ¨é“å¾·æƒ…æ„Ÿåˆ†ç±»ä¸­çš„å…¬å¹³æ€§è¯„ä¼°é‡è¦ã€‚</li>
<li>è·¨åŸŸè½¬ç§»å­¦ä¹ å­˜åœ¨ä¸å¯¹ç§°æ€§ï¼ŒTwitteråˆ°Redditçš„è½¬ç§»æ€§èƒ½ä¸‹é™å¹…åº¦æ›´å¤§ã€‚</li>
<li>éƒ¨åˆ†æ ‡ç­¾çš„å…¬å¹³æ€§å­˜åœ¨å·®è·ï¼Œå°¤å…¶æ˜¯æƒå¨æ ‡ç­¾ã€‚</li>
<li>å¼•å…¥é“å¾·å…¬å¹³æ€§ä¸€è‡´æ€§ï¼ˆMFCï¼‰æŒ‡æ ‡æ¥è¡¡é‡é“å¾·åŸºç¡€æ£€æµ‹çš„è·¨åŸŸç¨³å®šæ€§ã€‚</li>
<li>MFCä¸äººå£ç»Ÿè®¡å…¬å¹³å·®å¼‚å‘ˆç°å¼ºè´Ÿç›¸å…³ï¼Œå¹¶å…·æœ‰ç‹¬ç«‹çš„è¯„ä¼°ä»·å€¼ã€‚</li>
<li>å¿ è¯šæ ‡ç­¾æ˜¾ç¤ºæœ€é«˜çš„é“å¾·å…¬å¹³æ€§ä¸€è‡´æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.11222">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-91877c1e9d0f13afbf0558a4b5e3fc4a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812458&auth_key=1760812458-0-0-6ec3934b6ec6688e6ea99a7de24ccae0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Generative-AI-and-the-Transformation-of-Software-Development-Practices"><a href="#Generative-AI-and-the-Transformation-of-Software-Development-Practices" class="headerlink" title="Generative AI and the Transformation of Software Development Practices"></a>Generative AI and the Transformation of Software Development Practices</h2><p><strong>Authors:Vivek Acharya</strong></p>
<p>Generative AI is reshaping how software is designed, written, and maintained. Advances in large language models (LLMs) are enabling new development styles - from chat-oriented programming and â€˜vibe codingâ€™ to agentic programming - that can accelerate productivity and broaden access. This paper examines how AI-assisted techniques are changing software engineering practice, and the related issues of trust, accountability, and shifting skills. We survey iterative chat-based development, multi-agent systems, dynamic prompt orchestration, and integration via the Model Context Protocol (MCP). Using case studies and industry data, we outline both the opportunities (faster cycles, democratized coding) and the challenges (model reliability and cost) of applying generative AI to coding. We describe new roles, skills, and best practices for using AI in a responsible and effective way. </p>
<blockquote>
<p>ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ­£åœ¨é‡å¡‘è½¯ä»¶çš„è®¾è®¡ã€ç¼–å†™å’Œç»´æŠ¤æ–¹å¼ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥å‚¬ç”Ÿäº†æ–°çš„å¼€å‘é£æ ¼ï¼Œå¦‚é¢å‘èŠå¤©çš„ç¼–ç¨‹ã€â€œæ°›å›´ç¼–ç â€å’Œæ™ºèƒ½ç¼–ç¨‹ç­‰ï¼Œè¿™ä¸ä»…èƒ½åŠ é€Ÿç”Ÿäº§åŠ›ï¼Œè¿˜èƒ½æ‹“å®½è½¯ä»¶å¼€å‘çš„å¯åŠæ€§ã€‚æœ¬æ–‡æ¢è®¨äº†äººå·¥æ™ºèƒ½è¾…åŠ©æŠ€æœ¯å¦‚ä½•æ”¹å˜è½¯ä»¶å·¥ç¨‹å®è·µä»¥åŠç”±æ­¤äº§ç”Ÿçš„ä¿¡ä»»ã€é—®è´£åˆ¶å’ŒæŠ€èƒ½è½¬å˜é—®é¢˜ã€‚æˆ‘ä»¬è°ƒæŸ¥äº†åŸºäºè¿­ä»£èŠå¤©çš„å¼€å‘ã€å¤šæ™ºèƒ½ç³»ç»Ÿã€åŠ¨æ€æç¤ºç¼–æ’ä»¥åŠé€šè¿‡æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰çš„é›†æˆã€‚é€šè¿‡æ¡ˆä¾‹ç ”ç©¶å’Œè¡Œä¸šæ•°æ®ï¼Œæˆ‘ä»¬æ¦‚è¿°äº†å°†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åº”ç”¨äºç¼–ç çš„æœºé‡ï¼ˆæ›´å¿«çš„å‘¨æœŸã€æ°‘ä¸»åŒ–çš„ç¼–ç ï¼‰å’ŒæŒ‘æˆ˜ï¼ˆæ¨¡å‹å¯é æ€§å’Œæˆæœ¬ï¼‰ã€‚æˆ‘ä»¬æè¿°äº†åœ¨ä½¿ç”¨äººå·¥æ™ºèƒ½æ—¶éœ€è¦æ‹…å½“çš„æ–°è§’è‰²ã€æ–°æŠ€èƒ½ä»¥åŠæœ€ä½³å®è·µæ–¹å¼ï¼Œè¦åšåˆ°è´Ÿè´£ä»»å’Œæœ‰æ•ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.10819v1">PDF</a> 16 pages; 1 figure; preprint; v</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‘å±•æ¨åŠ¨äº†è½¯ä»¶è®¾è®¡ã€ç¼–å†™å’Œç»´æŠ¤æ–¹å¼çš„å˜é©ã€‚æ–°çš„å¼€å‘æ–¹å¼å¦‚é¢å‘èŠå¤©çš„ç¼–ç¨‹ã€â€œæ°›å›´ç¼–ç â€å’Œä»£ç†ç¼–ç¨‹ç­‰ï¼Œå¯ä»¥åŠ é€Ÿç”Ÿäº§åŠ›å’Œæ‰©å¤§è¦†ç›–é¢ã€‚æœ¬æ–‡æ¢è®¨äº†äººå·¥æ™ºèƒ½è¾…åŠ©æŠ€æœ¯å¦‚ä½•æ”¹å˜è½¯ä»¶å·¥ç¨‹å®è·µï¼Œä»¥åŠä¿¡ä»»ã€é—®è´£åˆ¶å’ŒæŠ€èƒ½è½¬å˜ç­‰é—®é¢˜ã€‚æ–‡ç« é€šè¿‡æ¡ˆä¾‹ç ”ç©¶å’Œè¡Œä¸šæ•°æ®ï¼Œæ¦‚è¿°äº†åº”ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åœ¨ç¼–ç ä¸­çš„æœºé‡å’ŒæŒ‘æˆ˜ï¼Œå¹¶æè¿°äº†ä½¿ç”¨äººå·¥æ™ºèƒ½çš„æ–°è§’è‰²ã€æŠ€èƒ½å’Œæœ€ä½³å®è·µã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‘å±•æ­£åœ¨æ¨åŠ¨è½¯ä»¶è¡Œä¸šçš„å˜é©ï¼ŒåŒ…æ‹¬è®¾è®¡ã€ç¼–å†™å’Œç»´æŠ¤æ–¹å¼ã€‚</li>
<li>æ–°çš„å¼€å‘æ–¹å¼å¦‚èŠå¤©ç¼–ç¨‹å’Œä»£ç†ç¼–ç¨‹å¯ä»¥æé«˜ç”Ÿäº§åŠ›å’Œæ‰©å¤§è¦†ç›–é¢ã€‚</li>
<li>AIè¾…åŠ©æŠ€æœ¯æ”¹å˜äº†è½¯ä»¶å·¥ç¨‹å®è·µï¼Œå¼•å‘äº†ä¿¡ä»»ã€é—®è´£åˆ¶å’ŒæŠ€èƒ½è½¬å˜ç­‰é—®é¢˜ã€‚</li>
<li>åº”ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åœ¨ç¼–ç ä¸­å­˜åœ¨æœºé‡å’ŒæŒ‘æˆ˜ï¼ŒåŒ…æ‹¬åŠ å¿«å¼€å‘å‘¨æœŸã€æ°‘ä¸»åŒ–ç¼–ç ç­‰ã€‚</li>
<li>ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åœ¨æ¨¡å‹å¯é æ€§å’Œæˆæœ¬æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>ä½¿ç”¨äººå·¥æ™ºèƒ½éœ€è¦æ‰¿æ‹…æ–°è§’è‰²å’Œå…·å¤‡æ–°æŠ€èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.10819">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-4b1ba79c5cb5b1759df6d8323ec1a06e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812466&auth_key=1760812466-0-0-347b7a446636dfa6b46ecdc2a0900285&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fcb20dd0bbb171421f88a93705bd6e5a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812473&auth_key=1760812473-0-0-00bc836d2e3a7aeacf5f99c8551bb35b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="X-VLA-Soft-Prompted-Transformer-as-Scalable-Cross-Embodiment-Vision-Language-Action-Model"><a href="#X-VLA-Soft-Prompted-Transformer-as-Scalable-Cross-Embodiment-Vision-Language-Action-Model" class="headerlink" title="X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment   Vision-Language-Action Model"></a>X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment   Vision-Language-Action Model</h2><p><strong>Authors:Jinliang Zheng, Jianxiong Li, Zhihao Wang, Dongxiu Liu, Xirui Kang, Yuchun Feng, Yinan Zheng, Jiayin Zou, Yilun Chen, Jia Zeng, Ya-Qin Zhang, Jiangmiao Pang, Jingjing Liu, Tai Wang, Xianyuan Zhan</strong></p>
<p>Successful generalist Vision-Language-Action (VLA) models rely on effective training across diverse robotic platforms with large-scale, cross-embodiment, heterogeneous datasets. To facilitate and leverage the heterogeneity in rich, diverse robotic data sources, we propose a novel Soft Prompt approach with minimally added parameters, by infusing prompt learning concepts into cross-embodiment robot learning and introducing separate sets of learnable embeddings for each distinct data source. These embeddings serve as embodiment-specific prompts, which in unity empower VLA models with effective exploitation of varying cross-embodiment features. Our new X-VLA, a neat flow-matching-based VLA architecture, relies exclusively on soft-prompted standard Transformer encoders, enjoying both scalability and simplicity. Evaluated across 6 simulations as well as 3 real-world robots, our 0.9B instantiation-X-VLA-0.9B simultaneously achieves SOTA performance over a sweep of benchmarks, demonstrating superior results on a wide axes of capabilities, from flexible dexterity to quick adaptation across embodiments, environments, and tasks. Website: <a target="_blank" rel="noopener" href="https://thu-air-dream.github.io/X-VLA/">https://thu-air-dream.github.io/X-VLA/</a> </p>
<blockquote>
<p>æˆåŠŸçš„é€šç”¨å‹è§†è§‰è¯­è¨€åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹ä¾èµ–äºåœ¨å¤šæ ·åŒ–çš„æœºå™¨äººå¹³å°ä¸Šè¿›è¡Œå¤§è§„æ¨¡ã€è·¨å½¢æ€ã€å¼‚è´¨æ•°æ®é›†çš„æœ‰æ•ˆè®­ç»ƒã€‚ä¸ºäº†ä¿ƒè¿›å¹¶åˆ©ç”¨ä¸°å¯Œå¤šæ ·çš„æœºå™¨äººæ•°æ®æºä¸­çš„å¼‚è´¨æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„è½¯æç¤ºæ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥æå°‘é‡çš„å‚æ•°ï¼Œå°†æç¤ºå­¦ä¹ çš„æ¦‚å¿µèå…¥åˆ°è·¨å½¢æ€æœºå™¨äººå­¦ä¹ ä¸­ï¼Œå¹¶ä¸ºæ¯ä¸ªä¸åŒçš„æ•°æ®æºå¼•å…¥å•ç‹¬çš„å­¦ä¹ åµŒå…¥é›†åˆã€‚è¿™äº›åµŒå…¥ä½œä¸ºç‰¹å®šå½¢æ€çš„æç¤ºï¼Œåœ¨ç»Ÿä¸€ä¸­èµ‹äºˆVLAæ¨¡å‹æœ‰æ•ˆåˆ©ç”¨å„ç§è·¨å½¢æ€ç‰¹å¾çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æ–°å‹X-VLAï¼Œä¸€ç§åŸºäºæ•´æ´æµåŒ¹é…çš„VLAæ¶æ„ï¼Œå®Œå…¨ä¾èµ–äºè½¯æç¤ºçš„æ ‡å‡†Transformerç¼–ç å™¨ï¼Œæ—¢å¯æ‰©å±•åˆç®€å•ã€‚åœ¨6ä¸ªæ¨¡æ‹Ÿç¯å¢ƒå’Œ3ä¸ªçœŸå®æœºå™¨äººä¸Šè¿›è¡Œè¯„ä¼°ï¼Œæˆ‘ä»¬çš„0.9Bå®ä¾‹åŒ–X-VLA-0.9BåŒæ—¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°æœ€æ–°æ€§èƒ½ï¼Œåœ¨å¹¿æ³›çš„èƒ½åŠ›è½´ä¸Šæ˜¾ç¤ºå‡ºå“è¶Šçš„ç»“æœï¼ŒåŒ…æ‹¬çµæ´»çš„çµå·§æ€§ã€å¿«é€Ÿé€‚åº”ä¸åŒå½¢æ€ã€ç¯å¢ƒå’Œä»»åŠ¡çš„èƒ½åŠ›ã€‚ç½‘ç«™åœ°å€ä¸ºï¼š<a target="_blank" rel="noopener" href="https://thu-air-dream.github.io/X-VLA/%E3%80%82">https://thu-air-dream.github.io/X-VLA/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.10274v1">PDF</a> preprint, technical report, 33 pages</p>
<p><strong>Summary</strong><br>     æ–°å‹é€šç”¨å‹è§†è§‰è¯­è¨€åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹é€šè¿‡è·¨å¤šç§æœºå™¨äººå¹³å°çš„å¤§è§„æ¨¡ã€è·¨å½¢æ€ã€å¼‚æ„æ•°æ®é›†è¿›è¡Œæœ‰æ•ˆè®­ç»ƒã€‚ä¸ºåˆ©ç”¨ä¸°å¯Œçš„æœºå™¨äººæ•°æ®æºä¸­çš„å¼‚è´¨æ€§ï¼Œæå‡ºä¸€ç§å¸¦æœ‰å°‘é‡é¢å¤–å‚æ•°çš„æ–°å‹è½¯æç¤ºæ–¹æ³•ï¼Œé€šè¿‡å°†æç¤ºå­¦ä¹ æ¦‚å¿µèå…¥è·¨å½¢æ€æœºå™¨äººå­¦ä¹ ï¼Œå¹¶ä¸ºæ¯ä¸ªä¸åŒæ•°æ®æºå¼•å…¥å•ç‹¬çš„å­¦ä¹ åµŒå…¥é›†åˆã€‚è¿™äº›åµŒå…¥ä½œä¸ºå½¢æ€ç‰¹å®šæç¤ºï¼Œä½¿VLAæ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨ä¸åŒçš„è·¨å½¢æ€ç‰¹å¾ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œæ–°å‹X-VLAæ¶æ„åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æœºå™¨äººä¸Šå‡è¾¾åˆ°æœ€æ–°æ€§èƒ½æ°´å¹³ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æˆåŠŸçš„ä¸€èˆ¬æ€§è§†è§‰è¯­è¨€åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹ä¾èµ–äºè·¨å¤šç§æœºå™¨äººå¹³å°çš„å¤§è§„æ¨¡ã€è·¨å½¢æ€ã€å¼‚æ„æ•°æ®é›†çš„æœ‰æ•ˆè®­ç»ƒã€‚</li>
<li>æå‡ºä¸€ç§æ–°å‹è½¯æç¤ºæ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥æç¤ºå­¦ä¹ æ¦‚å¿µæ¥åˆ©ç”¨ä¸°å¯Œçš„æœºå™¨äººæ•°æ®æºä¸­çš„å¼‚è´¨æ€§ã€‚</li>
<li>è½¯æç¤ºæ–¹æ³•ä½¿ç”¨å°‘é‡é¢å¤–å‚æ•°ï¼Œé€šè¿‡å¼•å…¥å½¢æ€ç‰¹å®šæç¤ºæ¥å¢å¼ºVLAæ¨¡å‹çš„èƒ½åŠ›ã€‚</li>
<li>X-VLAæ¶æ„æ˜¯ä¸€ç§åŸºäºæµç•…åŒ¹é…çš„VLAæ¶æ„ï¼Œä»…ä¾èµ–äºæ ‡å‡†Transformerç¼–ç å™¨çš„è½¯æç¤ºï¼Œå…·æœ‰å¯æ‰©å±•æ€§å’Œç®€å•æ€§ã€‚</li>
<li>åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æœºå™¨äººä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒX-VLAæ¶æ„è¾¾åˆ°æœ€æ–°æ€§èƒ½æ°´å¹³ã€‚</li>
<li>X-VLAæ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼ŒåŒ…æ‹¬çµæ´»æ€§å’Œå¿«é€Ÿé€‚åº”èƒ½åŠ›ç­‰æ–¹é¢çš„å¹¿æ³›èƒ½åŠ›ã€‚</li>
<li>è¯¥æ¨¡å‹çš„ç½‘ç«™åœ°å€ä¸ºï¼š<a target="_blank" rel="noopener" href="https://thu-air-dream.github.io/X-VLA/%E3%80%82">https://thu-air-dream.github.io/X-VLA/ã€‚</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.10274">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-d5d047ace36b849125d3ef7c8b601a62~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812481&auth_key=1760812481-0-0-800a84c3106ea4cde66de782f78e3c7a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bc01e782e4c7a726f818c356a92b2050~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812488&auth_key=1760812488-0-0-cba2d457e4a6405887f2c7fb06fad094&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f5224c0f66222096b7a2bb453c155b4c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812495&auth_key=1760812495-0-0-2f1c80b22255cba07249d1b48538cb1f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Graph-Diffusion-Transformers-are-In-Context-Molecular-Designers"><a href="#Graph-Diffusion-Transformers-are-In-Context-Molecular-Designers" class="headerlink" title="Graph Diffusion Transformers are In-Context Molecular Designers"></a>Graph Diffusion Transformers are In-Context Molecular Designers</h2><p><strong>Authors:Gang Liu, Jie Chen, Yihan Zhu, Michael Sun, Tengfei Luo, Nitesh V Chawla, Meng Jiang</strong></p>
<p>In-context learning allows large models to adapt to new tasks from a few demonstrations, but it has shown limited success in molecular design. Existing databases such as ChEMBL contain molecular properties spanning millions of biological assays, yet labeled data for each property remain scarce. To address this limitation, we introduce demonstration-conditioned diffusion models (DemoDiff), which define task contexts using a small set of molecule-score examples instead of text descriptions. These demonstrations guide a denoising Transformer to generate molecules aligned with target properties. For scalable pretraining, we develop a new molecular tokenizer with Node Pair Encoding that represents molecules at the motif level, requiring 5.5$\times$ fewer nodes. We curate a dataset containing millions of context tasks from multiple sources covering both drugs and materials, and pretrain a 0.7-billion-parameter model on it. Across 33 design tasks in six categories, DemoDiff matches or surpasses language models 100-1000$\times$ larger and achieves an average rank of 3.63 compared to 5.25-10.20 for domain-specific approaches. These results position DemoDiff as a molecular foundation model for in-context molecular design. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/liugangcode/DemoDiff">https://github.com/liugangcode/DemoDiff</a>. </p>
<blockquote>
<p>ä¸Šä¸‹æ–‡å­¦ä¹ å…è®¸å¤§å‹æ¨¡å‹ä»å°‘é‡æ¼”ç¤ºä¸­é€‚åº”æ–°ä»»åŠ¡ï¼Œä½†åœ¨åˆ†å­è®¾è®¡é¢†åŸŸå…¶æˆåŠŸæœ‰é™ã€‚ç°æœ‰æ•°æ®åº“å¦‚ChEMBLåŒ…å«è·¨è¶Šæ•°ç™¾ä¸‡ç”Ÿç‰©å®éªŒçš„åˆ†å­å±æ€§ï¼Œä½†é’ˆå¯¹æ¯ä¸ªå±æ€§çš„æ ‡è®°æ•°æ®ä»ç„¶ç¨€ç¼ºã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ¼”ç¤ºæ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆDemoDiffï¼‰ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨å°‘é‡åˆ†å­è¯„åˆ†ç¤ºä¾‹è€Œä¸æ˜¯æ–‡æœ¬æè¿°æ¥å®šä¹‰ä»»åŠ¡ä¸Šä¸‹æ–‡ã€‚è¿™äº›æ¼”ç¤ºå¼•å¯¼å»å™ªTransformerç”Ÿæˆä¸ç›®æ ‡å±æ€§å¯¹é½çš„åˆ†å­ã€‚ä¸ºäº†å¯æ‰©å±•çš„é¢„è®­ç»ƒï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ–°çš„åˆ†å­åˆ†è¯å™¨ï¼Œé‡‡ç”¨èŠ‚ç‚¹å¯¹ç¼–ç æ–¹å¼åœ¨ä¸»é¢˜çº§åˆ«è¡¨ç¤ºåˆ†å­ï¼Œæ‰€éœ€èŠ‚ç‚¹å‡å°‘äº†5.5å€ã€‚æˆ‘ä»¬ä»å¤šä¸ªæ¥æºæ•´ç†äº†ä¸€ä¸ªåŒ…å«æ•°ç™¾ä¸‡ä¸Šä¸‹æ–‡ä»»åŠ¡çš„æ•°æ®é›†ï¼Œæ¶µç›–äº†è¯ç‰©å’Œææ–™ï¼Œå¹¶åœ¨å…¶ä¸Šé¢„è®­ç»ƒäº†ä¸€ä¸ª0.7äº¿å‚æ•°çš„æ¨¡å‹ã€‚åœ¨6ä¸ªç±»åˆ«çš„33ä¸ªè®¾è®¡ä»»åŠ¡ä¸­ï¼ŒDemoDiffä¸è¯­è¨€æ¨¡å‹ç›¸åŒ¹é…æˆ–è¡¨ç°æ›´å¥½ï¼Œå…¶å¹³å‡æ’åä¸º3.63ï¼Œè€Œé¢†åŸŸç‰¹å®šæ–¹æ³•çš„æ’åä¸º5.25-10.20ã€‚è¿™äº›ç»“æœå°†DemoDiffå®šä½ä¸ºä¸Šä¸‹æ–‡åˆ†å­è®¾è®¡çš„åŸºç¡€æ¨¡å‹ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/liugangcode/DemoDiff%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/liugangcode/DemoDiffæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08744v1">PDF</a> 29 pages, 16 figures, 17 tables. Model available at:   <a target="_blank" rel="noopener" href="https://huggingface.co/liuganghuggingface/DemoDiff-0.7B">https://huggingface.co/liuganghuggingface/DemoDiff-0.7B</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºDemoDiffçš„åˆ†å­è®¾è®¡æ–°æ–¹æ³•ï¼Œå®ƒé€šè¿‡åˆ©ç”¨æ¼”ç¤ºæ¡ä»¶çš„æ‰©æ•£æ¨¡å‹ï¼ˆDemoDiffï¼‰å’ŒèŠ‚ç‚¹å¯¹ç¼–ç ï¼ˆNode Pair Encodingï¼‰æŠ€æœ¯ï¼Œå®ç°äº†åˆ†å­è®¾è®¡çš„è‡ªé€‚åº”å’Œå¤§è§„æ¨¡é¢„è®­ç»ƒã€‚è¯¥æ–¹æ³•é€šè¿‡ä¸€å°æ‰¹åˆ†å­åˆ†æ•°ç¤ºä¾‹å®šä¹‰ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼Œå¼•å¯¼å»å™ªTransformerç”Ÿæˆä¸ç›®æ ‡å±æ€§å¯¹é½çš„åˆ†å­ã€‚é€šè¿‡ä»å¤šä¸ªæ¥æºåˆ›å»ºåŒ…å«æ•°ç™¾ä¸‡ä¸Šä¸‹æ–‡ä»»åŠ¡çš„æ•°æ®é›†ï¼Œå¹¶å¯¹å…¶è¿›è¡Œé¢„è®­ç»ƒï¼ŒDemoDiffåœ¨å¤šä¸ªè®¾è®¡ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æˆæœï¼Œæˆä¸ºåˆ†å­è®¾è®¡é¢†åŸŸçš„åŸºç¡€æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DemoDiffåˆ©ç”¨æ¼”ç¤ºæ¡ä»¶çš„æ‰©æ•£æ¨¡å‹è¿›è¡Œåˆ†å­è®¾è®¡ï¼Œé€šè¿‡å°è§„æ¨¡çš„åˆ†å­åˆ†æ•°ç¤ºä¾‹å®šä¹‰ä»»åŠ¡ä¸Šä¸‹æ–‡ã€‚</li>
<li>å»å™ªTransformeråœ¨DemoDiffä¸­è¢«ç”¨äºç”Ÿæˆä¸ç›®æ ‡å±æ€§å¯¹é½çš„åˆ†å­ã€‚</li>
<li>Node Pair EncodingæŠ€æœ¯ç”¨äºå¤§è§„æ¨¡é¢„è®­ç»ƒåˆ†å­è®¾è®¡çš„æ¨¡å‹è¡¨ç¤ºã€‚</li>
<li>åˆ›å»ºäº†ä¸€ä¸ªåŒ…å«æ•°ç™¾ä¸‡ä¸Šä¸‹æ–‡ä»»åŠ¡çš„æ•°æ®é›†ï¼Œæ¶µç›–è¯ç‰©å’Œææ–™é¢†åŸŸã€‚</li>
<li>é¢„è®­ç»ƒçš„æ¨¡å‹åœ¨å¤šä¸ªè®¾è®¡ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä¸å¤§å‹è¯­è¨€æ¨¡å‹ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08744">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-0c81f2ef328b0309283c44870ac60a87~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812503&auth_key=1760812503-0-0-9edc36bd311b21e0b677cff0a48a7300&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b2678f0a8a6f4cdee1409891ec926124~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812511&auth_key=1760812511-0-0-ddad8ec98176bd464264418d6dfdeebb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-373196df7a7775ea5231f8e252f6eac7~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812517&auth_key=1760812517-0-0-016585c9ec962634d1ea299aaf1e676e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-30ad430f7f4bf92471ac807a0cd29e8f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812524&auth_key=1760812524-0-0-cdadc0ab3ba4cdd7f5e5287ea91a7863&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Machine-Unlearning-Meets-Adversarial-Robustness-via-Constrained-Interventions-on-LLMs"><a href="#Machine-Unlearning-Meets-Adversarial-Robustness-via-Constrained-Interventions-on-LLMs" class="headerlink" title="Machine Unlearning Meets Adversarial Robustness via Constrained   Interventions on LLMs"></a>Machine Unlearning Meets Adversarial Robustness via Constrained   Interventions on LLMs</h2><p><strong>Authors:Fatmazohra Rezkellah, Ramzi Dakhmouche</strong></p>
<p>With the increasing adoption of Large Language Models (LLMs), more customization is needed to ensure privacy-preserving and safe generation. We address this objective from two critical aspects: unlearning of sensitive information and robustness to jail-breaking attacks. We investigate various constrained optimization formulations that address both aspects in a \emph{unified manner}, by finding the smallest possible interventions on LLM weights that either make a given vocabulary set unreachable or embed the LLM with robustness to tailored attacks by shifting part of the weights to a \emph{safer} region. Beyond unifying two key properties, this approach contrasts with previous work in that it doesnâ€™t require an oracle classifier that is typically not available or represents a computational overhead. Surprisingly, we find that the simplest point-wise constraint-based intervention we propose leads to better performance than max-min interventions, while having a lower computational cost. Comparison against state-of-the-art defense methods demonstrates superior performance of the proposed approach. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ—¥ç›Šæ™®åŠï¼Œéœ€è¦æ›´å¤šçš„å®šåˆ¶åŒ–ä»¥ç¡®ä¿å…¶ç”Ÿæˆè¿‡ç¨‹ä¸­çš„éšç§ä¿æŠ¤å’Œå®‰å…¨æ€§ã€‚æˆ‘ä»¬ä»ä¸¤ä¸ªå…³é”®æ–¹é¢æ¥å®ç°è¿™ä¸€ç›®æ ‡ï¼šæ¶ˆé™¤æ•æ„Ÿä¿¡æ¯çš„é—å¿˜å’Œå¯¹æŠ—è¶Šç‹±æ”»å‡»çš„ç¨³å¥æ€§ã€‚æˆ‘ä»¬é€šè¿‡å¯»æ‰¾å¯¹LLMæƒé‡å°½å¯èƒ½å°çš„å¹²é¢„ï¼Œä»¥ä¸€ç§ç»Ÿä¸€çš„æ–¹å¼è§£å†³è¿™ä¸¤ä¸ªæ–¹é¢çš„é—®é¢˜ï¼Œè¦ä¹ˆä½¿ç»™å®šçš„è¯æ±‡é›†æ— æ³•è®¿é—®ï¼Œè¦ä¹ˆé€šè¿‡å°†éƒ¨åˆ†æƒé‡è½¬ç§»åˆ°â€œæ›´å®‰å…¨â€çš„åŒºåŸŸï¼Œä½¿LLMå¯¹å®šåˆ¶æ”»å‡»å…·æœ‰ç¨³å¥æ€§ã€‚é™¤äº†ç»Ÿä¸€è¿™ä¸¤ä¸ªå…³é”®å±æ€§ä¹‹å¤–ï¼Œè¿™ç§æ–¹æ³•ä¸ä¹‹å‰çš„å·¥ä½œå½¢æˆå¯¹æ¯”ï¼Œå› ä¸ºå®ƒä¸éœ€è¦é€šå¸¸ä¸å¯ç”¨æˆ–ä»£è¡¨è®¡ç®—å¼€é”€çš„oracleåˆ†ç±»å™¨ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œæˆ‘ä»¬å‘ç°æˆ‘ä»¬æå‡ºçš„æœ€ç®€å•çš„ç‚¹çº¦æŸå¹²é¢„åœ¨æ€§èƒ½ä¸Šä¼˜äºæœ€å¤§æœ€å°å¹²é¢„ï¼ŒåŒæ—¶è®¡ç®—æˆæœ¬æ›´ä½ã€‚ä¸æœ€å…ˆè¿›çš„é˜²å¾¡æ–¹æ³•çš„æ¯”è¾ƒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å…·æœ‰ä¼˜è¶Šçš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.03567v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¹¿æ³›åº”ç”¨ï¼Œéœ€è¦æ›´å¤šçš„å®šåˆ¶åŒ–æ¥ç¡®ä¿å…¶åœ¨ä¿æŠ¤éšç§å’Œå®‰å…¨ç”Ÿæˆæ–¹é¢çš„æ€§èƒ½ã€‚æœ¬æ–‡ä»ä¸¤ä¸ªå…³é”®æ–¹é¢ç€æ‰‹ï¼šæ¶ˆé™¤æ•æ„Ÿä¿¡æ¯å’ŒæŠµå¾¡è¶Šç‹±æ”»å‡»ã€‚é€šè¿‡æ¢ç©¶å„ç§çº¦æŸä¼˜åŒ–å…¬å¼ï¼Œä»¥ä¸€ç§ç»Ÿä¸€çš„æ–¹å¼è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ï¼Œé€šè¿‡å¯¹LLMæƒé‡è¿›è¡Œå°½å¯èƒ½å°çš„å¹²é¢„ï¼Œä½¿ç»™å®šçš„è¯æ±‡é›†æ— æ³•è®¿é—®ï¼Œæˆ–å°†éƒ¨åˆ†æƒé‡è½¬ç§»åˆ°â€œå®‰å…¨â€åŒºåŸŸï¼Œä½¿LLMå…·æœ‰å¯¹å®šåˆ¶æ”»å‡»çš„ç¨³å¥æ€§ã€‚è¿™ç§æ–¹æ³•ä¸ä»…ç»Ÿä¸€äº†ä¸¤ç§å…³é”®å±æ€§ï¼Œè€Œä¸”ä¸ä¹‹å‰çš„å·¥ä½œå½¢æˆå¯¹æ¯”ï¼Œå› ä¸ºå®ƒä¸éœ€è¦é€šå¸¸ä¸å¯ç”¨æˆ–ä»£è¡¨è®¡ç®—å¼€é”€çš„oracleåˆ†ç±»å™¨ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œæˆ‘ä»¬å‘ç°æœ€ç®€å•çš„åŸºäºç‚¹çº¦æŸçš„å¹²é¢„æ–¹æ³•æ¯”æœ€å¤§æœ€å°å¹²é¢„æ–¹æ³•è¡¨ç°æ›´å¥½ï¼ŒåŒæ—¶è®¡ç®—æˆæœ¬æ›´ä½ã€‚ä¸æœ€æ–°é˜²å¾¡æ–¹æ³•çš„å¯¹æ¯”æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¹¿æ³›åº”ç”¨éœ€è¦æ›´å¤šçš„å®šåˆ¶åŒ–ä»¥ç¡®ä¿éšç§å’Œå®‰å…¨ç”Ÿæˆã€‚</li>
<li>æ¶ˆé™¤æ•æ„Ÿä¿¡æ¯å’ŒæŠµå¾¡è¶Šç‹±æ”»å‡»æ˜¯LLMå®šåˆ¶åŒ–çš„ä¸¤ä¸ªå…³é”®æ–¹é¢ã€‚</li>
<li>é€šè¿‡çº¦æŸä¼˜åŒ–å…¬å¼ä»¥ç»Ÿä¸€æ–¹å¼è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ã€‚</li>
<li>é€šè¿‡å¯¹LLMæƒé‡è¿›è¡Œæœ€å°å¹²é¢„æ¥å®ç°è¯æ±‡é›†çš„ä¸å¯è¾¾æ€§æˆ–æ¨¡å‹å¯¹å®šåˆ¶æ”»å‡»çš„ç¨³å¥æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸ä¹‹å‰çš„å·¥ä½œä¸åŒï¼Œä¸éœ€è¦oracleåˆ†ç±»å™¨ã€‚</li>
<li>æœ€ç®€å•çš„åŸºäºç‚¹çº¦æŸçš„å¹²é¢„æ–¹æ³•è¡¨ç°æœ€ä½³ï¼ŒåŒæ—¶è®¡ç®—æˆæœ¬æ›´ä½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.03567">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-d898098daa046ce54cc232e6dddcd5e5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812532&auth_key=1760812532-0-0-fc998846a419e0526ac8b6afaef33ae6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e6ae81fb6af72e956905e01558e482dc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812539&auth_key=1760812539-0-0-59beb2fc73107975a8ede6dc09e6a3fc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-39ac17430a6b0fab7293498dcbee0852~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812545&auth_key=1760812545-0-0-c7e1a156dac37adff90b47c24ea958f7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-33b9d3b86211b2c4e65f6e2173c8f539~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812552&auth_key=1760812552-0-0-2a42ac60c039a9b00fe99b6568b54691&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-945e05abe9c306546ea9fd5971f6487e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812558&auth_key=1760812558-0-0-5f31c5942fd4b6a6f9b235eecb569ed7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Attention-Surgery-An-Efficient-Recipe-to-Linearize-Your-Video-Diffusion-Transformer"><a href="#Attention-Surgery-An-Efficient-Recipe-to-Linearize-Your-Video-Diffusion-Transformer" class="headerlink" title="Attention Surgery: An Efficient Recipe to Linearize Your Video Diffusion   Transformer"></a>Attention Surgery: An Efficient Recipe to Linearize Your Video Diffusion   Transformer</h2><p><strong>Authors:Mohsen Ghafoorian, Denis Korzhenkov, Amirhossein Habibian</strong></p>
<p>Transformer-based video diffusion models (VDMs) deliver state-of-the-art video generation quality but are constrained by the quadratic cost of self-attention, making long sequences and high resolutions computationally expensive. While linear attention offers sub-quadratic complexity, prior attempts fail to match the expressiveness of softmax attention without costly retraining. We introduce Attention Surgery, an efficient framework for linearizing or hybridizing attention in pretrained VDMs without training from scratch. Inspired by recent advances in language models, our method combines a novel hybrid attention mechanism-mixing softmax and linear tokens-with a lightweight distillation and fine-tuning pipeline requiring only a few GPU-days. Additionally, we incorporate a cost-aware block-rate strategy to balance expressiveness and efficiency across layers. Applied to Wan2.1 1.3B, a state-of-the-art DiT-based VDM, Attention Surgery achieves the first competitive sub-quadratic attention video diffusion models, reducing attention cost by up to 40% in terms of FLOPs, while maintaining generation quality as measured on the standard VBench and VBench-2.0 benchmarks. Project page is available at: <a target="_blank" rel="noopener" href="https://qualcomm-ai-research.github.io/attention-surgery">https://qualcomm-ai-research.github.io/attention-surgery</a>. </p>
<blockquote>
<p>åŸºäºTransformerçš„è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆVDMï¼‰æä¾›äº†æœ€å…ˆè¿›çš„è§†é¢‘ç”Ÿæˆè´¨é‡ï¼Œä½†å—åˆ°è‡ªæ³¨æ„åŠ›æœºåˆ¶äºŒæ¬¡æˆæœ¬çš„é™åˆ¶ï¼Œä½¿å¾—é•¿åºåˆ—å’Œé«˜åˆ†è¾¨ç‡çš„è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚è™½ç„¶çº¿æ€§æ³¨æ„åŠ›æä¾›äº†æ¬¡äºŒæ¬¡å¤æ‚åº¦ï¼Œä½†ä¹‹å‰çš„å°è¯•åœ¨æ²¡æœ‰æ˜‚è´µå†è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œæ— æ³•åŒ¹é…softmaxæ³¨æ„åŠ›çš„è¡¨ç°åŠ›ã€‚æˆ‘ä»¬å¼•å…¥äº†â€œæ³¨æ„åŠ›æ‰‹æœ¯â€è¿™ä¸€é«˜æ•ˆæ¡†æ¶ï¼Œç”¨äºåœ¨é¢„è®­ç»ƒçš„VDMä¸­çº¿æ€§åŒ–æˆ–æ··åˆæ³¨æ„åŠ›ï¼Œè€Œæ— éœ€ä»å¤´å¼€å§‹è®­ç»ƒã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†æ–°å‹æ··åˆæ³¨æ„åŠ›æœºåˆ¶â€”â€”æ··åˆsoftmaxå’Œçº¿æ€§ä»¤ç‰Œï¼Œä»¥åŠè½»é‡çº§çš„è’¸é¦å’Œå¾®è°ƒç®¡é“ï¼Œåªéœ€å‡ å¤©çš„GPUæ—¶é—´ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§æˆæœ¬æ„ŸçŸ¥çš„å—ç‡ç­–ç•¥ï¼Œä»¥åœ¨å±‚ä¹‹é—´å¹³è¡¡è¡¨ç°åŠ›å’Œæ•ˆç‡ã€‚åº”ç”¨äºWan2.1 1.3Bï¼ˆä¸€ç§åŸºäºDiTçš„VDMçš„å…ˆè¿›çŠ¶æ€ï¼‰ï¼Œæ³¨æ„åŠ›æ‰‹æœ¯å®ç°äº†é¦–ä¸ªå…·æœ‰ç«äº‰åŠ›çš„æ¬¡äºŒæ¬¡æ³¨æ„åŠ›è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œåœ¨FLOPsæ–¹é¢å°†æ³¨æ„åŠ›æˆæœ¬é™ä½äº†é«˜è¾¾40%ï¼ŒåŒæ—¶ä¿æŒåœ¨VBenchå’ŒVBench-2.0æ ‡å‡†åŸºå‡†ä¸Šçš„ç”Ÿæˆè´¨é‡ã€‚é¡¹ç›®é¡µé¢å¯åœ¨ä»¥ä¸‹ç½‘å€æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://qualcomm-ai-research.github.io/attention-surgery">https://qualcomm-ai-research.github.io/attention-surgery</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24899v2">PDF</a> </p>
<p><strong>Summary</strong>ï¼šåŸºäºTransformerçš„è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆVDMï¼‰è™½ç„¶èƒ½ç”Ÿæˆé«˜è´¨é‡çš„è§†é¢‘ï¼Œä½†ç”±äºè‡ªæ³¨æ„åŠ›çš„äºŒæ¬¡æˆæœ¬ï¼Œå¤„ç†é•¿åºåˆ—å’Œé«˜åˆ†è¾¨ç‡æ—¶è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚ç ”ç©¶è€…å¼•å…¥äº†ä¸€ç§åä¸ºAttention Surgeryçš„é«˜æ•ˆæ¡†æ¶ï¼Œå®ƒé€šè¿‡æ··åˆsoftmaxå’Œçº¿æ€§ä»¤ç‰Œæ¥å®ç°æ³¨æ„åŠ›çš„çº¿æ€§åŒ–æˆ–æ··åˆåŒ–ï¼Œä¸éœ€è¦ä»å¤´å¼€å§‹è®­ç»ƒå³å¯åº”ç”¨äºé¢„è®­ç»ƒçš„VDMã€‚è¿™ç§æ–¹æ³•ç»“åˆäº†è½»é‡çº§çš„è’¸é¦å’Œå¾®è°ƒç®¡é“ï¼Œå¹¶åœ¨ä¸šç•Œé¦–æ¬¡å®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„æ¬¡äºŒæ¬¡æ³¨æ„åŠ›è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œåœ¨FLOPsæ–¹é¢å°†æ³¨æ„åŠ›æˆæœ¬é™ä½äº†é«˜è¾¾40%ï¼ŒåŒæ—¶ä¿æŒäº†VBenchå’ŒVBench-2.0åŸºå‡†æµ‹è¯•ä¸­çš„ç”Ÿæˆè´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>åŸºäºTransformerçš„è§†é¢‘æ‰©æ•£æ¨¡å‹é¢ä¸´è®¡ç®—æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯å¤„ç†é•¿åºåˆ—å’Œé«˜åˆ†è¾¨ç‡æ—¶ã€‚</li>
<li>Attention Surgeryæ¡†æ¶æ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ï¼Œå®ƒé€šè¿‡æ··åˆsoftmaxå’Œçº¿æ€§æ³¨æ„åŠ›æœºåˆ¶æ¥å®ç°ã€‚</li>
<li>Attention Surgeryç»“åˆäº†è½»é‡çº§çš„è’¸é¦å’Œå¾®è°ƒç®¡é“ï¼Œä½¿å¾—è¯¥æ¡†æ¶èƒ½å¤Ÿåº”ç”¨äºé¢„è®­ç»ƒçš„VDMè€Œæ— éœ€ä»å¤´å¼€å§‹è®­ç»ƒã€‚</li>
<li>è¯¥æ–¹æ³•å¼•å…¥äº†æˆæœ¬æ„ŸçŸ¥çš„åŒºå—ç‡ç­–ç•¥ï¼Œä»¥å¹³è¡¡è¡¨è¾¾æ€§å’Œæ•ˆç‡ã€‚</li>
<li>Attention Surgeryåœ¨ç»´æŒç”Ÿæˆè´¨é‡çš„åŒæ—¶é™ä½äº†æ³¨æ„åŠ›æˆæœ¬ã€‚</li>
<li>åº”ç”¨åˆ°Wan2.1 1.3Bè¿™ä¸€å…ˆè¿›çš„åŸºäºDiTçš„è§†é¢‘æ‰©æ•£æ¨¡å‹åï¼Œå®ç°äº†æ¬¡äºŒæ¬¡æ³¨æ„åŠ›è§†é¢‘æ‰©æ•£æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24899">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-65d376121d40037bc9a01ab9ce975c38~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812565&auth_key=1760812565-0-0-3f4c812f1e75764b4184f22a8abcecd8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6f8177d43614092147559b396ecaad10~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812573&auth_key=1760812573-0-0-3ebda4b080905f7d8b1e65aa5170321b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bec84dd02159870e233cb60cd3d8d87b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812579&auth_key=1760812579-0-0-40d0d3372a467536751d34d6b48f4520&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-963569a31187361476fd2db2b5a81b4a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812586&auth_key=1760812586-0-0-d0893d9b27ec587b34d151484d639a64&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="SteeringSafety-A-Systematic-Safety-Evaluation-Framework-of-Representation-Steering-in-LLMs"><a href="#SteeringSafety-A-Systematic-Safety-Evaluation-Framework-of-Representation-Steering-in-LLMs" class="headerlink" title="SteeringSafety: A Systematic Safety Evaluation Framework of   Representation Steering in LLMs"></a>SteeringSafety: A Systematic Safety Evaluation Framework of   Representation Steering in LLMs</h2><p><strong>Authors:Vincent Siu, Nicholas Crispino, David Park, Nathan W. Henry, Zhun Wang, Yang Liu, Dawn Song, Chenguang Wang</strong></p>
<p>We introduce SteeringSafety, a systematic framework for evaluating representation steering methods across seven safety perspectives spanning 17 datasets. While prior work highlights general capabilities of representation steering, we systematically explore safety perspectives including bias, harmfulness, hallucination, social behaviors, reasoning, epistemic integrity, and normative judgment. Our framework provides modularized building blocks for state-of-the-art steering methods, enabling unified implementation of DIM, ACE, CAA, PCA, and LAT with recent enhancements like conditional steering. Results on Gemma-2-2B, Llama-3.1-8B, and Qwen-2.5-7B reveal that strong steering performance depends critically on pairing of method, model, and specific perspective. DIM shows consistent effectiveness, but all methods exhibit substantial entanglement: social behaviors show highest vulnerability (reaching degradation as high as 76%), jailbreaking often compromises normative judgment, and hallucination steering unpredictably shifts political views. Our findings underscore the critical need for holistic safety evaluations. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†SteeringSafetyï¼Œè¿™æ˜¯ä¸€ä¸ªè·¨è¶Šä¸ƒä¸ªå®‰å…¨è§†è§’ï¼Œæ¶µç›–17ä¸ªæ•°æ®é›†çš„è¯„ä¼°è¡¨ç¤ºè½¬å‘æ–¹æ³•çš„ç³»ç»Ÿæ€§æ¡†æ¶ã€‚è™½ç„¶ä»¥å‰çš„å·¥ä½œå¼ºè°ƒäº†è¡¨ç¤ºè½¬å‘çš„ä¸€èˆ¬èƒ½åŠ›ï¼Œä½†æˆ‘ä»¬ç³»ç»Ÿåœ°æ¢ç´¢äº†å®‰å…¨è§†è§’ï¼ŒåŒ…æ‹¬åè§ã€æœ‰å®³æ€§ã€å¹»è§‰ã€ç¤¾ä¼šè¡Œä¸ºã€æ¨ç†ã€è®¤çŸ¥å®Œæ•´æ€§å’Œè§„èŒƒåˆ¤æ–­ã€‚æˆ‘ä»¬çš„æ¡†æ¶ä¸ºæœ€å…ˆè¿›çš„è½¬å‘æ–¹æ³•æä¾›äº†æ¨¡å—åŒ–æ„å»ºå—ï¼Œèƒ½å¤Ÿå®ç°DIMã€ACEã€CAAã€PCAå’ŒLATçš„æœ€æ–°å¢å¼ºåŠŸèƒ½ï¼Œå¦‚æ¡ä»¶è½¬å‘ã€‚åœ¨Gemma-2-2Bã€Llama-3.1-8Bå’ŒQwen-2.5-7Bä¸Šçš„ç»“æœæ­ç¤ºï¼Œå¼ºå¤§çš„è½¬å‘æ€§èƒ½å…³é”®åœ¨äºæ–¹æ³•ã€æ¨¡å‹å’Œç‰¹å®šè§†è§’çš„é…å¯¹ã€‚DIMè¡¨ç°å‡ºæŒç»­çš„æœ‰æ•ˆæ€§ï¼Œä½†æ‰€æœ‰æ–¹æ³•éƒ½è¡¨ç°å‡ºæ˜¾è‘—çš„çº ç¼ ï¼šç¤¾ä¼šè¡Œä¸ºè¡¨ç°å‡ºæœ€é«˜çš„è„†å¼±æ€§ï¼ˆé€€åŒ–é«˜è¾¾76%ï¼‰ï¼Œè¶Šç‹±å¾€å¾€ä¼šæŸå®³è§„èŒƒåˆ¤æ–­ï¼Œå¹»è§‰è½¬å‘ä¸å¯é¢„æµ‹åœ°æ”¹å˜æ”¿æ²»è§‚ç‚¹ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå…¨é¢è¿›è¡Œå®‰å…¨è¯„ä¼°è‡³å…³é‡è¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13450v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†SteeringSafetyæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç”¨äºè¯„ä¼°è¡¨å¾å¼•å¯¼æ–¹æ³•åœ¨ä¸ƒä¸ªå®‰å…¨è§†è§’ä¸‹çš„è¡¨ç°ï¼Œæ¶µç›–17ä¸ªæ•°æ®é›†ã€‚æ–‡ç« æŒ‡å‡ºå…ˆå‰çš„ç›¸å…³å·¥ä½œæ›´å¤šåœ°å…³æ³¨äº†ä¸€èˆ¬èƒ½åŠ›çš„é—®é¢˜ç ”ç©¶ï¼Œè€Œå¦‚ä»Šç ”ç©¶æ¡†æ¶æ›´ä¸ºç³»ç»Ÿåœ°å¯¹ä¸ƒä¸ªæ–¹é¢çš„å®‰å…¨è§†è§’è¿›è¡Œæ¢ç´¢ï¼ŒåŒ…æ‹¬åè§ã€æœ‰å®³æ€§ã€å¹»è§‰ã€ç¤¾ä¼šè¡Œä¸ºã€æ¨ç†ã€è®¤çŸ¥å®Œæ•´æ€§ä»¥åŠè§„èŒƒåˆ¤æ–­ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡çš„æ¡†æ¶æä¾›äº†æ¨¡å—åŒ–ç»„ä»¶å—æ”¯æŒæœ€å‰æ²¿çš„å¼•å¯¼æ–¹æ³•æŠ€æœ¯å®æ–½å¦‚æ¡ä»¶å¼é©¾é©¶æ–¹æ³•ç­‰ç­‰ï¼Œèƒ½æå¤§çš„æ”¯æŒè¿›è¡Œæ•°æ®æŒ–æ˜æ¨¡å‹è®­ç»ƒç­‰ã€‚é€šè¿‡å¯¹ä¸åŒæ¨¡å‹åœ¨ä¸åŒå®‰å…¨è§†è§’ä¸‹çš„æ€§èƒ½è¯„ä¼°ï¼Œå‘ç°ä¸åŒçš„å¼•å¯¼æ–¹æ³•åœ¨ä¸åŒè§†è§’ä¸‹çš„è¡¨ç°å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚åŒæ—¶æŒ‡å‡ºç¤¾ä¼šè¡Œä¸ºæ–¹é¢å­˜åœ¨è¾ƒé«˜çš„è„†å¼±æ€§é£é™©è¾ƒé«˜ã€‚æœ¬ç ”ç©¶å¼ºè°ƒå¯¹è¡¨å¾å¼•å¯¼æ–¹æ³•çš„å…¨é¢å®‰å…¨è¯„ä¼°è‡³å…³é‡è¦ã€‚ç®€è€Œè¨€ä¹‹ï¼Œè®ºæ–‡æ·±å…¥æ¢è®¨äº†è¯„ä¼°AIé©¾é©¶å®‰å…¨çš„æ–°æ¡†æ¶å’Œå…¶ä¸åŒé¢†åŸŸåº”ç”¨ä¸­å‡ºç°çš„é—®é¢˜å’Œæ€§èƒ½ã€‚ç³»ç»Ÿåœ°ä»å¤šä¸ªè§’åº¦å¯¹é©¾é©¶å®‰å…¨è¿›è¡Œè¯„ä¼°ï¼Œå‘ç°ä¸åŒé©¾é©¶æ–¹æ³•çš„ä¼˜ç¼ºç‚¹å’Œæ½œåœ¨é£é™©ã€‚å¼ºè°ƒå…¨é¢è¯„ä¼°çš„é‡è¦æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä¸€ã€å¼•å…¥äº†SteeringSafetyæ¡†æ¶ï¼Œæ—¨åœ¨ç³»ç»Ÿåœ°è¯„ä¼°è¡¨å¾å¼•å¯¼æ–¹æ³•åœ¨ä¸ƒä¸ªå®‰å…¨è§†è§’ä¸‹çš„è¡¨ç°ã€‚è¿™äº›å®‰å…¨è§†è§’åŒ…æ‹¬åè§ã€æœ‰å®³æ€§ã€å¹»è§‰ç­‰ã€‚<br>äºŒã€è¯¥æ¡†æ¶æä¾›äº†æ¨¡å—åŒ–ç»„ä»¶å—ï¼Œæ”¯æŒå¤šç§å…ˆè¿›çš„é©¾é©¶æ–¹æ³•æŠ€æœ¯å®æ–½ï¼Œå¦‚æ¡ä»¶å¼é©¾é©¶æ–¹æ³•ç­‰ã€‚</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13450">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-cfa59efeaec60458700f90fac59f456c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812594&auth_key=1760812594-0-0-41109cd6f2cdef7367fa9f4e83271a38&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4da82681fe72b8d346b25ccecf14630a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812601&auth_key=1760812601-0-0-57590528e40ddf55a973b3183c626481&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-76da1418fdfe6c078d005ce2cf85b2eb~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812608&auth_key=1760812608-0-0-997f3e35e28ae00a5def83106e47947d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cf4d5ea97a493e02883d64170094c92d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812615&auth_key=1760812615-0-0-bdcfb0adfc0265b50ecdbc9737df05ed&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Beyond-Two-Stage-Training-Cooperative-SFT-and-RL-for-LLM-Reasoning"><a href="#Beyond-Two-Stage-Training-Cooperative-SFT-and-RL-for-LLM-Reasoning" class="headerlink" title="Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning"></a>Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning</h2><p><strong>Authors:Liang Chen, Xueting Han, Li Shen, Jing Bai, Kam-Fai Wong</strong></p>
<p>Reinforcement learning (RL) has proven effective in incentivizing the reasoning abilities of large language models (LLMs), but suffers from severe efficiency challenges due to its trial-and-error nature. While the common practice employs supervised fine-tuning (SFT) as a warm-up stage for RL, this decoupled two-stage approach suffers from catastrophic forgetting: second-stage RL gradually loses SFT-acquired behaviors and inefficiently explores new patterns. This study introduces a novel method for learning reasoning models that employs bilevel optimization to facilitate better cooperation between these training paradigms. By conditioning the SFT objective on the optimal RL policy, our approach enables SFT to meta-learn how to guide RLâ€™s optimization process. During training, the lower level performs RL updates while simultaneously receiving SFT supervision, and the upper level explicitly maximizes the cooperative gain-the performance advantage of joint SFT-RL training over RL alone. Empirical evaluations on five reasoning benchmarks demonstrate that our method consistently outperforms baselines and achieves a better balance between effectiveness and efficiency. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å·²è¯æ˜åœ¨æ¿€åŠ±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢éå¸¸æœ‰æ•ˆï¼Œä½†ç”±äºå…¶è¯•é”™æ€§è´¨è€Œé¢ä¸´ä¸¥é‡çš„æ•ˆç‡æŒ‘æˆ˜ã€‚è™½ç„¶é€šå¸¸çš„åšæ³•æ˜¯é‡‡ç”¨ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ä½œä¸ºRLçš„é¢„çƒ­é˜¶æ®µï¼Œä½†è¿™ç§è§£è€¦çš„ä¸¤é˜¶æ®µæ–¹æ³•å­˜åœ¨ç¾éš¾æ€§é—å¿˜çš„é—®é¢˜ï¼šç¬¬äºŒé˜¶æ®µRLé€æ¸å¤±å»SFTè·å¾—çš„è¡Œä¸ºï¼Œå¹¶ä¸”ä½æ•ˆåœ°æ¢ç´¢æ–°æ¨¡å¼ã€‚æœ¬ç ”ç©¶ä»‹ç»äº†ä¸€ç§ç”¨äºå­¦ä¹ æ¨ç†æ¨¡å‹çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨ä¸¤çº§ä¼˜åŒ–ï¼Œä»¥ä¿ƒè¿›è¿™äº›è®­ç»ƒèŒƒå¼ä¹‹é—´çš„æ›´å¥½åˆä½œã€‚é€šè¿‡ä»¥æœ€ä½³RLç­–ç•¥ä¸ºæ¡ä»¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä½¿SFTèƒ½å¤Ÿå…ƒå­¦ä¹ å¦‚ä½•å¼•å¯¼RLçš„ä¼˜åŒ–è¿‡ç¨‹ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œåº•å±‚æ‰§è¡ŒRLæ›´æ–°ï¼ŒåŒæ—¶æ¥å—SFTç›‘ç£ï¼Œè€Œä¸Šå±‚åˆ™æ˜¾å¼åœ°æœ€å¤§åŒ–åˆä½œå¢ç›Šâ€”â€”è”åˆSFT-RLè®­ç»ƒç›¸å¯¹äºä»…ä½¿ç”¨RLçš„æ€§èƒ½ä¼˜åŠ¿ã€‚åœ¨äº”ä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„ç»éªŒè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆä¼˜äºåŸºçº¿ï¼Œå¹¶åœ¨æœ‰æ•ˆæ€§å’Œæ•ˆç‡ä¹‹é—´è¾¾åˆ°æ›´å¥½çš„å¹³è¡¡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06948v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨æ¿€åŠ±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶è¯•é”™æ€§è´¨å¯¼è‡´æ•ˆç‡ä¸¥é‡æŒ‘æˆ˜ã€‚è™½ç„¶å¸¸è§åšæ³•æ˜¯é‡‡ç”¨ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ä½œä¸ºRLçš„é¢„çƒ­é˜¶æ®µï¼Œä½†è¿™ç§è§£è€¦çš„ä¸¤é˜¶æ®µæ–¹æ³•å­˜åœ¨ç¾éš¾æ€§é—å¿˜é—®é¢˜ï¼šç¬¬äºŒé˜¶æ®µRLä¼šé€æ­¥ä¸¢å¤±SFTè·å¾—çš„è¡Œä¸ºï¼Œå¹¶ä¸”æ•ˆç‡ä½ä¸‹åœ°æ¢ç´¢æ–°æ¨¡å¼ã€‚æœ¬ç ”ç©¶ä»‹ç»äº†ä¸€ç§æ–°çš„æ¨ç†æ¨¡å‹å­¦ä¹ æ–¹æ³•ï¼Œé‡‡ç”¨ä¸¤çº§ä¼˜åŒ–ï¼Œä¿ƒè¿›è¿™ä¸¤ç§è®­ç»ƒèŒƒå¼ä¹‹é—´çš„æ›´å¥½åˆä½œã€‚é€šè¿‡ä»¥æœ€ä¼˜RLç­–ç•¥ä¸ºæ¡ä»¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä½¿SFTèƒ½å¤Ÿå…ƒå­¦ä¹ å¦‚ä½•å¼•å¯¼RLçš„ä¼˜åŒ–è¿‡ç¨‹ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½çº§æ‰§è¡ŒRLæ›´æ–°ï¼ŒåŒæ—¶æ¥å—SFTç›‘ç£ï¼Œè€Œé«˜çº§åˆ™æ˜ç¡®æœ€å¤§åŒ–åˆä½œæ”¶ç›Šâ€”â€”è”åˆSFT-RLè®­ç»ƒç›¸å¯¹äºä»…ä½¿ç”¨RLçš„æ€§èƒ½ä¼˜åŠ¿ã€‚å®è¯è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨äº”ä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šå§‹ç»ˆä¼˜äºåŸºå‡†çº¿ï¼Œå¹¶åœ¨æœ‰æ•ˆæ€§å’Œæ•ˆç‡ä¹‹é—´å–å¾—æ›´å¥½å¹³è¡¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ åœ¨æ¿€åŠ±å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ä¸Šæœ‰æ•ˆï¼Œä½†é¢ä¸´æ•ˆç‡æŒ‘æˆ˜ã€‚</li>
<li>å¸¸è§å®è·µä¸­çš„ä¸¤é˜¶æ®µæ–¹æ³•ï¼ˆç›‘ç£å¾®è°ƒåæ¥å¼ºåŒ–å­¦ä¹ ï¼‰å­˜åœ¨ç¾éš¾æ€§é—å¿˜é—®é¢˜ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºä¸€ç§ç»“åˆç›‘ç£å¾®è°ƒä¸å¼ºåŒ–å­¦ä¹ çš„æ–°å‹è®­ç»ƒæ–¹æ³•ï¼Œé‡‡ç”¨ä¸¤çº§ä¼˜åŒ–ã€‚</li>
<li>è¯¥æ–¹æ³•ä½¿ç›‘ç£å¾®è°ƒèƒ½å¤Ÿå…ƒå­¦ä¹ å¦‚ä½•å¼•å¯¼å¼ºåŒ–å­¦ä¹ çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚</li>
<li>è®­ç»ƒè¿‡ç¨‹ä¸­åŒæ—¶æ‰§è¡Œå¼ºåŒ–å­¦ä¹ æ›´æ–°ä¸ç›‘ç£å¾®è°ƒç›‘ç£ã€‚</li>
<li>æ–¹æ³•çš„å®è¯è¯„ä¼°åœ¨äº”ä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06948">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-eb8668d6cdf61542bfae02b38cbd2376~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812622&auth_key=1760812622-0-0-827448736333e87d1c2f458aac110294&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e68d6982eff611ffe7cbf50944080593~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812629&auth_key=1760812629-0-0-5ec23e42029e6b6e03d215fa06f90dcb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c69c5e95ab4136d24003f1e6b9e2d7a4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812636&auth_key=1760812636-0-0-834df23ffcdcef6660d8a6d1626f79c7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Scaling-LLM-Planning-NL2FLOW-for-Parametric-Problem-Generation-and-Rigorous-Evaluation"><a href="#Scaling-LLM-Planning-NL2FLOW-for-Parametric-Problem-Generation-and-Rigorous-Evaluation" class="headerlink" title="Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and   Rigorous Evaluation"></a>Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and   Rigorous Evaluation</h2><p><strong>Authors:Jungkoo Kang</strong></p>
<p>Robust workflow composition is critical for effective agent performance, yet progress in Large Language Model (LLM) planning and reasoning is hindered by a scarcity of scalable evaluation data. This work introduces NL2Flow, a fully automated pipeline for generating and evaluating workflow planning problems. NL2Flow generates problems parametrically in a structured intermediate representation, translating them into both natural language and formal PDDL. I evaluate several open-source, instruct-tuned LLMs on a dataset of 2296 low-difficulty problems generated by NL2Flow. Results demonstrate that the best-performing model achieved 86% success in generating valid plans and 69% in generating optimal plans (for solvable problems). Regression analysis shows that the influence of problem characteristics on plan generation is contingent on both model and prompt design. Importantly, translating natural language problems into a structured JSON representation prior to symbolic planning significantly improved success rates, suggesting a benefit from neuro-symbolic integration. These findings underscore the importance of understanding error sources within LLM reasoning as systems scale to more complex tasks. As LLM reasoning scales to increasingly complex problems, understanding the shifting bottlenecks and sources of error within these systems will be crucial. </p>
<blockquote>
<p>å¥å£®çš„å·¥ä½œæµç»„åˆå¯¹äºæœ‰æ•ˆçš„ä»£ç†æ€§èƒ½è‡³å…³é‡è¦ï¼Œç„¶è€Œï¼Œç”±äºå¯æ‰©å±•è¯„ä¼°æ•°æ®çš„ç¨€ç¼ºï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è§„åˆ’å’Œæ¨ç†æ–¹é¢çš„è¿›å±•å—åˆ°äº†é˜»ç¢ã€‚è¿™é¡¹å·¥ä½œå¼•å…¥äº†NL2Flowï¼Œä¸€ä¸ªç”¨äºç”Ÿæˆå’Œè¯„ä¼°å·¥ä½œæµè§„åˆ’é—®é¢˜çš„å…¨è‡ªåŠ¨ç®¡é“ã€‚NL2Flowä»¥ç»“æ„åŒ–çš„ä¸­é—´è¡¨ç¤ºå½¢å¼è¿›è¡Œå‚æ•°åŒ–é—®é¢˜ç”Ÿæˆï¼Œå¹¶å°†å®ƒä»¬è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€æè¿°å’Œæ­£å¼çš„é€»è¾‘ç¨‹åºè®¾è®¡çš„PDDLæ ¼å¼ã€‚æˆ‘åœ¨ç”±NL2Flowç”Ÿæˆçš„åŒ…å«æœ‰éš¾åº¦çš„2296ä¸ªé—®é¢˜çš„æ•°æ®é›†ä¸Šè¯„ä¼°äº†å‡ ä¸ªå¼€æºçš„æŒ‡ä»¤å¾®è°ƒLLMã€‚ç»“æœè¡¨æ˜ï¼Œè¡¨ç°æœ€ä½³çš„æ¨¡å‹åœ¨ç”Ÿæˆæœ‰æ•ˆè®¡åˆ’æ–¹é¢å–å¾—äº†86%çš„æˆåŠŸç‡ï¼Œåœ¨ç”Ÿæˆæœ€ä¼˜è®¡åˆ’æ–¹é¢å–å¾—äº†69%ï¼ˆé’ˆå¯¹å¯è§£å†³çš„é—®é¢˜ï¼‰ã€‚å›å½’åˆ†æè¡¨æ˜ï¼Œé—®é¢˜ç‰¹æ€§å¯¹è®¡åˆ’ç”Ÿæˆçš„å½±å“å–å†³äºæ¨¡å‹å’Œæç¤ºè®¾è®¡ä¸¤è€…ã€‚é‡è¦çš„æ˜¯ï¼Œåœ¨ç¬¦å·è§„åˆ’ä¹‹å‰å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸ºç»“æ„åŒ–çš„JSONè¡¨ç¤ºå½¢å¼æ˜¾è‘—æé«˜äº†æˆåŠŸç‡ï¼Œè¿™è¡¨æ˜ç¥ç»ç¬¦å·èåˆçš„ç›Šå¤„ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†éšç€LLMç³»ç»Ÿå¤„ç†æ›´å¤æ‚çš„ä»»åŠ¡æ—¶ï¼Œç†è§£å…¶å†…éƒ¨é”™è¯¯æ¥æºçš„é‡è¦æ€§ã€‚éšç€LLMæ¨ç†è§£å†³æ„ˆå‘å¤æ‚çš„é—®é¢˜æ—¶ï¼Œäº†è§£è¿™äº›ç³»ç»Ÿä¸­ç“¶é¢ˆé—®é¢˜çš„å˜åŒ–åŠé”™è¯¯æ¥æºå°†ä¼šè‡³å…³é‡è¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02253v6">PDF</a> 30 pages, 7 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†NL2Flowè¿™ä¸€å…¨è‡ªåŠ¨åŒ–çš„ç®¡é“ç³»ç»Ÿï¼Œç”¨äºç”Ÿæˆå¹¶è¯„ä¼°å·¥ä½œæµç¨‹è§„åˆ’é—®é¢˜ã€‚è¯¥ç³»ç»Ÿèƒ½å¤Ÿå‚æ•°åŒ–ç”Ÿæˆé—®é¢˜ï¼Œå°†å…¶è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€ä¸æ­£å¼çš„PDDLè¯­è¨€ã€‚ä½œè€…è¯„ä¼°äº†å‡ æ¬¾å¼€æºã€ç»è¿‡æŒ‡ä»¤è°ƒæ•´çš„LLMæ¨¡å‹ï¼Œåœ¨NL2Flowç”Ÿæˆçš„2296ä¸ªä½éš¾åº¦é—®é¢˜ä¸Šè¿›è¡Œæµ‹è¯•ã€‚ç»“æœæ˜¾ç¤ºï¼Œæœ€ä½³æ¨¡å‹ç”Ÿæˆæœ‰æ•ˆè®¡åˆ’çš„æˆåŠŸç‡ä¸º86%ï¼Œå¯è§£å†³é—®é¢˜çš„æœ€ä¼˜è®¡åˆ’ç”Ÿæˆç‡ä¸º69%ã€‚å›å½’åˆ†ææ˜¾ç¤ºï¼Œé—®é¢˜ç‰¹æ€§å¯¹è®¡åˆ’ç”Ÿæˆçš„å½±å“å–å†³äºæ¨¡å‹ä¸æç¤ºè®¾è®¡ã€‚å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬åŒ–ä¸ºç»“æ„åŒ–JSONè¡¨ç¤ºå†è¿›è¡Œç¬¦å·è§„åˆ’ï¼Œèƒ½æ˜¾è‘—æé«˜æˆåŠŸç‡ï¼Œæ˜¾ç¤ºå‡ºç¥ç»ç¬¦å·èåˆçš„ç›Šå¤„ã€‚éšç€LLMç³»ç»Ÿå¤„ç†çš„ä»»åŠ¡è¶Šæ¥è¶Šå¤æ‚ï¼Œç†è§£é”™è¯¯æ¥æºå°†æˆä¸ºå…³é”®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NL2Flowæ˜¯ä¸€ä¸ªç”¨äºç”Ÿæˆå’Œè¯„ä¼°å·¥ä½œæµç¨‹è§„åˆ’é—®é¢˜çš„å…¨è‡ªåŠ¨ç®¡é“ç³»ç»Ÿã€‚</li>
<li>ç³»ç»Ÿèƒ½å¤Ÿå‚æ•°åŒ–ç”Ÿæˆé—®é¢˜ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€ä¸PDDLè¯­è¨€ã€‚</li>
<li>è¯„ä¼°äº†å¤šæ¬¾LLMæ¨¡å‹åœ¨NL2Flowç”Ÿæˆçš„ä½éš¾åº¦é—®é¢˜ä¸Šçš„è¡¨ç°ã€‚</li>
<li>æœ€ä½³æ¨¡å‹ç”Ÿæˆæœ‰æ•ˆè®¡åˆ’çš„æˆåŠŸç‡ä¸º86%ï¼Œç”Ÿæˆæœ€ä¼˜è®¡åˆ’çš„æˆåŠŸç‡ä¸º69%ã€‚</li>
<li>å›å½’åˆ†ææ˜¾ç¤ºé—®é¢˜ç‰¹æ€§ã€æ¨¡å‹åŠæç¤ºè®¾è®¡å‡å½±å“è®¡åˆ’ç”Ÿæˆã€‚</li>
<li>å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬åŒ–ä¸ºç»“æ„åŒ–JSONè¡¨ç¤ºå†è¿›è¡Œç¬¦å·è§„åˆ’ï¼Œèƒ½æ˜¾è‘—æé«˜è®¡åˆ’ç”ŸæˆæˆåŠŸç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02253">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-979b5a1bd2d4ef62a8a2055323ec0fee~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812644&auth_key=1760812644-0-0-c7ec144bcb73b0689ab5819948dac0bb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c8676c52a6d4df491038b7b1a1ab64ba~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812651&auth_key=1760812651-0-0-a495ce41d15b89fb005a6bb460ababf1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7947716bca6a42f1af2ab1d1733d8dc5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812657&auth_key=1760812657-0-0-b1e8a23a8b289629e44dc208e8c2607d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-349524b73c3bdcb1c15c6bebdca9821a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812665&auth_key=1760812665-0-0-439f92470d723647307f6fbdf64d5e72&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="When-Style-Breaks-Safety-Defending-LLMs-Against-Superficial-Style-Alignment"><a href="#When-Style-Breaks-Safety-Defending-LLMs-Against-Superficial-Style-Alignment" class="headerlink" title="When Style Breaks Safety: Defending LLMs Against Superficial Style   Alignment"></a>When Style Breaks Safety: Defending LLMs Against Superficial Style   Alignment</h2><p><strong>Authors:Yuxin Xiao, Sana Tonekaboni, Walter Gerych, Vinith Suriyakumar, Marzyeh Ghassemi</strong></p>
<p>Large language models (LLMs) can be prompted with specific styles (e.g., formatting responses as lists), including in malicious queries. Prior jailbreak research mainly augments these queries with additional string transformations to maximize attack success rate (ASR). However, the impact of style patterns in the original queries that are semantically irrelevant to the malicious intent remains unclear. In this work, we seek to understand whether style patterns compromise LLM safety, how superficial style alignment increases model vulnerability, and how best to mitigate these risks during alignment. We first define ASR inflation as the increase in ASR due to style patterns in existing jailbreak benchmark queries. By evaluating 32 LLMs across seven benchmarks, we find that nearly all models exhibit ASR inflation. Notably, the inflation correlates with an LLMâ€™s relative attention to style patterns, which also overlap more with its instruction-tuning data when inflation occurs. We then investigate superficial style alignment, and find that fine-tuning with specific styles makes LLMs more vulnerable to jailbreaks of those same styles. Finally, we propose SafeStyle, a defense strategy that incorporates a small amount of safety training data augmented to match the distribution of style patterns in the fine-tuning data. Across three LLMs, six fine-tuning style settings, and two real-world instruction-tuning datasets, SafeStyle consistently outperforms baselines in maintaining LLM safety. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä»¥é€šè¿‡ç‰¹å®šçš„é£æ ¼ï¼ˆå¦‚å°†ç­”å¤æ ¼å¼åŒ–ä¸ºåˆ—è¡¨ï¼‰æ¥æç¤ºï¼Œæ¶æ„æŸ¥è¯¢ä¹ŸåŒ…æ‹¬åœ¨å†…ã€‚å…ˆå‰çš„è¶Šç‹±ç ”ç©¶ä¸»è¦æ˜¯é€šè¿‡é¢å¤–çš„å­—ç¬¦ä¸²è½¬æ¢æ¥å¢å¼ºè¿™äº›æŸ¥è¯¢ï¼Œä»¥æœ€å¤§åŒ–æ”»å‡»æˆåŠŸç‡ï¼ˆASRï¼‰ã€‚ç„¶è€Œï¼ŒåŸå§‹æŸ¥è¯¢ä¸­ä¸æ¶æ„æ„å›¾è¯­ä¹‰ä¸Šä¸ç›¸å…³çš„é£æ ¼æ¨¡å¼çš„å½±å“ä»ä¸æ¸…æ¥šã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ—¨åœ¨äº†è§£é£æ ¼æ¨¡å¼æ˜¯å¦æŸå®³LLMçš„å®‰å…¨æ€§ï¼Œè¡¨é¢é£æ ¼å¯¹é½å¦‚ä½•å¢åŠ æ¨¡å‹çš„è„†å¼±æ€§ï¼Œä»¥åŠåœ¨å¯¹é½è¿‡ç¨‹ä¸­å¦‚ä½•æœ€å¥½åœ°å‡è½»è¿™äº›é£é™©ã€‚æˆ‘ä»¬é¦–å…ˆå®šä¹‰ASRè†¨èƒ€ä¸ºç°æœ‰è¶Šç‹±åŸºå‡†æŸ¥è¯¢ä¸­é£æ ¼æ¨¡å¼å¯¼è‡´çš„ASRå¢åŠ ã€‚é€šè¿‡å¯¹32ä¸ªLLMå’Œä¸ƒä¸ªåŸºå‡†çš„æµ‹è¯•ï¼Œæˆ‘ä»¬å‘ç°å‡ ä¹æ‰€æœ‰æ¨¡å‹éƒ½è¡¨ç°å‡ºASRè†¨èƒ€ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè†¨èƒ€ä¸LLMå¯¹é£æ ¼æ¨¡å¼çš„ç›¸å¯¹å…³æ³¨ç¨‹åº¦æœ‰å…³ï¼Œå½“å‘ç”Ÿè†¨èƒ€æ—¶ï¼Œå…¶ä¸æŒ‡ä»¤å¾®è°ƒæ•°æ®çš„é‡å ä¹Ÿæ›´å¤šã€‚ç„¶åæˆ‘ä»¬ç ”ç©¶äº†è¡¨é¢é£æ ¼å¯¹é½ï¼Œå‘ç°ç”¨ç‰¹å®šé£æ ¼è¿›è¡Œå¾®è°ƒä¼šä½¿LLMæ›´å®¹æ˜“å—åˆ°ç›¸åŒé£æ ¼çš„è¶Šç‹±æ”»å‡»ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†SafeStyleï¼Œè¿™æ˜¯ä¸€ç§é˜²å¾¡ç­–ç•¥ï¼Œå®ƒç»“åˆäº†å°‘é‡çš„å®‰å…¨è®­ç»ƒæ•°æ®ï¼Œä»¥åŒ¹é…å¾®è°ƒæ•°æ®ä¸­é£æ ¼æ¨¡å¼çš„åˆ†å¸ƒã€‚åœ¨ä¸‰ä¸ªLLMã€å…­ç§å¾®è°ƒé£æ ¼è®¾ç½®å’Œä¸¤ä¸ªç°å®ä¸–ç•ŒæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ä¸Šï¼ŒSafeStyleåœ¨ä¿æŒLLMå®‰å…¨æ€§æ–¹é¢å§‹ç»ˆä¼˜äºåŸºçº¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.07452v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ˜“å—åˆ°ç‰¹å®šé£æ ¼æç¤ºçš„å½±å“ï¼ŒåŒ…æ‹¬æ ¼å¼åŒ–å“åº”ä¸ºåˆ—è¡¨ç­‰ã€‚å…ˆå‰çš„ç ”ç©¶ä¸»è¦é€šè¿‡å¢åŠ é¢å¤–çš„å­—ç¬¦ä¸²è½¬æ¢æ¥å¢å¼ºæ¶æ„æŸ¥è¯¢çš„æ”»å‡»åŠ›ï¼ˆASRï¼‰ã€‚ç„¶è€Œï¼ŒåŸå§‹æŸ¥è¯¢ä¸­è¯­ä¹‰ä¸Šæ— å…³çš„é£æ ¼æ¨¡å¼å¯¹LLMå®‰å…¨çš„å½±å“å°šä¸æ¸…æ¥šã€‚æœ¬ç ”ç©¶æ—¨åœ¨ç†è§£é£æ ¼æ¨¡å¼æ˜¯å¦å±åŠLLMå®‰å…¨ï¼Œè¡¨é¢é£æ ¼å¯¹é½å¦‚ä½•å¢åŠ æ¨¡å‹æ¼æ´ï¼Œä»¥åŠåœ¨å¯¹é½è¿‡ç¨‹ä¸­å¦‚ä½•æœ€å¥½åœ°å‡è½»è¿™äº›é£é™©ã€‚ç ”ç©¶å‘ç°å‡ ä¹æ‰€æœ‰æ¨¡å‹éƒ½å­˜åœ¨å› é£æ ¼æ¨¡å¼å¯¼è‡´çš„ASRè†¨èƒ€ç°è±¡ï¼Œä¸”è†¨èƒ€ä¸æ¨¡å‹å¯¹é£æ ¼æ¨¡å¼çš„å…³æ³¨åº¦æœ‰å…³ï¼Œå½“å‘ç”Ÿè†¨èƒ€æ—¶ï¼Œä¸æŒ‡ä»¤è°ƒæ•´æ•°æ®çš„é‡å æ›´å¤šã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°ç‰¹å®šé£æ ¼çš„å¾®è°ƒä¼šä½¿LLMæ›´å®¹æ˜“å—åˆ°ç›¸åŒé£æ ¼çš„è¶Šç‹±æ”»å‡»ã€‚æœ€åï¼Œæå‡ºäº†ä¸€ç§é˜²å¾¡ç­–ç•¥SafeStyleï¼Œé€šè¿‡åŠ å…¥å°‘é‡ä¸å®‰å…¨è®­ç»ƒæ•°æ®ç›¸åŒ¹é…çš„é£æ ¼æ¨¡å¼åˆ†å¸ƒçš„å®‰å…¨è®­ç»ƒæ•°æ®æ¥æå‡LLMçš„å®‰å…¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMså¯ä»¥å—åˆ°ç‰¹å®šé£æ ¼æç¤ºçš„å½±å“ï¼ŒåŒ…æ‹¬æ ¼å¼åŒ–å“åº”ä¸ºåˆ—è¡¨ç­‰ã€‚</li>
<li>åŸå§‹æŸ¥è¯¢ä¸­çš„é£æ ¼æ¨¡å¼å¯¹LLMå®‰å…¨çš„å½±å“å°šä¸æ¸…æ¥šã€‚</li>
<li>è¿‘ä¹æ‰€æœ‰LLMæ¨¡å‹éƒ½å­˜åœ¨ASRè†¨èƒ€ç°è±¡ï¼Œå› é£æ ¼æ¨¡å¼å¯¼è‡´ã€‚</li>
<li>è†¨èƒ€ä¸LLMå¯¹é£æ ¼æ¨¡å¼çš„å…³æ³¨åº¦å’Œä¸æŒ‡ä»¤è°ƒæ•´æ•°æ®çš„é‡å æœ‰å…³ã€‚</li>
<li>ç‰¹å®šé£æ ¼çš„å¾®è°ƒä¼šä½¿LLMæ›´å®¹æ˜“å—åˆ°ç›¸åŒé£æ ¼çš„æ”»å‡»ã€‚</li>
<li>SafeStyleé˜²å¾¡ç­–ç•¥é€šè¿‡åŠ å…¥å®‰å…¨è®­ç»ƒæ•°æ®æå‡LLMå®‰å…¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.07452">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-dd7041053e6c73ed2cfac7801a3f4569~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812672&auth_key=1760812672-0-0-85e1bcdeac289079b0083a13678c0836&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-92fba668c4ab80020cf181442a996f3d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812680&auth_key=1760812680-0-0-ce6cef988120181116e931dc000aba40&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-113c02da76b57a94ee5964d92fefff90~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812687&auth_key=1760812687-0-0-e680cc0e96e6875aad4af83cdd14218f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-483cebd2e0f02ca813450650b3594eb1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812693&auth_key=1760812693-0-0-9f0e34dd504fe31d15a06f9064498d41&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4bc98946fd94b2de9293621ce70c00bc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812700&auth_key=1760812700-0-0-874b87d896fda69e37fffdaa6d3a9fc8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Uni-LoRA-One-Vector-is-All-You-Need"><a href="#Uni-LoRA-One-Vector-is-All-You-Need" class="headerlink" title="Uni-LoRA: One Vector is All You Need"></a>Uni-LoRA: One Vector is All You Need</h2><p><strong>Authors:Kaiyang Li, Shaobo Han, Qing Su, Wei Li, Zhipeng Cai, Shihao Ji</strong></p>
<p>Low-Rank Adaptation (LoRA) has become the de facto parameter-efficient fine-tuning (PEFT) method for large language models (LLMs) by constraining weight updates to low-rank matrices. Recent works such as Tied-LoRA, VeRA, and VB-LoRA push efficiency further by introducing additional constraints to reduce the trainable parameter space. In this paper, we show that the parameter space reduction strategies employed by these LoRA variants can be formulated within a unified framework, Uni-LoRA, where the LoRA parameter space, flattened as a high-dimensional vector space $R^D$, can be reconstructed through a projection from a subspace R^d, with $d \ll D$. We demonstrate that the fundamental difference among various LoRA methods lies in the choice of the projection matrix, $P \in R^{D \times d}$.Most existing LoRA variants rely on layer-wise or structure-specific projections that limit cross-layer parameter sharing, thereby compromising parameter efficiency. In light of this, we introduce an efficient and theoretically grounded projection matrix that is isometric, enabling global parameter sharing and reducing computation overhead. Furthermore, under the unified view of Uni-LoRA, this design requires only a single trainable vector to reconstruct LoRA parameters for the entire LLM - making Uni-LoRA both a unified framework and a â€œone-vector-onlyâ€ solution. Extensive experiments on GLUE, mathematical reasoning, and instruction tuning benchmarks demonstrate that Uni-LoRA achieves state-of-the-art parameter efficiency while outperforming or matching prior approaches in predictive performance. </p>
<blockquote>
<p>ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰å·²æˆä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ–¹æ³•çš„å®é™…æ ‡å‡†ï¼Œå®ƒé€šè¿‡çº¦æŸæƒé‡æ›´æ–°ä¸ºä½ç§©çŸ©é˜µã€‚æœ€è¿‘çš„å·¥ä½œï¼Œå¦‚Tied-LoRAã€VeRAå’ŒVB-LoRAï¼Œé€šè¿‡å¼•å…¥é¢å¤–çš„çº¦æŸæ¥å‡å°‘å¯è®­ç»ƒå‚æ•°ç©ºé—´ï¼Œä»è€Œè¿›ä¸€æ­¥æé«˜äº†æ•ˆç‡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†è¿™äº›LoRAå˜ä½“æ‰€é‡‡ç”¨çš„å‚æ•°ç©ºé—´ç¼©å‡ç­–ç•¥å¯ä»¥åœ¨ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶Uni-LoRAå†…åˆ¶å®šã€‚åœ¨è¿™ä¸ªæ¡†æ¶ä¸­ï¼ŒLoRAå‚æ•°ç©ºé—´è¢«å±•å¹³ä¸ºä¸€ä¸ªé«˜ç»´å‘é‡ç©ºé—´$R^D$ï¼Œå¯ä»¥é€šè¿‡ä»å­ç©ºé—´$R^d$çš„æŠ•å½±è¿›è¡Œé‡å»ºï¼Œå…¶ä¸­$d \ll D$ã€‚æˆ‘ä»¬è¯æ˜ï¼Œå„ç§LoRAæ–¹æ³•ä¹‹é—´çš„æ ¹æœ¬åŒºåˆ«åœ¨äºæŠ•å½±çŸ©é˜µçš„é€‰æ‹©ï¼Œ$P \in R^{D \times d}$ã€‚å¤§å¤šæ•°ç°æœ‰çš„LoRAå˜ä½“ä¾èµ–äºé€å±‚æˆ–ç»“æ„ç‰¹å®šçš„æŠ•å½±ï¼Œè¿™é™åˆ¶äº†è·¨å±‚å‚æ•°å…±äº«ï¼Œä»è€Œå½±å“äº†å‚æ•°æ•ˆç‡ã€‚é‰´äºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªé«˜æ•ˆä¸”ç†è®ºæ‰å®çš„æŠ•å½±çŸ©é˜µï¼Œè¯¥çŸ©é˜µæ˜¯ç­‰è·çš„ï¼Œèƒ½å¤Ÿå®ç°å…¨å±€å‚æ•°å…±äº«ï¼Œå¹¶å‡å°‘è®¡ç®—å¼€é”€ã€‚æ­¤å¤–ï¼Œåœ¨Uni-LoRAçš„ç»Ÿä¸€è§†è§’ä¸‹ï¼Œè¿™ç§è®¾è®¡ä»…éœ€è¦ä¸€ä¸ªå¯è®­ç»ƒçš„å‘é‡æ¥é‡å»ºæ•´ä¸ªLLMçš„LoRAå‚æ•°ï¼Œä½¿Uni-LoRAæ—¢æ˜¯ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªâ€œä»…ä¸€ä¸ªå‘é‡â€çš„è§£å†³æ–¹æ¡ˆã€‚åœ¨GLUEã€æ•°å­¦æ¨ç†å’ŒæŒ‡ä»¤è°ƒæ•´åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒUni-LoRAå®ç°äº†æœ€æ–°çš„å‚æ•°æ•ˆç‡ï¼ŒåŒæ—¶åœ¨é¢„æµ‹æ€§èƒ½ä¸Šä¼˜äºæˆ–åŒ¹é…äº†å…ˆå‰çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.00799v2">PDF</a> NeurIPS 2025 Spotlight</p>
<p><strong>Summary</strong></p>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä½ç§©é€‚é…ï¼ˆLoRAï¼‰æ–¹æ³•æ˜¯å‚æ•°é«˜æ•ˆçš„å¾®è°ƒï¼ˆPEFTï¼‰æ–¹æ³•ï¼Œé€šè¿‡çº¦æŸæƒé‡æ›´æ–°ä¸ºä½ç§©çŸ©é˜µæ¥å®ç°ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç»Ÿä¸€æ¡†æ¶Uni-LoRAï¼Œè¯¥æ¡†æ¶å¯ä»¥è¡¨è¿°LoRAæ–¹æ³•çš„å‚æ•°ç©ºé—´å‡å°‘ç­–ç•¥ã€‚é€šè¿‡æŠ•å½±çŸ©é˜µPï¼Œå°†LoRAå‚æ•°ç©ºé—´ä»é«˜ç»´å‘é‡ç©ºé—´RDé‡å»ºä¸ºå­ç©ºé—´Rdï¼Œå…¶ä¸­dâ‰ªDã€‚æœ¬æ–‡å¼•å…¥äº†ä¸€ç§é«˜æ•ˆä¸”ç†è®ºåŸºç¡€çš„ç­‰è·æŠ•å½±çŸ©é˜µï¼Œå®ç°å…¨å±€å‚æ•°å…±äº«ï¼Œé™ä½è®¡ç®—æˆæœ¬ã€‚Uni-LoRAæ˜¯ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œåªéœ€è¦ä¸€ä¸ªå¯è®­ç»ƒçš„å‘é‡æ¥é‡å»ºæ•´ä¸ªLLMçš„LoRAå‚æ•°ï¼Œå®ç°äº†å‚æ•°æ•ˆç‡çš„æå‡ã€‚å®éªŒè¡¨æ˜ï¼ŒUni-LoRAåœ¨å‚æ•°æ•ˆç‡æ–¹é¢è¾¾åˆ°æœ€æ–°æ°´å¹³ï¼ŒåŒæ—¶é¢„æµ‹æ€§èƒ½ä¼˜äºæˆ–åŒ¹é…å…ˆå‰çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LoRAå·²æˆä¸ºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ–¹æ³•çš„ä»£è¡¨ã€‚</li>
<li>LoRAé€šè¿‡çº¦æŸæƒé‡æ›´æ–°åˆ°ä½ç§©çŸ©é˜µæ¥å®ç°å‚æ•°æ•ˆç‡çš„æå‡ã€‚</li>
<li>Uni-LoRAæ¡†æ¶å¯ä»¥ç»Ÿä¸€è¡¨è¿°å„ç§LoRAæ–¹æ³•çš„å‚æ•°ç©ºé—´å‡å°‘ç­–ç•¥ã€‚</li>
<li>Uni-LoRAé€šè¿‡æŠ•å½±çŸ©é˜µå®ç°å‚æ•°ç©ºé—´çš„é‡å»ºï¼Œå¼ºè°ƒå…¨å±€å‚æ•°å…±äº«ã€‚</li>
<li>å¼•å…¥ç­‰è·æŠ•å½±çŸ©é˜µï¼Œæé«˜æ•ˆç‡å’Œç†è®ºæ”¯æ’‘ã€‚</li>
<li>Uni-LoRAåªéœ€ä¸€ä¸ªå¯è®­ç»ƒçš„å‘é‡æ¥é‡å»ºæ•´ä¸ªLLMçš„LoRAå‚æ•°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.00799">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-9c660b20f58c9adfaee96e8ed21d4d2f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812708&auth_key=1760812708-0-0-652933de05ab3bc965b9a0a1dd25df8a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5d64b9b72e7dfd29af125876ee37c6b3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812716&auth_key=1760812716-0-0-fd968a1b94f800df6169318a80244751&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-26e8dfe9f7a2cb029fe49acfa0f782d4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812723&auth_key=1760812723-0-0-2c9af178965d3b060b6d268c1fc23e20&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Attributing-Response-to-Context-A-Jensen-Shannon-Divergence-Driven-Mechanistic-Study-of-Context-Attribution-in-Retrieval-Augmented-Generation"><a href="#Attributing-Response-to-Context-A-Jensen-Shannon-Divergence-Driven-Mechanistic-Study-of-Context-Attribution-in-Retrieval-Augmented-Generation" class="headerlink" title="Attributing Response to Context: A Jensen-Shannon Divergence Driven   Mechanistic Study of Context Attribution in Retrieval-Augmented Generation"></a>Attributing Response to Context: A Jensen-Shannon Divergence Driven   Mechanistic Study of Context Attribution in Retrieval-Augmented Generation</h2><p><strong>Authors:Ruizhe Li, Chen Chen, Yuchen Hu, Yanjun Gao, Xi Wang, Emine Yilmaz</strong></p>
<p>Retrieval-Augmented Generation (RAG) leverages large language models (LLMs) combined with external contexts to enhance the accuracy and reliability of generated responses. However, reliably attributing generated content to specific context segments, context attribution, remains challenging due to the computationally intensive nature of current methods, which often require extensive fine-tuning or human annotation. In this work, we introduce a novel Jensen-Shannon Divergence driven method to Attribute Response to Context (ARC-JSD), enabling efficient and accurate identification of essential context sentences without additional fine-tuning, gradient-calculation or surrogate modelling. Evaluations on a wide range of RAG benchmarks, such as TyDi QA, Hotpot QA, and Musique, using instruction-tuned LLMs in different scales demonstrate superior accuracy and significant computational efficiency improvements compared to the previous surrogate-based method. Furthermore, our mechanistic analysis reveals specific attention heads and multilayer perceptron (MLP) layers responsible for context attribution, providing valuable insights into the internal workings of RAG models and how they affect RAG behaviours. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/ruizheliUOA/ARC_JSD">https://github.com/ruizheliUOA/ARC_JSD</a>. </p>
<blockquote>
<p>æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç»“åˆå¤–éƒ¨ä¸Šä¸‹æ–‡ï¼Œä»¥æé«˜ç”Ÿæˆå“åº”çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚ç„¶è€Œï¼Œç”±äºå½“å‰æ–¹æ³•çš„è®¡ç®—å¯†é›†æ€§è´¨ï¼Œå°†ç”Ÿæˆçš„å†…å®¹å¯é åœ°å½’å› äºç‰¹å®šçš„ä¸Šä¸‹æ–‡æ®µè½ï¼Œå³ä¸Šä¸‹æ–‡å½’å› ï¼Œä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œè¿™é€šå¸¸éœ€è¦å¤§é‡çš„å¾®è°ƒæˆ–äººå·¥æ ‡æ³¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹çš„åŸºäºJensen-Shannon Divergenceçš„å½’å› å“åº”åˆ°ä¸Šä¸‹æ–‡ï¼ˆARC-JSDï¼‰æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨æ— éœ€é¢å¤–å¾®è°ƒã€æ¢¯åº¦è®¡ç®—æˆ–æ›¿ä»£å»ºæ¨¡çš„æƒ…å†µä¸‹ï¼Œé«˜æ•ˆå‡†ç¡®åœ°è¯†åˆ«å‡ºå…³é”®çš„ä¸Šä¸‹æ–‡å¥å­ã€‚åœ¨TyDi QAã€Hotpot QAå’ŒMusiqueç­‰ä¸€ç³»åˆ—RAGåŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°ï¼Œä½¿ç”¨ä¸åŒè§„æ¨¡æŒ‡ä»¤è°ƒæ•´çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œè¯æ˜äº†ä¸ä¹‹å‰çš„åŸºäºæ›¿ä»£çš„æ–¹æ³•ç›¸æ¯”ï¼Œå…·æœ‰æ›´é«˜çš„å‡†ç¡®æ€§å’Œæ˜¾è‘—çš„è®¡ç®—æ•ˆç‡æ”¹è¿›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æœºåˆ¶åˆ†ææ­ç¤ºäº†è´Ÿè´£ä¸Šä¸‹æ–‡å½’å› çš„ç‰¹å®šæ³¨æ„åŠ›å¤´å’Œå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰å±‚ï¼Œä¸ºç†è§£RAGæ¨¡å‹çš„å†…éƒ¨å·¥ä½œåŸç†ä»¥åŠå®ƒä»¬å¦‚ä½•å½±å“RAGè¡Œä¸ºæä¾›äº†æœ‰ä»·å€¼çš„è§è§£ã€‚æˆ‘ä»¬çš„ä»£ç ä½äº<a target="_blank" rel="noopener" href="https://github.com/ruizheliUOA/ARC_JSD%E3%80%82">https://github.com/ruizheliUOA/ARC_JSDã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.16415v4">PDF</a> Best Paper Award at COLM 2025 XLLM-Reason-Plan Workshop; Accepted at   NeurIPS 2025 Mechanistic Interpretability Workshop</p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡ç»“åˆå¤–éƒ¨ä¸Šä¸‹æ–‡å¢å¼ºç”Ÿæˆå“åº”çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œå½¢æˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ã€‚ç„¶è€Œï¼Œç”±äºå½“å‰æ–¹æ³•çš„è®¡ç®—å¯†é›†æ€§è´¨ï¼Œå°†ç”Ÿæˆå†…å®¹å¯é åœ°å½’å› äºç‰¹å®šçš„ä¸Šä¸‹æ–‡æ®µè½ï¼ˆå³ä¸Šä¸‹æ–‡å½’å› ï¼‰ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œé€šå¸¸éœ€è¦å¤§é‡çš„å¾®è°ƒæˆ–äººå·¥æ ‡æ³¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºJensen-Shannon Divergenceçš„æ–°æ–¹æ³•â€”â€”ARC-JSDï¼ˆåŸºäºä¸Šä¸‹æ–‡å“åº”å½’å› ï¼‰ï¼Œèƒ½å¤Ÿé«˜æ•ˆå‡†ç¡®åœ°è¯†åˆ«å…³é”®ä¸Šä¸‹æ–‡å¥å­ï¼Œæ— éœ€é¢å¤–çš„å¾®è°ƒã€æ¢¯åº¦è®¡ç®—æˆ–ä»£ç†å»ºæ¨¡ã€‚åœ¨å¹¿æ³›çš„RAGåŸºå‡†æµ‹è¯•ä¸Šï¼Œå¦‚TyDi QAã€Hotpot QAå’ŒMusiqueç­‰ï¼Œä½¿ç”¨ä¸åŒè§„æ¨¡çš„æ•™å­¦æŒ‡ä»¤å‹LLMè¿›è¡Œè¯„ä¼°ï¼Œè¯æ˜å…¶åœ¨å‡†ç¡®æ€§ä¸Šä¼˜äºå…ˆå‰çš„åŸºäºä»£ç†çš„æ–¹æ³•ï¼Œå¹¶å¤§å¤§æé«˜äº†è®¡ç®—æ•ˆç‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æœºæ¢°åˆ†ææ­ç¤ºäº†è´Ÿè´£ä¸Šä¸‹æ–‡å½’å› çš„ç‰¹å®šæ³¨æ„åŠ›å¤´å’Œå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰å±‚ï¼Œä¸ºç†è§£RAGæ¨¡å‹çš„å†…éƒ¨å·¥ä½œåŸç†åŠå…¶å¯¹RAGè¡Œä¸ºçš„å½±å“æä¾›äº†å®è´µè§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RAGåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œå¤–éƒ¨ä¸Šä¸‹æ–‡æé«˜ç”Ÿæˆå“åº”çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚</li>
<li>ä¸Šä¸‹æ–‡å½’å› æ˜¯RAGä¸­çš„ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºéœ€è¦åŒºåˆ†ç”Ÿæˆå†…å®¹ä¸ç‰¹å®šä¸Šä¸‹æ–‡æ®µè½çš„å…³ç³»ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ARC-JSDï¼ŒåŸºäºJensen-Shannon Divergenceè¿›è¡Œä¸Šä¸‹æ–‡å“åº”å½’å› ã€‚</li>
<li>ARC-JSDèƒ½å¤Ÿåœ¨æ— éœ€é¢å¤–å¾®è°ƒã€æ¢¯åº¦è®¡ç®—æˆ–ä»£ç†å»ºæ¨¡çš„æƒ…å†µä¸‹ï¼Œé«˜æ•ˆå‡†ç¡®åœ°è¯†åˆ«å…³é”®ä¸Šä¸‹æ–‡å¥å­ã€‚</li>
<li>åœ¨å¤šç§RAGåŸºå‡†æµ‹è¯•ä¸Šï¼ŒARC-JSDè¡¨ç°å‡ºä¼˜å¼‚çš„å‡†ç¡®æ€§å’Œè®¡ç®—æ•ˆç‡ã€‚</li>
<li>ç ”ç©¶æ­ç¤ºäº†RAGæ¨¡å‹ä¸­è´Ÿè´£ä¸Šä¸‹æ–‡å½’å› çš„ç‰¹å®šæ³¨æ„åŠ›å¤´å’ŒMLPå±‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.16415">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-a2b6743052dc5fbe82c18421595c13cc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812752&auth_key=1760812752-0-0-0cf7eb6ee081fb7d1e4b02216d3746ae&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b76cc1728bda2137c84d7e3e8e30e36e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812759&auth_key=1760812759-0-0-801cec994816df7f0925dd2a51dec3dd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-18419d4250a2e2a4122090d7d5740c50~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812767&auth_key=1760812767-0-0-584117266079451f7e84a58f58c6563d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4b3aecf2b5a7171c613711aa6b5026df~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812773&auth_key=1760812773-0-0-a08a26ac3504d47d1f824697b39f7382&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1f3944b26a402227ec9c69b4b5775781~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812780&auth_key=1760812780-0-0-96edabb3d0bcdd37a993d3c126891540&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Efficient-Attention-via-Pre-Scoring-Prioritizing-Informative-Keys-in-Transformers"><a href="#Efficient-Attention-via-Pre-Scoring-Prioritizing-Informative-Keys-in-Transformers" class="headerlink" title="Efficient Attention via Pre-Scoring: Prioritizing Informative Keys in   Transformers"></a>Efficient Attention via Pre-Scoring: Prioritizing Informative Keys in   Transformers</h2><p><strong>Authors:Zhexiang Li, Haoyu Wang, Yutong Bao, David Woodruff</strong></p>
<p>Recent advances in transformer architectures deeply enhanced long-context language modeling. Among them, HyperAttention achieves competitive efficiency by combining a single-level LSH-based clustering with uniform residual sampling. However, HyperAttention fails to find all significant keys, which in turn raises the overall perplexity. We propose a pre-scoring mechanism that prioritizes significant keys before applying HyperAttention. We introduce three scoring methods: $k$-means and kernel $k$-means clustering, $k$-median clustering, and leverage score-based ranking (inspired by LevAttention) to filter keys effectively. We further replace HyperAttentionâ€™s original uniform residual sampling, relying exclusively on our pre-scoring mechanism. Experiments on ChatGLM2 (131k token context) reduce perplexity from 12 to 8.3, which outperforms standard HyperAttention. Moreover, when running on the Vision-Transformer (ViT), our method shows that it can guarantee similar accuracy compared with LevAttention, and will surpass LevAttention given specific parameters. Although this method introduces some computational overhead, its combination with HyperAttention achieves up to 20 times faster than FlashAttention, providing a balanced trade-off between speed and modeling accuracy. Our results highlight the effectiveness of integrating pre-scoring into hierarchical attention mechanisms, significantly improving transformer efficiency. </p>
<blockquote>
<p>è¿‘æœŸTransformeræ¶æ„çš„è¿›å±•æå¤§åœ°æå‡äº†é•¿è¯­å¢ƒè¯­è¨€å»ºæ¨¡çš„èƒ½åŠ›ã€‚å…¶ä¸­ï¼ŒHyperAttentioné€šè¿‡ç»“åˆå•çº§LSHï¼ˆå±€éƒ¨æ•æ„Ÿå“ˆå¸Œï¼‰èšç±»ä¸å‡åŒ€å‰©ä½™é‡‡æ ·å®ç°äº†ç«äº‰æ•ˆç‡ã€‚ç„¶è€Œï¼ŒHyperAttentionæ— æ³•æ‰¾åˆ°æ‰€æœ‰å…³é”®é”®ï¼Œè¿™åè€Œæé«˜äº†æ•´ä½“çš„å›°æƒ‘åº¦ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§é¢„è¯„åˆ†æœºåˆ¶ï¼Œåœ¨åº”ç”¨HyperAttentionä¹‹å‰ä¼˜å…ˆå¤„ç†é‡è¦é”®ã€‚æˆ‘ä»¬ä»‹ç»äº†ä¸‰ç§è¯„åˆ†æ–¹æ³•ï¼šKå‡å€¼å’Œæ ¸Kå‡å€¼èšç±»ã€Kä¸­ä½æ•°èšç±»å’ŒåŸºäºæ æ†è¯„åˆ†çš„æ’åï¼ˆå—LevAttentionå¯å‘ï¼‰ä»¥æœ‰æ•ˆåœ°è¿‡æ»¤é”®ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥ç”¨æˆ‘ä»¬çš„é¢„è¯„åˆ†æœºåˆ¶å–ä»£äº†HyperAttentionçš„åŸå§‹å‡åŒ€å‰©ä½™é‡‡æ ·ã€‚åœ¨ChatGLM2ï¼ˆ13.1ä¸‡ä»¤ç‰Œä¸Šä¸‹æ–‡ï¼‰ä¸Šçš„å®éªŒå°†å›°æƒ‘åº¦ä»12é™ä½åˆ°8.3ï¼Œè¶…è¿‡äº†æ ‡å‡†HyperAttentionçš„è¡¨ç°ã€‚æ­¤å¤–ï¼Œåœ¨Vision-Transformerï¼ˆViTï¼‰ä¸Šè¿è¡Œæ—¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ä¿è¯ä¸LevAttentionç›¸å½“çš„ç²¾åº¦ï¼Œå¹¶åœ¨ç»™å®šç‰¹å®šå‚æ•°æ—¶è¶…è¶ŠLevAttentionã€‚å°½ç®¡æ­¤æ–¹æ³•å¼•å…¥äº†ä¸€å®šçš„è®¡ç®—å¼€é”€ï¼Œä½†å®ƒä¸HyperAttentionçš„ç»“åˆå¯å®ç°é«˜è¾¾20å€çš„FlashAttentioné€Ÿåº¦ï¼Œåœ¨é€Ÿåº¦å’Œå»ºæ¨¡ç²¾åº¦ä¹‹é—´æä¾›äº†å¹³è¡¡çš„æŠ˜è¡·ã€‚æˆ‘ä»¬çš„ç»“æœçªå‡ºäº†å°†é¢„è¯„åˆ†é›†æˆåˆ°åˆ†å±‚æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„æœ‰æ•ˆæ€§ï¼Œæ˜¾è‘—æé«˜äº†Transformerçš„æ•ˆç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.11040v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸï¼ŒåŸºäºTransformeræ¶æ„çš„é•¿æ–‡æœ¬è¯­è¨€å»ºæ¨¡å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚HyperAttentioné€šè¿‡ç»“åˆå•çº§LSHèšç±»ä¸å‡åŒ€å‰©ä½™é‡‡æ ·å®ç°äº†é«˜æ•ˆçš„æ€§èƒ½ã€‚ç„¶è€Œï¼ŒHyperAttentionåœ¨å¯»æ‰¾å…³é”®ä¿¡æ¯æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´æ•´ä½“å›°æƒ‘åº¦å¢åŠ ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºä¸€ç§é¢„è¯„åˆ†æœºåˆ¶ï¼Œåœ¨é‡‡ç”¨HyperAttentionå‰å…ˆå¯¹å…³é”®ä¿¡æ¯è¿›è¡Œä¼˜å…ˆçº§æ’åºã€‚é€šè¿‡å¼•å…¥ä¸‰ç§è¯„åˆ†æ–¹æ³•â€”â€”Kå‡å€¼å’Œæ ¸Kå‡å€¼èšç±»ã€Kä¸­ä½æ•°èšç±»å’ŒåŸºäºæ æ†è¯„åˆ†çš„æ’åï¼ˆå—LevAttentionå¯å‘ï¼‰ï¼Œæœ‰æ•ˆç­›é€‰å…³é”®ä¿¡æ¯ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨ChatGLM2æ¨¡å‹ä¸Šåº”ç”¨æ­¤æ–¹æ³•å°†å›°æƒ‘åº¦ä»12é™è‡³8.3ï¼Œä¼˜äºæ ‡å‡†HyperAttentionã€‚æ­¤å¤–ï¼Œåœ¨Vision-Transformerï¼ˆViTï¼‰ä¸Šè¿è¡Œæ­¤æ–¹æ³•ï¼Œå¯ä¿è¯ä¸LevAttentionç›¸ä¼¼çš„ç²¾åº¦ï¼Œå¹¶åœ¨ç‰¹å®šå‚æ•°ä¸‹è¶…è¶ŠLevAttentionã€‚è™½ç„¶æ­¤æ–¹æ³•å¼•å…¥äº†ä¸€å®šçš„è®¡ç®—å¼€é”€ï¼Œä½†ä¸HyperAttentionç»“åˆåï¼Œå…¶é€Ÿåº¦å¯è¾¾FlashAttentionçš„20å€ï¼Œå®ç°äº†é€Ÿåº¦ä¸å»ºæ¨¡ç²¾åº¦ä¹‹é—´çš„å¹³è¡¡ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå°†é¢„è¯„åˆ†èå…¥åˆ†å±‚æ³¨æ„åŠ›æœºåˆ¶å¯æœ‰æ•ˆæé«˜Transformerçš„æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>HyperAttentioné€šè¿‡ç»“åˆLSHèšç±»å’Œå‡åŒ€å‰©ä½™é‡‡æ ·å®ç°é«˜æ•ˆæ€§èƒ½ã€‚</li>
<li>é¢„è¯„åˆ†æœºåˆ¶ç”¨äºä¼˜åŒ–HyperAttentionï¼Œä¼˜å…ˆå¤„ç†å…³é”®ä¿¡æ¯ã€‚</li>
<li>æå‡ºä¸‰ç§è¯„åˆ†æ–¹æ³•ï¼ˆKå‡å€¼èšç±»ã€æ ¸Kå‡å€¼èšç±»ã€åŸºäºæ æ†è¯„åˆ†çš„æ’åï¼‰ä»¥æœ‰æ•ˆç­›é€‰å…³é”®ä¿¡æ¯ã€‚</li>
<li>åœ¨ChatGLM2æ¨¡å‹ä¸Šåº”ç”¨æ­¤æ–¹æ³•å¯é™ä½å›°æƒ‘åº¦è‡³8.3ï¼Œä¼˜äºæ ‡å‡†HyperAttentionã€‚</li>
<li>åœ¨ViTä¸Šåº”ç”¨æ­¤æ–¹æ³•å¯ä¿è¯ä¸LevAttentionç›¸ä¼¼çš„ç²¾åº¦ï¼Œå¹¶åœ¨ç‰¹å®šå‚æ•°ä¸‹è¶…è¶Šä¹‹ã€‚</li>
<li>æ­¤æ–¹æ³•è™½ç„¶å¼•å…¥è®¡ç®—å¼€é”€ï¼Œä½†ä¸HyperAttentionç»“åˆåé€Ÿåº¦æ˜¾è‘—æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.11040">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-ddf50543db688e0f9fbed8f94cbb31e8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812787&auth_key=1760812787-0-0-ed373fcf390eec18cc794c32b81cb987&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-579c0689bf959f968999b882388f522f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812795&auth_key=1760812795-0-0-e441e170fbee30802b6bae0bc3fe234d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Falcon-A-Remote-Sensing-Vision-Language-Foundation-Model-Technical-Report"><a href="#Falcon-A-Remote-Sensing-Vision-Language-Foundation-Model-Technical-Report" class="headerlink" title="Falcon: A Remote Sensing Vision-Language Foundation Model (Technical   Report)"></a>Falcon: A Remote Sensing Vision-Language Foundation Model (Technical   Report)</h2><p><strong>Authors:Kelu Yao, Nuo Xu, Rong Yang, Yingying Xu, Zhuoyan Gao, Titinunt Kitrungrotsakul, Yi Ren, Pu Zhang, Jin Wang, Ning Wei, Chao Li</strong></p>
<p>This paper introduces a holistic vision-language foundation model tailored for remote sensing, named Falcon. Falcon offers a unified, prompt-based paradigm that effectively executes comprehensive and complex remote sensing tasks. Falcon demonstrates powerful understanding and reasoning abilities at the image, region, and pixel levels. Specifically, given simple natural language instructions and remote sensing images, Falcon can produce impressive results in text form across 14 distinct tasks, i.e., image classification, object detection, segmentation, image captioning, and etc. To facilitate Falconâ€™s training and empower its representation capacity to encode rich spatial and semantic information, we developed Falcon_SFT, a large-scale, multi-task, instruction-tuning dataset in the field of remote sensing. The Falcon_SFT dataset consists of approximately 78 million high-quality data samples, covering 5.6 million multi-spatial resolution and multi-view remote sensing images with diverse instructions. It features hierarchical annotations and undergoes manual sampling verification to ensure high data quality and reliability. Extensive comparative experiments are conducted, which verify that Falcon achieves remarkable performance over 67 datasets and 14 tasks, despite having only 0.7B parameters. We release the complete dataset, code, and model weights at <a target="_blank" rel="noopener" href="https://github.com/TianHuiLab/Falcon">https://github.com/TianHuiLab/Falcon</a>, hoping to help further develop the open-source community. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªä¸“ä¸ºé¥æ„Ÿé¢†åŸŸå®šåˆ¶çš„å…¨è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ï¼Œåä¸ºFalconã€‚Falconæä¾›äº†ä¸€ä¸ªåŸºäºæç¤ºçš„ç»Ÿä¸€èŒƒå¼ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ‰§è¡Œå…¨é¢ä¸”å¤æ‚çš„é¥æ„Ÿä»»åŠ¡ã€‚Falconåœ¨å›¾åƒã€åŒºåŸŸå’Œåƒç´ çº§åˆ«è¡¨ç°å‡ºå¼ºå¤§çš„ç†è§£å’Œæ¨ç†èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œç»™å®šç®€å•çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œé¥æ„Ÿå›¾åƒï¼ŒFalconå¯ä»¥åœ¨14ä¸ªä¸åŒä»»åŠ¡ä¸­ä»¥æ–‡æœ¬å½¢å¼äº§ç”Ÿä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœï¼Œä¾‹å¦‚å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€åˆ†å‰²ã€å›¾åƒæè¿°ç­‰ã€‚ä¸ºäº†è®­ç»ƒFalconå¹¶å¢å¼ºå…¶è¡¨ç¤ºèƒ½åŠ›ä»¥ç¼–ç ä¸°å¯Œçš„ç©ºé—´è¯­ä¹‰ä¿¡æ¯ï¼Œæˆ‘ä»¬å¼€å‘äº†é¥æ„Ÿé¢†åŸŸçš„å¤§è§„æ¨¡å¤šä»»åŠ¡æŒ‡ä»¤è°ƒæ•´æ•°æ®é›†Falcon_SFTã€‚Falcon_SFTæ•°æ®é›†åŒ…å«çº¦7800ä¸‡é«˜è´¨é‡æ•°æ®æ ·æœ¬ï¼Œæ¶µç›–560ä¸‡å¤šå…ƒç©ºé—´åˆ†è¾¨ç‡å’Œå¤šè§†è§’é¥æ„Ÿå›¾åƒä»¥åŠå¤šç§æŒ‡ä»¤ã€‚å®ƒé‡‡ç”¨åˆ†å±‚æ³¨é‡Šå¹¶ç»è¿‡æ‰‹åŠ¨é‡‡æ ·éªŒè¯ï¼Œä»¥ç¡®ä¿æ•°æ®çš„é«˜è´¨é‡å’Œå¯é æ€§ã€‚è¿›è¡Œäº†å¹¿æ³›çš„å¯¹æ¯”å®éªŒï¼ŒéªŒè¯äº†åœ¨67ä¸ªæ•°æ®é›†å’Œ14ä¸ªä»»åŠ¡ä¸­ï¼Œå°½ç®¡åªæœ‰0.7Bå‚æ•°ï¼Œä½†Falconå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/TianHuiLab/Falcon%E4%B8%8A%E5%8F%91%E5%B8%83%E4%BA%86%E5%AE%8C%E6%95%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E3%80%81%E4%BB%A3%E7%A0%81%E5%92%8C%E6%A8%A1%E5%9E%8B%E6%9D%83%E9%87%8D%EF%BC%8C%E5%B8%8C%E6%9C%9B%E8%83%BD%E5%B8%AE%E5%8A%A9%E8%BF%9B%E4%B8%80%E6%AD%A5%E6%8E%A8%E5%8A%A8%E5%BC%80%E6%BA%90%E7%A4%BE%E5%8C%BA%E7%9A%84%E5%8F%91%E5%B1%95%E3%80%82">https://github.com/TianHuiLab/Falconä¸Šå‘å¸ƒäº†å®Œæ•´çš„æ•°æ®é›†ã€ä»£ç å’Œæ¨¡å‹æƒé‡ï¼Œå¸Œæœ›èƒ½å¸®åŠ©è¿›ä¸€æ­¥æ¨åŠ¨å¼€æºç¤¾åŒºçš„å‘å±•ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.11070v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ä¸“ä¸ºé¥æ„Ÿé¢†åŸŸè®¾è®¡çš„å…¨æ¯è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹â€”â€”Falconã€‚è¯¥æ¨¡å‹é‡‡ç”¨åŸºäºæç¤ºçš„ç»Ÿä¸€èŒƒå¼ï¼Œèƒ½æœ‰æ•ˆæ‰§è¡Œå¤æ‚é¥æ„Ÿä»»åŠ¡ã€‚å€ŸåŠ©ç®€å•çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œé¥æ„Ÿå›¾åƒï¼ŒFalconå¯åœ¨14ç§ä¸åŒä»»åŠ¡ä¸­ä»¥æ–‡æœ¬å½¢å¼ç”Ÿæˆä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœã€‚ä¸ºè®­ç»ƒFalconå¹¶å¢å¼ºå…¶è¡¨ç¤ºèƒ½åŠ›ä»¥ç¼–ç ä¸°å¯Œçš„ç©ºé—´è¯­ä¹‰ä¿¡æ¯ï¼Œå›¢é˜Ÿå¼€å‘äº†å¤§å‹å¤šä»»åŠ¡æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†Falcon_SFTã€‚è¯¥æ•°æ®é›†åŒ…å«çº¦7800ä¸‡é«˜è´¨é‡æ•°æ®æ ·æœ¬ï¼Œè¦†ç›–560ä¸‡å¤šç§å¤šç©ºé—´åˆ†è¾¨ç‡å’Œå¤šè§†è§’çš„é¥æ„Ÿå›¾åƒï¼Œå¹¶å¸¦æœ‰å„ç§æŒ‡ä»¤ã€‚é€šè¿‡åˆ†å±‚æ³¨é‡Šå’Œæ‰‹åŠ¨é‡‡æ ·éªŒè¯ç¡®ä¿æ•°æ®çš„é«˜è´¨é‡å’Œå¯é æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒFalconåœ¨67ä¸ªæ•°æ®é›†å’Œ14é¡¹ä»»åŠ¡ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œå°½ç®¡å…¶å‚æ•°åªæœ‰0.7Bã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Falconæ˜¯ä¸€ç§é’ˆå¯¹é¥æ„Ÿé¢†åŸŸçš„å…¨æ¯è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ã€‚</li>
<li>Falconé‡‡ç”¨åŸºäºæç¤ºçš„ç»Ÿä¸€èŒƒå¼ï¼Œèƒ½æ‰§è¡Œå¤æ‚çš„é¥æ„Ÿä»»åŠ¡ã€‚</li>
<li>Falconèƒ½å¤„ç†åŒ…æ‹¬å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€åˆ†å‰²ã€å›¾åƒæè¿°ç­‰åœ¨å†…çš„14ç§ä¸åŒä»»åŠ¡ã€‚</li>
<li>ä¸ºè®­ç»ƒFalconï¼Œå¼€å‘äº†å¤§å‹å¤šä»»åŠ¡æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†Falcon_SFTã€‚</li>
<li>Falcon_SFTæ•°æ®é›†åŒ…å«çº¦7800ä¸‡é«˜è´¨é‡æ•°æ®æ ·æœ¬ï¼Œè¦†ç›–å¤šç§é¥æ„Ÿå›¾åƒã€‚</li>
<li>Falcon_SFTæ•°æ®é›†é€šè¿‡åˆ†å±‚æ³¨é‡Šå’Œæ‰‹åŠ¨é‡‡æ ·éªŒè¯ç¡®ä¿æ•°æ®è´¨é‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.11070">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-17c4e2def5d60ef7bb82f29b35f022be~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812802&auth_key=1760812802-0-0-9d8ca22f862100493b8cc54200e2f418&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-117c1b85e92798f334dbe9579a244132~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812809&auth_key=1760812809-0-0-91d1b8bf17eed6ad086e8aa7ad65b6e7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9f6c77dc8c37c7e8142cfee375502218~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812816&auth_key=1760812816-0-0-81871be22cfe71810678527a260c9b92&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-96ae2e0f79f0587e2b6d12141278fc4d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812823&auth_key=1760812823-0-0-42beae152c1250ecc2fe71c29a36e34d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0bb788efaa60bf642072237fa733e677~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812830&auth_key=1760812830-0-0-ae2009e81954c505e9db8a171565ed38&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="Disentangling-Feature-Structure-A-Mathematically-Provable-Two-Stage-Training-Dynamics-in-Transformers"><a href="#Disentangling-Feature-Structure-A-Mathematically-Provable-Two-Stage-Training-Dynamics-in-Transformers" class="headerlink" title="Disentangling Feature Structure: A Mathematically Provable Two-Stage   Training Dynamics in Transformers"></a>Disentangling Feature Structure: A Mathematically Provable Two-Stage   Training Dynamics in Transformers</h2><p><strong>Authors:Zixuan Gong, Shijia Li, Yong Liu, Jiaye Teng</strong></p>
<p>Transformers may exhibit two-stage training dynamics during the real-world training process. For instance, when training GPT-2 on the Counterfact dataset, the answers progress from syntactically incorrect to syntactically correct to semantically correct. However, existing theoretical analyses hardly account for this feature-level two-stage phenomenon, which originates from the disentangled two-type features like syntax and semantics. In this paper, we theoretically demonstrate how the two-stage training dynamics potentially occur in transformers. Specifically, we analyze the feature learning dynamics induced by the aforementioned disentangled two-type feature structure, grounding our analysis in a simplified yet illustrative setting that comprises a normalized ReLU self-attention layer and structured data. Such disentanglement of feature structure is general in practice, e.g., natural languages contain syntax and semantics, and proteins contain primary and secondary structures. To our best knowledge, this is the first rigorous result regarding a feature-level two-stage optimization process in transformers. Additionally, a corollary indicates that such a two-stage process is closely related to the spectral properties of the attention weights, which accords well with our empirical findings. </p>
<blockquote>
<p>åœ¨ç°å®ä¸–ç•Œä¸­çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒTransformerå¯èƒ½ä¼šå±•ç°å‡ºä¸¤é˜¶æ®µè®­ç»ƒåŠ¨æ€ã€‚ä¾‹å¦‚ï¼Œåœ¨Counterfactæ•°æ®é›†ä¸Šè®­ç»ƒGPT-2æ—¶ï¼Œç­”æ¡ˆçš„è¿›å±•ä»è¯­æ³•é”™è¯¯åˆ°è¯­æ³•æ­£ç¡®å†åˆ°è¯­ä¹‰æ­£ç¡®ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç†è®ºåˆ†æå¾ˆå°‘è€ƒè™‘è¿™ç§ç‰¹å¾å±‚é¢çš„ä¸¤é˜¶æ®µç°è±¡ï¼Œè¿™ç§ç°è±¡æºäºè§£è€¦çš„ä¸¤ç§ç±»å‹ç‰¹å¾ï¼Œå¦‚è¯­æ³•å’Œè¯­ä¹‰ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»ç†è®ºä¸Šè¯æ˜äº†Transformerä¸­ä¸¤é˜¶æ®µè®­ç»ƒåŠ¨æ€å¦‚ä½•å¯èƒ½å‘ç”Ÿã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åˆ†æäº†ç”±ä¸Šè¿°è§£è€¦çš„ä¸¤ç§ç±»å‹ç‰¹å¾ç»“æ„å¼•èµ·çš„ç‰¹å¾å­¦ä¹ åŠ¨æ€ï¼Œæˆ‘ä»¬çš„åˆ†æåŸºäºä¸€ä¸ªç®€åŒ–ä½†å…·æœ‰è¯´æ˜æ€§çš„è®¾ç½®ï¼ŒåŒ…æ‹¬ä¸€ä¸ªæ ‡å‡†åŒ–çš„ReLUè‡ªæ³¨æ„åŠ›å±‚å’Œç»“æ„åŒ–æ•°æ®ã€‚åœ¨å®è·µä¸­ï¼Œè¿™ç§ç‰¹å¾ç»“æ„çš„è§£è€¦æ˜¯æ™®éçš„ï¼Œä¾‹å¦‚è‡ªç„¶è¯­è¨€åŒ…å«è¯­æ³•å’Œè¯­ä¹‰ï¼Œè›‹ç™½è´¨åŒ…å«ä¸€çº§å’ŒäºŒçº§ç»“æ„ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯å…³äºTransformerä¸­ç‰¹å¾å±‚é¢çš„ä¸¤é˜¶æ®µä¼˜åŒ–è¿‡ç¨‹çš„é¦–ä¸ªä¸¥è°¨ç»“æœã€‚æ­¤å¤–ï¼Œä¸€ä¸ªæ¨è®ºè¡¨æ˜ï¼Œè¿™ç§ä¸¤é˜¶æ®µè¿‡ç¨‹ä¸æ³¨æ„åŠ›æƒé‡çš„è°±å±æ€§å¯†åˆ‡ç›¸å…³ï¼Œè¿™ä¸æˆ‘ä»¬çš„å®éªŒç»“æœç›¸å»åˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.20681v2">PDF</a> </p>
<p><strong>Summary</strong>ï¼š<br>åœ¨ç°å®ä¸–ç•Œè®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒTransformerå±•ç°å‡ºä¸¤é˜¶æ®µè®­ç»ƒåŠ¨æ€ã€‚ä¾‹å¦‚ï¼Œå¯¹GPT-2è¿›è¡ŒCounterfactæ•°æ®é›†è®­ç»ƒæ—¶ï¼Œç­”æ¡ˆä»è¯­æ³•ä¸æ­£ç¡®è¿›æ­¥åˆ°è¯­æ³•æ­£ç¡®å†åˆ°è¯­ä¹‰æ­£ç¡®ã€‚ç°æœ‰ç†è®ºå¾ˆå°‘åˆ†æç‰¹å¾å±‚é¢çš„ä¸¤é˜¶æ®µç°è±¡ï¼Œè¯¥ç°è±¡æºäºè¯­æ³•å’Œè¯­ä¹‰ç­‰è§£è€¦çš„ä¸¤ç§ç‰¹å¾ã€‚æœ¬æ–‡åœ¨ç®€åŒ–ä½†æœ‰ä»£è¡¨æ€§çš„è®¾ç½®ä¸­ï¼Œåˆ†æç”±è§£è€¦ç‰¹å¾ç»“æ„å¼•èµ·çš„ç‰¹å¾å­¦ä¹ åŠ¨æ€ï¼ŒåŒ…æ‹¬ä¸€ä¸ªå½’ä¸€åŒ–çš„ReLUè‡ªæ³¨æ„åŠ›å±‚å’Œç»“æ„åŒ–æ•°æ®ã€‚ç‰¹å¾ç»“æ„çš„è¿™ç§è§£è€¦åœ¨å®è·µä¸­æ˜¯æ™®éçš„ï¼Œä¾‹å¦‚è‡ªç„¶è¯­è¨€ä¸­çš„è¯­æ³•å’Œè¯­ä¹‰ï¼Œè›‹ç™½è´¨ä¸­çš„ä¸€çº§å’ŒäºŒçº§ç»“æ„ã€‚æœ¬æ–‡æ˜¯é¦–ä¸ªå…³äºTransformerä¸­ç‰¹å¾å±‚é¢çš„ä¸¤é˜¶æ®µä¼˜åŒ–è¿‡ç¨‹çš„ä¸¥è°¨ç»“æœã€‚æ­¤å¤–ï¼Œä¸€ä¸ªæ¨è®ºè¡¨æ˜ï¼Œè¿™ç§ä¸¤é˜¶æ®µè¿‡ç¨‹ä¸æ³¨æ„åŠ›æƒé‡çš„è°±å±æ€§å¯†åˆ‡ç›¸å…³ï¼Œè¿™ä¸æˆ‘ä»¬çš„å®è¯å‘ç°ç›¸å»åˆã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>Transformeråœ¨çœŸå®ä¸–ç•Œè®­ç»ƒè¿‡ç¨‹ä¸­å±•ç°å‡ºä¸¤é˜¶æ®µè®­ç»ƒåŠ¨æ€ã€‚</li>
<li>ä¸¤é˜¶æ®µç°è±¡æºäºè§£è€¦çš„ä¸¤ç§ç‰¹å¾ï¼Œå¦‚è¯­æ³•å’Œè¯­ä¹‰ã€‚</li>
<li>æœ¬æ–‡åœ¨ç®€åŒ–è®¾ç½®ä¸­åˆ†æäº†ç‰¹å¾å­¦ä¹ åŠ¨æ€ï¼ŒåŒ…æ‹¬è‡ªæ³¨æ„åŠ›å±‚å’Œç»“æ„åŒ–æ•°æ®ã€‚</li>
<li>ç‰¹å¾ç»“æ„çš„è§£è€¦åœ¨å¤šç§é¢†åŸŸä¸­æ˜¯æ™®éçš„ï¼Œå¦‚è‡ªç„¶è¯­è¨€å¤„ç†å’Œè›‹ç™½è´¨ç»“æ„ã€‚</li>
<li>è¿™æ˜¯é¦–ä¸ªå…³äºTransformerä¸­ç‰¹å¾å±‚é¢ä¸¤é˜¶æ®µä¼˜åŒ–è¿‡ç¨‹çš„ä¸¥è°¨ç ”ç©¶ã€‚</li>
<li>ä¸¤é˜¶æ®µè¿‡ç¨‹ä¸æ³¨æ„åŠ›æƒé‡çš„è°±å±æ€§å¯†åˆ‡ç›¸å…³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.20681">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-13a5c9dc73b588dc1680cd27959b1fce~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812837&auth_key=1760812837-0-0-c341c0e791b4a82662a1fb6b982a2a46&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0d0222f7329c9086dff59173cd75fffd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812844&auth_key=1760812844-0-0-f8d4aac0bf2f56b88064c945cdcbdc9b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="PRISM-Self-Pruning-Intrinsic-Selection-Method-for-Training-Free-Multimodal-Data-Selection"><a href="#PRISM-Self-Pruning-Intrinsic-Selection-Method-for-Training-Free-Multimodal-Data-Selection" class="headerlink" title="PRISM: Self-Pruning Intrinsic Selection Method for Training-Free   Multimodal Data Selection"></a>PRISM: Self-Pruning Intrinsic Selection Method for Training-Free   Multimodal Data Selection</h2><p><strong>Authors:Jinhe Bi, Yifan Wang, Danqi Yan,  Aniri, Wenke Huang, Zengjie Jin, Xiaowen Ma, Artur Hecker, Mang Ye, Xun Xiao, Hinrich Schuetze, Volker Tresp, Yunpu Ma</strong></p>
<p>Visual instruction tuning adapts pre-trained Multimodal Large Language Models (MLLMs) to follow human instructions for real-world applications. However, the rapid growth of these datasets introduces significant redundancy, leading to increased computational costs. Existing methods for selecting instruction data aim to prune this redundancy, but predominantly rely on computationally demanding techniques such as proxy-based inference or training-based metrics. Consequently, the substantial computational costs incurred by these selection processes often exacerbate the very efficiency bottlenecks they are intended to resolve, posing a significant challenge to the scalable and effective tuning of MLLMs. To address this challenge, we first identify a critical, yet previously overlooked, factor: the anisotropy inherent in visual feature distributions. We find that this anisotropy induces a \textit{Global Semantic Drift}, and overlooking this phenomenon is a key factor limiting the efficiency of current data selection methods. Motivated by this insight, we devise \textbf{PRISM}, the first training-free framework for efficient visual instruction selection. PRISM surgically removes the corrupting influence of global background features by modeling the intrinsic visual semantics via implicit re-centering. Empirically, PRISM reduces the end-to-end time for data selection and model tuning to just 30% of conventional pipelines. More remarkably, it achieves this efficiency while simultaneously enhancing performance, surpassing models fine-tuned on the full dataset across eight multimodal and three language understanding benchmarks, culminating in a 101.7% relative improvement over the baseline. The code is available for access via \href{<a target="_blank" rel="noopener" href="https://github.com/bibisbar/PRISM%7D%7Bthis">https://github.com/bibisbar/PRISM}{this</a> repository}. </p>
<blockquote>
<p>è§†è§‰æŒ‡ä»¤è°ƒæ•´é€‚åº”é¢„å…ˆè®­ç»ƒçš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ï¼Œä»¥éµå¾ªäººç±»æŒ‡ä»¤è¿›è¡Œå®é™…åº”ç”¨ã€‚ç„¶è€Œï¼Œè¿™äº›æ•°æ®çš„å¿«é€Ÿå¢é•¿å¼•å…¥äº†å¤§é‡çš„å†—ä½™ä¿¡æ¯ï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬å¢åŠ ã€‚ç°æœ‰çš„é€‰æ‹©æŒ‡ä»¤æ•°æ®çš„æ–¹æ³•æ—¨åœ¨åˆ é™¤è¿™äº›å†—ä½™ä¿¡æ¯ï¼Œä½†ä¸»è¦ä¾èµ–äºåŸºäºä»£ç†çš„æ¨æ–­æˆ–åŸºäºè®­ç»ƒçš„æŒ‡æ ‡ç­‰è®¡ç®—å¯†é›†çš„æŠ€æœ¯ã€‚å› æ­¤ï¼Œè¿™äº›é€‰æ‹©è¿‡ç¨‹äº§ç”Ÿçš„å·¨å¤§è®¡ç®—æˆæœ¬å¾€å¾€åŠ å‰§äº†å®ƒä»¬æ—¨åœ¨è§£å†³çš„æ•ˆç‡ç“¶é¢ˆï¼Œç»™MLLMçš„å¯æ‰©å±•å’Œæœ‰æ•ˆè°ƒæ•´å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬é¦–å…ˆç¡®å®šäº†ä¸€ä¸ªå…³é”®ä½†è¢«å¿½è§†çš„å› ç´ ï¼šè§†è§‰ç‰¹å¾åˆ†å¸ƒæ‰€å›ºæœ‰çš„å„å‘å¼‚æ€§ã€‚æˆ‘ä»¬å‘ç°è¿™ç§å„å‘å¼‚æ€§å¯¼è‡´äº†å…¨å±€è¯­ä¹‰æ¼‚ç§»ï¼Œå¿½è§†è¿™ä¸€ç°è±¡æ˜¯é™åˆ¶å½“å‰æ•°æ®é€‰æ‹©æ–¹æ³•æ•ˆç‡çš„å…³é”®å› ç´ ã€‚å—è¿™ä¸€è§è§£çš„å¯å‘ï¼Œæˆ‘ä»¬è®¾è®¡äº†PRISMï¼Œè¿™æ˜¯ä¸€ä¸ªæ— éœ€è®­ç»ƒå³å¯æœ‰æ•ˆè¿›è¡Œè§†è§‰æŒ‡ä»¤é€‰æ‹©çš„é¦–ä¸ªæ¡†æ¶ã€‚PRISMé€šè¿‡éšå¼é‡æ–°å®šä½å»ºæ¨¡å†…åœ¨è§†è§‰è¯­ä¹‰ï¼Œä»è€Œæ¶ˆé™¤å…¨å±€èƒŒæ™¯ç‰¹å¾çš„è…èš€å½±å“ã€‚ç»éªŒä¸Šï¼ŒPRISMå°†æ•°æ®é€‰æ‹©æ¨¡å‹å’Œæ¨¡å‹è°ƒæ•´çš„æ€»æ—¶é—´å‡å°‘åˆ°ä¼ ç»Ÿç®¡é“çš„ä»…30%ã€‚æ›´å€¼å¾—ä¸€æçš„æ˜¯ï¼Œåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶å®ç°è¿™ç§æ•ˆç‡ï¼ŒPRISMåœ¨å…«ä¸ªå¤šæ¨¡æ€å’Œä¸‰ä¸ªè¯­è¨€ç†è§£åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°è¶…è¿‡äº†åœ¨å®Œæ•´æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒåçš„æ¨¡å‹ï¼Œç›¸å¯¹äºåŸºçº¿æœ‰101.7%çš„ç›¸å¯¹æ”¹è¿›ã€‚ä»£ç å¯é€šè¿‡è®¿é—®æ­¤å­˜å‚¨åº“è·å¾—ï¼š<a target="_blank" rel="noopener" href="https://github.com/bibisbar/PRISM%E3%80%82">https://github.com/bibisbar/PRISMã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.12119v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>è§†è§‰æŒ‡ä»¤è°ƒæ•´ä½¿é¢„è®­ç»ƒçš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰èƒ½å¤Ÿéµå¾ªäººç±»æŒ‡ä»¤è¿›è¡Œå®é™…åº”ç”¨ã€‚ç„¶è€Œï¼Œæ•°æ®é›†çš„å¿«é€Ÿå¢é•¿å¼•å…¥äº†å¤§é‡å†—ä½™ï¼Œå¢åŠ äº†è®¡ç®—æˆæœ¬ã€‚ç°æœ‰çš„é€‰æ‹©æŒ‡ä»¤æ•°æ®çš„æ–¹æ³•æ—¨åœ¨å‡å°‘è¿™ç§å†—ä½™ï¼Œä½†ä¸»è¦ä¾èµ–äºè®¡ç®—å¯†é›†å‹çš„ä»£ç†æ¨ç†æˆ–åŸºäºè®­ç»ƒæŒ‡æ ‡çš„æŠ€æœ¯ã€‚å› æ­¤ï¼Œè¿™äº›é€‰æ‹©è¿‡ç¨‹äº§ç”Ÿçš„å·¨å¤§è®¡ç®—æˆæœ¬ç»å¸¸åŠ å‰§å®ƒä»¬è¯•å›¾è§£å†³çš„æ•ˆç‡ç“¶é¢ˆï¼Œç»™MLLMçš„å¯æ‰©å±•å’Œæœ‰æ•ˆè°ƒæ•´å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚é’ˆå¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬é¦–å…ˆç¡®å®šäº†ä¸€ä¸ªå…³é”®ä½†è¢«å¿½è§†çš„å› ç´ ï¼šè§†è§‰ç‰¹å¾åˆ†å¸ƒå›ºæœ‰çš„å„å‘å¼‚æ€§ã€‚æˆ‘ä»¬å‘ç°è¿™ç§å„å‘å¼‚æ€§ä¼šå¼•èµ·å…¨å±€è¯­ä¹‰æ¼‚ç§»ï¼Œå¿½ç•¥è¿™ä¸€ç°è±¡æ˜¯é™åˆ¶å½“å‰æ•°æ®é€‰æ‹©æ•ˆç‡çš„å…³é”®å› ç´ ã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†é¦–ä¸ªæ— éœ€è®­ç»ƒçš„è§†è§‰æŒ‡ä»¤é€‰æ‹©æ¡†æ¶â€”â€”PRISMã€‚PRISMé€šè¿‡éšæ€§é‡æ–°å®šä½å»ºæ¨¡å†…åœ¨è§†è§‰è¯­ä¹‰ï¼Œä»è€Œæ¶ˆé™¤äº†å…¨å±€èƒŒæ™¯ç‰¹å¾çš„ä¸åˆ©å½±å“ã€‚ç»éªŒè¡¨æ˜ï¼ŒPRISMå°†æ•°æ®é€‰æ‹©æ¨¡å‹è°ƒæ•´çš„æ—¶é—´ç¼©çŸ­åˆ°ä¼ ç»Ÿæµç¨‹çš„30%ã€‚æ›´å€¼å¾—ä¸€æçš„æ˜¯ï¼Œåœ¨ä¿æŒé«˜æ•ˆçš„åŒæ—¶ï¼Œå®ƒè¿˜æé«˜äº†æ€§èƒ½ï¼Œåœ¨å…«ä¸ªå¤šæ¨¡æ€å’Œä¸‰ä¸ªè¯­è¨€ç†è§£åŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†å…¨æ•°æ®é›†å¾®è°ƒæ¨¡å‹çš„è¡¨ç°ï¼Œç›¸å¯¹äºåŸºçº¿æœ‰101.7%çš„ç›¸å¯¹æ”¹è¿›ã€‚ä»£ç å¯é€šè¿‡æ­¤ä»“åº“è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/bibisbar/PRISM">https://github.com/bibisbar/PRISM</a>ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>è§†è§‰æŒ‡ä»¤è°ƒæ•´åœ¨ä½¿é¢„è®­ç»ƒçš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹é€‚åº”å®é™…åº”ç”¨æ–¹é¢å‘æŒ¥å…³é”®ä½œç”¨ï¼Œä½†æ•°æ®é›†çš„å†—ä½™å¢åŠ äº†è®¡ç®—æˆæœ¬ã€‚</li>
<li>å½“å‰çš„æ•°æ®é€‰æ‹©æ–¹æ³•ä¸»è¦ä¾èµ–äºè®¡ç®—å¯†é›†å‹çš„ä»£ç†æ¨ç†æˆ–åŸºäºè®­ç»ƒæŒ‡æ ‡çš„æŠ€æœ¯ï¼Œè¿™å¢åŠ äº†é¢å¤–çš„è®¡ç®—æˆæœ¬ã€‚</li>
<li>è§†è§‰ç‰¹å¾åˆ†å¸ƒçš„å„å‘å¼‚æ€§æ˜¯æ•°æ®é€‰æ‹©è¿‡ç¨‹ä¸­çš„ä¸€ä¸ªé‡è¦ä½†è¢«å¿½è§†çš„å› ç´ ã€‚</li>
<li>å„å‘å¼‚æ€§å¯¼è‡´å…¨å±€è¯­ä¹‰æ¼‚ç§»ï¼Œè¿™æ˜¯é™åˆ¶å½“å‰æ•°æ®é€‰æ‹©æ–¹æ³•æ•ˆç‡çš„å…³é”®å› ç´ ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒå…è´¹çš„è§†è§‰æŒ‡ä»¤é€‰æ‹©æ¡†æ¶PRISMï¼Œé€šè¿‡éšæ€§é‡æ–°å®šä½å»ºæ¨¡å†…åœ¨è§†è§‰è¯­ä¹‰ï¼Œæœ‰æ•ˆå»é™¤å…¨å±€èƒŒæ™¯ç‰¹å¾çš„å½±å“ã€‚</li>
<li>PRISMåœ¨æ•°æ®é€‰æ‹©å’Œæ—¶é—´æ•ˆç‡æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæµç¨‹ï¼Œå°†æ—¶é—´ç¼©çŸ­è‡³30%ã€‚</li>
<li>PRISMåœ¨æé«˜æ€§èƒ½çš„åŒæ—¶ä¿æŒé«˜æ•ˆï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¿‡å…¨æ•°æ®é›†å¾®è°ƒæ¨¡å‹çš„è¡¨ç°ï¼Œå¹¶å®ç°ç›¸å¯¹åŸºçº¿çš„å¤§å¹…æ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.12119">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-40c85a8e8dde894888c2e177bfa9d473~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812851&auth_key=1760812851-0-0-90ee70d3223e5a1055abcf8bcd7454d3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bde1dcc6e15385d0f1760683550f0136~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812859&auth_key=1760812859-0-0-05f5b3694ff3adfdac4cdf5f234880f6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-30d4e27bd2b763da96997bd38d2901a7~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812865&auth_key=1760812865-0-0-f74af298f05faa8e78c7d94a46664d4f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-dd84548db753a623fd9dea6f533b1ff8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760812872&auth_key=1760812872-0-0-d09eb795262313c7170311493ad295da&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-19/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-19/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-19/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-ed4e6db8b619aba3aaab617ff5d119b5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760814182&auth_key=1760814182-0-0-5e9cc6bd1fad6981c0ed915c8e83f113&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-19  Highlighting What Matters Promptable Embeddings for Attribute-Focused   Image Retrieval
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-19/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-a67bbd7b6fa932a2fa5e550137d2933a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760810410&auth_key=1760810410-0-0-b578d88a4d8a46c82cd688c74962f8f2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-19  RoboGPT-R1 Enhancing Robot Planning with Reinforcement Learning
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31686.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
