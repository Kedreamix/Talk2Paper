<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Speech">
    <meta name="description" content="Speech 方向最新论文已更新，请持续关注 Update in 2024-12-24  Data-Centric Improvements for Enhancing Multi-Modal Understanding in   Spoken Conversation Modeling">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Speech | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-d63e042eb0a74cd35eff6d889a6d6a8b.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Speech</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Speech/">
                                <span class="chip bg-color">Speech</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                Speech
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-12-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-24
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    4.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    18 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2024-12-24-更新"><a href="#2024-12-24-更新" class="headerlink" title="2024-12-24 更新"></a>2024-12-24 更新</h1><h2 id="Data-Centric-Improvements-for-Enhancing-Multi-Modal-Understanding-in-Spoken-Conversation-Modeling"><a href="#Data-Centric-Improvements-for-Enhancing-Multi-Modal-Understanding-in-Spoken-Conversation-Modeling" class="headerlink" title="Data-Centric Improvements for Enhancing Multi-Modal Understanding in   Spoken Conversation Modeling"></a>Data-Centric Improvements for Enhancing Multi-Modal Understanding in   Spoken Conversation Modeling</h2><p><strong>Authors:Maximillian Chen, Ruoxi Sun, Sercan Ö. Arık</strong></p>
<p>Conversational assistants are increasingly popular across diverse real-world applications, highlighting the need for advanced multimodal speech modeling. Speech, as a natural mode of communication, encodes rich user-specific characteristics such as speaking rate and pitch, making it critical for effective interaction. Our work introduces a data-centric customization approach for efficiently enhancing multimodal understanding in conversational speech modeling. Central to our contributions is a novel multi-task learning paradigm that involves designing auxiliary tasks to utilize a small amount of speech data. Our approach achieves state-of-the-art performance on the Spoken-SQuAD benchmark, using only 10% of the training data with open-weight models, establishing a robust and efficient framework for audio-centric conversational modeling. We also introduce ASK-QA, the first dataset for multi-turn spoken dialogue with ambiguous user requests and dynamic evaluation inputs. Code and data forthcoming. </p>
<blockquote>
<p>对话助理在不同现实世界应用中的普及度越来越高，这强调了先进多模态语音建模的需求。语音作为一种自然的交流方式，编码了丰富的用户特定特征，如语速和音调，对于有效交互至关重要。我们的工作介绍了一种以数据为中心的定制方法，以提高对话语音模型中的多模态理解效率。我们工作的核心贡献是一种新型多任务学习范式，涉及设计辅助任务以利用少量语音数据。我们的方法在使用仅10%的训练数据的情况下，在Spoken-SQuAD基准测试中实现了最先进的性能，并使用了公开权重模型，为以音频为中心的对话建模建立了稳健高效框架。我们还介绍了ASK-QA数据集，这是首个用于具有模糊用户请求和动态评估输入的多次对话语音的数据集。代码和数据即将发布。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15995v1">PDF</a> 22 pages, 6 figures, 14 tables</p>
<p><strong>Summary</strong></p>
<p>本文介绍了一种面向对话语音建模的数据中心定制方法，采用多任务学习范式设计辅助任务来高效利用少量语音数据。此方法在Spoken-SQuAD基准测试上表现卓越，仅需使用10%的训练数据即可实现开放权重模型的性能。此外，本文还引入了ASK-QA数据集，用于处理具有模糊用户请求和动态评估输入的对话语音建模。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>对话助手在现实世界的多种应用显示了先进的多模态语音建模的必要性。</li>
<li>语音包含丰富的用户特征，如语速和音调，对有效交互至关重要。</li>
<li>本文提出了一种数据中心的定制方法，通过多任务学习范式高效增强多模态理解对话语音建模。</li>
<li>所提方法仅使用少量语音数据在Spoken-SQuAD基准测试中取得领先表现。</li>
<li>开放权重模型可实现更加灵活的适应性和泛化能力。</li>
<li>引入了ASK-QA数据集，适用于具有模糊用户请求和动态评估输入的对话建模。该数据集可支持复杂的自然语言处理和机器学习应用。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15995">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-8bcea860b374dc275cad7caa341a00eb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f235bfd160a75b5d7c2d5b2ee62c2086.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-25cfd46adf6d53aa3cb681722e5d3bfb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d63e042eb0a74cd35eff6d889a6d6a8b.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="MathSpeech-Leveraging-Small-LMs-for-Accurate-Conversion-in-Mathematical-Speech-to-Formula"><a href="#MathSpeech-Leveraging-Small-LMs-for-Accurate-Conversion-in-Mathematical-Speech-to-Formula" class="headerlink" title="MathSpeech: Leveraging Small LMs for Accurate Conversion in Mathematical   Speech-to-Formula"></a>MathSpeech: Leveraging Small LMs for Accurate Conversion in Mathematical   Speech-to-Formula</h2><p><strong>Authors:Sieun Hyeon, Kyudan Jung, Jaehee Won, Nam-Joon Kim, Hyun Gon Ryu, Hyuk-Jae Lee, Jaeyoung Do</strong></p>
<p>In various academic and professional settings, such as mathematics lectures or research presentations, it is often necessary to convey mathematical expressions orally. However, reading mathematical expressions aloud without accompanying visuals can significantly hinder comprehension, especially for those who are hearing-impaired or rely on subtitles due to language barriers. For instance, when a presenter reads Euler’s Formula, current Automatic Speech Recognition (ASR) models often produce a verbose and error-prone textual description (e.g., e to the power of i x equals cosine of x plus i $\textit{side}$ of x), instead of the concise $\LaTeX{}$ format (i.e., $ e^{ix} &#x3D; \cos(x) + i\sin(x) $), which hampers clear understanding and communication. To address this issue, we introduce MathSpeech, a novel pipeline that integrates ASR models with small Language Models (sLMs) to correct errors in mathematical expressions and accurately convert spoken expressions into structured $\LaTeX{}$ representations. Evaluated on a new dataset derived from lecture recordings, MathSpeech demonstrates $\LaTeX{}$ generation capabilities comparable to leading commercial Large Language Models (LLMs), while leveraging fine-tuned small language models of only 120M parameters. Specifically, in terms of CER, BLEU, and ROUGE scores for $\LaTeX{}$ translation, MathSpeech demonstrated significantly superior capabilities compared to GPT-4o. We observed a decrease in CER from 0.390 to 0.298, and higher ROUGE&#x2F;BLEU scores compared to GPT-4o. </p>
<blockquote>
<p>在各种学术和专业场合，如数学讲座或研究报告会中，传达数学表达式是常有的需求。然而，在没有视觉辅助的情况下大声阅读数学表达式会显著阻碍理解，特别是对于听力受损者或由于语言障碍而依赖字幕的人。例如，当演讲者朗读欧拉公式时，当前的自动语音识别（ASR）模型通常会生成冗长和易出错的文本描述（例如，“e的i次方乘以x等于x的余弦值加上i倍的x的正弦值”），而不是简洁的LaTeX格式（即，$ e^{ix} &#x3D; \cos(x) + i\sin(x) $）。为了解决这一问题，我们推出了MathSpeech，这是一个新型管道，它将ASR模型与小语言模型（sLMs）相结合，以纠正数学表达式中的错误，并将口头表达准确转换为结构化的LaTeX表示。在新的基于讲座录音的数据集上进行评估，MathSpeech展现出与领先的商业大型语言模型（LLMs）相当的LaTeX生成能力，同时利用仅包含1.2亿参数的小型语言模型的微调版本。具体来说，在LaTeX翻译的CER、BLEU和ROUGE分数方面，MathSpeech相较于GPT-4o展现出显著更优的能力。我们观察到CER从0.390降至0.298，并且相较于GPT-4o具有更高的ROUGE&#x2F;BLEU分数。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15655v1">PDF</a> Accepted in AAAI 2025</p>
<p><strong>Summary</strong></p>
<p>数学表达式在学术和专业场合中的口头传达至关重要，然而由于听力障碍或语言障碍的问题，仅凭听觉往往难以理解。因此当前自动语音识别模型在对数学公式的识别上存在不足。本研究提出一种名为MathSpeech的新型管道，通过ASR模型与小型语言模型的结合，修正数学表达式中的错误，并将其准确转换为结构化的LaTeX表示形式。实验证明，MathSpeech在生成LaTeX方面表现出色，与大型语言模型相比具有竞争力，同时仅使用微调的小型语言模型（仅含1.2亿参数）。相较于GPT-4o模型，MathSpeech在CER、BLEU和ROUGE得分上均表现出显著优势。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>数学表达式口头传达在学术和专业场合中非常重要，但听力障碍和语言障碍可能影响理解。</li>
<li>当前自动语音识别模型（ASR）在对数学公式的识别上存在不足，需要新方法改进。</li>
<li>MathSpeech是一种新型管道，结合了ASR模型和小型语言模型（sLMs），能修正数学表达错误并转换为LaTeX格式。</li>
<li>MathSpeech展现出出色的LaTeX生成能力，性能与大型语言模型（LLMs）相当，但使用的是微调的小型语言模型。</li>
<li>MathSpeech在字符错误率（CER）方面相较于GPT-4o有显著改进，同时BLEU和ROUGE得分也更高。</li>
<li>MathSpeech有望提高数学公式口头传达的清晰度，特别是在学术和专业场合中。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15655">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-a15600b02fbe1aab4420be8dbd5b0212.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-05a5cf8d4ca64c5cc20f2423412a1091.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1a592a59eba266bd68116fad348ee50.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9ab3f9bd2b19eda66d2c923e65210e5d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2a15f34f1d571524465543c3fd880be7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b62bb4573e34d41208bd8b7485515fad.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-76b73c6c4722bde7b6b964ac507d4bcc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-588333a0c24c983c8be848aeabdb44ce.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Transcribing-and-Translating-Fast-and-Slow-Joint-Speech-Translation-and-Recognition"><a href="#Transcribing-and-Translating-Fast-and-Slow-Joint-Speech-Translation-and-Recognition" class="headerlink" title="Transcribing and Translating, Fast and Slow: Joint Speech Translation   and Recognition"></a>Transcribing and Translating, Fast and Slow: Joint Speech Translation   and Recognition</h2><p><strong>Authors:Niko Moritz, Ruiming Xie, Yashesh Gaur, Ke Li, Simone Merello, Zeeshan Ahmed, Frank Seide, Christian Fuegen</strong></p>
<p>We propose the joint speech translation and recognition (JSTAR) model that leverages the fast-slow cascaded encoder architecture for simultaneous end-to-end automatic speech recognition (ASR) and speech translation (ST). The model is transducer-based and uses a multi-objective training strategy that optimizes both ASR and ST objectives simultaneously. This allows JSTAR to produce high-quality streaming ASR and ST results. We apply JSTAR in a bilingual conversational speech setting with smart-glasses, where the model is also trained to distinguish speech from different directions corresponding to the wearer and a conversational partner. Different model pre-training strategies are studied to further improve results, including training of a transducer-based streaming machine translation (MT) model for the first time and applying it for parameter initialization of JSTAR. We demonstrate superior performances of JSTAR compared to a strong cascaded ST model in both BLEU scores and latency. </p>
<blockquote>
<p>我们提出了联合语音翻译和识别（JSTAR）模型，该模型利用快慢级联编码器架构实现端到端的同步语音识别（ASR）和语音翻译（ST）。该模型基于转换器结构，采用多目标训练策略，可同时优化ASR和ST的目标。这允许JSTAR产生高质量的流式ASR和ST结果。我们将JSTAR应用于智能眼镜的双语对话语音场景中，该模型还经过训练，能够区分佩戴者和对话伙伴从不同方向发出的语音。我们研究了不同的模型预训练策略来进一步提高结果，包括首次训练基于转换器的流式机器翻译（MT）模型，并将其应用于JSTAR的参数初始化。我们证明了与强大的级联ST模型相比，JSTAR在BLEU得分和延迟方面都表现出卓越的性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15415v1">PDF</a> Submitted to ICASSP 2025</p>
<p><strong>摘要</strong></p>
<p>提出一种联合语音翻译与识别（JSTAR）模型，采用快慢级联编码器架构，实现端到端的自动语音识别（ASR）和语音识别（ST）的同步。该模型基于转换器结构，采用多目标训练策略，可同时优化ASR和ST目标。这使得JSTAR能够产生高质量的流式ASR和ST结果。我们将JSTAR应用于智能眼镜的双语对话语音场景中，该模型还可以训练以区分佩戴者和对话伙伴的不同方向语音。研究了不同的模型预训练策略来进一步提高结果，包括首次训练基于转换器的流式机器翻译（MT）模型，并将其应用于JSTAR的参数初始化。我们证明了JSTAR与强大的级联ST模型相比的优越性，在BLEU得分和延迟方面都表现更佳。</p>
<p><strong>要点</strong></p>
<ol>
<li>JSTAR模型结合了语音翻译和识别功能，采用快慢级联编码器架构实现端到端的自动语音识别和语音识别同步。</li>
<li>基于转换器结构，采用多目标训练策略优化ASR和ST目标。</li>
<li>JSTAR模型可以产生高质量的流式ASR和ST结果。</li>
<li>将JSTAR应用于智能眼镜的双语对话场景，能区分不同方向的语音。</li>
<li>研究了不同的模型预训练策略来提高性能，包括首次训练基于转换器的流式机器翻译模型。</li>
<li>JSTAR相较于传统的级联ST模型在BLEU得分和延迟方面表现更优秀。</li>
<li>JSTAR模型展示了其在联合语音翻译和识别领域的潜力与应用前景。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15415">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-0ddf0e35421d824f2de08d8f7ec13e0a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-88577442d9186f2cecc05809e112a39c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-98a2123da8360554845c0cf38721f993.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-40adf1263f147167173c186ca3580440.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-295e62bbc3b1af5e1fd15b7ba8ac5d9c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d9fcd50ce3accb9e68437859a4f77d9f.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="LAMA-UT-Language-Agnostic-Multilingual-ASR-through-Orthography-Unification-and-Language-Specific-Transliteration"><a href="#LAMA-UT-Language-Agnostic-Multilingual-ASR-through-Orthography-Unification-and-Language-Specific-Transliteration" class="headerlink" title="LAMA-UT: Language Agnostic Multilingual ASR through Orthography   Unification and Language-Specific Transliteration"></a>LAMA-UT: Language Agnostic Multilingual ASR through Orthography   Unification and Language-Specific Transliteration</h2><p><strong>Authors:Sangmin Lee, Woo-Jin Chung Hong-Goo Kang</strong></p>
<p>Building a universal multilingual automatic speech recognition (ASR) model that performs equitably across languages has long been a challenge due to its inherent difficulties. To address this task we introduce a Language-Agnostic Multilingual ASR pipeline through orthography Unification and language-specific Transliteration (LAMA-UT). LAMA-UT operates without any language-specific modules while matching the performance of state-of-the-art models trained on a minimal amount of data. Our pipeline consists of two key steps. First, we utilize a universal transcription generator to unify orthographic features into Romanized form and capture common phonetic characteristics across diverse languages. Second, we utilize a universal converter to transform these universal transcriptions into language-specific ones. In experiments, we demonstrate the effectiveness of our proposed method leveraging universal transcriptions for massively multilingual ASR. Our pipeline achieves a relative error reduction rate of 45% when compared to Whisper and performs comparably to MMS, despite being trained on only 0.1% of Whisper’s training data. Furthermore, our pipeline does not rely on any language-specific modules. However, it performs on par with zero-shot ASR approaches which utilize additional language-specific lexicons and language models. We expect this framework to serve as a cornerstone for flexible multilingual ASR systems that are generalizable even to unseen languages. </p>
<blockquote>
<p>构建一个普遍的多语种自动语音识别（ASR）模型，以实现在各种语言之间的平等表现，一直是一个挑战，因为其固有的困难。为了解决这一任务，我们通过正字法统一和针对特定语言的转写（LAMA-UT），引入了语言无关的多语种ASR管道。LAMA-UT在没有任何针对特定语言的模块的情况下运行，同时匹配在少量数据上训练的最新模型的性能。我们的管道由两个关键步骤组成。首先，我们利用通用转录生成器将正字特征统一为罗马化形式，并捕捉不同语言的共同语音特征。其次，我们利用通用转换器将这些通用转录转化为特定语言的转录。在实验中，我们证明了利用通用转录进行大规模多语种ASR的方法的有效性。与whisper相比，我们的管道在相对误差减少率上实现了45%的降低，并且在仅使用whisper 0.1%的训练数据的情况下，其性能与MMS相当。此外，我们的管道不依赖于任何针对特定语言的模块，但其性能与零射击ASR方法持平，后者利用额外的针对特定语言的词典和语言模型。我们希望这个框架能成为灵活的多语种ASR系统的基石，甚至可以对未见过的语言进行泛化。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15299v1">PDF</a> </p>
<p><strong>Summary</strong>：<br>提出一种跨语言通用的自动语音识别（ASR）模型构建方法，通过正字法统一和语言特定转写（LAMA-UT）解决不同语言间ASR的难题。该方法无需任何特定语言的模块，在小数据集上就能达到前沿性能。该方法包含两个关键步骤：首先利用通用转录生成器将正字法特征统一转换为罗马化形式，捕捉不同语言的共同语音特征；其次利用通用转换器将这些通用转录转换为特定语言的转录。实验证明，该方法在大量多语种ASR中利用通用转录的有效性，相较于whisper有45%的相对误差降低率，并在训练数据量仅为whisper的0.1%的情况下表现良好。该框架为灵活的多语种ASR系统奠定了基础，能够推广到未见过的语言。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>提出了一种新的跨语言自动语音识别模型构建方法LAMA-UT。</li>
<li>该方法通过正字法统一和语言特定转写解决多语种ASR的难题。</li>
<li>LAMA-UT无需特定语言的模块，能在小数据集上达到前沿性能。</li>
<li>方法包含通用转录生成器和通用转换器两个关键步骤。</li>
<li>实验证明该方法利用通用转录的有效性，相对误差降低率达到了45%。</li>
<li>该方法在训练数据量较少的情况下表现良好，仅使用whisper的0.1%数据。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15299">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-b2c536266cda58c263ea61ebbfb02a26.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-13f6665919362a43b62f117bf6042fc0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dfc81b8ef37d4829f839cb43f11615d4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-20ec2ecd2c93cfe0696c6bf3bb289930.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f37cddc603f3c7adeee8087c92c9b82a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5bb6c4a866ad64b884589bec1338808c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d8aaa412a79522c7557e862d10d32879.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="MERaLiON-SpeechEncoder-Towards-a-Speech-Foundation-Model-for-Singapore-and-Beyond"><a href="#MERaLiON-SpeechEncoder-Towards-a-Speech-Foundation-Model-for-Singapore-and-Beyond" class="headerlink" title="MERaLiON-SpeechEncoder: Towards a Speech Foundation Model for Singapore   and Beyond"></a>MERaLiON-SpeechEncoder: Towards a Speech Foundation Model for Singapore   and Beyond</h2><p><strong>Authors:Muhammad Huzaifah, Geyu Lin, Tianchi Liu, Hardik B. Sailor, Kye Min Tan, Tarun K. Vangani, Qiongqiong Wang, Jeremy H. M. Wong, Nancy F. Chen, Ai Ti Aw</strong></p>
<p>This technical report describes the MERaLiON-SpeechEncoder, a foundation model designed to support a wide range of downstream speech applications. Developed as part of Singapore’s National Multimodal Large Language Model Programme, the MERaLiON-SpeechEncoder is tailored to address the speech processing needs in Singapore and the surrounding Southeast Asian region. The model currently supports mainly English, including the variety spoken in Singapore. We are actively expanding our datasets to gradually cover other languages in subsequent releases. The MERaLiON-SpeechEncoder was pre-trained from scratch on 200,000 hours of unlabelled speech data using a self-supervised learning approach based on masked language modelling. We describe our training procedure and hyperparameter tuning experiments in detail below. Our evaluation demonstrates improvements to spontaneous and Singapore speech benchmarks for speech recognition, while remaining competitive to other state-of-the-art speech encoders across ten other speech tasks. We commit to releasing our model, supporting broader research endeavours, both in Singapore and beyond. </p>
<blockquote>
<p>本技术报告描述了MERaLiON-SpeechEncoder，这是一款旨在支持多种下游语音应用的基础模型。作为新加坡国家多模态大型语言模型计划的一部分，MERaLiON-SpeechEncoder被特别设计以满足新加坡及其周边东南亚地区的语音处理需求。该模型目前主要支持英语，包括在新加坡使用的各种英语。我们正在积极扩充数据集，在后续版本中逐步覆盖其他语言。MERaLiON-SpeechEncoder使用基于掩码语言建模的自我监督学习方法，从零开始预训练了20万小时的未标记语音数据。我们会在下文详细描述我们的训练过程和超参数调整实验。我们的评估表明，该模型在语音识别方面对自然和新加坡语音基准测试有所改进，同时在其他十个语音任务上与其他最先进的语音编码器保持竞争力。我们致力于发布我们的模型，以支持新加坡及其以外的更广泛的研究工作。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.11538v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>MERaLiON-SpeechEncoder是一款为应对新加坡及周边东南亚地区语音处理需求而设计的基础模型，支持多种下游语音应用。该模型在大量未标注的语音数据上采用自我监督的学习方式预训练，并在多种语音任务上表现优异。模型目前主要支持英语，未来版本将逐渐覆盖其他语言。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MERaLiON-SpeechEncoder是一款为满足新加坡及东南亚地区语音处理需求而设计的基础模型。</li>
<li>模型支持多种下游语音应用。</li>
<li>MERaLiON-SpeechEncoder在大量未标注的语音数据上进行预训练。</li>
<li>该模型采用自我监督的学习方式，基于masked language modelling。</li>
<li>模型在多种语音任务上表现优异，包括语音识别等。</li>
<li>目前模型主要支持英语，未来会逐步覆盖其他语言。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.11538">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2024-12-24\./crop_Speech/2412.11538v2/page_0_0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d8c84ce936718c7b54c0743d6b0f7476.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-abfe384737ae5af8863bcface658936d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b7ff95419903deb40e8156cc9451a79b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bdafa5a6643b9f45ce63aa236df1669b.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-24/Speech/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-24/Speech/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Speech/">
                                    <span class="chip bg-color">Speech</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-24/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-495a697add0d962273763844d8dba102.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN 方向最新论文已更新，请持续关注 Update in 2024-12-24  What to Preserve and What to Transfer Faithful, Identity-Preserving   Diffusion-based Hairstyle Transfer
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-24/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-ca9559e98bd33a5067aa24182dadcb8e.jpg" class="responsive-img" alt="检测/分割/跟踪">
                        
                        <span class="card-title">检测/分割/跟踪</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            检测/分割/跟踪 方向最新论文已更新，请持续关注 Update in 2024-12-24  Mask-RadarNet Enhancing Transformer With Spatial-Temporal Semantic   Context for Radar Object Detection in Autonomous Driving
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                    检测/分割/跟踪
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                        <span class="chip bg-color">检测/分割/跟踪</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">27348.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
