<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-24  Tacit Learning with Adaptive Information Selection for Cooperative   Multi-Agent Reinforcement Learning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-c30275e38a084ae99a2feb9c3b5590ab.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-24
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    42 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-12-24-æ›´æ–°"><a href="#2024-12-24-æ›´æ–°" class="headerlink" title="2024-12-24 æ›´æ–°"></a>2024-12-24 æ›´æ–°</h1><h2 id="Tacit-Learning-with-Adaptive-Information-Selection-for-Cooperative-Multi-Agent-Reinforcement-Learning"><a href="#Tacit-Learning-with-Adaptive-Information-Selection-for-Cooperative-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Tacit Learning with Adaptive Information Selection for Cooperative   Multi-Agent Reinforcement Learning"></a>Tacit Learning with Adaptive Information Selection for Cooperative   Multi-Agent Reinforcement Learning</h2><p><strong>Authors:Lunjun Liu, Weilai Jiang, Yaonan Wang</strong></p>
<p>In multi-agent reinforcement learning (MARL), the centralized training with decentralized execution (CTDE) framework has gained widespread adoption due to its strong performance. However, the further development of CTDE faces two key challenges. First, agents struggle to autonomously assess the relevance of input information for cooperative tasks, impairing their decision-making abilities. Second, in communication-limited scenarios with partial observability, agents are unable to access global information, restricting their ability to collaborate effectively from a global perspective. To address these challenges, we introduce a novel cooperative MARL framework based on information selection and tacit learning. In this framework, agents gradually develop implicit coordination during training, enabling them to infer the cooperative behavior of others in a discrete space without communication, relying solely on local information. Moreover, we integrate gating and selection mechanisms, allowing agents to adaptively filter information based on environmental changes, thereby enhancing their decision-making capabilities. Experiments on popular MARL benchmarks show that our framework can be seamlessly integrated with state-of-the-art algorithms, leading to significant performance improvements. </p>
<blockquote>
<p>åœ¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­ï¼Œç”±äºå¼ºå¤§çš„æ€§èƒ½è¡¨ç°ï¼Œé‡‡ç”¨é›†ä¸­è®­ç»ƒä¸åˆ†æ•£æ‰§è¡Œï¼ˆCTDEï¼‰æ¡†æ¶çš„æ–¹æ³•å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚ç„¶è€Œï¼ŒCTDEçš„è¿›ä¸€æ­¥å‘å±•é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ã€‚é¦–å…ˆï¼Œæ™ºèƒ½ä½“éš¾ä»¥è‡ªä¸»è¯„ä¼°è¾“å…¥ä¿¡æ¯å¯¹äºååŒä»»åŠ¡çš„ç›¸å…³æ€§ï¼Œä»è€ŒæŸå®³äº†å…¶å†³ç­–èƒ½åŠ›ã€‚å…¶æ¬¡ï¼Œåœ¨é€šä¿¡å—é™ä¸”éƒ¨åˆ†å¯è§‚æµ‹çš„åœºæ™¯ä¸­ï¼Œæ™ºèƒ½ä½“æ— æ³•è®¿é—®å…¨å±€ä¿¡æ¯ï¼Œé™åˆ¶äº†å®ƒä»¬ä»å…¨å±€è§’åº¦è¿›è¡Œæœ‰æ•ˆåä½œçš„èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºä¿¡æ¯é€‰æ‹©å’Œé»˜è¯†å­¦ä¹ çš„æ–°å‹åˆä½œMARLæ¡†æ¶ã€‚åœ¨æ­¤æ¡†æ¶ä¸­ï¼Œæ™ºèƒ½ä½“åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸å‘å±•å‡ºéšæ€§åè°ƒï¼Œä½¿å®ƒä»¬èƒ½å¤Ÿåœ¨ç¦»æ•£ç©ºé—´ä¸­ä¸ä¾èµ–é€šä¿¡å°±èƒ½æ¨æ–­å‡ºä»–äººçš„åˆä½œè¡Œä¸ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç»“åˆäº†é—¨æ§å’Œé€‰æ‹©æœºåˆ¶ï¼Œä½¿æ™ºèƒ½ä½“èƒ½æ ¹æ®ç¯å¢ƒå˜åŒ–è‡ªé€‚åº”åœ°è¿‡æ»¤ä¿¡æ¯ï¼Œä»è€Œæé«˜å…¶å†³ç­–èƒ½åŠ›ã€‚åœ¨æµè¡Œçš„MARLåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å¯ä»¥æ— ç¼åœ°èå…¥æœ€å…ˆè¿›çš„ç®—æ³•ï¼Œå¸¦æ¥æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15639v1">PDF</a> Accepted by AAMAS 2025 (Extended Abstract)</p>
<p><strong>Summary</strong></p>
<p>åœ¨åŸºäºä¿¡æ¯é€‰æ‹©å’Œé»˜å¼å­¦ä¹ çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ¡†æ¶ä¸­ï¼Œæ™ºèƒ½ä½“é€šè¿‡è®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸å‘å±•éšå¼åè°ƒï¼Œèƒ½åœ¨å±€éƒ¨ä¿¡æ¯ç¯å¢ƒä¸‹æ¨æ–­å…¶ä»–æ™ºèƒ½ä½“çš„åˆä½œè¡Œä¸ºã€‚è¯¥æ¡†æ¶è§£å†³äº†é›†ä¸­è®­ç»ƒä¸åˆ†æ•£æ‰§è¡Œæ¡†æ¶é¢ä¸´çš„ä¿¡æ¯ç­›é€‰ä¸å…¨å±€æ²Ÿé€šé—®é¢˜ï¼Œæé«˜äº†æ™ºèƒ½ä½“åœ¨ç‰¹å®šç¯å¢ƒä¸­çš„å†³ç­–èƒ½åŠ›ã€‚é€šè¿‡æµè¡Œçš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åŸºå‡†æµ‹è¯•ï¼Œè¯¥æ¡†æ¶ä¸ç°æœ‰å…ˆè¿›ç®—æ³•çš„ç»“åˆè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­æ™®éé‡‡ç”¨é›†ä¸­è®­ç»ƒä¸åˆ†æ•£æ‰§è¡Œï¼ˆCTDEï¼‰æ¡†æ¶ã€‚æ­¤æ¡†æ¶å­˜åœ¨è‡ªä¸»è¯„ä¼°è¾“å…¥ä¿¡æ¯çš„é‡è¦æ€§å’Œå…¨å±€ä¿¡æ¯éš¾ä»¥è·å–çš„é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºä¿¡æ¯é€‰æ‹©å’Œé»˜å¼å­¦ä¹ çš„æ–°å‹åˆä½œMARLæ¡†æ¶ï¼Œè§£å†³äº†ä¸Šè¿°é—®é¢˜ã€‚æ™ºèƒ½ä½“é€šè¿‡è®­ç»ƒé€æ¸å‘å±•éšå¼åè°ƒï¼Œå¯ä»¥åœ¨ç¦»æ•£ç©ºé—´ä¸­ä»…ä¾èµ–å±€éƒ¨ä¿¡æ¯æ¨æ–­å…¶ä»–æ™ºèƒ½ä½“çš„åˆä½œè¡Œä¸ºã€‚</li>
<li>æ–°æ¡†æ¶èåˆäº†é—¨æ§å’Œé€‰æ‹©æœºåˆ¶ï¼Œå…è®¸æ™ºèƒ½ä½“æ ¹æ®ç¯å¢ƒå˜åŒ–è‡ªé€‚åº”åœ°ç­›é€‰ä¿¡æ¯ï¼Œå¢å¼ºäº†å†³ç­–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15639">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7f7c304129f77c8fd8957971bf73d836.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4c13821a1701fb99bdb4f4643efd044e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19b1203af9e35282371010546c6ff5ab.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-772b51958c86fa3aa46eed555885fe58.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-03a786febe9de38824d3a03fb960e146.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ae63531229a9b34ed997778a5334e1c9.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Multi-modal-Agent-Tuning-Building-a-VLM-Driven-Agent-for-Efficient-Tool-Usage"><a href="#Multi-modal-Agent-Tuning-Building-a-VLM-Driven-Agent-for-Efficient-Tool-Usage" class="headerlink" title="Multi-modal Agent Tuning: Building a VLM-Driven Agent for Efficient Tool   Usage"></a>Multi-modal Agent Tuning: Building a VLM-Driven Agent for Efficient Tool   Usage</h2><p><strong>Authors:Zhi Gao, Bofei Zhang, Pengxiang Li, Xiaojian Ma, Tao Yuan, Yue Fan, Yuwei Wu, Yunde Jia, Song-Chun Zhu, Qing Li</strong></p>
<p>The advancement of large language models (LLMs) prompts the development of multi-modal agents, which are used as a controller to call external tools, providing a feasible way to solve practical tasks. In this paper, we propose a multi-modal agent tuning method that automatically generates multi-modal tool-usage data and tunes a vision-language model (VLM) as the controller for powerful tool-usage reasoning. To preserve the data quality, we prompt the GPT-4o mini model to generate queries, files, and trajectories, followed by query-file and trajectory verifiers. Based on the data synthesis pipeline, we collect the MM-Traj dataset that contains 20K tasks with trajectories of tool usage. Then, we develop the T3-Agent via \underline{T}rajectory \underline{T}uning on VLMs for \underline{T}ool usage using MM-Traj. Evaluations on the GTA and GAIA benchmarks show that the T3-Agent consistently achieves improvements on two popular VLMs: MiniCPM-V-8.5B and {Qwen2-VL-7B}, which outperforms untrained VLMs by $20%$, showing the effectiveness of the proposed data synthesis pipeline, leading to high-quality data for tool-usage capabilities. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›å±•ï¼Œå¤šæ¨¡æ€ä»£ç†çš„å‘å±•ä¹Ÿéšä¹‹è€Œæ¥ã€‚è¿™äº›ä»£ç†è¢«ç”¨ä½œæ§åˆ¶å™¨æ¥è°ƒç”¨å¤–éƒ¨å·¥å…·ï¼Œä¸ºè§£å†³å®é™…ä»»åŠ¡æä¾›äº†å¯è¡Œçš„æ–¹æ³•ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€ä»£ç†è°ƒæ•´æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯è‡ªåŠ¨ç”Ÿæˆå¤šæ¨¡æ€å·¥å…·ä½¿ç”¨æ•°æ®ï¼Œå¹¶è°ƒæ•´è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä½œä¸ºå¼ºå¤§çš„å·¥å…·ä½¿ç”¨æ§åˆ¶å™¨ã€‚ä¸ºäº†ä¿æŒæ•°æ®è´¨é‡ï¼Œæˆ‘ä»¬å¼•å¯¼GPT-4oå°å‹æ¨¡å‹ç”ŸæˆæŸ¥è¯¢ã€æ–‡ä»¶å’Œè½¨è¿¹ï¼Œéšåè¿›è¡ŒæŸ¥è¯¢æ–‡ä»¶éªŒè¯å™¨å’Œè½¨è¿¹éªŒè¯å™¨ã€‚åŸºäºæ•°æ®åˆæˆç®¡é“ï¼Œæˆ‘ä»¬æ”¶é›†äº†åŒ…å«2ä¸‡ä¸ªä»»åŠ¡çš„MM-Trajæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å·¥å…·ä½¿ç”¨è½¨è¿¹ã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨MM-Trajçš„è½¨è¿¹è°ƒæ•´VLMæ¥å¼€å‘T3-Agentã€‚åœ¨GTAå’ŒGAIAåŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒT3-Agentåœ¨ä¸¤æ¬¾æµè¡Œçš„VLMä¸ŠæŒç»­å®ç°æ”¹è¿›ï¼šMiniCPM-V-8.5Bå’ŒQwen2-VL-7Bã€‚ç›¸è¾ƒäºæœªç»è®­ç»ƒçš„VLMï¼Œå…¶æ€§èƒ½æé«˜äº†20%ï¼Œæ˜¾ç¤ºäº†æ‰€æå‡ºçš„æ•°æ®åˆæˆç®¡é“çš„æœ‰æ•ˆæ€§ï¼Œè¯¥ç®¡é“æœ‰åŠ©äºä¸ºå·¥å…·ä½¿ç”¨èƒ½åŠ›æä¾›é«˜è´¨é‡æ•°æ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15606v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›æ­¥æ¨åŠ¨äº†å¤šæ¨¡æ€ä»£ç†çš„å‘å±•ï¼Œä½œä¸ºè°ƒç”¨å¤–éƒ¨å·¥å…·çš„æ§åˆ¶å™¨ï¼Œä¸ºè§£å†³å®é™…ä»»åŠ¡æä¾›äº†å¯è¡Œçš„æ–¹æ³•ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€ä»£ç†è°ƒä¼˜æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯è‡ªåŠ¨ç”Ÿæˆå¤šæ¨¡æ€å·¥å…·ä½¿ç”¨æ•°æ®ï¼Œå¹¶è°ƒæ•´è§†è§‰è¯­è¨€æ¨¡å‹ä½œä¸ºå¼ºå¤§çš„å·¥å…·ä½¿ç”¨æ§åˆ¶å™¨ã€‚é€šè¿‡GPT-4oå°å‹æ¨¡å‹ç”ŸæˆæŸ¥è¯¢ã€æ–‡ä»¶å’Œè½¨è¿¹ï¼Œå¹¶é€šè¿‡æŸ¥è¯¢æ–‡ä»¶å’Œè½¨è¿¹éªŒè¯å™¨ä¿è¯æ•°æ®è´¨é‡ã€‚åŸºäºæ•°æ®åˆæˆç®¡é“ï¼Œæˆ‘ä»¬æ”¶é›†äº†MM-Trajæ•°æ®é›†ï¼ŒåŒ…å«å…·æœ‰å·¥å…·ä½¿ç”¨è½¨è¿¹çš„2ä¸‡ä¸ªä»»åŠ¡ã€‚é€šè¿‡MM-Trajä¸Šçš„è½¨è¿¹è°ƒä¼˜VLMså¼€å‘T3-Agentï¼Œåœ¨GTAå’ŒGAIAåŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒT3-Agentåœ¨ä¸¤ç§æµè¡Œçš„VLMsä¸Šå®ç°äº†æŒç»­çš„æ”¹è¿›ï¼Œå³MiniCPM-V-8.5Bå’ŒQwen2-VL-7Bï¼Œå…¶æ€§èƒ½ä¼˜äºæœªè®­ç»ƒçš„VLMsè¾¾20%ï¼Œè¯æ˜äº†æ•°æ®åˆæˆç®¡é“çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå·¥å…·ä½¿ç”¨èƒ½åŠ›ç”Ÿæˆé«˜è´¨é‡æ•°æ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›æ­¥æ¨åŠ¨äº†å¤šæ¨¡æ€ä»£ç†çš„å‘å±•ï¼Œè¿™äº›ä»£ç†å¯ç”¨ä½œå¤–éƒ¨å·¥å…·çš„æ§åˆ¶å™¨ä»¥è§£å†³å®é™…ä»»åŠ¡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€ä»£ç†è°ƒä¼˜æ–¹æ³•ï¼Œèƒ½è‡ªåŠ¨ç”Ÿæˆå¤šæ¨¡æ€å·¥å…·ä½¿ç”¨æ•°æ®ã€‚</li>
<li>åˆ©ç”¨GPT-4oå°å‹æ¨¡å‹ç”ŸæˆæŸ¥è¯¢ã€æ–‡ä»¶å’Œè½¨è¿¹ï¼Œç¡®ä¿æ•°æ®è´¨é‡ã€‚</li>
<li>åŸºäºæ•°æ®åˆæˆç®¡é“ï¼Œæ”¶é›†äº†åŒ…å«2ä¸‡ä¸ªä»»åŠ¡çš„MM-Trajæ•°æ®é›†ã€‚</li>
<li>å¼€å‘äº†ä¸€ä¸ªåä¸ºT3-Agentçš„å·¥å…·ï¼Œé€šè¿‡è½¨è¿¹è°ƒä¼˜è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ã€‚</li>
<li>åœ¨GTAå’ŒGAIAåŸºå‡†æµ‹è¯•ä¸Šï¼ŒT3-Agentåœ¨ä¸¤ç§æµè¡Œçš„VLMsä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15606">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-268afcff9f222c16d93b74f989d18b88.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a8dda2d00eb1b900c3e1645b50ec9af4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a88943776924dfe5ec1b0304cc1f95b5.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Multi-Agent-Reinforcement-Learning-for-Sequential-Satellite-Assignment-Problems"><a href="#Multi-Agent-Reinforcement-Learning-for-Sequential-Satellite-Assignment-Problems" class="headerlink" title="Multi Agent Reinforcement Learning for Sequential Satellite Assignment   Problems"></a>Multi Agent Reinforcement Learning for Sequential Satellite Assignment   Problems</h2><p><strong>Authors:Joshua Holder, Natasha Jaques, Mehran Mesbahi</strong></p>
<p>Assignment problems are a classic combinatorial optimization problem in which a group of agents must be assigned to a group of tasks such that maximum utility is achieved while satisfying assignment constraints. Given the utility of each agent completing each task, polynomial-time algorithms exist to solve a single assignment problem in its simplest form. However, in many modern-day applications such as satellite constellations, power grids, and mobile robot scheduling, assignment problems unfold over time, with the utility for a given assignment depending heavily on the state of the system. We apply multi-agent reinforcement learning to this problem, learning the value of assignments by bootstrapping from a known polynomial-time greedy solver and then learning from further experience. We then choose assignments using a distributed optimal assignment mechanism rather than by selecting them directly. We demonstrate that this algorithm is theoretically justified and avoids pitfalls experienced by other RL algorithms in this setting. Finally, we show that our algorithm significantly outperforms other methods in the literature, even while scaling to realistic scenarios with hundreds of agents and tasks. </p>
<blockquote>
<p>åˆ†é…é—®é¢˜æ˜¯ç»å…¸ç»„åˆä¼˜åŒ–é—®é¢˜ä¹‹ä¸€ï¼Œå…¶ä¸­å¿…é¡»å°†ä¸€ç»„ä»£ç†åˆ†é…ç»™ä¸€ç»„ä»»åŠ¡ï¼Œä»¥åœ¨æ»¡è¶³åˆ†é…çº¦æŸçš„åŒæ—¶å®ç°æœ€å¤§æ•ˆç”¨ã€‚ç»™å®šæ¯ä¸ªä»£ç†å®Œæˆæ¯ä¸ªä»»åŠ¡çš„æ•ˆç”¨ï¼Œå­˜åœ¨å¤šé¡¹å¼æ—¶é—´ç®—æ³•æ¥è§£å†³æœ€ç®€å•çš„å•ä¸€åˆ†é…é—®é¢˜ã€‚ç„¶è€Œï¼Œåœ¨è®¸å¤šç°ä»£åº”ç”¨ï¼ˆå¦‚å«æ˜Ÿæ˜Ÿåº§ã€ç”µç½‘å’Œç§»åŠ¨æœºå™¨äººè°ƒåº¦ï¼‰ä¸­ï¼Œåˆ†é…é—®é¢˜ä¼šéšç€æ—¶é—´çš„æ¨ç§»è€Œå±•å¼€ï¼Œç»™å®šåˆ†é…çš„æ•ˆç”¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºç³»ç»Ÿçš„çŠ¶æ€ã€‚æˆ‘ä»¬åº”ç”¨å¤šä»£ç†å¼ºåŒ–å­¦ä¹ æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œé€šè¿‡ä»å·²çŸ¥çš„å¤šé¡¹å¼æ—¶é—´è´ªå©ªæ±‚è§£å™¨ä¸­è¿›è¡Œå¼•å¯¼å¹¶å­¦ä¹ è¿›ä¸€æ­¥çš„ç»éªŒæ¥ä¼°ç®—åˆ†é…çš„ä»·å€¼ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨åˆ†å¸ƒå¼æœ€ä¼˜åˆ†é…æœºåˆ¶æ¥é€‰æ‹©åˆ†é…ï¼Œè€Œä¸æ˜¯ç›´æ¥é€‰æ‹©å®ƒä»¬ã€‚æˆ‘ä»¬è¯æ˜äº†è¯¥ç®—æ³•çš„ç†è®ºä¾æ®ï¼Œé¿å…äº†å…¶ä»–å¼ºåŒ–å­¦ä¹ ç®—æ³•åœ¨æ­¤è®¾ç½®ä¸­é‡åˆ°çš„é™·é˜±ã€‚æœ€åï¼Œæˆ‘ä»¬è¯æ˜æˆ‘ä»¬çš„ç®—æ³•åœ¨æ–‡çŒ®ä¸­çš„å…¶ä»–æ–¹æ³•ä¸­å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œå³ä½¿åœ¨æ‰©å±•åˆ°å…·æœ‰æ•°ç™¾ä¸ªä»£ç†å’Œä»»åŠ¡çš„å®é™…åœºæ™¯ä¸­ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15573v1">PDF</a> </p>
<p><strong>Summary</strong><br>     ç»„åˆä¼˜åŒ–é—®é¢˜ä¸­çš„åˆ†é…é—®é¢˜æ˜¯ä¸€ç±»ç»å…¸é—®é¢˜ï¼Œå³å¦‚ä½•è®©ä¸€ç»„ä»£ç†å®Œæˆä¸€ç»„ä»»åŠ¡ï¼Œä»¥å®ç°æœ€å¤§æ•ˆç”¨å¹¶æ»¡è¶³åˆ†é…çº¦æŸã€‚å¯¹äºç®€å•çš„åˆ†é…é—®é¢˜ï¼Œå­˜åœ¨å¤šé¡¹å¼æ—¶é—´ç®—æ³•ã€‚ä½†åœ¨ç°ä»£åº”ç”¨å¦‚å«æ˜Ÿæ˜Ÿåº§ã€ç”µç½‘å’Œç§»åŠ¨æœºå™¨äººè°ƒåº¦ä¸­ï¼Œåˆ†é…é—®é¢˜éšæ—¶é—´å±•å¼€ï¼Œæ•ˆç”¨å–å†³äºç³»ç»Ÿçš„çŠ¶æ€ã€‚æˆ‘ä»¬åº”ç”¨å¤šä»£ç†å¼ºåŒ–å­¦ä¹ æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œé€šè¿‡ä»å·²çŸ¥çš„å¤šé¡¹å¼æ—¶é—´è´ªå¿ƒæ±‚è§£å™¨ä¸­è¿›è¡Œå¼•å¯¼å¹¶ä»ç»éªŒä¸­å­¦ä¹ æ¥è¯„ä¼°åˆ†é…çš„ä»·å€¼ã€‚æˆ‘ä»¬ä½¿ç”¨åˆ†å¸ƒå¼æœ€ä¼˜åˆ†é…æœºåˆ¶è¿›è¡Œé€‰æ‹©è€Œéç›´æ¥é€‰æ‹©åˆ†é…æ–¹å¼ã€‚æˆ‘ä»¬çš„ç®—æ³•ç†è®ºåˆç†ä¸”èƒ½é¿å…å…¶ä»–å¼ºåŒ–å­¦ä¹ ç®—æ³•åœ¨æ­¤è®¾ç½®ä¸­çš„é™·é˜±ã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬çš„ç®—æ³•åœ¨æ–‡çŒ®ä¸­çš„å…¶ä»–æ–¹æ³•ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œç”šè‡³åœ¨æ‰©å±•åˆ°æ•°ç™¾ä¸ªä»£ç†å’Œä»»åŠ¡çš„å®é™…åœºæ™¯ä¸­ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆ†é…é—®é¢˜æ˜¯ç»„åˆä¼˜åŒ–ä¸­çš„ç»å…¸é—®é¢˜ï¼Œæ¶‰åŠå°†ä»£ç†åˆ†é…ç»™ä»»åŠ¡ä»¥å®ç°æœ€å¤§æ•ˆç”¨å¹¶æ»¡è¶³çº¦æŸã€‚</li>
<li>åœ¨ç°ä»£åº”ç”¨ä¸­ï¼Œåˆ†é…é—®é¢˜éšç€æ—¶é—´å±•å¼€ï¼Œä¸”æ•ˆç”¨å–å†³äºç³»ç»ŸçŠ¶æ€ã€‚</li>
<li>å¤šä»£ç†å¼ºåŒ–å­¦ä¹ ç”¨äºè§£å†³å¤æ‚çš„åˆ†é…é—®é¢˜ã€‚</li>
<li>é€šè¿‡ç»“åˆå¤šé¡¹å¼æ—¶é—´è´ªå¿ƒæ±‚è§£å™¨å’Œç»éªŒå­¦ä¹ æ¥è¯„ä¼°åˆ†é…ä»·å€¼ã€‚</li>
<li>ä½¿ç”¨åˆ†å¸ƒå¼æœ€ä¼˜åˆ†é…æœºåˆ¶è¿›è¡Œé€‰æ‹©ï¼Œé¿å…ç›´æ¥é€‰æ‹©åˆ†é…æ–¹å¼ã€‚</li>
<li>æ‰€æå‡ºçš„ç®—æ³•åœ¨ç†è®ºä¸Šæ˜¯åˆç†çš„ï¼Œå¹¶èƒ½æœ‰æ•ˆé¿å…å…¶ä»–å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„é™·é˜±ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15573">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ff7df73d07e3bc468554881e3eb8b316.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf791d6a83508a1e169659d0f09d7a32.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8f68a888c64bfe102e6969d3d49ae35b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b015d7371f27cf3d6427a10658324c12.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-77569896ead2a1872b9473be29aba9fb.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Novelty-Guided-Data-Reuse-for-Efficient-and-Diversified-Multi-Agent-Reinforcement-Learning"><a href="#Novelty-Guided-Data-Reuse-for-Efficient-and-Diversified-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Novelty-Guided Data Reuse for Efficient and Diversified Multi-Agent   Reinforcement Learning"></a>Novelty-Guided Data Reuse for Efficient and Diversified Multi-Agent   Reinforcement Learning</h2><p><strong>Authors:Yangkun Chen, Kai Yang, Jian Tao, Jiafei Lyu</strong></p>
<p>Recently, deep Multi-Agent Reinforcement Learning (MARL) has demonstrated its potential to tackle complex cooperative tasks, pushing the boundaries of AI in collaborative environments. However, the efficiency of these systems is often compromised by inadequate sample utilization and a lack of diversity in learning strategies. To enhance MARL performance, we introduce a novel sample reuse approach that dynamically adjusts policy updates based on observation novelty. Specifically, we employ a Random Network Distillation (RND) network to gauge the novelty of each agentâ€™s current state, assigning additional sample update opportunities based on the uniqueness of the data. We name our method Multi-Agent Novelty-GuidEd sample Reuse (MANGER). This method increases sample efficiency and promotes exploration and diverse agent behaviors. Our evaluations confirm substantial improvements in MARL effectiveness in complex cooperative scenarios such as Google Research Football and super-hard StarCraft II micromanagement tasks. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œæ·±åº¦å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰å·²æ˜¾ç¤ºå‡ºå…¶åœ¨è§£å†³å¤æ‚åˆä½œä»»åŠ¡æ–¹é¢çš„æ½œåŠ›ï¼Œæ¨åŠ¨äº†äººå·¥æ™ºèƒ½åœ¨åä½œç¯å¢ƒä¸­çš„è¾¹ç•Œã€‚ç„¶è€Œï¼Œè¿™äº›ç³»ç»Ÿçš„æ•ˆç‡å¸¸å¸¸å› æ ·æœ¬åˆ©ç”¨ä¸è¶³å’Œå­¦ä¹ ç­–ç•¥ç¼ºä¹å¤šæ ·æ€§è€Œå—åˆ°å½±å“ã€‚ä¸ºäº†æé«˜MARLçš„æ€§èƒ½ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹æ ·æœ¬å†åˆ©ç”¨æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ ¹æ®è§‚æµ‹çš„æ–°é¢–æ€§åŠ¨æ€è°ƒæ•´ç­–ç•¥æ›´æ–°ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é‡‡ç”¨éšæœºç½‘ç»œè’¸é¦ï¼ˆRNDï¼‰ç½‘ç»œæ¥è¡¡é‡æ¯ä¸ªæ™ºèƒ½ä½“çš„å½“å‰çŠ¶æ€çš„æ–°é¢–æ€§ï¼Œæ ¹æ®æ•°æ®çš„å”¯ä¸€æ€§åˆ†é…é¢å¤–çš„æ ·æœ¬æ›´æ–°æœºä¼šã€‚æˆ‘ä»¬å°†æˆ‘ä»¬çš„æ–¹æ³•å‘½åä¸ºå¤šæ™ºèƒ½ä½“æ–°é¢–æ€§å¼•å¯¼æ ·æœ¬å†åˆ©ç”¨ï¼ˆMANGERï¼‰ã€‚æ­¤æ–¹æ³•æé«˜äº†æ ·æœ¬æ•ˆç‡ï¼Œå¹¶ä¿ƒè¿›äº†æ¢ç´¢å’Œæ™ºèƒ½ä½“çš„å¤šæ ·åŒ–è¡Œä¸ºã€‚æˆ‘ä»¬çš„è¯„ä¼°åœ¨å¤æ‚çš„åˆä½œåœºæ™¯ä¸­ç¡®è®¤äº†MARLçš„å¤§å¹…æ”¹è¿›ï¼Œä¾‹å¦‚åœ¨Google Research Footballå’Œè¶…çº§éš¾çš„æ˜Ÿé™…äº‰éœ¸IIå¾®è§‚ç®¡ç†ä»»åŠ¡ä¸­ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15517v1">PDF</a> AAAI 2025</p>
<p><strong>Summary</strong></p>
<p>æ·±åº¦å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰åœ¨è§£å†³å¤æ‚çš„ååŒä»»åŠ¡æ–¹é¢å…·æœ‰å·¨å¤§çš„æ½œåŠ›ï¼Œæ¨åŠ¨äº†äººå·¥æ™ºèƒ½åœ¨åä½œç¯å¢ƒä¸­çš„è¾¹ç•Œæ‰©å±•ã€‚ç„¶è€Œï¼Œæ ·æœ¬åˆ©ç”¨ç‡ä¸è¶³å’Œå­¦ä¹ ç­–ç•¥ç¼ºä¹å¤šæ ·æ€§å¸¸å¸¸å½±å“è¿™ç±»ç³»ç»Ÿçš„æ•ˆç‡ã€‚ä¸ºæå‡MARLæ€§èƒ½ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹æ ·æœ¬å¤ç”¨æ–¹æ³•â€”â€”Multi-Agent Novelty-GuidEd sample Reuseï¼ˆMANGERï¼‰ï¼Œè¯¥æ–¹æ³•æ ¹æ®è§‚æµ‹çš„æ–°é¢–æ€§åŠ¨æ€è°ƒæ•´ç­–ç•¥æ›´æ–°ã€‚å…·ä½“åœ°ï¼Œæˆ‘ä»¬é‡‡ç”¨Random Network Distillationï¼ˆRNDï¼‰ç½‘ç»œè¯„ä¼°å„æ™ºèƒ½ä½“çš„å½“å‰çŠ¶æ€çš„æ–°é¢–æ€§ï¼Œå¹¶æ ¹æ®æ•°æ®çš„ç‹¬ç‰¹æ€§åˆ†é…é¢å¤–çš„æ ·æœ¬æ›´æ–°æœºä¼šã€‚æ­¤æ–¹æ³•æé«˜äº†æ ·æœ¬æ•ˆç‡ï¼Œä¿ƒè¿›äº†æ¢ç´¢å’Œæ™ºèƒ½ä½“çš„å¤šæ ·åŒ–è¡Œä¸ºã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œåœ¨å¤æ‚çš„ååŒåœºæ™¯å¦‚Google Research Footballå’Œè¶…çº§å›°éš¾çš„StarCraft IIå¾®è§‚ç®¡ç†ä»»åŠ¡ä¸­ï¼ŒMARLçš„æœ‰æ•ˆæ€§å¾—åˆ°äº†æ˜¾è‘—æé«˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰åœ¨è§£å†³å¤æ‚çš„ååŒä»»åŠ¡æ–¹é¢å…·æœ‰æ½œåŠ›ã€‚</li>
<li>å½“å‰MARLç³»ç»Ÿå¸¸é¢ä¸´æ ·æœ¬åˆ©ç”¨ç‡ä¸è¶³å’Œå­¦ä¹ ç­–ç•¥ç¼ºä¹å¤šæ ·æ€§çš„é—®é¢˜ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ–°å‹æ ·æœ¬å¤ç”¨æ–¹æ³•â€”â€”MANGERï¼Œæ ¹æ®è§‚æµ‹çš„æ–°é¢–æ€§åŠ¨æ€è°ƒæ•´ç­–ç•¥æ›´æ–°ã€‚</li>
<li>MANGERæ–¹æ³•é‡‡ç”¨RNDç½‘ç»œè¯„ä¼°æ™ºèƒ½ä½“çš„å½“å‰çŠ¶æ€çš„æ–°é¢–æ€§ã€‚</li>
<li>MANGERæé«˜äº†æ ·æœ¬æ•ˆç‡ï¼Œä¿ƒè¿›äº†æ¢ç´¢å’Œæ™ºèƒ½ä½“çš„å¤šæ ·åŒ–è¡Œä¸ºã€‚</li>
<li>åœ¨å¤æ‚çš„ååŒåœºæ™¯ä¸­ï¼Œå¦‚Google Research Footballå’ŒStarCraft IIå¾®è§‚ç®¡ç†ä»»åŠ¡ï¼ŒMANGERæ–¹æ³•æé«˜äº†MARLçš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15517">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e1d9095e9e92617c8868b34de23e0fef.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1aed80cc60f638c88ce3e5ab1a39094d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2af9b0034f2ab65168c98cddd234bdd8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ac49829b3e3b02da7b53bc4491139ff6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-843f1e75da850e5468b9ee2e1002b22f.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Mitigating-Social-Bias-in-Large-Language-Models-A-Multi-Objective-Approach-within-a-Multi-Agent-Framework"><a href="#Mitigating-Social-Bias-in-Large-Language-Models-A-Multi-Objective-Approach-within-a-Multi-Agent-Framework" class="headerlink" title="Mitigating Social Bias in Large Language Models: A Multi-Objective   Approach within a Multi-Agent Framework"></a>Mitigating Social Bias in Large Language Models: A Multi-Objective   Approach within a Multi-Agent Framework</h2><p><strong>Authors:Zhenjie Xu, Wenqing Chen, Yi Tang, Xuanying Li, Cheng Hu, Zhixuan Chu, Kui Ren, Zibin Zheng, Zhichao Lu</strong></p>
<p>Natural language processing (NLP) has seen remarkable advancements with the development of large language models (LLMs). Despite these advancements, LLMs often produce socially biased outputs. Recent studies have mainly addressed this problem by prompting LLMs to behave ethically, but this approach results in unacceptable performance degradation. In this paper, we propose a multi-objective approach within a multi-agent framework (MOMA) to mitigate social bias in LLMs without significantly compromising their performance. The key idea of MOMA involves deploying multiple agents to perform causal interventions on bias-related contents of the input questions, breaking the shortcut connection between these contents and the corresponding answers. Unlike traditional debiasing techniques leading to performance degradation, MOMA substantially reduces bias while maintaining accuracy in downstream tasks. Our experiments conducted on two datasets and two models demonstrate that MOMA reduces bias scores by up to 87.7%, with only a marginal performance degradation of up to 6.8% in the BBQ dataset. Additionally, it significantly enhances the multi-objective metric icat in the StereoSet dataset by up to 58.1%. Code will be made available at <a target="_blank" rel="noopener" href="https://github.com/Cortantse/MOMA">https://github.com/Cortantse/MOMA</a>. </p>
<blockquote>
<p>è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‘å±•è€Œå–å¾—äº†æ˜¾è‘—è¿›æ­¥ã€‚ç„¶è€Œï¼Œå°½ç®¡æœ‰è¿™äº›è¿›å±•ï¼ŒLLMé€šå¸¸ä¼šäº§ç”Ÿå¸¦æœ‰ç¤¾ä¼šåè§çš„ç»“æœã€‚æœ€è¿‘çš„ç ”ç©¶ä¸»è¦é€šè¿‡æç¤ºLLMä»¥ç¬¦åˆé“å¾·çš„è¡Œä¸ºæ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†è¿™ç§æ–¹æ³•ä¼šå¯¼è‡´æ€§èƒ½ä¸å¯æ¥å—çš„ä¸‹é™ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤šç›®æ ‡å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼ˆMOMAï¼‰çš„æ–¹æ³•ï¼Œä»¥å‡è½»LLMä¸­çš„ç¤¾ä¼šåè§ï¼Œè€Œä¸ä¼šå¯¹å…¶æ€§èƒ½é€ æˆé‡å¤§æŸå®³ã€‚MOMAçš„å…³é”®æ€æƒ³æ˜¯åˆ©ç”¨å¤šä¸ªæ™ºèƒ½ä½“å¯¹è¾“å…¥é—®é¢˜ä¸­çš„åè§ç›¸å…³å†…å®¹è¿›è¡Œå› æœå¹²é¢„ï¼Œä»è€Œåˆ‡æ–­è¿™äº›å†…å®¹ä¸ç›¸åº”ç­”æ¡ˆä¹‹é—´çš„ç›´æ¥è”ç³»ã€‚ä¸ä¼ ç»Ÿçš„å¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™çš„æ¶ˆé™¤åè§æŠ€æœ¯ä¸åŒï¼ŒMOMAåœ¨é™ä½åè§çš„åŒæ—¶ï¼Œä¿æŒä¸‹æ¸¸ä»»åŠ¡çš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªæ•°æ®é›†å’Œä¸¤ä¸ªæ¨¡å‹ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒMOMAå°†åè§åˆ†æ•°é™ä½äº†é«˜è¾¾87.7%ï¼Œä»…åœ¨BBQæ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¸‹é™å¹…åº¦ä¸ºæœ€é«˜6.8%ã€‚æ­¤å¤–ï¼Œå®ƒåœ¨StereoSetæ•°æ®é›†ä¸Šæ˜¾è‘—æé«˜äº†å¤šç›®æ ‡æŒ‡æ ‡icatï¼Œæœ€é«˜æå‡äº†58.1%ã€‚ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/Cortantse/MOMA">https://github.com/Cortantse/MOMA</a>ä¸Šæä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15504v1">PDF</a> This work has been accepted at The 39th Annual AAAI Conference on   Artificial Intelligence (AAAI-2025)</p>
<p><strong>Summary</strong><br>è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰é¢†åŸŸéšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‘å±•å–å¾—äº†æ˜¾è‘—è¿›æ­¥ã€‚ç„¶è€Œï¼ŒLLMçš„è¾“å‡ºå¸¸å¸¦æœ‰ç¤¾ä¼šåè§ã€‚å°½ç®¡å·²æœ‰ç ”ç©¶é€šè¿‡æç¤ºLLMä»¥ç¬¦åˆä¼¦ç†çš„æ–¹å¼è¡Œä¸ºæ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½†è¿™å¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚æœ¬æ–‡æå‡ºä¸€ç§å¤šç›®æ ‡å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼ˆMOMAï¼‰çš„æ–¹æ³•ï¼Œæ—¨åœ¨ç¼“è§£LLMä¸­çš„ç¤¾ä¼šåè§é—®é¢˜ï¼ŒåŒæ—¶ä¸ä¼šæ˜¾è‘—æŸå®³æ€§èƒ½ã€‚MOMAçš„å…³é”®æ€æƒ³æ˜¯åˆ©ç”¨å¤šä¸ªæ™ºèƒ½ä½“å¯¹è¾“å…¥é—®é¢˜ä¸­çš„åè§ç›¸å…³å†…å®¹è¿›è¡Œå› æœå¹²é¢„ï¼Œåˆ‡æ–­è¿™äº›å†…å®¹ä¸ç›¸åº”ç­”æ¡ˆä¹‹é—´çš„ç›´æ¥è”ç³»ã€‚ä¸ä¼ ç»Ÿå¯¼è‡´æ€§èƒ½ä¸‹é™çš„æ¶ˆé™¤åè§æŠ€æœ¯ä¸åŒï¼ŒMOMAåœ¨é™ä½åè§çš„åŒæ—¶ç»´æŒä¸‹æ¸¸ä»»åŠ¡çš„å‡†ç¡®æ€§ã€‚åœ¨ä¸¤é¡¹æ•°æ®é›†å’Œä¸¤ä¸ªæ¨¡å‹ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼ŒMOMAå°†åè§å¾—åˆ†é™ä½äº†é«˜è¾¾87.7%ï¼ŒåŒæ—¶åœ¨BBQæ•°æ®é›†ä¸Šçš„æ€§èƒ½ä»…è½»å¾®ä¸‹é™6.8%ã€‚æ­¤å¤–ï¼Œå®ƒåœ¨StereoSetæ•°æ®é›†ä¸Šçš„å¤šç›®æ ‡æŒ‡æ ‡icatä¹Ÿæœ‰æ˜¾è‘—æå‡ï¼Œæå‡äº†é«˜è¾¾58.1%ã€‚ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/Cortantse/MOMA%E5%85%AC%E5%BC%80%E5%88%86%E4%BA%AB%E3%80%82">https://github.com/Cortantse/MOMAå…¬å¼€åˆ†äº«ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¾“å‡ºå¸¸å¸¦æœ‰ç¤¾ä¼šåè§ã€‚</li>
<li>ä¼ ç»Ÿè§£å†³åè§é—®é¢˜çš„æ–¹æ³•å¯èƒ½å¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™ã€‚</li>
<li>MOMAæ–¹æ³•é€šè¿‡å¤šæ™ºèƒ½ä½“æ¡†æ¶è¿›è¡Œå› æœå¹²é¢„ï¼Œæ—¨åœ¨ç¼“è§£LLMä¸­çš„ç¤¾ä¼šåè§é—®é¢˜ã€‚</li>
<li>MOMAåœ¨é™ä½åè§çš„åŒæ—¶ç»´æŒä¸‹æ¸¸ä»»åŠ¡çš„å‡†ç¡®æ€§ã€‚</li>
<li>åœ¨å®éªŒæ•°æ®é›†ä¸Šï¼ŒMOMAæ˜¾è‘—é™ä½äº†åè§å¾—åˆ†ï¼Œæœ€é«˜è¾¾87.7%ã€‚</li>
<li>MOMAå¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“è½»å¾®ï¼Œæ€§èƒ½ä¸‹é™æœ€é«˜è¾¾6.8%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15504">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3d0c6c31cf211219480bf8b94d123917.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff2617591e1a6fe5cdc1034eea6331b7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-323b419cffe6c17dd7e83506a3518e94.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3f8fcbcc706e98cc1954bfa1a98ce4c9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6bbac2731363dd7748025f96c9b87078.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4b268901f2b7e9815f059b10914344a6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-98379efcba6a17d3901466613f46273d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-490fa04f1e227757e9a21b49cc68b362.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="AdaSociety-An-Adaptive-Environment-with-Social-Structures-for-Multi-Agent-Decision-Making"><a href="#AdaSociety-An-Adaptive-Environment-with-Social-Structures-for-Multi-Agent-Decision-Making" class="headerlink" title="AdaSociety: An Adaptive Environment with Social Structures for   Multi-Agent Decision-Making"></a>AdaSociety: An Adaptive Environment with Social Structures for   Multi-Agent Decision-Making</h2><p><strong>Authors:Yizhe Huang, Xingbo Wang, Hao Liu, Fanqi Kong, Aoyang Qin, Min Tang, Xiaoxi Wang, Song-Chun Zhu, Mingjie Bi, Siyuan Qi, Xue Feng</strong></p>
<p>Traditional interactive environments limit agentsâ€™ intelligence growth with fixed tasks. Recently, single-agent environments address this by generating new tasks based on agent actions, enhancing task diversity. We consider the decision-making problem in multi-agent settings, where tasks are further influenced by social connections, affecting rewards and information access. However, existing multi-agent environments lack a combination of adaptive physical surroundings and social connections, hindering the learning of intelligent behaviors. To address this, we introduce AdaSociety, a customizable multi-agent environment featuring expanding state and action spaces, alongside explicit and alterable social structures. As agents progress, the environment adaptively generates new tasks with social structures for agents to undertake. In AdaSociety, we develop three mini-games showcasing distinct social structures and tasks. Initial results demonstrate that specific social structures can promote both individual and collective benefits, though current reinforcement learning and LLM-based algorithms show limited effectiveness in leveraging social structures to enhance performance. Overall, AdaSociety serves as a valuable research platform for exploring intelligence in diverse physical and social settings. The code is available at <a target="_blank" rel="noopener" href="https://github.com/bigai-ai/AdaSociety">https://github.com/bigai-ai/AdaSociety</a>. </p>
<blockquote>
<p>ä¼ ç»Ÿçš„äº¤äº’ç¯å¢ƒé€šè¿‡å›ºå®šä»»åŠ¡é™åˆ¶äº†ä»£ç†çš„æ™ºèƒ½å¢é•¿ã€‚æœ€è¿‘ï¼Œå•ä»£ç†ç¯å¢ƒé€šè¿‡åŸºäºä»£ç†è¡ŒåŠ¨ç”Ÿæˆæ–°ä»»åŠ¡æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæé«˜äº†ä»»åŠ¡çš„å¤šæ ·æ€§ã€‚æˆ‘ä»¬è€ƒè™‘å¤šä»£ç†ç¯å¢ƒä¸­çš„å†³ç­–é—®é¢˜ï¼Œå…¶ä¸­çš„ä»»åŠ¡å—åˆ°ç¤¾ä¼šè¿æ¥çš„è¿›ä¸€æ­¥å½±å“ï¼Œä»è€Œå½±å“å¥–åŠ±å’Œä¿¡æ¯çš„è·å–ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¤šä»£ç†ç¯å¢ƒç¼ºä¹è‡ªé€‚åº”çš„ç‰©ç†ç¯å¢ƒå’Œç¤¾ä¼šè¿æ¥çš„ç»„åˆï¼Œé˜»ç¢äº†æ™ºèƒ½è¡Œä¸ºçš„å­¦ä¹ ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†AdaSocietyï¼Œè¿™æ˜¯ä¸€ä¸ªå¯å®šåˆ¶çš„å¤šä»£ç†ç¯å¢ƒï¼Œå…·æœ‰å¯æ‰©å±•çš„çŠ¶æ€å’Œè¡ŒåŠ¨ç©ºé—´ï¼Œä»¥åŠæ˜ç¡®ä¸”å¯æ›´æ”¹çš„ç¤¾ä¼šç»“æ„ã€‚éšç€ä»£ç†çš„è¿›æ­¥ï¼Œç¯å¢ƒä¼šè‡ªé€‚åº”åœ°ç”Ÿæˆå…·æœ‰ç¤¾ä¼šç»“æ„çš„æ–°ä»»åŠ¡ä¾›ä»£ç†æ‰§è¡Œã€‚åœ¨AdaSocietyä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸‰ä¸ªå°å‹æ¸¸æˆï¼Œå±•ç¤ºäº†ä¸åŒçš„ç¤¾ä¼šç»“æ„å’Œä»»åŠ¡ã€‚åˆæ­¥ç»“æœè¡¨æ˜ï¼Œç‰¹å®šçš„ç¤¾ä¼šç»“æ„å¯ä»¥ä¿ƒè¿›ä¸ªäººå’Œé›†ä½“çš„åˆ©ç›Šï¼Œå°½ç®¡ç›®å‰çš„å¼ºåŒ–å­¦ä¹ å’ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç®—æ³•åœ¨åˆ©ç”¨ç¤¾ä¼šç»“æ„æé«˜æ€§èƒ½æ–¹é¢æ˜¾ç¤ºå‡ºæœ‰é™çš„æœ‰æ•ˆæ€§ã€‚æ€»çš„æ¥è¯´ï¼ŒAdaSocietyæ˜¯ä¸€ä¸ªæœ‰ä»·å€¼çš„ç ”ç©¶å¹³å°ï¼Œå¯ç”¨äºæ¢ç´¢åœ¨å¤šæ ·åŒ–çš„ç‰©ç†å’Œç¤¾ä¼šç¯å¢ƒä¸­çš„æ™ºèƒ½ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/bigai-ai/AdaSociety">https://github.com/bigai-ai/AdaSociety</a>è·å¾—ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.03865v3">PDF</a> Accepted at NeurIPS D&amp;B 2024</p>
<p><strong>Summary</strong></p>
<p>ä¼ ç»Ÿäº¤äº’ç¯å¢ƒé™åˆ¶æ™ºèƒ½ä»£ç†çš„å‘å±•ï¼Œä»»åŠ¡å›ºå®šã€‚è¿‘æœŸï¼Œå•ä»£ç†ç¯å¢ƒé€šè¿‡ç”ŸæˆåŸºäºä»£ç†è¡Œä¸ºçš„æ–°ä»»åŠ¡ï¼Œå¢å¼ºä»»åŠ¡å¤šæ ·æ€§ï¼Œæ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚æœ¬æ–‡ç ”ç©¶å¤šä»£ç†ç¯å¢ƒä¸­çš„å†³ç­–é—®é¢˜ï¼Œä»»åŠ¡å—ç¤¾ä¼šè¿æ¥å½±å“ï¼Œæ”¹å˜å¥–åŠ±å’Œèµ„è®¯è·å–ã€‚ç„¶è€Œï¼Œç°æœ‰å¤šä»£ç†ç¯å¢ƒç¼ºä¹è‡ªé€‚åº”çš„ç‰©ç†ç¯å¢ƒå’Œç¤¾ä¼šè¿æ¥ï¼Œé˜»ç¢æ™ºèƒ½è¡Œä¸ºçš„å­¦ä¹ ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºAdaSocietyï¼Œä¸€ä¸ªå¯å®šåˆ¶çš„å¤šä»£ç†ç¯å¢ƒï¼Œæ‹¥æœ‰æ‰©å±•çš„çŠ¶æ€å’Œè¡ŒåŠ¨ç©ºé—´ï¼Œä»¥åŠæ˜ç¡®ä¸”å¯æ”¹å˜çš„ç¤¾ä¼šç»“æ„ã€‚éšç€ä»£ç†çš„è¿›æ­¥ï¼Œç¯å¢ƒä¼šè‡ªé€‚åº”ç”Ÿæˆå…·æœ‰ç¤¾ä¼šç»“æ„çš„æ–°ä»»åŠ¡ä¾›ä»£ç†æ‰§è¡Œã€‚åœ¨AdaSocietyä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸‰ä¸ªå±•ç¤ºä¸åŒç¤¾ä¼šç»“æ„å’Œä»»åŠ¡çš„å°æ¸¸æˆã€‚åˆæ­¥ç»“æœæ˜¾ç¤ºï¼Œç‰¹å®šçš„ç¤¾ä¼šç»“æ„å¯ä»¥ä¿ƒè¿›ä¸ªäººå’Œé›†ä½“çš„åˆ©ç›Šï¼Œä½†ç›®å‰çš„å¼ºåŒ–å­¦ä¹ å’Œå¤§å‹è¯­è¨€æ¨¡å‹ç®—æ³•åœ¨åˆ©ç”¨ç¤¾ä¼šç»“æ„æé«˜æ€§èƒ½æ–¹é¢æ•ˆæœæœ‰é™ã€‚æ€»ä½“è€Œè¨€ï¼ŒAdaSocietyæ˜¯ä¸€ä¸ªæœ‰ä»·å€¼çš„ç ”ç©¶å¹³å°ï¼Œç”¨äºæ¢ç´¢ä¸åŒç‰©ç†å’Œç¤¾ä¼šç¯å¢ƒä¸‹çš„æ™ºèƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¼ ç»Ÿäº¤äº’ç¯å¢ƒé™åˆ¶æ™ºèƒ½ä»£ç†çš„å‘å±•ï¼Œä»»åŠ¡å›ºå®šï¼Œå•ä»£ç†ç¯å¢ƒé€šè¿‡ç”Ÿæˆæ–°ä»»åŠ¡å¢å¼ºä»»åŠ¡å¤šæ ·æ€§ã€‚</li>
<li>å¤šä»£ç†ç¯å¢ƒä¸­çš„å†³ç­–å—ç¤¾ä¼šè¿æ¥å½±å“ï¼Œæ”¹å˜å¥–åŠ±å’Œèµ„è®¯è·å–ã€‚</li>
<li>ç°æœ‰å¤šä»£ç†ç¯å¢ƒç¼ºä¹è‡ªé€‚åº”çš„ç‰©ç†ç¯å¢ƒå’Œç¤¾ä¼šè¿æ¥ã€‚</li>
<li>AdaSocietyæ˜¯ä¸€ä¸ªå¯å®šåˆ¶çš„å¤šä»£ç†ç¯å¢ƒï¼Œæ‹¥æœ‰æ‰©å±•çš„çŠ¶æ€å’Œè¡ŒåŠ¨ç©ºé—´ï¼Œä»¥åŠç¤¾ä¼šç»“æ„ã€‚</li>
<li>AdaSocietyç¯å¢ƒä¸­ï¼Œä»£ç†å¯ä»¥åœ¨æ‰§è¡Œä»»åŠ¡çš„è¿›ç¨‹ä¸­è‡ªé€‚åº”åœ°ç”Ÿæˆå…·æœ‰ç¤¾ä¼šç»“æ„çš„æ–°ä»»åŠ¡ã€‚</li>
<li>åˆæ­¥ç ”ç©¶æ˜¾ç¤ºç‰¹å®šç¤¾ä¼šç»“æ„å¯¹ä¸ªäººå’Œé›†ä½“æœ‰ç›Šï¼Œä½†ç°æœ‰ç®—æ³•åœ¨åˆ©ç”¨ç¤¾ä¼šç»“æ„æé«˜æ™ºèƒ½è¡Œä¸ºæ€§èƒ½æ–¹é¢æœ‰é™ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.03865">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a7a922fcb4dea37a229524deaae01767.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-40fd698afd250054ea2b435a592027fa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8a99a111b26b5137b58d4ed1caedaf33.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8d0a7c8c54cc553e2da5073afb34c2bf.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="MLE-bench-Evaluating-Machine-Learning-Agents-on-Machine-Learning-Engineering"><a href="#MLE-bench-Evaluating-Machine-Learning-Agents-on-Machine-Learning-Engineering" class="headerlink" title="MLE-bench: Evaluating Machine Learning Agents on Machine Learning   Engineering"></a>MLE-bench: Evaluating Machine Learning Agents on Machine Learning   Engineering</h2><p><strong>Authors:Jun Shern Chan, Neil Chowdhury, Oliver Jaffe, James Aung, Dane Sherburn, Evan Mays, Giulio Starace, Kevin Liu, Leon Maksin, Tejal Patwardhan, Lilian Weng, Aleksander MÄ…dry</strong></p>
<p>We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering. To this end, we curate 75 ML engineering-related competitions from Kaggle, creating a diverse set of challenging tasks that test real-world ML engineering skills such as training models, preparing datasets, and running experiments. We establish human baselines for each competition using Kaggleâ€™s publicly available leaderboards. We use open-source agent scaffolds to evaluate several frontier language models on our benchmark, finding that the best-performing setupâ€“OpenAIâ€™s o1-preview with AIDE scaffoldingâ€“achieves at least the level of a Kaggle bronze medal in 16.9% of competitions. In addition to our main results, we investigate various forms of resource scaling for AI agents and the impact of contamination from pre-training. We open-source our benchmark code (github.com&#x2F;openai&#x2F;mle-bench&#x2F;) to facilitate future research in understanding the ML engineering capabilities of AI agents. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†MLE-benchï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¡¡é‡AIä»£ç†åœ¨æœºå™¨å­¦ä¹ å·¥ç¨‹æ–¹é¢è¡¨ç°å¦‚ä½•çš„åŸºå‡†æµ‹è¯•ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä»Kaggleä¸­ç²¾å¿ƒæŒ‘é€‰äº†75ä¸ªä¸æœºå™¨å­¦ä¹ å·¥ç¨‹ç›¸å…³çš„ç«èµ›ï¼Œåˆ›å»ºäº†ä¸€ç³»åˆ—å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡é›†ï¼Œè¿™äº›ä»»åŠ¡æµ‹è¯•äº†ç°å®ä¸–ç•Œä¸­æœºå™¨å­¦ä¹ å·¥ç¨‹çš„æŠ€èƒ½ï¼Œå¦‚è®­ç»ƒæ¨¡å‹ã€å‡†å¤‡æ•°æ®é›†å’Œè¿›è¡Œå®éªŒã€‚æˆ‘ä»¬åˆ©ç”¨Kaggleçš„å…¬å¼€æ’è¡Œæ¦œä¸ºæ¯ä¸ªç«èµ›åˆ¶å®šäººç±»åŸºå‡†ã€‚æˆ‘ä»¬ä½¿ç”¨å¼€æºä»£ç†è„šæ‰‹æ¶æ¥è¯„ä¼°å‰æ²¿è¯­è¨€æ¨¡å‹åœ¨æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ï¼Œå‘ç°è¡¨ç°æœ€ä½³çš„é…ç½®æ˜¯OpenAIçš„o1-previewä¸AIDEè„šæ‰‹æ¶ï¼Œåœ¨16.9%çš„ç«èµ›ä¸­è‡³å°‘è¾¾åˆ°Kaggleé“œç‰Œæ°´å¹³ã€‚é™¤äº†æˆ‘ä»¬çš„ä¸»è¦ç»“æœå¤–ï¼Œæˆ‘ä»¬è¿˜ç ”ç©¶äº†AIä»£ç†çš„å„ç§èµ„æºæ‰©å±•å½¢å¼å’Œé¢„è®­ç»ƒæ±¡æŸ“çš„å½±å“ã€‚æˆ‘ä»¬å¼€æºæˆ‘ä»¬çš„åŸºå‡†ä»£ç ï¼ˆgithub.com&#x2F;openai&#x2F;mle-bench&#x2F;ï¼‰ï¼Œä»¥ä¿ƒè¿›æœªæ¥å¯¹AIä»£ç†æœºå™¨å­¦ä¹ å·¥ç¨‹èƒ½åŠ›çš„ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.07095v5">PDF</a> 10 pages, 17 pages appendix. Equal contribution by first seven   authors, authors randomized. Added Section A.9</p>
<p><strong>Summary</strong></p>
<p>MLE-benchæ˜¯ä¸“é—¨ç”¨äºè¡¡é‡AIä»£ç†åœ¨æœºå™¨å­¦ä¹ å·¥ç¨‹æ–¹é¢çš„æ€§èƒ½çš„åŸºå‡†æµ‹è¯•å¹³å°ã€‚é€šè¿‡å¯¹Kaggleä¸Šçš„75ä¸ªä¸æœºå™¨å­¦ä¹ å·¥ç¨‹ç›¸å…³çš„ç«èµ›è¿›è¡Œæ•´ç†ï¼Œå½¢æˆäº†ä¸€ä¸ªå¤šæ ·åŒ–ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡é›†ï¼Œæ¶‰åŠæ¨¡å‹è®­ç»ƒã€æ•°æ®é›†å‡†å¤‡å’Œå®éªŒè¿è¡Œç­‰çœŸå®ä¸–ç•Œçš„æŠ€èƒ½ã€‚é€šè¿‡å¼€æºä»£ç†è„šæ‰‹æ¶å¯¹å‰æ²¿è¯­è¨€æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œå‘ç°æœ€ä½³è¡¨ç°çš„ç»„åˆæ˜¯OpenAIçš„o1-previewä¸AIDEè„šæ‰‹æ¶ç»„åˆï¼Œåœ¨æŸäº›ç«èµ›ä¸­è¾¾åˆ°äº†Kaggleé“œç‰Œæ°´å¹³ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ¢è®¨äº†AIä»£ç†çš„å„ç§èµ„æºæ‰©å±•å½¢å¼å’Œé¢„è®­ç»ƒæ±¡æŸ“çš„å½±å“ï¼Œå¹¶å…¬å¼€äº†åŸºå‡†æµ‹è¯•ä»£ç ï¼Œä»¥ä¿ƒè¿›æœªæ¥å¯¹AIä»£ç†çš„æœºå™¨å­¦ä¹ å·¥ç¨‹èƒ½åŠ›çš„ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MLE-benchæ˜¯ä¸€ä¸ªè¡¡é‡AIä»£ç†åœ¨æœºå™¨å­¦ä¹ å·¥ç¨‹æ–¹é¢æ€§èƒ½çš„åŸºå‡†æµ‹è¯•å¹³å°ã€‚</li>
<li>å¹³å°é€šè¿‡æ•´ç†Kaggleä¸Šçš„75ä¸ªç›¸å…³ç«èµ›ï¼Œå½¢æˆå¤šæ ·åŒ–ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡é›†ã€‚</li>
<li>å¼€æºä»£ç†è„šæ‰‹æ¶è¢«ç”¨äºè¯„ä¼°å‰æ²¿è¯­è¨€æ¨¡å‹ã€‚</li>
<li>æœ€ä½³è¡¨ç°çš„AIä»£ç†ç»„åˆæ˜¯OpenAIçš„o1-previewä¸AIDEè„šæ‰‹æ¶ç»„åˆã€‚</li>
<li>è¯¥ç»„åˆåœ¨æŸäº›ç«èµ›ä¸­è¾¾åˆ°äº†Kaggleé“œç‰Œæ°´å¹³ã€‚</li>
<li>ç ”ç©¶è¿˜æ¢è®¨äº†AIä»£ç†çš„èµ„æºæ‰©å±•å’Œé¢„è®­ç»ƒæ±¡æŸ“é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.07095">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-590d0dd834c04d8fcda18a842c706e7a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c30275e38a084ae99a2feb9c3b5590ab.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6029a310edb0f83fd5ac9b802eb7a464.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7a8ffefe1a18446049dbb08c8e36ff37.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-33cf9a6a8dcd92969723a32b91587a61.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="LTLf-Synthesis-on-First-Order-Agent-Programs-in-Nondeterministic-Environments"><a href="#LTLf-Synthesis-on-First-Order-Agent-Programs-in-Nondeterministic-Environments" class="headerlink" title="LTLf Synthesis on First-Order Agent Programs in Nondeterministic   Environments"></a>LTLf Synthesis on First-Order Agent Programs in Nondeterministic   Environments</h2><p><strong>Authors:Till Hofmann, Jens ClaÃŸen</strong></p>
<p>We investigate the synthesis of policies for high-level agent programs expressed in Golog, a language based on situation calculus that incorporates nondeterministic programming constructs. Unlike traditional approaches for program realization that assume full agent control or rely on incremental search, we address scenarios where environmental nondeterminism significantly influences program outcomes. Our synthesis problem involves deriving a policy that successfully realizes a given Golog program while ensuring the satisfaction of a temporal specification, expressed in Linear Temporal Logic on finite traces (LTLf), across all possible environmental behaviors. By leveraging an expressive class of first-order action theories, we construct a finite game arena that encapsulates program executions and tracks the satisfaction of the temporal goal. A game-theoretic approach is employed to derive such a policy. Experimental results demonstrate this approachâ€™s feasibility in domains with unbounded objects and non-local effects. This work bridges agent programming and temporal logic synthesis, providing a framework for robust agent behavior in nondeterministic environments. </p>
<blockquote>
<p>æˆ‘ä»¬ç ”ç©¶äº†åœ¨Gologä¸­è¡¨è¾¾çš„é«˜çº§ä»£ç†ç¨‹åºçš„ç­–ç•¥åˆæˆã€‚Gologæ˜¯ä¸€ç§åŸºäºæƒ…å†µè®¡ç®—çš„è¯­è¨€ï¼Œå®ƒç»“åˆäº†éç¡®å®šæ€§ç¼–ç¨‹ç»“æ„ã€‚ä¸å‡è®¾å®Œå…¨ä»£ç†æ§åˆ¶æˆ–ä¾èµ–äºå¢é‡æœç´¢çš„ä¼ ç»Ÿç¨‹åºå®ç°æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬è§£å†³äº†ç¯å¢ƒéç¡®å®šæ€§å¯¹ç¨‹åºç»“æœäº§ç”Ÿé‡å¤§å½±å“çš„åœºæ™¯ã€‚æˆ‘ä»¬çš„åˆæˆé—®é¢˜æ¶‰åŠæ¨å¯¼å‡ºæˆåŠŸå®ç°ç»™å®šGologç¨‹åºçš„ç­–ç•¥ï¼ŒåŒæ—¶ç¡®ä¿åœ¨æ‰€æœ‰å¯èƒ½çš„ç¯å¢ƒè¡Œä¸ºä¸­ï¼Œä»¥æœ‰é™è½¨è¿¹ä¸Šçš„çº¿æ€§æ—¶åºé€»è¾‘ï¼ˆLTLfï¼‰è¡¨è¾¾çš„æ—¶åºè§„èŒƒå¾—åˆ°æ»¡è¶³ã€‚é€šè¿‡åˆ©ç”¨ä¸€é˜¶åŠ¨ä½œç†è®ºçš„è¡¨ç°åŠ›ä¸°å¯Œçš„ç±»åˆ«ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæœ‰é™çš„åšå¼ˆèˆå°ï¼Œè¯¥èˆå°æ¶µç›–äº†ç¨‹åºæ‰§è¡Œå¹¶è·Ÿè¸ªæ—¶åºç›®æ ‡çš„æ»¡è¶³æƒ…å†µã€‚é‡‡ç”¨åšå¼ˆè®ºçš„æ–¹æ³•æ¨å¯¼å‡ºè¿™æ ·çš„ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…·æœ‰æ— é™å¯¹è±¡å’Œéå±€éƒ¨å½±å“çš„é¢†åŸŸä¸­æ˜¯å¯è¡Œçš„ã€‚è¿™é¡¹å·¥ä½œå°†ä»£ç†ç¼–ç¨‹å’Œæ—¶åºé€»è¾‘åˆæˆè”ç³»åœ¨ä¸€èµ·ï¼Œä¸ºåœ¨éç¡®å®šæ€§ç¯å¢ƒä¸­å®ç°ç¨³å¥çš„ä»£ç†è¡Œä¸ºæä¾›äº†æ¡†æ¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.00726v2">PDF</a> Accepted at AAAIâ€™25</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†åœ¨åŸºäºæƒ…å¢ƒè®¡ç®—çš„è¯­è¨€Gologä¸­è¡¨è¾¾çš„é«˜çº§ä»£ç†ç¨‹åºçš„ç­–ç•¥åˆæˆã€‚é’ˆå¯¹ç¯å¢ƒéç¡®å®šæ€§å¯¹ç¨‹åºç»“æœäº§ç”Ÿæ˜¾è‘—å½±å“çš„æƒ…å†µï¼Œæå‡ºäº†ä¸€ç§åˆæˆç­–ç•¥ã€‚è¯¥ç­–ç•¥èƒ½å¤ŸæˆåŠŸå®ç°ç»™å®šçš„Gologç¨‹åºï¼Œå¹¶ç¡®ä¿åœ¨æ‰€æœ‰å¯èƒ½çš„ç¯å¢ƒè¡Œä¸ºä¸­æ»¡è¶³çº¿æ€§æ—¶åºé€»è¾‘å¯¹æœ‰é™è½¨è¿¹çš„æ—¶ç©ºè§„èŒƒã€‚é€šè¿‡åˆ©ç”¨ä¸€é˜¶åŠ¨ä½œç†è®ºï¼Œæ„å»ºäº†ä¸€ä¸ªæœ‰é™çš„åšå¼ˆåœºæ‰€ï¼Œè¯¥åœºæ‰€èƒ½å¤Ÿå°è£…ç¨‹åºæ‰§è¡Œå¹¶è·Ÿè¸ªæ—¶é—´ç›®æ ‡çš„æ»¡è¶³æƒ…å†µã€‚é‡‡ç”¨åšå¼ˆè®ºçš„æ–¹æ³•æ¨å¯¼å‡ºè¿™ç§ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…·æœ‰æ— é™å¯¹è±¡å’Œéå±€éƒ¨æ•ˆåº”çš„é¢†åŸŸä¸­æ˜¯å¯è¡Œçš„ã€‚è¿™é¡¹å·¥ä½œå°†ä»£ç†ç¼–ç¨‹å’Œæ—¶åºé€»è¾‘åˆæˆè”ç³»åœ¨ä¸€èµ·ï¼Œä¸ºåœ¨ä¸ç¡®å®šç¯å¢ƒä¸­å®ç°ç¨³å¥çš„ä»£ç†è¡Œä¸ºæä¾›äº†æ¡†æ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶äº†åŸºäºæƒ…å¢ƒè®¡ç®—çš„è¯­è¨€Gologä¸­çš„é«˜çº§ä»£ç†ç¨‹åºç­–ç•¥åˆæˆã€‚</li>
<li>è§£å†³äº†ç¯å¢ƒéç¡®å®šæ€§æ˜¾è‘—å½±å“ç¨‹åºç»“æœçš„é—®é¢˜ã€‚</li>
<li>æˆåŠŸå®ç°äº†ç»™å®šGologç¨‹åºï¼Œç¡®ä¿åœ¨æ‰€æœ‰å¯èƒ½çš„ç¯å¢ƒè¡Œä¸ºä¸­æ»¡è¶³çº¿æ€§æ—¶åºé€»è¾‘å¯¹æœ‰é™è½¨è¿¹çš„æ—¶ç©ºè§„èŒƒã€‚</li>
<li>åˆ©ç”¨ä¸€é˜¶åŠ¨ä½œç†è®ºæ„å»ºäº†ä¸€ä¸ªæœ‰é™çš„åšå¼ˆåœºæ‰€ï¼Œç”¨äºå°è£…ç¨‹åºæ‰§è¡Œå¹¶è·Ÿè¸ªæ—¶é—´ç›®æ ‡çš„æ»¡è¶³æƒ…å†µã€‚</li>
<li>é‡‡ç”¨åšå¼ˆè®ºæ–¹æ³•æ¨å¯¼å‡ºç­–ç•¥ã€‚</li>
<li>å®éªŒéªŒè¯äº†è¯¥ç­–ç•¥åœ¨å…·æœ‰æ— é™å¯¹è±¡å’Œéå±€éƒ¨æ•ˆåº”çš„é¢†åŸŸçš„å¯è¡Œæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.00726">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dbd247dbdbde07585226164d8d8f9f81.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="DialSim-A-Real-Time-Simulator-for-Evaluating-Long-Term-Multi-Party-Dialogue-Understanding-of-Conversational-Agents"><a href="#DialSim-A-Real-Time-Simulator-for-Evaluating-Long-Term-Multi-Party-Dialogue-Understanding-of-Conversational-Agents" class="headerlink" title="DialSim: A Real-Time Simulator for Evaluating Long-Term Multi-Party   Dialogue Understanding of Conversational Agents"></a>DialSim: A Real-Time Simulator for Evaluating Long-Term Multi-Party   Dialogue Understanding of Conversational Agents</h2><p><strong>Authors:Jiho Kim, Woosog Chay, Hyeonji Hwang, Daeun Kyung, Hyunseung Chung, Eunbyeol Cho, Yohan Jo, Edward Choi</strong></p>
<p>Recent advancements in Large Language Models (LLMs) have significantly enhanced the capabilities of conversational agents, making them applicable to various fields (e.g., education). Despite their progress, the evaluation of the agents often overlooks the complexities of real-world conversations, such as real-time interactions, multi-party dialogues, and extended contextual dependencies. To bridge this gap, we introduce DialSim, a real-time dialogue simulator. In this simulator, an agent is assigned the role of a character from popular TV shows, requiring it to respond to spontaneous questions using past dialogue information and to distinguish between known and unknown information. Key features of DialSim include assessing the agentâ€™s ability to respond within a reasonable time limit, handling long-term multi-party dialogues, and evaluating performance under randomized questioning with LongDialQA, a novel, high-quality question-answering dataset. Our experiments using DialSim reveal the strengths and weaknesses of the latest conversational agents, offering valuable insights for future advancements in conversational AI. DialSim is available at <a target="_blank" rel="noopener" href="https://dialsim.github.io/">https://dialsim.github.io/</a>. </p>
<blockquote>
<p>æœ€è¿‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥æ˜¾è‘—å¢å¼ºäº†å¯¹è¯ä»£ç†çš„èƒ½åŠ›ï¼Œä½¿å…¶é€‚ç”¨äºå„ä¸ªé¢†åŸŸï¼ˆä¾‹å¦‚æ•™è‚²ï¼‰ã€‚å°½ç®¡å–å¾—äº†è¿›å±•ï¼Œä½†å¯¹ä»£ç†çš„è¯„ä¼°å¾€å¾€å¿½ç•¥äº†ç°å®ä¸–ç•Œä¸­å¯¹è¯çš„å¤æ‚æ€§ï¼Œå¦‚å®æ—¶äº’åŠ¨ã€å¤šæ–¹å¯¹è¯å’Œæ‰©å±•çš„ä¸Šä¸‹æ–‡ä¾èµ–å…³ç³»ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†DialSimï¼Œä¸€ä¸ªå®æ—¶å¯¹è¯æ¨¡æ‹Ÿå™¨ã€‚åœ¨è¿™ä¸ªæ¨¡æ‹Ÿå™¨ä¸­ï¼Œä»£ç†è¢«åˆ†é…æ‰®æ¼”æµè¡Œç”µè§†å‰§ä¸­çš„è§’è‰²ï¼Œéœ€è¦åˆ©ç”¨è¿‡å»çš„å¯¹è¯ä¿¡æ¯å›ç­”çªå‘é—®é¢˜ï¼Œå¹¶åŒºåˆ†å·²çŸ¥å’ŒæœªçŸ¥ä¿¡æ¯ã€‚DialSimçš„å…³é”®åŠŸèƒ½åŒ…æ‹¬è¯„ä¼°ä»£ç†åœ¨åˆç†æ—¶é—´é™åˆ¶å†…ä½œå‡ºååº”çš„èƒ½åŠ›ï¼Œå¤„ç†é•¿æœŸå¤šæ–¹å¯¹è¯ï¼Œä»¥åŠä½¿ç”¨æ–°çš„é«˜è´¨é‡é—®ç­”æ•°æ®é›†LongDialQAåœ¨éšæœºæé—®ä¸‹è¯„ä¼°æ€§èƒ½ã€‚æˆ‘ä»¬ä½¿ç”¨DialSimè¿›è¡Œçš„å®éªŒæ­ç¤ºäº†æœ€æ–°å¯¹è¯ä»£ç†çš„ä¼˜ç¼ºç‚¹ï¼Œä¸ºå¯¹è¯AIçš„æœªæ¥è¿›æ­¥æä¾›äº†å®è´µè§è§£ã€‚DialSimå¯åœ¨<a target="_blank" rel="noopener" href="https://dialsim.github.io/%E8%AE%BF%E9%97%AE%E3%80%82">https://dialsim.github.io/è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.13144v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°è¿›å±•æ˜¾è‘—å¢å¼ºäº†å¯¹è¯ä»£ç†çš„èƒ½åŠ›ï¼Œä½¿å…¶é€‚ç”¨äºå¤šä¸ªé¢†åŸŸï¼ˆå¦‚æ•™è‚²ï¼‰ã€‚ç„¶è€Œï¼Œå¯¹ä»£ç†çš„è¯„ä¼°å¾€å¾€å¿½ç•¥äº†ç°å®å¯¹è¯çš„å¤æ‚æ€§ï¼Œå¦‚å®æ—¶äº’åŠ¨ã€å¤šæ–¹å¯¹è¯å’Œæ‰©å±•çš„ä¸Šä¸‹æ–‡ä¾èµ–å…³ç³»ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æ¨å‡ºäº†DialSimå®æ—¶å¯¹è¯æ¨¡æ‹Ÿå™¨ã€‚è¯¥æ¨¡æ‹Ÿå™¨è¦æ±‚ä»£ç†æ‰®æ¼”æµè¡Œç”µè§†èŠ‚ç›®ä¸­çš„è§’è‰²ï¼Œæ ¹æ®è¿‡å»çš„å¯¹è¯ä¿¡æ¯å¯¹çªå‘é—®é¢˜ä½œå‡ºå›åº”ï¼Œå¹¶åŒºåˆ†å·²çŸ¥å’ŒæœªçŸ¥ä¿¡æ¯ã€‚DialSimçš„å…³é”®åŠŸèƒ½åŒ…æ‹¬è¯„ä¼°ä»£ç†åœ¨åˆç†æ—¶é—´é™åˆ¶å†…ä½œå‡ºå›åº”çš„èƒ½åŠ›ã€å¤„ç†é•¿æœŸå¤šæ–¹å¯¹è¯çš„èƒ½åŠ›ä»¥åŠä½¿ç”¨LongDialQAè¿™ä¸€æ–°å‹é«˜è´¨é‡é—®ç­”æ•°æ®é›†åœ¨éšæœºæé—®ä¸‹è¯„ä¼°è¡¨ç°çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„å®éªŒæ­ç¤ºäº†æœ€æ–°å¯¹è¯ä»£ç†çš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿ï¼Œä¸ºå¯¹è¯AIçš„æœªæ¥å‘å±•æä¾›äº†å®è´µè§è§£ã€‚DialSimå¯è®¿é—®ç½‘ç«™ä¸ºï¼š<a target="_blank" rel="noopener" href="https://dialsim.github.io/%E3%80%82">https://dialsim.github.io/ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥å¢å¼ºäº†å¯¹è¯ä»£ç†çš„èƒ½åŠ›ï¼Œæ¨åŠ¨å…¶åœ¨å¤šé¢†åŸŸåº”ç”¨ã€‚</li>
<li>ç°æœ‰çš„ä»£ç†è¯„ä¼°æ–¹æ³•å¾€å¾€å¿½ç•¥ç°å®å¯¹è¯çš„å¤æ‚æ€§ï¼Œå¦‚å®æ—¶äº’åŠ¨ã€å¤šæ–¹å¯¹è¯å’Œä¸Šä¸‹æ–‡ä¾èµ–ã€‚</li>
<li>DialSimæ˜¯ä¸€ä¸ªå®æ—¶å¯¹è¯æ¨¡æ‹Ÿå™¨ï¼Œæ—¨åœ¨å¼¥è¡¥ä¸Šè¿°å·®è·ã€‚</li>
<li>DialSimè¦æ±‚ä»£ç†æ‰®æ¼”æµè¡Œç”µè§†èŠ‚ç›®ä¸­çš„è§’è‰²ï¼Œå¹¶åŸºäºè¿‡å»å¯¹è¯ä¿¡æ¯å›åº”çªå‘é—®é¢˜ã€‚</li>
<li>DialSimå…·å¤‡è¯„ä¼°ä»£ç†åœ¨ç‰¹å®šæ¡ä»¶ä¸‹çš„èƒ½åŠ›ï¼Œå¦‚å“åº”æ—¶é—´ã€å¤„ç†å¤šæ–¹å¯¹è¯å’Œéšæœºæé—®ä¸‹çš„è¡¨ç°ã€‚</li>
<li>é€šè¿‡ä½¿ç”¨DialSimè¿›è¡Œçš„å®éªŒæ­ç¤ºäº†å¯¹è¯ä»£ç†çš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.13144">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8c584e38d7012780efb32b44fea140b0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-63d65a3a4162150e3e7d6f1345f8dc41.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-379e21ea0c54cf9485a322e0008379cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7a61eea18be2c4241dbae6e672909886.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-45d7f7754df33406b50d25bff52bf58d.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="LLM-Based-Multi-Agent-Systems-for-Software-Engineering-Literature-Review-Vision-and-the-Road-Ahead"><a href="#LLM-Based-Multi-Agent-Systems-for-Software-Engineering-Literature-Review-Vision-and-the-Road-Ahead" class="headerlink" title="LLM-Based Multi-Agent Systems for Software Engineering: Literature   Review, Vision and the Road Ahead"></a>LLM-Based Multi-Agent Systems for Software Engineering: Literature   Review, Vision and the Road Ahead</h2><p><strong>Authors:Junda He, Christoph Treude, David Lo</strong></p>
<p>Integrating Large Language Models (LLMs) into autonomous agents marks a significant shift in the research landscape by offering cognitive abilities that are competitive with human planning and reasoning. This paper explores the transformative potential of integrating Large Language Models into Multi-Agent (LMA) systems for addressing complex challenges in software engineering (SE). By leveraging the collaborative and specialized abilities of multiple agents, LMA systems enable autonomous problem-solving, improve robustness, and provide scalable solutions for managing the complexity of real-world software projects. In this paper, we conduct a systematic review of recent primary studies to map the current landscape of LMA applications across various stages of the software development lifecycle (SDLC). To illustrate current capabilities and limitations, we perform two case studies to demonstrate the effectiveness of state-of-the-art LMA frameworks. Additionally, we identify critical research gaps and propose a comprehensive research agenda focused on enhancing individual agent capabilities and optimizing agent synergy. Our work outlines a forward-looking vision for developing fully autonomous, scalable, and trustworthy LMA systems, laying the foundation for the evolution of Software Engineering 2.0. </p>
<blockquote>
<p>å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é›†æˆåˆ°è‡ªä¸»ä»£ç†ä¸­ï¼Œä¸ºç ”ç©¶é¢†åŸŸå¸¦æ¥äº†æ˜¾è‘—çš„å˜åŒ–ï¼Œæä¾›äº†ä¸äººç±»è§„åˆ’å’Œæ¨ç†ç›¸ç«äº‰çš„è®¤çŸ¥èƒ½åŠ›ã€‚æœ¬æ–‡æ¢è®¨äº†å°†å¤§å‹è¯­è¨€æ¨¡å‹é›†æˆåˆ°å¤šä»£ç†ï¼ˆLMAï¼‰ç³»ç»Ÿä¸­ï¼Œä»¥è§£å†³è½¯ä»¶å·¥ç¨‹ï¼ˆSEï¼‰ä¸­çš„å¤æ‚æŒ‘æˆ˜çš„å˜é©æ½œåŠ›ã€‚é€šè¿‡åˆ©ç”¨å¤šä¸ªä»£ç†çš„åä½œå’Œä¸“é—¨èƒ½åŠ›ï¼ŒLMAç³»ç»Ÿèƒ½å¤Ÿå®ç°è‡ªä¸»è§£å†³é—®é¢˜ï¼Œæé«˜ç¨³å¥æ€§ï¼Œå¹¶æä¾›ç®¡ç†çœŸå®ä¸–ç•Œè½¯ä»¶é¡¹ç›®å¤æ‚æ€§çš„å¯æ‰©å±•è§£å†³æ–¹æ¡ˆã€‚æœ¬æ–‡å°†å¯¹æœ€è¿‘çš„ä¸»è¦ç ”ç©¶è¿›è¡Œç³»ç»Ÿæ€§çš„å›é¡¾ï¼Œä»¥æ˜ å°„è½¯ä»¶å¼€å‘ç”Ÿå‘½å‘¨æœŸï¼ˆSDLCï¼‰å„ä¸ªé˜¶æ®µä¸­LMAåº”ç”¨çš„å½“å‰æ ¼å±€ã€‚ä¸ºäº†è¯´æ˜å½“å‰çš„èƒ½åŠ›å’Œå±€é™æ€§ï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä¸¤ä¸ªæ¡ˆä¾‹ç ”ç©¶ï¼Œä»¥å±•ç¤ºæœ€æ–°LMAæ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ç¡®å®šäº†å…³é”®çš„ç ”ç©¶ç©ºç™½ï¼Œå¹¶æå‡ºäº†ä»¥å¢å¼ºå•ä¸ªä»£ç†èƒ½åŠ›å’Œä¼˜åŒ–ä»£ç†ååŒä¸ºé‡ç‚¹çš„ç»¼åˆç ”ç©¶è®®ç¨‹ã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ºå¼€å‘å®Œå…¨è‡ªä¸»ã€å¯æ‰©å±•å’Œå¯ä¿¡èµ–çš„LMAç³»ç»Ÿæç»˜äº†ä¸€ä¸ªå‰ç»æ€§çš„æ„¿æ™¯ï¼Œä¸ºè½¯ä»¶å·¥ç¨‹2.0çš„æ¼”å˜å¥ å®šäº†åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.04834v3">PDF</a> TOSEM 2030 Special Issue</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰èå…¥è‡ªä¸»ä»£ç†æ ‡å¿—ç€ç ”ç©¶é¢†åŸŸçš„é‡å¤§è½¬å˜ï¼Œä¸ºè½¯ä»¶å·¥ç¨‹ä¸­è§£å†³å¤æ‚æŒ‘æˆ˜æä¾›äº†ä¸äººç±»è§„åˆ’ã€æ¨ç†ç›¸ç«äº‰çš„è®¤çŸ¥èƒ½åŠ›ã€‚æœ¬æ–‡æ¢è®¨äº†å°†å¤§å‹è¯­è¨€æ¨¡å‹èå…¥å¤šä»£ç†ï¼ˆLMAï¼‰ç³»ç»Ÿçš„å˜é©æ½œåŠ›ï¼Œé€šè¿‡å¤šä¸ªä»£ç†çš„åä½œå’Œç‰¹æ®Šèƒ½åŠ›ï¼ŒLMAç³»ç»Ÿå¯å®ç°è‡ªä¸»è§£å†³é—®é¢˜ã€æé«˜ç¨³å¥æ€§ï¼Œå¹¶ä¸ºçœŸå®ä¸–ç•Œè½¯ä»¶é¡¹ç›®çš„å¤æ‚æ€§ç®¡ç†æä¾›å¯æ‰©å±•è§£å†³æ–¹æ¡ˆã€‚æœ¬æ–‡è¿›è¡Œè¿‘æœŸä¸»è¦ç ”ç©¶çš„ç³»ç»Ÿç»¼è¿°ï¼Œä»¥äº†è§£LMAåº”ç”¨åœ¨è½¯ä»¶å¼€å‘ç”Ÿå‘½å‘¨æœŸï¼ˆSDLCï¼‰å„é˜¶æ®µä¸­çš„ç°çŠ¶ã€‚é€šè¿‡ä¸¤ä¸ªæ¡ˆä¾‹ç ”ç©¶å±•ç¤ºæœ€å…ˆè¿›LMAæ¡†æ¶çš„æœ‰æ•ˆæ€§å¹¶å‘ç°é‡è¦ç ”ç©¶å·®è·ï¼Œæå‡ºä¼˜åŒ–ä¸ªä½“ä»£ç†èƒ½åŠ›å’Œä»£ç†ååŒçš„å…¨é¢ç ”ç©¶è®®ç¨‹ã€‚æœ¬æ–‡å·¥ä½œä¸ºæœªæ¥è½¯ä»¶å·¥ç¨‹çš„è‡ªä¸»åŒ–ã€å¯æ‰©å±•æ€§å’Œå¯ä¿¡åº¦å‘å±•å¥ å®šäº†åŸºçŸ³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰èå…¥è‡ªä¸»ä»£ç†ä¸ºè½¯ä»¶å·¥ç¨‹ä¸­è§£å†³å¤æ‚æŒ‘æˆ˜æä¾›äº†ä¸äººç±»è§„åˆ’ã€æ¨ç†èƒ½åŠ›ç›¸å½“çš„è®¤çŸ¥å·¥å…·ã€‚</li>
<li>LMAç³»ç»Ÿé€šè¿‡å¤šä»£ç†çš„åä½œå’Œç‰¹æ®Šèƒ½åŠ›å®ç°è‡ªä¸»è§£å†³é—®é¢˜ï¼Œæé«˜ç¨³å¥æ€§å¹¶åº”å¯¹çœŸå®ä¸–ç•Œè½¯ä»¶é¡¹ç›®çš„å¤æ‚æ€§ç®¡ç†éœ€æ±‚ã€‚</li>
<li>ç³»ç»Ÿç»¼è¿°å±•ç¤ºäº†LMAåœ¨è½¯ä»¶å¼€å‘ç”Ÿå‘½å‘¨æœŸä¸åŒé˜¶æ®µçš„ç°çŠ¶ï¼Œé€šè¿‡æ¡ˆä¾‹ç ”ç©¶è¯æ˜äº†æœ€å…ˆè¿›LMAæ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>å‘ç°å½“å‰ç ”ç©¶çš„é‡å¤§å·®è·å¹¶å‘¼åå¢å¼ºä¸ªä½“ä»£ç†èƒ½åŠ›ä¸ä¼˜åŒ–ä»£ç†ååŒçš„ç ”ç©¶è®®ç¨‹ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.04834">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e7fab5bfcd969e38795c0e11089b5ff0.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="ExpeL-LLM-Agents-Are-Experiential-Learners"><a href="#ExpeL-LLM-Agents-Are-Experiential-Learners" class="headerlink" title="ExpeL: LLM Agents Are Experiential Learners"></a>ExpeL: LLM Agents Are Experiential Learners</h2><p><strong>Authors:Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, Gao Huang</strong></p>
<p>The recent surge in research interest in applying large language models (LLMs) to decision-making tasks has flourished by leveraging the extensive world knowledge embedded in LLMs. While there is a growing demand to tailor LLMs for custom decision-making tasks, finetuning them for specific tasks is resource-intensive and may diminish the modelâ€™s generalization capabilities. Moreover, state-of-the-art language models like GPT-4 and Claude are primarily accessible through API calls, with their parametric weights remaining proprietary and unavailable to the public. This scenario emphasizes the growing need for new methodologies that allow learning from agent experiences without requiring parametric updates. To address these problems, we introduce the Experiential Learning (ExpeL) agent. Our agent autonomously gathers experiences and extracts knowledge using natural language from a collection of training tasks. At inference, the agent recalls its extracted insights and past experiences to make informed decisions. Our empirical results highlight the robust learning efficacy of the ExpeL agent, indicating a consistent enhancement in its performance as it accumulates experiences. We further explore the emerging capabilities and transfer learning potential of the ExpeL agent through qualitative observations and additional experiments. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œå¯¹äºå°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨äºå†³ç­–åˆ¶å®šä»»åŠ¡çš„ç ”ç©¶å…´è¶£æ¿€å¢ï¼Œè¿™å¾—ç›ŠäºLLMä¸­åµŒå…¥çš„ä¸°å¯Œçš„ä¸–ç•ŒçŸ¥è¯†ã€‚è™½ç„¶å¯¹é’ˆå¯¹ç‰¹å®šå†³ç­–åˆ¶å®šä»»åŠ¡å®šåˆ¶LLMçš„éœ€æ±‚ä¸æ–­å¢é•¿ï¼Œä½†å¯¹å®ƒä»¬è¿›è¡Œå¾®è°ƒæ˜¯èµ„æºå¯†é›†å‹çš„ï¼Œå¹¶ä¸”å¯èƒ½ä¼šé™ä½æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒåƒGPT-4å’ŒClaudeç­‰æœ€å…ˆè¿›çš„è¯­è¨€æ¨¡å‹ä¸»è¦é€šè¿‡APIè°ƒç”¨è®¿é—®ï¼Œå…¶å‚æ•°æƒé‡ä¿æŒä¸“æœ‰ä¸”ä¸å¯¹å…¬ä¼—å¼€æ”¾ã€‚è¿™ä¸€æƒ…æ™¯å¼ºè°ƒäº†å¯¹æ–°æ–¹æ³•çš„éœ€æ±‚ä¸æ–­å¢é•¿ï¼Œè¿™äº›æ–¹æ³•å…è®¸ä»ä»£ç†ç»éªŒä¸­å­¦ä¹ è€Œæ— éœ€è¿›è¡Œå‚æ•°æ›´æ–°ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä½“éªŒå¼å­¦ä¹ ï¼ˆExpeLï¼‰ä»£ç†ã€‚æˆ‘ä»¬çš„ä»£ç†èƒ½å¤Ÿè‡ªä¸»æ”¶é›†ç»éªŒå¹¶ä½¿ç”¨è‡ªç„¶è¯­è¨€ä»ä¸€ç³»åˆ—è®­ç»ƒä»»åŠ¡ä¸­æå–çŸ¥è¯†ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œä»£ç†ä¼šå›æƒ³èµ·å…¶æå–çš„è§è§£å’Œè¿‡å»çš„ç»éªŒæ¥åšå‡ºå†³ç­–ã€‚æˆ‘ä»¬çš„å®è¯ç»“æœçªå‡ºäº†ExpeLä»£ç†çš„ç¨³å¥å­¦ä¹ æ•ˆç›Šï¼Œæ˜¾ç¤ºéšç€ç»éªŒçš„ç§¯ç´¯ï¼Œå…¶æ€§èƒ½æŒç»­æé«˜ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡å®šæ€§è§‚å¯Ÿå’Œé¢å¤–å®éªŒæ¢ç´¢äº†ExpeLä»£ç†çš„æ–°å…´èƒ½åŠ›å’Œè¿ç§»å­¦ä¹ çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10144v3">PDF</a> Accepted by the 38th Annual AAAI Conference on Artificial   Intelligence (AAAI-24)</p>
<p><strong>Summary</strong></p>
<p>å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å†³ç­–ä»»åŠ¡ä¸­çš„åº”ç”¨è¿‘æœŸå—åˆ°å¹¿æ³›å…³æ³¨ï¼Œå€ŸåŠ©LLMsä¸­åµŒå…¥çš„ä¸°å¯Œä¸–ç•ŒçŸ¥è¯†ï¼Œç›¸å…³ç ”ç©¶è“¬å‹ƒå‘å±•ã€‚ç„¶è€Œï¼Œé’ˆå¯¹ç‰¹å®šä»»åŠ¡å®šåˆ¶LLMsçš„éœ€æ±‚æ—¥ç›Šå¢é•¿ï¼Œä½†å¯¹å…¶è¿›è¡Œå¾®è°ƒéœ€è¦å¤§é‡èµ„æºï¼Œå¹¶å¯èƒ½é™ä½æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸»æµè¯­è¨€æ¨¡å‹å¦‚GPT-4å’ŒClaudeä¸»è¦é€šè¿‡APIè°ƒç”¨è®¿é—®ï¼Œå…¶å‚æ•°æƒé‡ä¿æŒä¸“æœ‰ï¼Œæ— æ³•å…¬å¼€ã€‚åœ¨æ­¤èƒŒæ™¯ä¸‹ï¼Œå¼ºè°ƒäº†å¯¹æ–°æ–¹æ³•è®ºçš„éœ€æ±‚ï¼Œè¯¥æ–¹æ³•è®ºéœ€è¦èƒ½å¤Ÿåœ¨ä¸è¦æ±‚è¿›è¡Œå‚æ•°æ›´æ–°çš„æƒ…å†µä¸‹ä»ä»£ç†ç»éªŒä¸­å­¦ä¹ ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†Experiential Learningï¼ˆExpeLï¼‰ä»£ç†ã€‚è¯¥ä»£ç†èƒ½å¤Ÿè‡ªä¸»æ”¶é›†ç»éªŒï¼Œå¹¶åˆ©ç”¨è‡ªç„¶è¯­è¨€ä»å¤§é‡è®­ç»ƒä»»åŠ¡ä¸­æå–çŸ¥è¯†ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œä»£ç†ä¼šå›é¡¾å…¶æå–çš„è§è§£å’Œè¿‡å»çš„ç»éªŒä»¥åšå‡ºæ˜æ™ºçš„å†³ç­–ã€‚æˆ‘ä»¬çš„å®è¯ç»“æœçªå‡ºäº†ExpeLä»£ç†çš„å¼ºå¤§å­¦ä¹ æ•ˆèƒ½ï¼Œæ˜¾ç¤ºéšç€ç»éªŒçš„ç§¯ç´¯ï¼Œå…¶æ€§èƒ½æŒç»­æé«˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å†³ç­–ä»»åŠ¡ä¸­çš„åº”ç”¨å—åˆ°å…³æ³¨ï¼Œä½†å®šåˆ¶LLMsçš„å¾®è°ƒéœ€è¦å¤§é‡èµ„æºå’Œå¯èƒ½å½±å“æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>å½“å‰ä¸»æµè¯­è¨€æ¨¡å‹å¦‚GPT-4å’ŒClaudeé€šè¿‡APIè°ƒç”¨è®¿é—®ï¼Œå‚æ•°æƒé‡ä¿æŒä¸“æœ‰ã€‚</li>
<li>éœ€è¦æ–°çš„æ–¹æ³•è®ºï¼Œèƒ½å¤Ÿåœ¨ä¸æ›´æ–°å‚æ•°çš„æƒ…å†µä¸‹ä»ä»£ç†ç»éªŒä¸­å­¦ä¹ ã€‚</li>
<li>Experiential Learningï¼ˆExpeLï¼‰ä»£ç†èƒ½å¤Ÿè‡ªä¸»æ”¶é›†ç»éªŒå¹¶ä»è®­ç»ƒä»»åŠ¡ä¸­æå–çŸ¥è¯†ã€‚</li>
<li>ExpeLä»£ç†åˆ©ç”¨è‡ªç„¶è¯­è¨€å’Œè¿‡å»çš„ç»éªŒæ¥åšå‡ºå†³ç­–ã€‚</li>
<li>å®è¯ç»“æœæ˜¾ç¤ºExpeLä»£ç†å…·æœ‰å¼ºå¤§çš„å­¦ä¹ æ•ˆèƒ½ï¼Œéšç€ç»éªŒçš„ç§¯ç´¯ï¼Œæ€§èƒ½æŒç»­æé«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2308.10144">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e3a6392c12db5e50ec1317060499316d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-397cfa93ed1d77ad62be41ef8e4f341a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f2f7200cdda4bad7117b6627e563efcc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-707db1600814640234730b3437f2a19a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7e083a5b67d99bab4426f444490ee70f.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-24/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-24/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-24/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-f6f173a6496bfc3db3faf3a0df7918b5.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-24  MR-GDINO Efficient Open-World Continual Object Detection
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-24/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-be79195cff13bb52b890b45f510ba140.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-24  HoVLE Unleashing the Power of Monolithic Vision-Language Models with   Holistic Vision-Language Embedding
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">11880.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
