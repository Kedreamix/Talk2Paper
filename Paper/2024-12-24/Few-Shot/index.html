<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-24  MR-GDINO Efficient Open-World Continual Object Detection">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-f6f173a6496bfc3db3faf3a0df7918b5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-24
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    30 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-12-24-æ›´æ–°"><a href="#2024-12-24-æ›´æ–°" class="headerlink" title="2024-12-24 æ›´æ–°"></a>2024-12-24 æ›´æ–°</h1><h2 id="MR-GDINO-Efficient-Open-World-Continual-Object-Detection"><a href="#MR-GDINO-Efficient-Open-World-Continual-Object-Detection" class="headerlink" title="MR-GDINO: Efficient Open-World Continual Object Detection"></a>MR-GDINO: Efficient Open-World Continual Object Detection</h2><p><strong>Authors:Bowen Dong, Zitong Huang, Guanglei Yang, Lei Zhang, Wangmeng Zuo</strong></p>
<p>Open-world (OW) recognition and detection models show strong zero- and few-shot adaptation abilities, inspiring their use as initializations in continual learning methods to improve performance. Despite promising results on seen classes, such OW abilities on unseen classes are largely degenerated due to catastrophic forgetting. To tackle this challenge, we propose an open-world continual object detection task, requiring detectors to generalize to old, new, and unseen categories in continual learning scenarios. Based on this task, we present a challenging yet practical OW-COD benchmark to assess detection abilities. The goal is to motivate OW detectors to simultaneously preserve learned classes, adapt to new classes, and maintain open-world capabilities under few-shot adaptations. To mitigate forgetting in unseen categories, we propose MR-GDINO, a strong, efficient and scalable baseline via memory and retrieval mechanisms within a highly scalable memory pool. Experimental results show that existing continual detectors suffer from severe forgetting for both seen and unseen categories. In contrast, MR-GDINO largely mitigates forgetting with only 0.1% activated extra parameters, achieving state-of-the-art performance for old, new, and unseen categories. </p>
<blockquote>
<p>å¼€æ”¾ä¸–ç•Œï¼ˆOWï¼‰è¯†åˆ«å’Œæ£€æµ‹æ¨¡å‹è¡¨ç°å‡ºå¼ºå¤§çš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬é€‚åº”åŠ›ï¼Œè¿™æ¿€å‘äº†å®ƒä»¬ä½œä¸ºåˆå§‹åŒ–åœ¨æŒç»­å­¦ä¹ æ–¹æ³•ä¸­çš„ä½¿ç”¨ï¼Œä»¥æé«˜æ€§èƒ½ã€‚å°½ç®¡åœ¨å·²çŸ¥ç±»åˆ«ä¸Šå–å¾—äº†æœ‰å‰æ™¯çš„ç»“æœï¼Œä½†ç”±äºç¾éš¾æ€§é—å¿˜ï¼Œè¿™ç±»OWæ¨¡å‹åœ¨æœªçŸ¥ç±»åˆ«ä¸Šçš„èƒ½åŠ›å¤§å¤§é€€åŒ–ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¼€æ”¾ä¸–ç•ŒæŒç»­ç›®æ ‡æ£€æµ‹ä»»åŠ¡ï¼Œè¦æ±‚æ£€æµ‹å™¨åœ¨æŒç»­å­¦ä¹ åœºæ™¯ä¸­æ¨å¹¿åˆ°æ—§ã€æ–°å’ŒæœªçŸ¥ç±»åˆ«ã€‚åŸºäºè¿™é¡¹ä»»åŠ¡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§ä½†å®ç”¨çš„OW-CODåŸºå‡†æµ‹è¯•æ¥è¯„ä¼°æ£€æµ‹èƒ½åŠ›ã€‚ç›®æ ‡æ˜¯æ¿€åŠ±OWæ£€æµ‹å™¨åœ¨ä¿ç•™å·²å­¦ç±»åˆ«ã€é€‚åº”æ–°ç±»åˆ«å’Œç»´æŒå¼€æ”¾ä¸–ç•Œèƒ½åŠ›çš„åŒæ—¶ï¼Œè¿›è¡Œå°‘æ ·æœ¬é€‚åº”ã€‚ä¸ºäº†ç¼“è§£å¯¹æœªçŸ¥ç±»åˆ«çš„é—å¿˜ï¼Œæˆ‘ä»¬æå‡ºäº†MR-GDINOï¼Œè¿™æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ã€é«˜æ•ˆçš„ã€å¯æ‰©å±•çš„åŸºçº¿ï¼Œé€šè¿‡å†…å­˜å’Œæ£€ç´¢æœºåˆ¶åœ¨ä¸€ä¸ªé«˜åº¦å¯æ‰©å±•çš„å†…å­˜æ± å†…å®ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰çš„æŒç»­æ£€æµ‹å™¨åœ¨å·²çŸ¥å’ŒæœªçŸ¥ç±»åˆ«ä¸Šéƒ½å­˜åœ¨ä¸¥é‡çš„é—å¿˜é—®é¢˜ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒMR-GDINOåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šç¼“è§£äº†é—å¿˜é—®é¢˜ï¼Œåªéœ€æ¿€æ´»0.1%çš„é¢å¤–å‚æ•°ï¼Œå³å¯å®ç°å¯¹æ—§ã€æ–°å’ŒæœªçŸ¥ç±»åˆ«çš„æœ€ä½³æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15979v1">PDF</a> Website: <a target="_blank" rel="noopener" href="https://m1saka.moe/owcod/">https://m1saka.moe/owcod/</a> . Code is available at:   <a target="_blank" rel="noopener" href="https://github.com/DongSky/MR-GDINO">https://github.com/DongSky/MR-GDINO</a></p>
<p><strong>Summary</strong></p>
<p>å¼€æ”¾ä¸–ç•Œï¼ˆOWï¼‰è¯†åˆ«ä¸æ£€æµ‹æ¨¡å‹åœ¨é›¶æ¬¡å’Œå°‘æ¬¡é€‚åº”æ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œåœ¨æŒç»­å­¦ä¹ æ–¹æ³•ä¸­ä½œä¸ºåˆå§‹åŒ–ä½¿ç”¨æœ‰åŠ©äºæé«˜æ€§èƒ½ã€‚ç„¶è€Œï¼Œå¯¹äºæœªè§ç±»åˆ«ï¼Œè¿™ç§èƒ½åŠ›ä¼šå¤§å¤§é€€åŒ–ï¼Œé¢ä¸´ç¾éš¾æ€§é—å¿˜çš„é—®é¢˜ã€‚ä¸ºè§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†å¼€æ”¾ä¸–ç•ŒæŒç»­å¯¹è±¡æ£€æµ‹ä»»åŠ¡ï¼Œè¦æ±‚æ£€æµ‹å™¨åœ¨æŒç»­å­¦ä¹ åœºæ™¯ä¸­æ³›åŒ–åˆ°æ—§ã€æ–°å’Œæœªè§ç±»åˆ«ã€‚åŸºäºæ­¤ä»»åŠ¡ï¼Œæœ¬æ–‡æ„å»ºäº†ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§ä¸”å®ç”¨çš„OW-CODåŸºå‡†æµ‹è¯•é›†ï¼Œä»¥è¯„ä¼°æ£€æµ‹èƒ½åŠ›ã€‚ç›®æ ‡æ˜¯æ¿€åŠ±OWæ£€æµ‹å™¨åœ¨å°‘æ¬¡é€‚åº”çš„åŒæ—¶ä¿ç•™å·²å­¦ç±»åˆ«ã€é€‚åº”æ–°ç±»åˆ«å¹¶ä¿æŒå¼€æ”¾ä¸–ç•Œçš„èƒ½åŠ›ã€‚ä¸ºç¼“è§£æœªè§ç±»åˆ«çš„é—å¿˜é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†MR-GDINOï¼Œé€šè¿‡å†…å­˜å’Œæ£€ç´¢æœºåˆ¶æ„å»ºäº†ä¸€ä¸ªé«˜åº¦å¯æ‰©å±•çš„å†…å­˜æ± ä¸­çš„å¼ºæ•ˆã€é«˜æ•ˆä¸”å¯æ‰©å±•çš„åŸºçº¿ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰çš„æŒç»­æ£€æµ‹å™¨åœ¨æ—§ç±»åˆ«å’Œæ–°ç±»åˆ«ä¸Šéƒ½å­˜åœ¨ä¸¥é‡çš„é—å¿˜é—®é¢˜ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒMR-GDINOä»…æ¿€æ´»é¢å¤–çš„0.1%å‚æ•°å³å¯å¤§å¤§ç¼“è§£é—å¿˜é—®é¢˜ï¼Œå¹¶åœ¨æ—§ã€æ–°å’Œæœªè§ç±»åˆ«ä¸Šå®ç°æœ€ä½³æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼€æ”¾ä¸–ç•Œè¯†åˆ«ä¸æ£€æµ‹æ¨¡å‹å…·å¤‡å¼ºå¤§çš„é›¶æ¬¡å’Œå°‘æ¬¡é€‚åº”èƒ½åŠ›ï¼Œé€‚ç”¨äºæŒç»­å­¦ä¹ åœºæ™¯ã€‚</li>
<li>åœ¨æŒç»­å­¦ä¹ ç¯å¢ƒä¸­ï¼Œæ¨¡å‹å¯¹æœªè§ç±»åˆ«çš„é€‚åº”èƒ½åŠ›é€€åŒ–ï¼Œé¢ä¸´ç¾éš¾æ€§é—å¿˜é—®é¢˜ã€‚</li>
<li>æå‡ºå¼€æ”¾ä¸–ç•ŒæŒç»­å¯¹è±¡æ£€æµ‹ä»»åŠ¡ï¼Œè¦æ±‚æ¨¡å‹åœ¨æŒç»­å­¦ä¹ åœºæ™¯ä¸­æ³›åŒ–åˆ°æ—§ã€æ–°å’Œæœªè§ç±»åˆ«ã€‚</li>
<li>æ„å»ºOW-CODåŸºå‡†æµ‹è¯•é›†ä»¥è¯„ä¼°æ£€æµ‹æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>MR-GDINOé€šè¿‡å†…å­˜å’Œæ£€ç´¢æœºåˆ¶æå‡ºä¸€ç§å¼ºæ•ˆã€é«˜æ•ˆä¸”å¯æ‰©å±•çš„åŸºçº¿è§£å†³æ–¹æ¡ˆã€‚</li>
<li>ç°æœ‰æŒç»­æ£€æµ‹å™¨åœ¨æ—§ç±»åˆ«å’Œæ–°ç±»åˆ«ä¸Šè¡¨ç°ä¸ä½³ï¼Œå­˜åœ¨ä¸¥é‡çš„é—å¿˜é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15979">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c7655ea5bfe2c7edf5cda28a810297e6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c67f270d92a0b582e0f8224b537b87e4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5f259829d5f680f4587202efbf032300.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-045237e83a4e9cb7eb47acc5651e9fa0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Enhancing-Generalized-Few-Shot-Semantic-Segmentation-via-Effective-Knowledge-Transfer"><a href="#Enhancing-Generalized-Few-Shot-Semantic-Segmentation-via-Effective-Knowledge-Transfer" class="headerlink" title="Enhancing Generalized Few-Shot Semantic Segmentation via Effective   Knowledge Transfer"></a>Enhancing Generalized Few-Shot Semantic Segmentation via Effective   Knowledge Transfer</h2><p><strong>Authors:Xinyue Chen, Miaojing Shi, Zijian Zhou, Lianghua He, Sophia Tsoka</strong></p>
<p>Generalized few-shot semantic segmentation (GFSS) aims to segment objects of both base and novel classes, using sufficient samples of base classes and few samples of novel classes. Representative GFSS approaches typically employ a two-phase training scheme, involving base class pre-training followed by novel class fine-tuning, to learn the classifiers for base and novel classes respectively. Nevertheless, distribution gap exists between base and novel classes in this process. To narrow this gap, we exploit effective knowledge transfer from base to novel classes. First, a novel prototype modulation module is designed to modulate novel class prototypes by exploiting the correlations between base and novel classes. Second, a novel classifier calibration module is proposed to calibrate the weight distribution of the novel classifier according to that of the base classifier. Furthermore, existing GFSS approaches suffer from a lack of contextual information for novel classes due to their limited samples, we thereby introduce a context consistency learning scheme to transfer the contextual knowledge from base to novel classes. Extensive experiments on PASCAL-5$^i$ and COCO-20$^i$ demonstrate that our approach significantly enhances the state of the art in the GFSS setting. The code is available at: <a target="_blank" rel="noopener" href="https://github.com/HHHHedy/GFSS-EKT">https://github.com/HHHHedy/GFSS-EKT</a>. </p>
<blockquote>
<p>å¹¿ä¹‰å°‘æ ·æœ¬è¯­ä¹‰åˆ†å‰²ï¼ˆGFSSï¼‰æ—¨åœ¨åˆ©ç”¨åŸºç¡€ç±»åˆ«çš„å……è¶³æ ·æœ¬å’Œå°‘é‡æ–°ç±»åˆ«çš„æ ·æœ¬ï¼Œå¯¹åŸºç¡€ç±»åˆ«å’Œæ–°ç±»åˆ«çš„å¯¹è±¡è¿›è¡Œåˆ†å‰²ã€‚ä»£è¡¨æ€§çš„GFSSæ–¹æ³•é€šå¸¸é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæ–¹æ¡ˆï¼ŒåŒ…æ‹¬åŸºç¡€ç±»åˆ«é¢„è®­ç»ƒå’Œæ–°ç±»åˆ«å¾®è°ƒï¼Œä»¥åˆ†åˆ«å­¦ä¹ åŸºç¡€ç±»åˆ«å’Œæ–°ç±»åˆ«çš„åˆ†ç±»å™¨ã€‚ç„¶è€Œï¼Œåœ¨æ­¤è¿‡ç¨‹ä¸­ï¼ŒåŸºç¡€ç±»åˆ«å’Œæ–°ç±»åˆ«ä¹‹é—´å­˜åœ¨åˆ†å¸ƒå·®è·ã€‚ä¸ºäº†ç¼©å°è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬ä»åŸºç¡€ç±»åˆ«åˆ°æ–°ç±»åˆ«å®ç°äº†æœ‰æ•ˆçš„çŸ¥è¯†è½¬ç§»ã€‚é¦–å…ˆï¼Œè®¾è®¡äº†ä¸€ä¸ªæ–°å‹åŸå‹è°ƒåˆ¶æ¨¡å—ï¼Œé€šè¿‡åˆ©ç”¨åŸºç¡€ç±»åˆ«å’Œæ–°ç±»åˆ«ä¹‹é—´çš„ç›¸å…³æ€§æ¥è°ƒèŠ‚æ–°ç±»åˆ«åŸå‹ã€‚å…¶æ¬¡ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„åˆ†ç±»å™¨æ ¡å‡†æ¨¡å—ï¼Œæ ¹æ®åŸºç¡€åˆ†ç±»å™¨çš„æƒé‡åˆ†å¸ƒæ ¡å‡†æ–°åˆ†ç±»å™¨çš„æƒé‡åˆ†å¸ƒã€‚æ­¤å¤–ï¼Œç”±äºç°æœ‰GFSSæ–¹æ³•æ–°ç±»åˆ«æ ·æœ¬æœ‰é™ï¼Œç¼ºä¹ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå› æ­¤æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ä¸Šä¸‹æ–‡ä¸€è‡´æ€§å­¦ä¹ æ–¹æ¡ˆï¼Œå°†ä¸Šä¸‹æ–‡çŸ¥è¯†ä»åŸºç¡€ç±»åˆ«è½¬ç§»åˆ°æ–°ç±»åˆ«ã€‚åœ¨PASCAL-5iå’ŒCOCO-20iä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨GFSSè®¾ç½®ä¸­æ˜¾è‘—æé«˜äº†ç°æœ‰æŠ€æœ¯æ°´å¹³ã€‚ä»£ç å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/HHHHedy/GFSS-EKT%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/HHHHedy/GFSS-EKTè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15835v1">PDF</a> Accepted to AAAI 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å¹¿ä¹‰å°æ ·æœ¬è¯­ä¹‰åˆ†å‰²ï¼ˆGFSSï¼‰çš„ç›®æ ‡å’Œæ–¹æ³•ã€‚GFSSæ—¨åœ¨åˆ©ç”¨åŸºç¡€ç±»çš„å……è¶³æ ·æœ¬å’Œæ–°é¢–ç±»çš„å°‘é‡æ ·æœ¬å¯¹åŸºç¡€ç±»å’Œæ–°é¢–ç±»çš„å¯¹è±¡è¿›è¡Œåˆ†å‰²ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„çŸ¥è¯†è½¬ç§»æ–¹æ³•ï¼Œç¼©å°åŸºç¡€ç±»å’Œæ–°é¢–ç±»ä¹‹é—´çš„åˆ†å¸ƒå·®è·ã€‚è®¾è®¡äº†ä¸€ä¸ªæ–°å‹åŸå‹è°ƒåˆ¶æ¨¡å—ï¼Œåˆ©ç”¨åŸºç¡€ç±»å’Œæ–°é¢–ç±»ä¹‹é—´çš„ç›¸å…³æ€§æ¥è°ƒåˆ¶æ–°é¢–ç±»åŸå‹ã€‚åŒæ—¶ï¼Œæå‡ºäº†ä¸€ä¸ªæ–°å‹åˆ†ç±»å™¨æ ¡å‡†æ¨¡å—ï¼Œæ ¹æ®åŸºç¡€åˆ†ç±»å™¨çš„æƒé‡åˆ†å¸ƒæ ¡å‡†æ–°é¢–åˆ†ç±»å™¨çš„æƒé‡åˆ†å¸ƒã€‚ä¸ºäº†è§£å†³æ–°é¢–ç±»æ ·æœ¬æœ‰é™å¯¼è‡´çš„ç¼ºä¹ä¸Šä¸‹æ–‡ä¿¡æ¯çš„é—®é¢˜ï¼Œå¼•å…¥äº†ä¸Šä¸‹æ–‡ä¸€è‡´æ€§å­¦ä¹ æ–¹æ¡ˆï¼Œå°†ä¸Šä¸‹æ–‡çŸ¥è¯†ä»åŸºç¡€ç±»è½¬ç§»åˆ°æ–°é¢–ç±»ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨PASCAL-5iå’ŒCOCO-20iæ•°æ®é›†ä¸Šæ˜¾è‘—æé«˜äº†GFSSçš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¹¿ä¹‰å°æ ·æœ¬è¯­ä¹‰åˆ†å‰²ï¼ˆGFSSï¼‰æ—¨åœ¨åˆ©ç”¨åŸºç¡€ç±»çš„å……è¶³æ ·æœ¬å’Œæ–°é¢–ç±»çš„å°‘é‡æ ·æœ¬è¿›è¡Œå¯¹è±¡åˆ†å‰²ã€‚</li>
<li>ç°æœ‰çš„GFSSæ–¹æ³•å­˜åœ¨åŸºç¡€ç±»å’Œæ–°é¢–ç±»ä¹‹é—´çš„åˆ†å¸ƒå·®è·é—®é¢˜ã€‚</li>
<li>é€šè¿‡è®¾è®¡æ–°å‹åŸå‹è°ƒåˆ¶æ¨¡å—å’Œåˆ†ç±»å™¨æ ¡å‡†æ¨¡å—ï¼Œå®ç°æœ‰æ•ˆçŸ¥è¯†ä»åŸºç¡€ç±»åˆ°æ–°é¢–ç±»çš„è½¬ç§»ï¼Œä»¥ç¼©å°åˆ†å¸ƒå·®è·ã€‚</li>
<li>å¼•å…¥ä¸Šä¸‹æ–‡ä¸€è‡´æ€§å­¦ä¹ æ–¹æ¡ˆï¼Œè§£å†³æ–°é¢–ç±»æ ·æœ¬æœ‰é™å¯¼è‡´çš„ç¼ºä¹ä¸Šä¸‹æ–‡ä¿¡æ¯çš„é—®é¢˜ã€‚</li>
<li>æ–¹æ³•åœ¨PASCAL-5iå’ŒCOCO-20iæ•°æ®é›†ä¸Šæ˜¾è‘—æé«˜äº†GFSSçš„æ€§èƒ½ã€‚</li>
<li>ä»£ç å·²å…¬å¼€å¯ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15835">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-ecaff4a12309e7ee95857aad4934ed45.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9a8a1555cd16ff3560124fd8e93ab9c4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d41ecf29a590825409d849458efff70e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ba55cfb02798ab66f5ca304097ee84c1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8048e08d4cf4612af6e59c75cef6be05.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Cross-Modal-Few-Shot-Learning-with-Second-Order-Neural-Ordinary-Differential-Equations"><a href="#Cross-Modal-Few-Shot-Learning-with-Second-Order-Neural-Ordinary-Differential-Equations" class="headerlink" title="Cross-Modal Few-Shot Learning with Second-Order Neural Ordinary   Differential Equations"></a>Cross-Modal Few-Shot Learning with Second-Order Neural Ordinary   Differential Equations</h2><p><strong>Authors:Yi Zhang, Chun-Wun Cheng, Junyi He, Zhihai He, Carola-Bibiane SchÃ¶nlieb, Yuyan Chen, Angelica I Aviles-Rivero</strong></p>
<p>We introduce SONO, a novel method leveraging Second-Order Neural Ordinary Differential Equations (Second-Order NODEs) to enhance cross-modal few-shot learning. By employing a simple yet effective architecture consisting of a Second-Order NODEs model paired with a cross-modal classifier, SONO addresses the significant challenge of overfitting, which is common in few-shot scenarios due to limited training examples. Our second-order approach can approximate a broader class of functions, enhancing the modelâ€™s expressive power and feature generalization capabilities. We initialize our cross-modal classifier with text embeddings derived from class-relevant prompts, streamlining training efficiency by avoiding the need for frequent text encoder processing. Additionally, we utilize text-based image augmentation, exploiting CLIPâ€™s robust image-text correlation to enrich training data significantly. Extensive experiments across multiple datasets demonstrate that SONO outperforms existing state-of-the-art methods in few-shot learning performance. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†ä¸€ç§æ–°çš„æ–¹æ³•SONOï¼Œå®ƒåˆ©ç”¨äºŒé˜¶ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆSecond-Order NODEsï¼‰å¢å¼ºè·¨æ¨¡æ€å°æ ·æœ¬å­¦ä¹ ã€‚SONOé‡‡ç”¨ç®€å•æœ‰æ•ˆçš„æ¶æ„ï¼ŒåŒ…æ‹¬äºŒé˜¶NODEsæ¨¡å‹å’Œè·¨æ¨¡æ€åˆ†ç±»å™¨ï¼Œè§£å†³äº†å°æ ·æœ¬åœºæ™¯ä¸­å¸¸è§çš„è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œè¿™æ˜¯ç”±äºè®­ç»ƒæ ·æœ¬æœ‰é™æ‰€è‡´ã€‚æˆ‘ä»¬çš„äºŒé˜¶æ–¹æ³•å¯ä»¥è¿‘ä¼¼æ›´å¹¿æ³›çš„å‡½æ•°ï¼Œæé«˜æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›å’Œç‰¹å¾æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬ç”¨ä¸ç±»åˆ«ç›¸å…³çš„æç¤ºç”Ÿæˆçš„æ–‡æœ¬åµŒå…¥æ¥åˆå§‹åŒ–æˆ‘ä»¬çš„è·¨æ¨¡æ€åˆ†ç±»å™¨ï¼Œé¿å…äº†é¢‘ç¹ä½¿ç”¨æ–‡æœ¬ç¼–ç å™¨å¤„ç†çš„éœ€æ±‚ï¼Œä»è€Œç®€åŒ–äº†è®­ç»ƒæ•ˆç‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ©ç”¨åŸºäºæ–‡æœ¬çš„å›¾åƒå¢å¼ºï¼Œåˆ©ç”¨CLIPå¼ºå¤§çš„å›¾åƒ-æ–‡æœ¬ç›¸å…³æ€§ï¼Œæ˜¾è‘—ä¸°å¯Œè®­ç»ƒæ•°æ®ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒSONOåœ¨å°‘æ ·æœ¬å­¦ä¹ æ€§èƒ½ä¸Šè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15813v1">PDF</a> </p>
<p><strong>Summary</strong><br>SONOæ˜¯ä¸€ç§åˆ©ç”¨äºŒé˜¶ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆSecond-Order NODEsï¼‰å¢å¼ºè·¨æ¨¡æ€å°æ ·å­¦ä¹ çš„æ–°æ–¹æ³•ã€‚å®ƒé€šè¿‡é‡‡ç”¨ç®€å•æœ‰æ•ˆçš„æ¶æ„ï¼Œç»“åˆäºŒé˜¶ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹æ¨¡å‹å’Œè·¨æ¨¡æ€åˆ†ç±»å™¨ï¼Œè§£å†³äº†å°æ ·åœºæ™¯ä¸‹å› è®­ç»ƒæ ·æœ¬æœ‰é™è€Œå¯¼è‡´çš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚äºŒé˜¶æ–¹æ³•èƒ½æ›´å¹¿æ³›åœ°é€¼è¿‘å„ç±»å‡½æ•°ï¼Œå¢å¼ºæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›å’Œç‰¹å¾æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒSONOä½¿ç”¨åŸºäºæ–‡æœ¬çš„å›¾åƒå¢å¼ºæŠ€æœ¯ï¼Œåˆ©ç”¨CLIPçš„å›¾åƒæ–‡æœ¬ç›¸å…³æ€§ä¸°å¯Œè®­ç»ƒæ•°æ®ã€‚å®éªŒè¯æ˜ï¼ŒSONOåœ¨å°‘æ ·æœ¬å­¦ä¹ æ–¹é¢çš„æ€§èƒ½ä¼˜äºç°æœ‰å…ˆè¿›æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SONOåˆ©ç”¨äºŒé˜¶ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆSecond-Order NODEsï¼‰å¢å¼ºè·¨æ¨¡æ€å°æ ·å­¦ä¹ ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡ç»“åˆäºŒé˜¶ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹æ¨¡å‹å’Œè·¨æ¨¡æ€åˆ†ç±»å™¨ï¼Œè§£å†³äº†å°æ ·åœºæ™¯ä¸­çš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚</li>
<li>äºŒé˜¶æ–¹æ³•èƒ½å¤Ÿæ›´å¹¿æ³›åœ°é€¼è¿‘å„ç±»å‡½æ•°ï¼Œæé«˜æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›å’Œç‰¹å¾æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>SONOä½¿ç”¨åŸºäºæ–‡æœ¬çš„å›¾åƒåµŒå…¥åˆå§‹åŒ–è·¨æ¨¡æ€åˆ†ç±»å™¨ï¼Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚</li>
<li>åˆ©ç”¨CLIPçš„å›¾åƒæ–‡æœ¬ç›¸å…³æ€§è¿›è¡ŒåŸºäºæ–‡æœ¬çš„å›¾åƒå¢å¼ºã€‚</li>
<li>é€šè¿‡ä¸°å¯Œçš„å®éªŒéªŒè¯ï¼ŒSONOåœ¨å°‘æ ·æœ¬å­¦ä¹ æ–¹é¢æ€§èƒ½ä¼˜è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15813">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1349311fe633a25222599df7052a2e23.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-62fd490c93a17edf24fd02e7ab31dcbe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-26ce0cef777a6bdf39a1b5a3b3b7a934.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="The-Role-of-Recurrency-in-Image-Segmentation-for-Noisy-and-Limited-Sample-Settings"><a href="#The-Role-of-Recurrency-in-Image-Segmentation-for-Noisy-and-Limited-Sample-Settings" class="headerlink" title="The Role of Recurrency in Image Segmentation for Noisy and Limited   Sample Settings"></a>The Role of Recurrency in Image Segmentation for Noisy and Limited   Sample Settings</h2><p><strong>Authors:David Calhas, JoÃ£o Marques, Arlindo L. Oliveira</strong></p>
<p>The biological brain has inspired multiple advances in machine learning. However, most state-of-the-art models in computer vision do not operate like the human brain, simply because they are not capable of changing or improving their decisions&#x2F;outputs based on a deeper analysis. The brain is recurrent, while these models are not. It is therefore relevant to explore what would be the impact of adding recurrent mechanisms to existing state-of-the-art architectures and to answer the question of whether recurrency can improve existing architectures. To this end, we build on a feed-forward segmentation model and explore multiple types of recurrency for image segmentation. We explore self-organizing, relational, and memory retrieval types of recurrency that minimize a specific energy function. In our experiments, we tested these models on artificial and medical imaging data, while analyzing the impact of high levels of noise and few-shot learning settings. Our results do not validate our initial hypothesis that recurrent models should perform better in these settings, suggesting that these recurrent architectures, by themselves, are not sufficient to surpass state-of-the-art feed-forward versions and that additional work needs to be done on the topic. </p>
<blockquote>
<p>ç”Ÿç‰©å¤§è„‘ä¸ºæœºå™¨å­¦ä¹ å¸¦æ¥äº†è¯¸å¤šè¿›æ­¥ã€‚ç„¶è€Œï¼Œè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å¤§å¤šæ•°æœ€æ–°æ¨¡å‹å¹¶ä¸å¦‚äººè„‘é‚£æ ·è¿ä½œï¼ŒåŸå› ä»…ä»…åœ¨äºå®ƒä»¬æ— æ³•åŸºäºæ›´æ·±å…¥çš„åˆ†ææ¥æ”¹å˜æˆ–æ”¹è¿›å…¶å†³ç­–&#x2F;è¾“å‡ºã€‚å¤§è„‘æ˜¯é€’å½’çš„ï¼Œè€Œè¿™äº›æ¨¡å‹å¹¶ä¸æ˜¯ã€‚å› æ­¤ï¼Œæ¢ç´¢åœ¨ç°æœ‰æœ€æ–°æ¶æ„ä¸­æ·»åŠ é€’å½’æœºåˆ¶çš„å½±å“ï¼Œä»¥åŠé€’å½’èƒ½å¦æ”¹è¿›ç°æœ‰æ¶æ„çš„é—®é¢˜ï¼Œæ˜¯ååˆ†é‡è¦çš„ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åœ¨å‰é¦ˆåˆ†å‰²æ¨¡å‹çš„åŸºç¡€ä¸Šï¼Œæ¢ç´¢äº†å¤šç§ç”¨äºå›¾åƒåˆ†å‰²çš„é€’å½’ç±»å‹ã€‚æˆ‘ä»¬æ¢ç´¢äº†æœ€å°åŒ–ç‰¹å®šèƒ½é‡å‡½æ•°çš„è‡ªç»„ç»‡ã€å…³ç³»å’Œå†…å­˜æ£€ç´¢ä¸‰ç§ç±»å‹çš„é€’å½’ã€‚åœ¨å®éªŒä¸­ï¼Œæˆ‘ä»¬å¯¹äººå·¥å’ŒåŒ»å­¦æˆåƒæ•°æ®è¿›è¡Œäº†æµ‹è¯•ï¼ŒåŒæ—¶åˆ†æäº†é«˜å™ªå£°å’Œå°‘é•œå¤´å­¦ä¹ è®¾ç½®çš„å½±å“ã€‚æˆ‘ä»¬çš„ç»“æœå¹¶æœªè¯å®æˆ‘ä»¬çš„åˆæ­¥å‡è®¾ï¼Œå³é€’å½’æ¨¡å‹åœ¨è¿™äº›è®¾ç½®ä¸­çš„è¡¨ç°ä¼šæ›´å¥½ï¼Œè¿™è¡¨æ˜è¿™äº›é€’å½’æ¶æ„æœ¬èº«ä¸è¶³ä»¥è¶…è¶Šæœ€æ–°çš„å‰é¦ˆç‰ˆæœ¬ï¼Œå¹¶ä¸”è¿˜éœ€è¦åœ¨æ­¤ä¸»é¢˜ä¸ŠæŠ•å…¥é¢å¤–çš„å·¥ä½œã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15734v1">PDF</a> 24 pages</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æ¢ç´¢äº†å°†é€’å½’æœºåˆ¶æ·»åŠ åˆ°ç°æœ‰æœ€å…ˆè¿›çš„æ¶æ„ä¸­å¯¹å›¾åƒåˆ†å‰²çš„å½±å“ï¼Œå®éªŒäº†è‡ªæˆ‘ç»„ç»‡ã€å…³ç³»å’Œå†…å­˜æ£€ç´¢ç­‰å¤šç§é€’å½’ç±»å‹ã€‚ç„¶è€Œï¼Œå®éªŒç»“æœå¹¶ä¸æ”¯æŒåˆå§‹å‡è®¾ï¼Œå³é€’å½’æ¨¡å‹åœ¨é«˜å™ªå£°å’Œå°‘é•œå¤´å­¦ä¹ ç¯å¢ƒä¸­è¡¨ç°æ›´å¥½ï¼Œè¡¨æ˜ä»…ä¾é è¿™äº›é€’å½’æ¶æ„ä¸è¶³ä»¥è¶…è¶Šç°æœ‰æœ€å…ˆè¿›çš„å‰é¦ˆç‰ˆæœ¬ï¼Œéœ€è¦åœ¨æ­¤ä¸»é¢˜ä¸Šè¿›ä¸€æ­¥å¼€å±•å·¥ä½œã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é€’å½’æœºåˆ¶åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸå…·æœ‰æ¢ç´¢æ½œåŠ›ã€‚</li>
<li>ç ”ç©¶äººå‘˜å°è¯•å°†é€’å½’æœºåˆ¶æ·»åŠ åˆ°ç°æœ‰æœ€å…ˆè¿›çš„æ¶æ„ä¸­è¿›è¡Œå›¾åƒåˆ†å‰²ã€‚</li>
<li>å®éªŒåŒ…æ‹¬è‡ªæˆ‘ç»„ç»‡ã€å…³ç³»å’Œå†…å­˜æ£€ç´¢ç­‰ç±»å‹çš„é€’å½’ã€‚</li>
<li>å®éªŒåœ¨é«˜å™ªå£°å’Œå°‘é•œå¤´å­¦ä¹ ç¯å¢ƒä¸‹è¿›è¡Œã€‚</li>
<li>å®éªŒç»“æœä¸æ”¯æŒå‡è®¾é€’å½’æ¨¡å‹ä¼šè¡¨ç°æ›´å¥½ã€‚</li>
<li>é€’å½’æ¶æ„æœ¬èº«ä¸è¶³ä»¥è¶…è¶Šç°æœ‰æœ€å…ˆè¿›çš„é¦ˆé€å‰ç‰ˆæœ¬ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15734">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6658043ebace6a32214666964b876d41.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c0ebaf64ad2fb81c637a5bb7aaff19f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2675f79d3ef59d1e6ec442b98dc53b26.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-03531701b060add6cffd8a479e5787ed.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Task-Specific-Preconditioner-for-Cross-Domain-Few-Shot-Learning"><a href="#Task-Specific-Preconditioner-for-Cross-Domain-Few-Shot-Learning" class="headerlink" title="Task-Specific Preconditioner for Cross-Domain Few-Shot Learning"></a>Task-Specific Preconditioner for Cross-Domain Few-Shot Learning</h2><p><strong>Authors:Suhyun Kang, Jungwon Park, Wonseok Lee, Wonjong Rhee</strong></p>
<p>Cross-Domain Few-Shot Learning<del>(CDFSL) methods typically parameterize models with task-agnostic and task-specific parameters. To adapt task-specific parameters, recent approaches have utilized fixed optimization strategies, despite their potential sub-optimality across varying domains or target tasks. To address this issue, we propose a novel adaptation mechanism called Task-Specific Preconditioned gradient descent</del>(TSP). Our method first meta-learns Domain-Specific Preconditioners~(DSPs) that capture the characteristics of each meta-training domain, which are then linearly combined using task-coefficients to form the Task-Specific Preconditioner. The preconditioner is applied to gradient descent, making the optimization adaptive to the target task. We constrain our preconditioners to be positive definite, guiding the preconditioned gradient toward the direction of steepest descent. Empirical evaluations on the Meta-Dataset show that TSP achieves state-of-the-art performance across diverse experimental scenarios. </p>
<blockquote>
<p>è·¨åŸŸå°æ ·æœ¬å­¦ä¹ ï¼ˆCDFSLï¼‰æ–¹æ³•é€šå¸¸ä½¿ç”¨ä»»åŠ¡é€šç”¨å‚æ•°å’Œä»»åŠ¡ç‰¹å®šå‚æ•°å¯¹æ¨¡å‹è¿›è¡Œå‚æ•°åŒ–ã€‚ä¸ºäº†è°ƒæ•´ä»»åŠ¡ç‰¹å®šå‚æ•°ï¼Œå°½ç®¡ä¸åŒçš„é¢†åŸŸæˆ–ç›®æ ‡ä»»åŠ¡å¯èƒ½å­˜åœ¨æ½œåœ¨çš„æœ€ä¼˜æ€§å·®å¼‚ï¼Œä½†æœ€è¿‘çš„æ–¹æ³•ä»é‡‡ç”¨äº†å›ºå®šçš„ä¼˜åŒ–ç­–ç•¥ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„è‡ªé€‚åº”æœºåˆ¶ï¼Œç§°ä¸ºä»»åŠ¡ç‰¹å®šé¢„è°ƒèŠ‚æ¢¯åº¦ä¸‹é™ï¼ˆTSPï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆé€šè¿‡å…ƒå­¦ä¹ é¢†åŸŸç‰¹å®šé¢„è°ƒèŠ‚å™¨ï¼ˆDSPï¼‰ï¼Œæ•æ‰æ¯ä¸ªå…ƒè®­ç»ƒé¢†åŸŸçš„ç‰¹å¾ï¼Œç„¶åä½¿ç”¨ä»»åŠ¡ç³»æ•°è¿›è¡Œçº¿æ€§ç»„åˆï¼Œå½¢æˆä»»åŠ¡ç‰¹å®šé¢„è°ƒèŠ‚å™¨ã€‚é¢„è°ƒèŠ‚å™¨åº”ç”¨äºæ¢¯åº¦ä¸‹é™ï¼Œä½¿ä¼˜åŒ–é€‚åº”ç›®æ ‡ä»»åŠ¡ã€‚æˆ‘ä»¬å°†é¢„è°ƒèŠ‚å™¨é™åˆ¶ä¸ºæ­£å®šçŸ©é˜µï¼Œå¼•å¯¼é¢„è°ƒèŠ‚æ¢¯åº¦æœå‘æœ€é™¡ä¸‹é™æ–¹å‘ã€‚åœ¨Meta-Datasetä¸Šçš„ç»éªŒè¯„ä¼°è¡¨æ˜ï¼ŒTSPåœ¨å¤šç§å®éªŒåœºæ™¯ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15483v1">PDF</a> Accepted by AAAI 2025</p>
<p><strong>Summary</strong></p>
<p>æ–‡ç« æå‡ºäº†åŸºäºè·¨åŸŸçš„å°æ ·æœ¬å­¦ä¹ ï¼ˆCDFSLï¼‰æ–¹æ³•çš„ä¸€ç§æ”¹è¿›è‡ªé€‚åº”æœºåˆ¶ï¼Œç§°ä¸ºä»»åŠ¡ç‰¹å®šé¢„å¤„ç†æ¢¯åº¦ä¸‹é™ï¼ˆTSPï¼‰ã€‚TSPé€šè¿‡å…ƒå­¦ä¹ é¢†åŸŸç‰¹å®šé¢„å¤„ç†å™¨ï¼ˆDSPï¼‰æ¥æ•è·æ¯ä¸ªå…ƒè®­ç»ƒé¢†åŸŸçš„ç‰¹å¾ï¼Œç„¶åä½¿ç”¨ä»»åŠ¡ç³»æ•°è¿›è¡Œçº¿æ€§ç»„åˆå½¢æˆä»»åŠ¡ç‰¹å®šé¢„å¤„ç†å™¨ã€‚é¢„å¤„ç†å™¨åº”ç”¨äºæ¢¯åº¦ä¸‹é™ï¼Œä½¿ä¼˜åŒ–é€‚åº”ç›®æ ‡ä»»åŠ¡ã€‚åœ¨Meta-Datasetä¸Šçš„å®è¯è¯„ä¼°è¡¨æ˜ï¼ŒTSPåœ¨å¤šç§å®éªŒåœºæ™¯ä¸‹å‡è¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è·¨åŸŸå°æ ·æœ¬å­¦ä¹ æ–¹æ³•é€šå¸¸ä½¿ç”¨ä»»åŠ¡æ— å…³å’Œä»»åŠ¡ç‰¹å®šçš„å‚æ•°å¯¹æ¨¡å‹è¿›è¡Œå‚æ•°åŒ–ã€‚</li>
<li>æœ€è¿‘çš„æ–¹æ³•ä½¿ç”¨å›ºå®šçš„ä¼˜åŒ–ç­–ç•¥æ¥é€‚åº”ä»»åŠ¡ç‰¹å®šå‚æ•°ï¼Œä½†è¿™åœ¨ä¸åŒé¢†åŸŸæˆ–ç›®æ ‡ä»»åŠ¡ä¸­å¯èƒ½è¡¨ç°ä¸ä½³ã€‚</li>
<li>æå‡ºçš„TSPæ–¹æ³•é€šè¿‡å…ƒå­¦ä¹ é¢†åŸŸç‰¹å®šé¢„å¤„ç†å™¨ï¼ˆDSPï¼‰æ•è·æ¯ä¸ªå…ƒè®­ç»ƒé¢†åŸŸçš„ç‰¹å¾ã€‚</li>
<li>TSPä½¿ç”¨çº¿æ€§ç»„åˆå’Œä»»åŠ¡ç³»æ•°å½¢æˆä»»åŠ¡ç‰¹å®šé¢„å¤„ç†å™¨ï¼Œç”¨äºæ¢¯åº¦ä¸‹é™ã€‚</li>
<li>é¢„å¤„ç†å™¨ä½¿ä¼˜åŒ–é€‚åº”ç›®æ ‡ä»»åŠ¡çš„ç‰¹æ€§ã€‚</li>
<li>é€šè¿‡çº¦æŸé¢„å¤„ç†å™¨ä¸ºæ­£å®šçŸ©é˜µï¼Œå¯ä»¥å¼•å¯¼é¢„å¤„ç†æ¢¯åº¦å‘æœ€é™¡æ–¹å‘ä¸‹é™ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15483">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f6f173a6496bfc3db3faf3a0df7918b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ce0a70b331162dcc3d8b47a11f594887.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-41a9081d11a92d1c909fc75db19dc734.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f22146968be77ff2e87a2ec07d84e542.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7c31ffc597389ad533a216ae5176a215.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="PERC-Plan-As-Query-Example-Retrieval-for-Underrepresented-Code-Generation"><a href="#PERC-Plan-As-Query-Example-Retrieval-for-Underrepresented-Code-Generation" class="headerlink" title="PERC: Plan-As-Query Example Retrieval for Underrepresented Code   Generation"></a>PERC: Plan-As-Query Example Retrieval for Underrepresented Code   Generation</h2><p><strong>Authors:Jaeseok Yoo, Hojae Han, Youngwon Lee, Jaejin Kim, Seung-won Hwang</strong></p>
<p>Code generation with large language models has shown significant promise, especially when employing retrieval-augmented generation (RAG) with few-shot examples. However, selecting effective examples that enhance generation quality remains a challenging task, particularly when the target programming language (PL) is underrepresented. In this study, we present two key findings: (1) retrieving examples whose presented algorithmic plans can be referenced for generating the desired behavior significantly improves generation accuracy, and (2) converting code into pseudocode effectively captures such algorithmic plans, enhancing retrieval quality even when the source and the target PLs are different. Based on these findings, we propose Plan-as-query Example Retrieval for few-shot prompting in Code generation (PERC), a novel framework that utilizes algorithmic plans to identify and retrieve effective examples. We validate the effectiveness of PERC through extensive experiments on the CodeContests, HumanEval and MultiPL-E benchmarks: PERC consistently outperforms the state-of-the-art RAG methods in code generation, both when the source and target programming languages match or differ, highlighting its adaptability and robustness in diverse coding environments. </p>
<blockquote>
<p>ä»£ç ç”Ÿæˆä¸å¤§å‹è¯­è¨€æ¨¡å‹ç›¸ç»“åˆå·²ç»å±•ç°å‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½¿ç”¨å°æ ·æœ¬æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„æƒ…å†µä¸‹ã€‚ç„¶è€Œï¼Œåœ¨é€‰æ‹©èƒ½å¤Ÿæé«˜ç”Ÿæˆè´¨é‡çš„æœ‰æ•ˆæ ·æœ¬æ–¹é¢ï¼Œä»ç„¶æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨ç›®æ ‡ç¼–ç¨‹è¯­è¨€ï¼ˆPLï¼‰ä»£è¡¨æ€§ä¸è¶³çš„æƒ…å†µä¸‹ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å‘ç°äº†ä¸¤ä¸ªå…³é”®ç»“æœï¼šï¼ˆ1ï¼‰æ£€ç´¢é‚£äº›æä¾›çš„ç®—æ³•è®¡åˆ’å¯ä»¥ä½œä¸ºç”Ÿæˆæ‰€éœ€è¡Œä¸ºçš„å‚è€ƒï¼Œå¯ä»¥æ˜¾è‘—æé«˜ç”Ÿæˆå‡†ç¡®æ€§ï¼›ï¼ˆ2ï¼‰å°†ä»£ç è½¬æ¢ä¸ºä¼ªä»£ç å¯ä»¥æœ‰æ•ˆåœ°æ•è·æ­¤ç±»ç®—æ³•è®¡åˆ’ï¼Œå³ä½¿åœ¨æºè¯­è¨€å’Œç›®æ ‡ç¼–ç¨‹è¯­è¨€ä¸åŒçš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½æé«˜æ£€ç´¢è´¨é‡ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œæˆ‘ä»¬æå‡ºäº†é¢å‘ä»£ç ç”Ÿæˆçš„å°æ ·æœ¬æç¤ºçš„â€œè®¡åˆ’æŸ¥è¯¢ç¤ºä¾‹æ£€ç´¢â€ï¼ˆPERCï¼‰æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ç®—æ³•è®¡åˆ’æ¥è¯†åˆ«å’Œæ£€ç´¢æœ‰æ•ˆç¤ºä¾‹ã€‚æˆ‘ä»¬åœ¨CodeContestsã€HumanEvalå’ŒMultiPL-EåŸºå‡†æµ‹è¯•ä¸Šå¯¹PERCçš„æœ‰æ•ˆæ€§è¿›è¡Œäº†å¹¿æ³›å®éªŒéªŒè¯ï¼šæ— è®ºæ˜¯åœ¨æºè¯­è¨€å’Œç›®æ ‡ç¼–ç¨‹è¯­è¨€ç›¸åŒ¹é…è¿˜æ˜¯å­˜åœ¨å·®å¼‚çš„æƒ…å†µä¸‹ï¼ŒPERCåœ¨ä»£ç ç”Ÿæˆæ–¹é¢å§‹ç»ˆä¼˜äºæœ€æ–°RAGæ–¹æ³•ï¼Œçªæ˜¾å…¶åœ¨å¤šæ ·åŒ–ç¼–ç ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œç¨³å¥æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.12447v2">PDF</a> Accepted by COLING 2025 main conference</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä»£ç ç”Ÿæˆæ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯é‡‡ç”¨å°‘é‡ç¤ºä¾‹çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯ã€‚æœ¬ç ”ç©¶å‘ç°ï¼šä¸€æ˜¯æ£€ç´¢èƒ½å±•ç¤ºç®—æ³•è®¡åˆ’çš„ä¾‹å­èƒ½æ˜¾è‘—æé«˜ç”Ÿæˆå‡†ç¡®æ€§ï¼›äºŒæ˜¯å°†ä»£ç è½¬åŒ–ä¸ºä¼ªä»£ç èƒ½æœ‰æ•ˆæ•æ‰ç®—æ³•è®¡åˆ’ï¼Œç”šè‡³åœ¨æºè¯­è¨€å’Œç›®æ ‡ç¼–ç¨‹è¯­è¨€ä¸åŒçš„æƒ…å†µä¸‹ä¹Ÿèƒ½æé«˜æ£€ç´¢è´¨é‡ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œæå‡ºäº†åŸºäºç®—æ³•è®¡åˆ’æ£€ç´¢æœ‰æ•ˆç¤ºä¾‹çš„æ–°æ¡†æ¶â€”â€”Plan-as-query Example Retrieval for few-shot prompting in Code generationï¼ˆPERCï¼‰ã€‚åœ¨CodeContestsã€HumanEvalå’ŒMultiPL-EåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒPERCåœ¨ä»£ç ç”Ÿæˆæ–¹é¢å§‹ç»ˆä¼˜äºæœ€æ–°çš„RAGæ–¹æ³•ï¼Œæ— è®ºæ˜¯åœ¨æºè¯­è¨€å’Œç›®æ ‡ç¼–ç¨‹è¯­è¨€ç›¸åŒ¹é…è¿˜æ˜¯ä¸ç›¸åŒ¹é…çš„æƒ…å†µä¸‹ï¼Œéƒ½å±•ç°äº†å…¶åœ¨å¤šç§ç¼–ç¨‹ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œç¨³å¥æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ£€ç´¢å±•ç¤ºç®—æ³•è®¡åˆ’çš„ä¾‹å­èƒ½æ˜¾è‘—æé«˜ä»£ç ç”Ÿæˆçš„å‡†ç¡®æ€§ã€‚</li>
<li>å°†ä»£ç è½¬åŒ–ä¸ºä¼ªä»£ç æœ‰åŠ©äºæé«˜æ£€ç´¢è´¨é‡ï¼Œå°¤å…¶åœ¨æºè¯­è¨€å’Œç›®æ ‡ç¼–ç¨‹è¯­è¨€ä¸åŒæ—¶ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºç®—æ³•è®¡åˆ’çš„æ£€ç´¢æ¡†æ¶PERCï¼Œç”¨äºåœ¨å°‘é‡æç¤ºä¸‹è¿›è¡Œä»£ç ç”Ÿæˆã€‚</li>
<li>PERCåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜äºæœ€æ–°çš„RAGæ–¹æ³•ã€‚</li>
<li>PERCåœ¨æºè¯­è¨€å’Œç›®æ ‡ç¼–ç¨‹è¯­è¨€ç›¸åŒ¹é…æˆ–ä¸ç›¸åŒ¹é…çš„æƒ…å†µä¸‹éƒ½èƒ½æœ‰æ•ˆå·¥ä½œã€‚</li>
<li>PERCåœ¨å¤šç§ç¼–ç¨‹ç¯å¢ƒä¸­å±•ç°å‡ºé€‚åº”æ€§å’Œç¨³å¥æ€§ã€‚</li>
<li>ä»£ç ç”Ÿæˆæ˜¯å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸€ä¸ªé‡è¦åº”ç”¨é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯åœ¨ä½¿ç”¨å°‘é‡ç¤ºä¾‹çš„æƒ…å†µä¸‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.12447">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-871464023cce5fff10c461da3cfc9945.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0109fad767ab94d484400ac5069615ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-edf566b65c4287d516b082a83d064dd1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c7d98e336f3140319ca6c4004e2f4dc7.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Manta-Enhancing-Mamba-for-Few-Shot-Action-Recognition-of-Long-Sub-Sequence"><a href="#Manta-Enhancing-Mamba-for-Few-Shot-Action-Recognition-of-Long-Sub-Sequence" class="headerlink" title="Manta: Enhancing Mamba for Few-Shot Action Recognition of Long   Sub-Sequence"></a>Manta: Enhancing Mamba for Few-Shot Action Recognition of Long   Sub-Sequence</h2><p><strong>Authors:Wenbo Huang, Jinghui Zhang, Guang Li, Lei Zhang, Shuoyuan Wang, Fang Dong, Jiahui Jin, Takahiro Ogawa, Miki Haseyama</strong></p>
<p>In few-shot action recognition (FSAR), long sub-sequences of video naturally express entire actions more effectively. However, the high computational complexity of mainstream Transformer-based methods limits their application. Recent Mamba demonstrates efficiency in modeling long sequences, but directly applying Mamba to FSAR overlooks the importance of local feature modeling and alignment. Moreover, long sub-sequences within the same class accumulate intra-class variance, which adversely impacts FSAR performance. To solve these challenges, we propose a Matryoshka MAmba and CoNtrasTive LeArning framework (Manta). Firstly, the Matryoshka Mamba introduces multiple Inner Modules to enhance local feature representation, rather than directly modeling global features. An Outer Module captures dependencies of timeline between these local features for implicit temporal alignment. Secondly, a hybrid contrastive learning paradigm, combining both supervised and unsupervised methods, is designed to mitigate the negative effects of intra-class variance accumulation. The Matryoshka Mamba and the hybrid contrastive learning paradigm operate in two parallel branches within Manta, enhancing Mamba for FSAR of long sub-sequence. Manta achieves new state-of-the-art performance on prominent benchmarks, including SSv2, Kinetics, UCF101, and HMDB51. Extensive empirical studies prove that Manta significantly improves FSAR of long sub-sequence from multiple perspectives. </p>
<blockquote>
<p>åœ¨å°‘é‡åŠ¨ä½œè¯†åˆ«ï¼ˆFSARï¼‰ä¸­ï¼Œè§†é¢‘çš„é•¿å­åºåˆ—æ›´è‡ªç„¶åœ°è¡¨è¾¾äº†æ•´ä¸ªåŠ¨ä½œã€‚ç„¶è€Œï¼Œä¸»æµåŸºäºTransformerçš„æ–¹æ³•çš„é«˜è®¡ç®—å¤æ‚åº¦é™åˆ¶äº†å…¶åº”ç”¨ã€‚æœ€è¿‘çš„Mambaåœ¨å»ºæ¨¡é•¿åºåˆ—æ–¹é¢å±•ç¤ºäº†æ•ˆç‡ï¼Œä½†ç›´æ¥å°†Mambaåº”ç”¨äºFSARå¿½è§†äº†å±€éƒ¨ç‰¹å¾å»ºæ¨¡å’Œå¯¹é½çš„é‡è¦æ€§ã€‚æ­¤å¤–ï¼ŒåŒä¸€ç±»åˆ«å†…çš„é•¿å­åºåˆ—ä¼šç´¯ç§¯ç±»å†…å·®å¼‚ï¼Œè¿™å¯¹FSARæ€§èƒ½äº§ç”Ÿä¸åˆ©å½±å“ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªMatryoshka Mambaå’Œå¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼ˆMantaï¼‰ã€‚é¦–å…ˆï¼ŒMatryoshka Mambaå¼•å…¥äº†å¤šä¸ªå†…éƒ¨æ¨¡å—æ¥å¢å¼ºå±€éƒ¨ç‰¹å¾è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ç›´æ¥å»ºæ¨¡å…¨å±€ç‰¹å¾ã€‚å¤–éƒ¨æ¨¡å—æ•è·è¿™äº›å±€éƒ¨ç‰¹å¾ä¹‹é—´æ—¶é—´çº¿çš„ä¾èµ–æ€§ï¼Œè¿›è¡Œéšå¼çš„æ—¶é—´å¯¹é½ã€‚å…¶æ¬¡ï¼Œç»“åˆæœ‰ç›‘ç£å’Œæ— ç›‘ç£æ–¹æ³•çš„æ··åˆå¯¹æ¯”å­¦ä¹ èŒƒå¼ï¼Œæ—¨åœ¨å‡è½»ç±»å†…å·®å¼‚ç§¯ç´¯å¸¦æ¥çš„è´Ÿé¢å½±å“ã€‚Matryoshka Mambaå’Œæ··åˆå¯¹æ¯”å­¦ä¹ èŒƒå¼åœ¨Mantaçš„ä¸¤ä¸ªå¹¶è¡Œåˆ†æ”¯ä¸­è¿è¡Œï¼Œå¢å¼ºäº†Mambaå¯¹é•¿å­åºåˆ—çš„FSARèƒ½åŠ›ã€‚Mantaåœ¨åŒ…æ‹¬SSv2ã€Kineticsã€UCF101å’ŒHMDB51åœ¨å†…çš„ä¸»æµåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æœ€æ–°çŠ¶æ€çš„æ€§èƒ½ã€‚å¤§é‡çš„å®è¯ç ”ç©¶è¯æ˜ï¼ŒMantaä»å¤šä¸ªè§’åº¦æ˜¾è‘—æé«˜äº†é•¿å­åºåˆ—çš„FSARæ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.07481v2">PDF</a> Accepted by AAAI 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹å°‘æ ·æœ¬åŠ¨ä½œè¯†åˆ«ï¼ˆFSARï¼‰çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºMantaçš„æ–°æ¡†æ¶ã€‚Mantaé€šè¿‡Matryoshka Mambaå’Œæ··åˆå¯¹æ¯”å­¦ä¹ çš„æ–¹æ³•è§£å†³äº†é•¿åºåˆ—å»ºæ¨¡å’Œå±€éƒ¨ç‰¹å¾å¯¹é½çš„é—®é¢˜ï¼Œä»¥åŠåŒç±»å†…æ–¹å·®ç§¯ç´¯å¸¦æ¥çš„é—®é¢˜ã€‚Matryoshka Mambaé€šè¿‡å¼•å…¥å¤šä¸ªå†…éƒ¨æ¨¡å—å¢å¼ºå±€éƒ¨ç‰¹å¾è¡¨ç¤ºï¼Œå¤–éƒ¨æ¨¡å—åˆ™æ•æ‰è¿™äº›å±€éƒ¨ç‰¹å¾çš„æ—¶é—´çº¿ä¾èµ–æ€§ä»¥å®ç°éšå¼æ—¶é—´å¯¹é½ã€‚æ··åˆå¯¹æ¯”å­¦ä¹ èŒƒå¼ç»“åˆç›‘ç£å’Œæ— ç›‘ç£æ–¹æ³•ï¼Œå‡è½»äº†åŒç±»å†…æ–¹å·®ç§¯ç´¯çš„è´Ÿé¢å½±å“ã€‚Mantaåœ¨SSv2ã€Kineticsã€UCF101å’ŒHMDB51ç­‰ä¸»æµåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€æ–°çŠ¶æ€çš„è‰ºæœ¯æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Mantaæ¡†æ¶è§£å†³äº†å°‘æ ·æœ¬åŠ¨ä½œè¯†åˆ«ï¼ˆFSARï¼‰ä¸­é•¿åºåˆ—å»ºæ¨¡çš„æŒ‘æˆ˜ã€‚</li>
<li>Matryoshka Mambaé€šè¿‡å¼•å…¥å¤šä¸ªå†…éƒ¨æ¨¡å—å’Œå¤–éƒ¨æ¨¡å—ï¼Œå¢å¼ºäº†å±€éƒ¨ç‰¹å¾è¡¨ç¤ºå’Œæ—¶é—´çº¿ä¾èµ–æ€§æ•æ‰ã€‚</li>
<li>æ··åˆå¯¹æ¯”å­¦ä¹ èŒƒå¼ç»“åˆç›‘ç£å’Œæ— ç›‘ç£æ–¹æ³•ï¼Œä»¥å‡è½»åŒç±»å†…æ–¹å·®ç§¯ç´¯çš„è´Ÿé¢å½±å“ã€‚</li>
<li>Mantaå®ç°äº†å¯¹é•¿åºåˆ—çš„éšå¼æ—¶é—´å¯¹é½ã€‚</li>
<li>Mantaåœ¨å¤šä¸ªä¸»æµåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€æ–°çŠ¶æ€çš„è‰ºæœ¯æ€§èƒ½ã€‚</li>
<li>Matryoshka Mambaå’Œæ··åˆå¯¹æ¯”å­¦ä¹ èŒƒå¼åœ¨Mantaæ¡†æ¶ä¸­å¹¶è¡Œè¿ä½œï¼Œå¢å¼ºäº†Mambaå¯¹FSARé•¿å­åºåˆ—çš„è¯†åˆ«èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.07481">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-791b23804e885cd93246cbb74bf90011.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d16c2681d6549d6322cdf09a77cba898.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b7850902a9c3912646aa3a165d6fc9b2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d1d20f12b2ec1bc52f161cf0f0f664e5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d3efc2920012bc9e302b18d829345f0e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-27e490f47ca16f70e9a33df1c71fe152.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-34c6e325a9bcc51cecd7512552bf34d5.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Multimodal-Task-Vectors-Enable-Many-Shot-Multimodal-In-Context-Learning"><a href="#Multimodal-Task-Vectors-Enable-Many-Shot-Multimodal-In-Context-Learning" class="headerlink" title="Multimodal Task Vectors Enable Many-Shot Multimodal In-Context Learning"></a>Multimodal Task Vectors Enable Many-Shot Multimodal In-Context Learning</h2><p><strong>Authors:Brandon Huang, Chancharik Mitra, Assaf Arbelle, Leonid Karlinsky, Trevor Darrell, Roei Herzig</strong></p>
<p>The recent success of interleaved Large Multimodal Models (LMMs) in few-shot learning suggests that in-context learning (ICL) with many examples can be promising for learning new tasks. However, this many-shot multimodal ICL setting has one crucial problem: it is fundamentally limited by the modelâ€™s context length set at pretraining. The problem is especially prominent in the multimodal domain, which processes both text and images, requiring additional tokens. This motivates the need for a multimodal method to compress many shots into fewer tokens without finetuning. In this work, we enable LMMs to perform multimodal, many-shot in-context learning by leveraging Multimodal Task Vectors (MTV) â€“ compact implicit representations of in-context examples compressed in the modelâ€™s attention heads. Specifically, we first demonstrate the existence of such MTV in LMMs and then leverage these extracted MTV to enable many-shot in-context learning for various vision-and-language tasks. Our experiments suggest that MTV can scale in performance with the number of compressed shots and generalize to similar out-of-domain tasks without additional context length for inference. Code: <a target="_blank" rel="noopener" href="https://github.com/Brandon3964/MultiModal-Task-Vector">https://github.com/Brandon3964/MultiModal-Task-Vector</a> </p>
<blockquote>
<p>è¿‘æœŸçš„ç©¿æ’å¼å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰åœ¨å°‘æ ·æœ¬å­¦ä¹ ä¸­çš„æˆåŠŸè¡¨æ˜ï¼Œä½¿ç”¨å¤šä¸ªä¾‹å­çš„ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰å¯¹äºå­¦ä¹ æ–°ä»»åŠ¡å¯èƒ½æ˜¯å¾ˆæœ‰å‰æ™¯çš„ã€‚ç„¶è€Œï¼Œè¿™ç§å¤šæ¨¡æ€çš„è®¸å¤šä¾‹å­ä¸Šä¸‹æ–‡å­¦ä¹ ç¯å¢ƒå­˜åœ¨ä¸€ä¸ªå…³é”®é—®é¢˜ï¼šå®ƒä»æ ¹æœ¬ä¸Šå—åˆ°æ¨¡å‹åœ¨é¢„è®­ç»ƒæ—¶è®¾å®šçš„ä¸Šä¸‹æ–‡é•¿åº¦çš„é™åˆ¶ã€‚è¿™ä¸ªé—®é¢˜åœ¨å¤šæ¨¡æ€é¢†åŸŸå°¤ä¸ºçªå‡ºï¼Œè¯¥é¢†åŸŸéœ€è¦å¤„ç†æ–‡æœ¬å’Œå›¾åƒï¼Œéœ€è¦é¢å¤–çš„æ ‡è®°ç¬¦å·ã€‚è¿™ä¿ƒä½¿éœ€è¦ä¸€ç§å¤šæ¨¡æ€æ–¹æ³•ï¼Œå°†å¤šä¸ªæ ·æœ¬å‹ç¼©æˆæ›´å°‘çš„æ ‡è®°ç¬¦å·ï¼Œæ— éœ€å¾®è°ƒã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡åˆ©ç”¨å¤šæ¨¡æ€ä»»åŠ¡å‘é‡ï¼ˆMTVï¼‰â€”â€”å‹ç¼©åœ¨æ¨¡å‹æ³¨æ„åŠ›å¤´ä¸­çš„ä¸Šä¸‹æ–‡ä¾‹å­çš„ç´§å‡‘éšå¼è¡¨ç¤ºï¼Œä½¿LMMsèƒ½å¤Ÿæ‰§è¡Œå¤šæ¨¡æ€ã€å¤šä¾‹å­çš„ä¸Šä¸‹æ–‡å­¦ä¹ ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆè¯æ˜è¿™ç§MTVåœ¨LMMsä¸­çš„å­˜åœ¨æ€§ï¼Œç„¶ååˆ©ç”¨è¿™äº›æå–çš„MTVæ¥ä¸ºå„ç§è§†è§‰å’Œè¯­è¨€ä»»åŠ¡æä¾›å¤šä¾‹å­çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œéšç€å‹ç¼©æ ·æœ¬æ•°é‡çš„å¢åŠ ï¼ŒMTVçš„æ€§èƒ½ä¹Ÿå¯ä»¥æé«˜ï¼Œå¹¶èƒ½å¤Ÿæ¨å¹¿åˆ°ç±»ä¼¼çš„åŸŸå¤–ä»»åŠ¡ï¼Œæ— éœ€é¢å¤–çš„æ¨ç†ä¸Šä¸‹æ–‡é•¿åº¦ã€‚ä»£ç ï¼š<a target="_blank" rel="noopener" href="https://github.com/Brandon3964/MultiModal-Task-Vector">https://github.com/Brandon3964/MultiModal-Task-Vector</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.15334v3">PDF</a> Published in NeurIPS 2024</p>
<p><strong>Summary</strong></p>
<p>å¤§æ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰åœ¨å°‘æ ·æœ¬å­¦ä¹ ä¸­çš„æˆåŠŸè¡¨æ˜ï¼Œåˆ©ç”¨å¤§é‡å®ä¾‹è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ˜¯æœ‰å‰æ™¯çš„ã€‚ç„¶è€Œï¼Œå¤šæ¨¡æ€çš„ä¸Šä¸‹æ–‡å­¦ä¹ é¢ä¸´ä¸€ä¸ªå…³é”®é—®é¢˜ï¼šæ¨¡å‹é¢„è®­ç»ƒæ—¶çš„ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ã€‚ç‰¹åˆ«æ˜¯åœ¨å¤„ç†æ–‡æœ¬å’Œå›¾åƒçš„å¤šæ¨¡æ€é¢†åŸŸï¼Œè¯¥é—®é¢˜å°¤ä¸ºçªå‡ºï¼Œéœ€è¦é¢å¤–çš„æ ‡è®°ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§å¤šæ¨¡æ€æ–¹æ³•å°†å¤šä¸ªæ ·æœ¬å‹ç¼©æˆæ›´å°‘çš„æ ‡è®°ï¼Œæ— éœ€å¾®è°ƒã€‚æœ¬ç ”ç©¶é€šè¿‡åˆ©ç”¨å¤šä»»åŠ¡å‘é‡ï¼ˆMTVï¼‰ï¼Œä½¿LMMsèƒ½å¤Ÿè¿›è¡Œå¤šæ¨¡æ€ã€å¤šä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œå¤šä»»åŠ¡å‘é‡æ˜¯é¢„è®­ç»ƒæ¨¡å‹ä¸­æ³¨æ„åŠ›å¤´å†…å‹ç¼©çš„ä¸Šä¸‹æ–‡å®ä¾‹çš„ç´§å‡‘éšå¼è¡¨ç¤ºã€‚å®éªŒè¡¨æ˜ï¼ŒMTVåœ¨å‹ç¼©æ ·æœ¬æ•°é‡å¢åŠ æ—¶æ€§èƒ½æœ‰æ‰€æå‡ï¼Œå¹¶èƒ½æ¨å¹¿åˆ°ç±»ä¼¼çš„å¤–åŸŸä»»åŠ¡ï¼Œæ— éœ€é¢å¤–çš„æ¨ç†ä¸Šä¸‹æ–‡é•¿åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§æ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰åœ¨å°‘æ ·æœ¬å­¦ä¹ ä¸­çš„æˆåŠŸè¡¨æ˜ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ½œåŠ›å·¨å¤§ã€‚</li>
<li>å¤šæ¨¡æ€ä¸Šä¸‹æ–‡å­¦ä¹ é¢ä¸´é¢„è®­ç»ƒæ—¶çš„ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶é—®é¢˜ã€‚</li>
<li>å¤šä»»åŠ¡å‘é‡ï¼ˆMTVï¼‰æ˜¯æ¨¡å‹æ³¨æ„åŠ›å¤´å†…çš„éšå¼è¡¨ç¤ºï¼Œèƒ½è§£å†³å¤šæ¨¡æ€ã€å¤šä¸Šä¸‹æ–‡å­¦ä¹ é—®é¢˜ã€‚</li>
<li>MTVé€šè¿‡å‹ç¼©ä¸Šä¸‹æ–‡å®ä¾‹ï¼Œä½¿LMMsèƒ½å¤Ÿå¤„ç†æ›´å¤šçš„æ ·æœ¬ã€‚</li>
<li>MTVåœ¨å‹ç¼©æ ·æœ¬æ•°é‡å¢åŠ æ—¶æ€§èƒ½æå‡ï¼Œå¹¶é€‚ç”¨äºå„ç§è§†è§‰å’Œè¯­è¨€ä»»åŠ¡ã€‚</li>
<li>MTVæ–¹æ³•èƒ½å¤Ÿæ¨å¹¿åˆ°ç±»ä¼¼çš„å¤–åŸŸä»»åŠ¡ï¼Œæ— éœ€é¢å¤–çš„æ¨ç†ä¸Šä¸‹æ–‡é•¿åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.15334">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-625fcaf6b8482c2b91ee1f0f5716f75d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cd4a4aad7d696d8b9ef065d854ca17d6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b4e5c40ab6ec63cc5e01283186526739.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-24/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-24/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-24/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-05105c3999a0c6cd1deccd2dd5951ec0.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-24  Self-supervised Spatial-Temporal Learner for Precipitation Nowcasting
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-24/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c30275e38a084ae99a2feb9c3b5590ab.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-24  Tacit Learning with Adaptive Information Selection for Cooperative   Multi-Agent Reinforcement Learning
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">13597.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
