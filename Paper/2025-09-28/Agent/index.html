<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-28  Interactive Recommendation Agent with Active User Commands">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-e0d5900374554ad37a901982ed34ab44')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-28
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-15
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    21.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    85 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-28-æ›´æ–°"><a href="#2025-09-28-æ›´æ–°" class="headerlink" title="2025-09-28 æ›´æ–°"></a>2025-09-28 æ›´æ–°</h1><h2 id="Interactive-Recommendation-Agent-with-Active-User-Commands"><a href="#Interactive-Recommendation-Agent-with-Active-User-Commands" class="headerlink" title="Interactive Recommendation Agent with Active User Commands"></a>Interactive Recommendation Agent with Active User Commands</h2><p><strong>Authors:Jiakai Tang, Yujie Luo, Xunke Xi, Fei Sun, Xueyang Feng, Sunhao Dai, Chao Yi, Dian Chen, Zhujin Gao, Yang Li, Xu Chen, Wen Chen, Jian Wu, Yuning Jiang, Bo Zheng</strong></p>
<p>Traditional recommender systems rely on passive feedback mechanisms that limit users to simple choices such as like and dislike. However, these coarse-grained signals fail to capture usersâ€™ nuanced behavior motivations and intentions. In turn, current systems cannot also distinguish which specific item attributes drive user satisfaction or dissatisfaction, resulting in inaccurate preference modeling. These fundamental limitations create a persistent gap between user intentions and system interpretations, ultimately undermining user satisfaction and harming system effectiveness.   To address these limitations, we introduce the Interactive Recommendation Feed (IRF), a pioneering paradigm that enables natural language commands within mainstream recommendation feeds. Unlike traditional systems that confine users to passive implicit behavioral influence, IRF empowers active explicit control over recommendation policies through real-time linguistic commands. To support this paradigm, we develop RecBot, a dual-agent architecture where a Parser Agent transforms linguistic expressions into structured preferences and a Planner Agent dynamically orchestrates adaptive tool chains for on-the-fly policy adjustment. To enable practical deployment, we employ simulation-augmented knowledge distillation to achieve efficient performance while maintaining strong reasoning capabilities. Through extensive offline and long-term online experiments, RecBot shows significant improvements in both user satisfaction and business outcomes. </p>
<blockquote>
<p>ä¼ ç»Ÿæ¨èç³»ç»Ÿä¾èµ–äºè¢«åŠ¨åé¦ˆæœºåˆ¶ï¼Œè¿™äº›æœºåˆ¶ä½¿ç”¨æˆ·åªèƒ½é€‰æ‹©ç®€å•çš„å–œæ¬¢æˆ–ä¸å–œæ¬¢ç­‰é€‰é¡¹ã€‚ç„¶è€Œï¼Œè¿™äº›ç²—ç²’åº¦çš„ä¿¡å·æ— æ³•æ•æ‰ç”¨æˆ·ç»†å¾®çš„è¡Œä¸ºåŠ¨æœºå’Œæ„å›¾ã€‚å› æ­¤ï¼Œå½“å‰ç³»ç»Ÿä¹Ÿæ— æ³•åŒºåˆ†å“ªäº›ç‰¹å®šé¡¹ç›®å±æ€§é©±åŠ¨ç”¨æˆ·æ»¡æ„æˆ–ä¸æ»¡æ„ï¼Œå¯¼è‡´åå¥½å»ºæ¨¡ä¸å‡†ç¡®ã€‚è¿™äº›åŸºæœ¬å±€é™é€ æˆäº†ç”¨æˆ·æ„å›¾ä¸ç³»ç»Ÿè§£é‡Šä¹‹é—´çš„æŒä¹…å·®è·ï¼Œæœ€ç»ˆæŸå®³äº†ç”¨æˆ·æ»¡æ„åº¦å’Œç³»ç»Ÿæ•ˆç‡ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™ï¼Œæˆ‘ä»¬å¼•å…¥äº†äº¤äº’å¼æ¨èé¦ˆé€ï¼ˆIRFï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å¼€åˆ›æ€§çš„èŒƒå¼ï¼Œèƒ½å¤Ÿåœ¨ä¸»æµæ¨èé¦ˆé€ä¸­å®ç°è‡ªç„¶è¯­è¨€å‘½ä»¤ã€‚ä¸åŒäºé™åˆ¶ç”¨æˆ·å—åˆ°è¢«åŠ¨éšæ€§è¡Œä¸ºå½±å“çš„ä¼ ç»Ÿç³»ç»Ÿï¼ŒIRFé€šè¿‡å®æ—¶è¯­è¨€å‘½ä»¤èµ‹äºˆç”¨æˆ·å¯¹æ¨èç­–ç•¥è¿›è¡Œä¸»åŠ¨æ˜ç¡®æ§åˆ¶çš„èƒ½åŠ›ã€‚ä¸ºäº†æ”¯æŒè¿™ä¸€èŒƒå¼ï¼Œæˆ‘ä»¬å¼€å‘äº†RecBotï¼Œè¿™æ˜¯ä¸€ç§åŒä»£ç†æ¶æ„ï¼Œå…¶ä¸­è§£æå™¨ä»£ç†å°†è¯­è¨€è¡¨è¾¾è½¬åŒ–ä¸ºç»“æ„åŒ–åå¥½ï¼Œè€Œè§„åˆ’å™¨ä»£ç†åˆ™åŠ¨æ€åè°ƒé€‚åº”æ€§çš„å·¥å…·é“¾ï¼Œç”¨äºå³æ—¶ç­–ç•¥è°ƒæ•´ã€‚ä¸ºäº†å®ç°å®é™…éƒ¨ç½²ï¼Œæˆ‘ä»¬é‡‡ç”¨ä»¿çœŸå¢å¼ºçŸ¥è¯†è’¸é¦æ³•ï¼Œåœ¨ä¿æŒå¼ºå¤§æ¨ç†èƒ½åŠ›çš„åŒæ—¶å®ç°é«˜æ•ˆæ€§èƒ½ã€‚é€šè¿‡å¤§é‡ç¦»çº¿æµ‹è¯•å’Œé•¿æœŸåœ¨çº¿å®éªŒï¼ŒRecBotåœ¨ç”¨æˆ·æ»¡æ„åº¦å’Œä¸šåŠ¡æˆæœæ–¹é¢éƒ½æ˜¾ç¤ºå‡ºæ˜¾è‘—æ”¹å–„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21317v1">PDF</a> Under Review</p>
<p><strong>Summary</strong></p>
<p>ä¼ ç»Ÿæ¨èç³»ç»Ÿä¾èµ–è¢«åŠ¨åé¦ˆæœºåˆ¶ï¼Œä½¿ç”¨æˆ·åªèƒ½é€‰æ‹©ç®€å•çš„å–œæ¬¢æˆ–ä¸å–œæ¬¢ï¼Œè¿™ç§ç²—ç²’åº¦çš„ä¿¡å·æ— æ³•æ•æ‰ç”¨æˆ·å¤æ‚çš„è¡Œä¸ºåŠ¨æœºå’Œæ„å›¾ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†äº¤äº’æ¨èé¦ˆï¼ˆIRFï¼‰è¿™ä¸€å¼€åˆ›æ€§ç†å¿µï¼Œå¹¶åœ¨ä¸»æµæ¨èç³»ç»Ÿä¸­å¼•å…¥è‡ªç„¶è¯­è¨€å‘½ä»¤ã€‚IRFé€šè¿‡å®æ—¶è¯­è¨€å‘½ä»¤ä½¿ç”¨æˆ·èƒ½å¤Ÿä¸»åŠ¨æ§åˆ¶æ¨èç­–ç•¥ï¼Œè€Œä¼ ç»Ÿç³»ç»Ÿåªèƒ½è¢«åŠ¨æ¥å—ç”¨æˆ·éšæ€§è¡Œä¸ºå½±å“ã€‚ä¸ºå®ç°è¿™ä¸€ç†å¿µï¼Œæˆ‘ä»¬å¼€å‘äº†RecBotç³»ç»Ÿï¼Œè¯¥ç³»ç»ŸåŒ…å«è§£æå™¨ä»£ç†ï¼ˆå°†è¯­è¨€è¡¨è¾¾å¼è½¬åŒ–ä¸ºç»“æ„åŒ–åå¥½ï¼‰å’Œè§„åˆ’å™¨ä»£ç†ï¼ˆåŠ¨æ€åè°ƒå³æ—¶ç­–ç•¥è°ƒæ•´å·¥å…·é“¾ï¼‰ã€‚é€šè¿‡æ¨¡æ‹Ÿå¢å¼ºçŸ¥è¯†è’¸é¦æŠ€æœ¯ï¼ŒRecBotå®ç°äº†é«˜æ•ˆæ€§èƒ½å¹¶ä¿æŒå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒè¯æ˜ï¼ŒRecBotåœ¨ç”¨æˆ·æ»¡æ„åº¦å’Œä¸šåŠ¡æˆæœæ–¹é¢å–å¾—äº†æ˜¾è‘—æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¼ ç»Ÿæ¨èç³»ç»Ÿä¾èµ–è¢«åŠ¨åé¦ˆæœºåˆ¶ï¼Œæ— æ³•æ•æ‰ç”¨æˆ·å¤æ‚çš„è¡Œä¸ºåŠ¨æœºå’Œæ„å›¾ã€‚</li>
<li>äº¤äº’æ¨èé¦ˆï¼ˆIRFï¼‰ç†å¿µå¼•å…¥è‡ªç„¶è¯­è¨€å‘½ä»¤ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿä¸»åŠ¨æ§åˆ¶æ¨èç­–ç•¥ã€‚</li>
<li>RecBotç³»ç»ŸåŒ…æ‹¬è§£æå™¨ä»£ç†å’Œè§„åˆ’å™¨ä»£ç†ï¼Œåˆ†åˆ«è´Ÿè´£å°†è¯­è¨€è½¬åŒ–ä¸ºç»“æ„åŒ–åå¥½å’ŒåŠ¨æ€è°ƒæ•´æ¨èç­–ç•¥ã€‚</li>
<li>æ¨¡æ‹Ÿå¢å¼ºçŸ¥è¯†è’¸é¦æŠ€æœ¯ä½¿RecBotå®ç°é«˜æ•ˆæ€§èƒ½å¹¶ä¿æŒå¼ºå¤§æ¨ç†èƒ½åŠ›ã€‚</li>
<li>ç”¨æˆ·æ»¡æ„åº¦å’Œä¸šåŠ¡æˆæœå¾—åˆ°äº†æ˜¾è‘—æ”¹è¿›ã€‚</li>
<li>RecBotç³»ç»Ÿèƒ½å¤Ÿé€šè¿‡å®æ—¶è¯­è¨€å‘½ä»¤è¿›è¡Œå³æ—¶ç­–ç•¥è°ƒæ•´ï¼Œæé«˜ç³»ç»Ÿçš„é€‚åº”æ€§å’Œçµæ´»æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21317">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d8356d1f203bb0f069e9485cce2f164e" align="middle">
<img src="https://picx.zhimg.com/v2-7f5f3ec9f16c664a1d5ffa692bb8ca0f" align="middle">
<img src="https://picx.zhimg.com/v2-f2ee8de866ca3bb4dd943c20d80b8257" align="middle">
<img src="https://picx.zhimg.com/v2-16988c5e3ddf548507f8afd1dcb31e29" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Nova-Real-Time-Agentic-Vision-Language-Model-Serving-with-Adaptive-Cross-Stage-Parallelization"><a href="#Nova-Real-Time-Agentic-Vision-Language-Model-Serving-with-Adaptive-Cross-Stage-Parallelization" class="headerlink" title="Nova: Real-Time Agentic Vision-Language Model Serving with Adaptive   Cross-Stage Parallelization"></a>Nova: Real-Time Agentic Vision-Language Model Serving with Adaptive   Cross-Stage Parallelization</h2><p><strong>Authors:Yuhang Xu, Shengzhong Liu, Dong Zhang, Bingheng Yan, Fan Wu, Guihai Chen</strong></p>
<p>This paper presents Nova, a real-time scheduling framework for serving agentic vision-language models (VLMs) on a single GPU with balanced per-request latency and overall request process throughput. Our design begins by enabling effective pipelining across vision encode, LLM prefill, and LLM decode stages of VLMs, by exploiting their heterogeneous resource demands during execution and incorporating elastic GPU spatial partitioning among stages to maximally utilize the compute and memory resources. Building on this, we introduce a real-time scheduling algorithm that adaptively calibrates resource allocation among stages based on a Pareto-optimal analysis of the latency-throughput trade-off, allowing the system to sustain responsiveness and resource efficiency under dynamic request loads. To further alleviate GPU memory pressure, we design a lightweight weight offloading strategy for vision encoders that preserves inference efficiency with minimized memory overhead. Extensive evaluations on both synthetic and real-world agent workloads demonstrate that Nova consistently outperforms the state-of-the-art baselines, improving the maximum latency by up to 23.3%, while keeping competitive throughput. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†Novaï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºå•ä¸€GPUä¸Šè¿è¡Œçš„agenticè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰æä¾›çš„å®æ—¶è°ƒåº¦æ¡†æ¶ï¼Œå®ƒèƒ½å¤Ÿåœ¨æ¯ä¸ªè¯·æ±‚å»¶è¿Ÿå’Œæ•´ä½“è¯·æ±‚å¤„ç†ååé‡ä¹‹é—´å®ç°å¹³è¡¡ã€‚æˆ‘ä»¬çš„è®¾è®¡é¦–å…ˆé€šè¿‡åœ¨VLMçš„æ„¿æ™¯ç¼–ç ã€LLMé¢„å¡«å……å’ŒLLMè§£ç é˜¶æ®µå®ç°æœ‰æ•ˆçš„ç®¡é“åŒ–ï¼Œåˆ©ç”¨è¿™äº›é˜¶æ®µåœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­çš„å¼‚æ„èµ„æºéœ€æ±‚ï¼Œå¹¶èå…¥å¼¹æ€§GPUç©ºé—´åˆ†åŒºä»¥æœ€å¤§åŒ–åˆ©ç”¨è®¡ç®—å’Œå†…å­˜èµ„æºã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å®æ—¶è°ƒåº¦ç®—æ³•ï¼Œè¯¥ç®—æ³•åŸºäºå»¶è¿Ÿ-ååé‡æƒè¡¡çš„å¸•ç´¯æ‰˜æœ€ä¼˜åˆ†æï¼Œè‡ªé€‚åº”åœ°æ ¡å‡†å„é˜¶æ®µçš„èµ„æºåˆ†é…ï¼Œä½¿ç³»ç»Ÿèƒ½å¤Ÿåœ¨åŠ¨æ€è¯·æ±‚è´Ÿè½½ä¸‹ä¿æŒå“åº”æ€§å’Œèµ„æºæ•ˆç‡ã€‚ä¸ºäº†è¿›ä¸€æ­¥ç¼“è§£GPUå†…å­˜å‹åŠ›ï¼Œæˆ‘ä»¬ä¸ºè§†è§‰ç¼–ç å™¨è®¾è®¡äº†ä¸€ç§è½»é‡çº§çš„å¸è½½ç­–ç•¥ï¼Œä»¥æœ€å°çš„å†…å­˜å¼€é”€ä¿æŒæ¨ç†æ•ˆç‡ã€‚å¯¹åˆæˆå’ŒçœŸå®ä¸–ç•Œä»£ç†å·¥ä½œè´Ÿè½½çš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒNovaå§‹ç»ˆä¼˜äºæœ€æ–°åŸºçº¿ï¼Œæœ€å¤§å»¶è¿Ÿæé«˜äº†é«˜è¾¾23.3%ï¼ŒåŒæ—¶ä¿æŒç«äº‰åŠ›ååé‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21301v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥è®ºæ–‡ä»‹ç»äº†Novaï¼Œä¸€ä¸ªä¸ºå•ä¸€GPUä¸ŠæœåŠ¡ä»£ç†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰æä¾›å®æ—¶è°ƒåº¦æ¡†æ¶ã€‚Novaé€šè¿‡ç®¡é“åŒ–è®¾è®¡ï¼Œæœ‰æ•ˆåº”å¯¹VLMsçš„å¼‚æ„èµ„æºéœ€æ±‚ï¼Œå¹¶å¼•å…¥å®æ—¶è°ƒåº¦ç®—æ³•ï¼Œæ ¹æ®å»¶è¿Ÿå’Œååé‡çš„å¸•ç´¯æ‰˜æœ€ä¼˜åˆ†æè‡ªé€‚åº”è°ƒæ•´èµ„æºåˆ†é…ã€‚æ­¤å¤–ï¼ŒNovaè¿˜è®¾è®¡äº†ä¸€ç§è½»é‡çº§å¸è½½ç­–ç•¥ä»¥å‡è½»GPUå†…å­˜å‹åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒNovaåœ¨æ€§èƒ½ä¸Šè¶…è¶Šç°æœ‰æŠ€æœ¯ï¼Œæœ€å¤§å»¶è¿Ÿé™ä½äº†é«˜è¾¾23.3%ï¼ŒåŒæ—¶ä¿æŒç«äº‰åŠ›ååé‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Novaæ˜¯ä¸€ä¸ªç”¨äºå•ä¸€GPUä¸Šä»£ç†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„å®æ—¶è°ƒåº¦æ¡†æ¶ã€‚</li>
<li>Novaé€šè¿‡ç®¡é“è®¾è®¡æœ‰æ•ˆåº”å¯¹VLMsçš„å¼‚æ„èµ„æºéœ€æ±‚ã€‚</li>
<li>Novaå¼•å…¥äº†ä¸€ç§åŸºäºå»¶è¿Ÿå’Œååé‡å¸•ç´¯æ‰˜æœ€ä¼˜åˆ†æçš„å®æ—¶è°ƒåº¦ç®—æ³•ã€‚</li>
<li>Novaé€šè¿‡è‡ªé€‚åº”èµ„æºåˆ†é…åœ¨åŠ¨æ€è¯·æ±‚è´Ÿè½½ä¸‹ä¿æŒå“åº”æ€§å’Œèµ„æºæ•ˆç‡ã€‚</li>
<li>Novaè®¾è®¡äº†ä¸€ç§è½»é‡çº§å¸è½½ç­–ç•¥ä»¥å‡è½»GPUå†…å­˜å‹åŠ›ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒNovaåœ¨æ€§èƒ½ä¸Šè¶…è¶Šç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21301">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-29b5cf73b9b291563f2425f90c13f309" align="middle">
<img src="https://picx.zhimg.com/v2-97cafcf1e82e081860b8ab3c32a405a5" align="middle">
<img src="https://picx.zhimg.com/v2-b75d37e03ea959169ae0d7ef8b90184c" align="middle">
<img src="https://picx.zhimg.com/v2-16975ba3ccef0f61745b446d7cc75e0b" align="middle">
<img src="https://picx.zhimg.com/v2-ab00005a0e50c352bf26df3837c150f4" align="middle">
<img src="https://picx.zhimg.com/v2-4377d93cf819dd9fb3969cf6180cb7e4" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="VC-Agent-An-Interactive-Agent-for-Customized-Video-Dataset-Collection"><a href="#VC-Agent-An-Interactive-Agent-for-Customized-Video-Dataset-Collection" class="headerlink" title="VC-Agent: An Interactive Agent for Customized Video Dataset Collection"></a>VC-Agent: An Interactive Agent for Customized Video Dataset Collection</h2><p><strong>Authors:Yidan Zhang, Mutian Xu, Yiming Hao, Kun Zhou, Jiahao Chang, Xiaoqiang Liu, Pengfei Wan, Hongbo Fu, Xiaoguang Han</strong></p>
<p>Facing scaling laws, video data from the internet becomes increasingly important. However, collecting extensive videos that meet specific needs is extremely labor-intensive and time-consuming. In this work, we study the way to expedite this collection process and propose VC-Agent, the first interactive agent that is able to understand usersâ€™ queries and feedback, and accordingly retrieve&#x2F;scale up relevant video clips with minimal user input. Specifically, considering the user interface, our agent defines various user-friendly ways for the user to specify requirements based on textual descriptions and confirmations. As for agent functions, we leverage existing multi-modal large language models to connect the userâ€™s requirements with the video content. More importantly, we propose two novel filtering policies that can be updated when user interaction is continually performed. Finally, we provide a new benchmark for personalized video dataset collection, and carefully conduct the user study to verify our agentâ€™s usage in various real scenarios. Extensive experiments demonstrate the effectiveness and efficiency of our agent for customized video dataset collection. Project page: <a target="_blank" rel="noopener" href="https://allenyidan.github.io/vcagent_page/">https://allenyidan.github.io/vcagent_page/</a>. </p>
<blockquote>
<p>é¢å¯¹ä¸æ–­æ‰©å¤§è§„æ¨¡çš„æ³•å¾‹æ³•è§„ï¼Œäº’è”ç½‘è§†é¢‘æ•°æ®å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚ç„¶è€Œï¼Œæ”¶é›†æ»¡è¶³ç‰¹å®šéœ€æ±‚çš„å¤§é‡è§†é¢‘æä¸ºè€—è´¹åŠ³åŠ¨åŠ›å’Œæ—¶é—´ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å¦‚ä½•åŠ å¿«è¿™ä¸€æ”¶é›†è¿‡ç¨‹ï¼Œå¹¶æå‡ºäº†VC-Agentï¼Œè¿™æ˜¯ä¸€ä¸ªé¦–æ¬¾èƒ½å¤Ÿç†è§£ç”¨æˆ·æŸ¥è¯¢å’Œåé¦ˆçš„äº¤äº’å¼ä»£ç†ã€‚å®ƒèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·éœ€æ±‚æ£€ç´¢æˆ–æ‰©å±•ç›¸å…³è§†é¢‘ç‰‡æ®µï¼Œåªéœ€æå°‘çš„ç”¨æˆ·è¾“å…¥ã€‚å…·ä½“æ¥è¯´ï¼Œå°±ç”¨æˆ·ç•Œé¢è€Œè¨€ï¼Œæˆ‘ä»¬çš„ä»£ç†ä¸ºç”¨æˆ·æä¾›äº†å„ç§å‹å¥½çš„æ–¹å¼ï¼ŒåŸºäºæ–‡æœ¬æè¿°å’Œç¡®è®¤æ¥æŒ‡å®šè¦æ±‚ã€‚è‡³äºä»£ç†åŠŸèƒ½ï¼Œæˆ‘ä»¬åˆ©ç”¨ç°æœ‰çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹å°†ç”¨æˆ·çš„è¦æ±‚ä¸è§†é¢‘å†…å®¹è¿æ¥èµ·æ¥ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§æ–°å‹è¿‡æ»¤ç­–ç•¥ï¼Œå®ƒä»¬å¯ä»¥åœ¨ç”¨æˆ·äº¤äº’æŒç»­è¿›è¡Œæ—¶å¾—åˆ°æ›´æ–°ã€‚æœ€åï¼Œæˆ‘ä»¬ä¸ºä¸ªæ€§åŒ–è§†é¢‘æ•°æ®é›†æ”¶é›†æä¾›äº†ä¸€ä¸ªæ–°åŸºå‡†ï¼Œå¹¶é€šè¿‡ç”¨æˆ·ç ”ç©¶ä»”ç»†éªŒè¯äº†æˆ‘ä»¬çš„ä»£ç†åœ¨å„ç§å®é™…åœºæ™¯ä¸­çš„ä½¿ç”¨ã€‚å¤§é‡å®éªŒè¯æ˜äº†æˆ‘ä»¬çš„ä»£ç†åœ¨å®šåˆ¶è§†é¢‘æ•°æ®é›†æ”¶é›†æ–¹é¢çš„æœ‰æ•ˆæ€§å’Œæ•ˆç‡ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://allenyidan.github.io/vcagent_page/%E3%80%82">https://allenyidan.github.io/vcagent_page/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21291v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://allenyidan.github.io/vcagent_page/">https://allenyidan.github.io/vcagent_page/</a></p>
<p><strong>Summary</strong></p>
<p>é¢å¯¹äº’è”ç½‘ä¸Šè§†é¢‘æ•°æ®çš„è§„æ¨¡å¢é•¿ï¼Œæ”¶é›†æ»¡è¶³ç‰¹å®šéœ€æ±‚çš„è§†é¢‘å˜å¾—è¶Šæ¥è¶Šé‡è¦ï¼Œä½†è¿™ä¸€è¿‡ç¨‹æå…¶è€—è´¹æ—¶é—´å’ŒåŠ³åŠ¨åŠ›ã€‚æœ¬ç ”ç©¶æ—¨åœ¨åŠ é€Ÿè¿™ä¸€è¿‡ç¨‹ï¼Œæå‡ºVC-Agentï¼Œè¿™æ˜¯ä¸€ä¸ªèƒ½å¤Ÿç†è§£ç”¨æˆ·æŸ¥è¯¢å’Œåé¦ˆçš„é¦–ä¸ªäº¤äº’å¼ä»£ç†ã€‚é€šè¿‡æœ€å°åŒ–ç”¨æˆ·è¾“å…¥ï¼Œè¯¥ä»£ç†èƒ½å¤Ÿæ£€ç´¢å’Œæ‰©å±•ç›¸å…³è§†é¢‘ç‰‡æ®µã€‚æˆ‘ä»¬çš„ä»£ç†å®šä¹‰å„ç§ç”¨æˆ·å‹å¥½çš„æ–¹å¼è®©ç”¨æˆ·åŸºäºæ–‡æœ¬æè¿°å’Œç¡®è®¤æ¥æŒ‡å®šè¦æ±‚ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ©ç”¨ç°æœ‰çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹å°†ç”¨æˆ·è¦æ±‚ä¸è§†é¢‘å†…å®¹è¿æ¥èµ·æ¥ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬æå‡ºä¸¤ç§æ–°å‹è¿‡æ»¤ç­–ç•¥ï¼Œå¯éšç€ç”¨æˆ·äº’åŠ¨çš„è¿ç»­è¿›è¡Œè€Œæ›´æ–°ã€‚æœ€åï¼Œæˆ‘ä»¬ä¸ºä¸ªæ€§åŒ–è§†é¢‘æ•°æ®é›†æ”¶é›†æä¾›äº†ä¸€ä¸ªæ–°åŸºå‡†æµ‹è¯•ï¼Œå¹¶é€šè¿‡ç”¨æˆ·ç ”ç©¶ä»”ç»†éªŒè¯äº†è¯¥ä»£ç†åœ¨å„ç§å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¢å¯¹äº’è”ç½‘ä¸Šè§†é¢‘æ•°æ®çš„è§„æ¨¡å¢é•¿ï¼Œè§†é¢‘æ”¶é›†å˜å¾—è‡³å…³é‡è¦ï¼Œä½†è¿™ä¸€è¿‡ç¨‹å…·æœ‰æŒ‘æˆ˜æ€§å’Œè€—æ—¶æ€§ã€‚</li>
<li>VC-Agentæ˜¯ä¸€ä¸ªäº¤äº’å¼ä»£ç†ï¼Œæ—¨åœ¨åŠ é€Ÿæ»¡è¶³ç‰¹å®šéœ€æ±‚çš„è§†é¢‘æ”¶é›†è¿‡ç¨‹ã€‚</li>
<li>VC-Agentèƒ½å¤Ÿç†è§£ç”¨æˆ·æŸ¥è¯¢å’Œåé¦ˆï¼Œå¹¶æœ€å°åŒ–ç”¨æˆ·è¾“å…¥ä»¥æ£€ç´¢å’Œæ‰©å±•ç›¸å…³è§†é¢‘ç‰‡æ®µã€‚</li>
<li>è¯¥ä»£ç†é‡‡ç”¨å¤šç§ç”¨æˆ·å‹å¥½çš„æ–¹å¼å…è®¸ç”¨æˆ·æŒ‡å®šè¦æ±‚ï¼Œå¦‚æ–‡æœ¬æè¿°å’Œç¡®è®¤ã€‚</li>
<li>åˆ©ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹è¿æ¥ç”¨æˆ·è¦æ±‚ä¸è§†é¢‘å†…å®¹ã€‚</li>
<li>VC-Agentæå‡ºä¸¤ç§å¯éšç”¨æˆ·äº’åŠ¨æ›´æ–°è€Œæ›´æ–°çš„æ–°å‹è¿‡æ»¤ç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21291">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c2ce17864727c679036ab0324a6d4d5d" align="middle">
<img src="https://picx.zhimg.com/v2-c3294d308cb9acc26517357fdbdf13d6" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Tree-Search-for-LLM-Agent-Reinforcement-Learning"><a href="#Tree-Search-for-LLM-Agent-Reinforcement-Learning" class="headerlink" title="Tree Search for LLM Agent Reinforcement Learning"></a>Tree Search for LLM Agent Reinforcement Learning</h2><p><strong>Authors:Yuxiang Ji, Ziyu Ma, Yong Wang, Guanhua Chen, Xiangxiang Chu, Liaoni Wu</strong></p>
<p>Recent advances in reinforcement learning (RL) have significantly enhanced the agentic capabilities of large language models (LLMs). In long-term and multi-turn agent tasks, existing approaches driven solely by outcome rewards often suffer from the problem of sparse supervision. To address the challenge, we propose Tree-based Group Relative Policy Optimization (Tree-GRPO), a grouped agent RL method based on tree search, where each tree node represents the complete agent interaction step. By sharing common prefixes, the tree search sampling increases the number of rollouts achievable within a fixed budget of tokens or tool calls. Moreover, we find that the tree-structured trajectory naturally allows the construction of step-wise process supervised signals even using only the outcome reward. Based on this, Tree-GRPO estimates the grouped relative advantages both on intra-tree and inter-tree levels. Through theoretical analysis, we demonstrate that the objective of intra-tree level group relative policy optimization is equivalent to that of step-level direct preference learning. Experiments across 11 datasets and 3 types of QA tasks demonstrate the superiority of the proposed tree-based RL over the chain-based RL method. </p>
<blockquote>
<p>æœ€è¿‘å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„è¿›å±•å¤§å¤§æé«˜äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†èƒ½åŠ›ã€‚åœ¨é•¿æœŸå’Œå¤šè½®ä»£ç†ä»»åŠ¡ä¸­ï¼Œä»…ç”±ç»“æœå¥–åŠ±é©±åŠ¨çš„ä¼ ç»Ÿæ–¹æ³•å¸¸å¸¸é¢ä¸´ç›‘ç£ç¨€ç–çš„é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºæ ‘æœç´¢çš„åˆ†ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆTree-GRPOï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åˆ†ç»„ä»£ç†RLæ–¹æ³•ï¼Œå…¶ä¸­æ¯ä¸ªæ ‘èŠ‚ç‚¹ä»£è¡¨å®Œæ•´çš„ä»£ç†äº¤äº’æ­¥éª¤ã€‚é€šè¿‡å…±äº«å…¬å…±å‰ç¼€ï¼Œæ ‘æœç´¢é‡‡æ ·å¢åŠ äº†åœ¨å›ºå®šé¢„ç®—çš„ä»¤ç‰Œæˆ–å·¥å…·è°ƒç”¨æœŸé—´å¯å®ç°çš„æ»šåŠ¨æ¬¡æ•°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°æ ‘çŠ¶è½¨è¿¹è‡ªç„¶åœ°å…è®¸å³ä½¿åªä½¿ç”¨ç»“æœå¥–åŠ±ä¹Ÿèƒ½æ„å»ºé€æ­¥è¿‡ç¨‹ç›‘ç£ä¿¡å·ã€‚åŸºäºæ­¤ï¼ŒTree-GRPOä¼°è®¡äº†æ ‘å†…å’Œæ ‘é—´çš„åˆ†ç»„ç›¸å¯¹ä¼˜åŠ¿ã€‚é€šè¿‡ç†è®ºåˆ†æï¼Œæˆ‘ä»¬è¯æ˜äº†æ ‘å†…çº§åˆ«åˆ†ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–çš„ç›®æ ‡ä¸æ­¥éª¤çº§åˆ«ç›´æ¥åå¥½å­¦ä¹ çš„ç›®æ ‡æ˜¯ä¸€è‡´çš„ã€‚åœ¨11ä¸ªæ•°æ®é›†å’Œ3ç§é—®ç­”ä»»åŠ¡ä¸Šçš„å®éªŒè¯æ˜äº†åŸºäºæ ‘çš„RLä¼˜äºåŸºäºé“¾çš„RLæ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21240v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†èƒ½åŠ›æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚åœ¨é•¿æœŸå’Œå¤šè½®ä»£ç†ä»»åŠ¡ä¸­ï¼Œä»…ç”±ç»“æœå¥–åŠ±é©±åŠ¨çš„ç°æœ‰æ–¹æ³•å¸¸å¸¸é¢ä¸´ç›‘ç£ç¨€ç–çš„é—®é¢˜ã€‚ä¸ºè§£å†³æ­¤æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºæ ‘æœç´¢çš„åˆ†ç»„ä»£ç†å¼ºåŒ–å­¦ä¹ æ–¹æ³•â€”â€”Tree-GRPOã€‚æ ‘ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨å®Œæ•´çš„ä»£ç†äº¤äº’æ­¥éª¤ï¼Œé€šè¿‡å…±äº«å…±åŒçš„å‰ç¼€ï¼Œæ ‘æœç´¢é‡‡æ ·æé«˜äº†åœ¨å›ºå®šé¢„ç®—çš„æ ‡è®°æˆ–å·¥å…·è°ƒç”¨æ¬¡æ•°ä¸­å¯å®ç°çš„rolloutsçš„æ•°é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°æ ‘ç»“æ„è½¨è¿¹è‡ªç„¶å…è®¸æ„å»ºåˆ†æ­¥è¿‡ç¨‹ç›‘ç£ä¿¡å·ï¼Œå³ä½¿åªä½¿ç”¨ç»“æœå¥–åŠ±ã€‚åŸºäºæ­¤ï¼ŒTree-GRPOä¼°è®¡äº†æ ‘å†…å’Œæ ‘é—´çš„åˆ†ç»„ç›¸å¯¹ä¼˜åŠ¿ã€‚é€šè¿‡ç†è®ºåˆ†æï¼Œæˆ‘ä»¬è¯æ˜äº†æ ‘å†…çº§åˆ«çš„åˆ†ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ç›®æ ‡ä¸æ­¥éª¤çº§åˆ«çš„ç›´æ¥åå¥½å­¦ä¹ ç›®æ ‡æ˜¯ç­‰ä»·çš„ã€‚è·¨11ä¸ªæ•°æ®é›†å’Œ3ç§é—®ç­”ä»»åŠ¡çš„å®éªŒè¯æ˜äº†åŸºäºæ ‘çš„å¼ºåŒ–å­¦ä¹ ç›¸è¾ƒäºåŸºäºé“¾çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ å¢å¼ºäº†å¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†èƒ½åŠ›ã€‚</li>
<li>åœ¨é•¿æœŸå’Œå¤šè½®ä»£ç†ä»»åŠ¡ä¸­ï¼Œç°æœ‰æ–¹æ³•é¢ä¸´ç›‘ç£ç¨€ç–çš„é—®é¢˜ã€‚</li>
<li>Tree-GRPOæ˜¯ä¸€ç§åŸºäºæ ‘æœç´¢çš„åˆ†ç»„ä»£ç†å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚</li>
<li>æ ‘æœç´¢é€šè¿‡å…±äº«å‰ç¼€æé«˜äº†rolloutsçš„æ•°é‡ã€‚</li>
<li>æ ‘ç»“æ„è½¨è¿¹å…è®¸æ„å»ºåˆ†æ­¥è¿‡ç¨‹ç›‘ç£ä¿¡å·ï¼Œå³ä½¿åªä½¿ç”¨ç»“æœå¥–åŠ±ã€‚</li>
<li>Tree-GRPOä¼°è®¡äº†æ ‘å†…å’Œæ ‘é—´çš„åˆ†ç»„ç›¸å¯¹ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21240">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d57591234dfc8351abfab2140917af24" align="middle">
<img src="https://picx.zhimg.com/v2-c7f19634b6665ebcc39d85c51eec0f1a" align="middle">
<img src="https://picx.zhimg.com/v2-afcb6cf789dae8597d7b22aafea00fbf" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="SGMem-Sentence-Graph-Memory-for-Long-Term-Conversational-Agents"><a href="#SGMem-Sentence-Graph-Memory-for-Long-Term-Conversational-Agents" class="headerlink" title="SGMem: Sentence Graph Memory for Long-Term Conversational Agents"></a>SGMem: Sentence Graph Memory for Long-Term Conversational Agents</h2><p><strong>Authors:Yaxiong Wu, Yongyue Zhang, Sheng Liang, Yong Liu</strong></p>
<p>Long-term conversational agents require effective memory management to handle dialogue histories that exceed the context window of large language models (LLMs). Existing methods based on fact extraction or summarization reduce redundancy but struggle to organize and retrieve relevant information across different granularities of dialogue and generated memory. We introduce SGMem (Sentence Graph Memory), which represents dialogue as sentence-level graphs within chunked units, capturing associations across turn-, round-, and session-level contexts. By combining retrieved raw dialogue with generated memory such as summaries, facts and insights, SGMem supplies LLMs with coherent and relevant context for response generation. Experiments on LongMemEval and LoCoMo show that SGMem consistently improves accuracy and outperforms strong baselines in long-term conversational question answering. </p>
<blockquote>
<p>é•¿æœŸå¯¹è¯ä»£ç†éœ€è¦æœ‰æ•ˆçš„å†…å­˜ç®¡ç†æ¥å¤„ç†è¶…è¿‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸Šä¸‹æ–‡çª—å£çš„å¯¹è¯å†å²ã€‚ç°æœ‰åŸºäºäº‹å®æå–æˆ–æ‘˜è¦çš„æ–¹æ³•è™½ç„¶å¯ä»¥å‡å°‘å†—ä½™ï¼Œä½†åœ¨ä¸åŒç²’åº¦çš„å¯¹è¯å’Œç»„ç»‡æ£€ç´¢ç›¸å…³ä¿¡æ¯æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œä»¥åŠåœ¨ç”Ÿæˆå†…å­˜æ—¶çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬å¼•å…¥SGMemï¼ˆå¥å­å›¾å†…å­˜ï¼‰ï¼Œå®ƒå°†å¯¹è¯è¡¨ç¤ºä¸ºåˆ†å—å•å…ƒå†…çš„å¥å­çº§å›¾å½¢ï¼Œæ•æ‰è½®æ¬¡ã€å›åˆå’Œä¼šè¯çº§ä¸Šä¸‹æ–‡ä¹‹é—´çš„å…³è”ã€‚é€šè¿‡å°†æ£€ç´¢åˆ°çš„åŸå§‹å¯¹è¯ä¸ç”Ÿæˆçš„å†…å­˜ï¼ˆå¦‚æ‘˜è¦ã€äº‹å®å’Œè§è§£ï¼‰ç›¸ç»“åˆï¼ŒSGMemä¸ºLLMæä¾›è¿è´¯ä¸”ç›¸å…³çš„ä¸Šä¸‹æ–‡ï¼Œä»¥ç”Ÿæˆå“åº”ã€‚åœ¨LongMemEvalå’ŒLoCoMoä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSGMemåœ¨é—®ç­”ä¸­é•¿æœŸå¯¹è¯çš„å‡†ç¡®æ€§å’Œè¡¨ç°å‡è¡¨ç°ä¼˜äºå¼ºå¤§çš„åŸºçº¿æ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21212v1">PDF</a> 19 pages, 6 figures, 1 table</p>
<p><strong>Summary</strong>ï¼š<br>é•¿æœŸå¯¹è¯æœºå™¨äººéœ€è¦æœ‰æ•ˆçš„å†…å­˜ç®¡ç†æ¥åº”å¯¹è¶…å‡ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸Šä¸‹æ–‡çª—å£çš„å¯¹è¯å†å²ã€‚ç°æœ‰æ–¹æ³•åŸºäºäº‹å®æå–æˆ–æ‘˜è¦å‡å°‘å†—ä½™ï¼Œä½†éš¾ä»¥ç»„ç»‡å’Œæ£€ç´¢ä¸åŒç²’åº¦å¯¹è¯å’Œç”Ÿæˆè®°å¿†ä¸­çš„ç›¸å…³ä¿¡æ¯ã€‚æˆ‘ä»¬æå‡ºSGMemï¼ˆå¥å­å›¾å†…å­˜ï¼‰ï¼Œå®ƒå°†å¯¹è¯è¡¨ç¤ºä¸ºå¥å­çº§å›¾å—å†…çš„å—çŠ¶å•å…ƒï¼Œæ•æ‰è·¨è½®æ¬¡ã€å›åˆå’Œä¼šè¯çº§åˆ«çš„ä¸Šä¸‹æ–‡å…³è”ã€‚é€šè¿‡å°†æ£€ç´¢åˆ°çš„åŸå§‹å¯¹è¯ä¸ç”Ÿæˆçš„å†…å­˜ï¼ˆå¦‚æ‘˜è¦ã€äº‹å®å’Œè§è§£ï¼‰ç›¸ç»“åˆï¼ŒSGMemä¸ºLLMæä¾›è¿è´¯ä¸”ç›¸å…³çš„ä¸Šä¸‹æ–‡ï¼Œç”¨äºç”Ÿæˆå“åº”ã€‚åœ¨LongMemEvalå’ŒLoCoMoä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSGMemåœ¨é•¿æœŸçš„å¯¹è¯é—®ç­”ä¸­æé«˜äº†å‡†ç¡®æ€§å¹¶è¶…è¶Šäº†å¼ºå¤§çš„åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>é•¿æœŸå¯¹è¯æœºå™¨äººéœ€è¦æœ‰æ•ˆç®¡ç†å†…å­˜æ¥åº”å¯¹è¶…å‡ºå¤§å‹è¯­è¨€æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£çš„å¯¹è¯å†å²ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦åŸºäºäº‹å®æå–æˆ–æ‘˜è¦æŠ€æœ¯æ¥å¤„ç†å¯¹è¯å†å²ï¼Œä½†å­˜åœ¨ç»„ç»‡ç›¸å…³ä¿¡æ¯çš„æŒ‘æˆ˜ã€‚</li>
<li>SGMemé€šè¿‡å¥å­çº§å›¾å—è¡¨ç¤ºå¯¹è¯ï¼Œæ•æ‰ä¸åŒç²’åº¦ï¼ˆè½®æ¬¡ã€å›åˆå’Œä¼šè¯çº§åˆ«ï¼‰çš„ä¸Šä¸‹æ–‡å…³è”ã€‚</li>
<li>SGMemç»“åˆäº†æ£€ç´¢åˆ°çš„åŸå§‹å¯¹è¯å’Œç”Ÿæˆçš„å†…å­˜ï¼ˆå¦‚æ‘˜è¦ã€äº‹å®å’Œè§è§£ï¼‰ã€‚</li>
<li>SGMemä¸ºLLMæä¾›äº†è¿è´¯ä¸”ç›¸å…³çš„ä¸Šä¸‹æ–‡ï¼Œå¢å¼ºäº†å“åº”ç”Ÿæˆçš„èƒ½åŠ›ã€‚</li>
<li>åœ¨LongMemEvalå’ŒLoCoMoå®éªŒä¸Šï¼ŒSGMemåœ¨é•¿æœŸçš„å¯¹è¯é—®ç­”ä¸­è¡¨ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21212">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-60e8dbf6c4803a0bfd418eaff86519d4" align="middle">
<img src="https://picx.zhimg.com/v2-061fce753eccbbc82bb50ff90bab6b1b" align="middle">
<img src="https://picx.zhimg.com/v2-2ca32906cbd9630d55de2d1702cc92ad" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Eigen-1-Adaptive-Multi-Agent-Refinement-with-Monitor-Based-RAG-for-Scientific-Reasoning"><a href="#Eigen-1-Adaptive-Multi-Agent-Refinement-with-Monitor-Based-RAG-for-Scientific-Reasoning" class="headerlink" title="Eigen-1: Adaptive Multi-Agent Refinement with Monitor-Based RAG for   Scientific Reasoning"></a>Eigen-1: Adaptive Multi-Agent Refinement with Monitor-Based RAG for   Scientific Reasoning</h2><p><strong>Authors:Xiangru Tang, Wanghan Xu, Yujie Wang, Zijie Guo, Daniel Shao, Jiapeng Chen, Cixuan Zhang, Ziyi Wang, Lixin Zhang, Guancheng Wan, Wenlong Zhang, Lei Bai, Zhenfei Yin, Philip Torr, Hanrui Wang, Di Jin</strong></p>
<p>Large language models (LLMs) have recently shown strong progress on scientific reasoning, yet two major bottlenecks remain. First, explicit retrieval fragments reasoning, imposing a hidden â€œtool taxâ€ of extra tokens and steps. Second, multi-agent pipelines often dilute strong solutions by averaging across all candidates. We address these challenges with a unified framework that combines implicit retrieval and structured collaboration. At its foundation, a Monitor-based retrieval module operates at the token level, integrating external knowledge with minimal disruption to reasoning. On top of this substrate, Hierarchical Solution Refinement (HSR) iteratively designates each candidate as an anchor to be repaired by its peers, while Quality-Aware Iterative Reasoning (QAIR) adapts refinement to solution quality. On Humanityâ€™s Last Exam (HLE) Bio&#x2F;Chem Gold, our framework achieves 48.3% accuracy â€“ the highest reported to date, surpassing the strongest agent baseline by 13.4 points and leading frontier LLMs by up to 18.1 points, while simultaneously reducing token usage by 53.5% and agent steps by 43.7%. Results on SuperGPQA and TRQA confirm robustness across domains. Error analysis shows that reasoning failures and knowledge gaps co-occur in over 85% of cases, while diversity analysis reveals a clear dichotomy: retrieval tasks benefit from solution variety, whereas reasoning tasks favor consensus. Together, these findings demonstrate how implicit augmentation and structured refinement overcome the inefficiencies of explicit tool use and uniform aggregation. Code is available at: <a target="_blank" rel="noopener" href="https://github.com/tangxiangru/Eigen-1">https://github.com/tangxiangru/Eigen-1</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç§‘æŠ€æ¨ç†æ–¹é¢æœ€è¿‘å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»ç„¶å­˜åœ¨ä¸¤ä¸ªä¸»è¦ç“¶é¢ˆã€‚é¦–å…ˆï¼Œæ˜ç¡®çš„æ£€ç´¢ç‰‡æ®µæ¨ç†ï¼Œä¼šé¢å¤–å¢åŠ æ ‡è®°å’Œæ­¥éª¤ï¼Œä»è€Œäº§ç”Ÿä¸€ç§éšè—çš„â€œå·¥å…·ç¨â€ã€‚å…¶æ¬¡ï¼Œå¤šæ™ºèƒ½ä½“ç®¡é“å¾€å¾€ä¼šé€šè¿‡å¹³å‡æ‰€æœ‰å€™é€‰è€…æ¥å‰Šå¼±å¼ºæœ‰åŠ›çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬ç”¨ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶æ¥è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†éšå¼æ£€ç´¢å’Œç»“æ„åŒ–åä½œã€‚åœ¨è¯¥æ¡†æ¶çš„åŸºç¡€ä¸Šï¼Œä¸€ä¸ªåŸºäºç›‘è§†å™¨çš„æ£€ç´¢æ¨¡å—åœ¨ä»¤ç‰Œå±‚é¢è¿è¡Œï¼Œå°†å¤–éƒ¨çŸ¥è¯†ä¸æ¨ç†çš„å¹²æ‰°é™è‡³æœ€ä½ã€‚åœ¨è¿™ä¸ªåŸºç¡€ä¹‹ä¸Šï¼Œåˆ†å±‚è§£å†³æ–¹æ¡ˆç²¾ç‚¼ï¼ˆHSRï¼‰ä¼šè¿­ä»£åœ°æŒ‡å®šæ¯ä¸ªå€™é€‰è€…ä½œä¸ºé”šç‚¹ï¼Œç”±åŒé¾„äººè¿›è¡Œä¿®å¤ï¼Œè€Œè´¨é‡æ„ŸçŸ¥è¿­ä»£æ¨ç†ï¼ˆQAIRï¼‰åˆ™æ ¹æ®è§£å†³æ–¹æ¡ˆè´¨é‡è¿›è¡Œç²¾ç‚¼ã€‚åœ¨äººç±»æœ€åè€ƒè¯•ï¼ˆHLEï¼‰ç”Ÿç‰©&#x2F;åŒ–å­¦é‡‘ç‰Œç§‘ç›®ä¸Šï¼Œæˆ‘ä»¬çš„æ¡†æ¶è¾¾åˆ°äº†48.3%çš„å‡†ç¡®ç‡â€”â€”è¿™æ˜¯è¿„ä»Šä¸ºæ­¢æŠ¥å‘Šçš„æœ€é«˜å‡†ç¡®ç‡ï¼Œæ¯”æœ€å¼ºçš„æ™ºèƒ½ä½“åŸºå‡†é«˜å‡º13.4ä¸ªç™¾åˆ†ç‚¹ï¼Œé¢†å…ˆå‰æ²¿çš„LLMé«˜è¾¾18.1ä¸ªç™¾åˆ†ç‚¹ï¼ŒåŒæ—¶å‡å°‘äº†53.5%çš„ä»¤ç‰Œä½¿ç”¨é‡å’Œ43.7%çš„æ™ºèƒ½ä½“æ­¥éª¤ã€‚åœ¨SuperGPQAå’ŒTRQAä¸Šçš„ç»“æœè¯å®äº†å…¶åœ¨ä¸åŒé¢†åŸŸçš„ç¨³å¥æ€§ã€‚é”™è¯¯åˆ†æè¡¨æ˜ï¼Œæ¨ç†å¤±è´¥å’ŒçŸ¥è¯†ç©ºç™½åœ¨è¶…è¿‡85%çš„æƒ…å†µä¸‹åŒæ—¶å­˜åœ¨ï¼Œè€Œå¤šæ ·æ€§åˆ†ææ˜¾ç¤ºäº†ä¸€ä¸ªæ˜ç¡®çš„äºŒå…ƒæ€§ï¼šæ£€ç´¢ä»»åŠ¡å—ç›Šäºè§£å†³æ–¹æ¡ˆçš„å¤šæ ·æ€§ï¼Œè€Œæ¨ç†ä»»åŠ¡åˆ™å€¾å‘äºè¾¾æˆå…±è¯†ã€‚è¿™äº›å‘ç°å…±åŒè¡¨æ˜ï¼Œéšå¼å¢å¼ºå’Œç»“æ„åŒ–ç²¾ç‚¼å¦‚ä½•å…‹æœæ˜¾å¼å·¥å…·ä½¿ç”¨å’Œç»Ÿä¸€èšåˆçš„æ•ˆç‡ä½ä¸‹é—®é¢˜ã€‚ä»£ç å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/tangxiangru/Eigen-1%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/tangxiangru/Eigen-1ä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21193v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç§‘å­¦æ¨ç†æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»å­˜åœ¨ä¸¤ä¸ªä¸»è¦ç“¶é¢ˆï¼šä¸€æ˜¯æ˜¾å¼æ£€ç´¢ç‰‡æ®µåŒ–æ¨ç†ï¼Œå¢åŠ äº†é¢å¤–çš„æ ‡è®°å’Œæ­¥éª¤çš„â€œå·¥å…·ç¨â€ï¼›äºŒæ˜¯å¤šä»£ç†ç®¡é“å¾€å¾€ä¼šé€šè¿‡å¹³å‡æ‰€æœ‰å€™é€‰è€…æ¥å‰Šå¼±ä¼˜è´¨è§£å†³æ–¹æ¡ˆçš„ä¼˜åŠ¿ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œç»“åˆéšå¼æ£€ç´¢å’Œç»“æ„åŒ–åä½œæ¥è§£å†³è¿™äº›æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶ä»¥ç›‘æ§å™¨ä¸ºåŸºç¡€çš„æ£€ç´¢æ¨¡å—åœ¨ä»¤ç‰Œçº§åˆ«è¿è¡Œï¼Œå°†å¤–éƒ¨çŸ¥è¯†ä¸æ¨ç†çš„å¹²æ‰°é™è‡³æœ€ä½ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œåˆ†å±‚è§£å†³æ–¹æ¡ˆç»†åŒ–ï¼ˆHSRï¼‰ä¼šè¿­ä»£åœ°æŒ‡å®šæ¯ä¸ªå€™é€‰è€…ä½œä¸ºé”šç‚¹ï¼Œç”±åŒé¾„äººè¿›è¡Œä¿®å¤ï¼Œè€Œè´¨é‡æ„ŸçŸ¥è¿­ä»£æ¨ç†ï¼ˆQAIRï¼‰åˆ™æ ¹æ®è§£å†³æ–¹æ¡ˆè´¨é‡è¿›è¡Œé€‚åº”ã€‚åœ¨Humanityâ€™s Last Examï¼ˆHLEï¼‰ç”Ÿç‰©&#x2F;åŒ–å­¦é‡‘ç‰Œä»»åŠ¡ä¸Šï¼Œæˆ‘ä»¬çš„æ¡†æ¶è¾¾åˆ°äº†48.3%çš„å‡†ç¡®ç‡ï¼Œè¿™æ˜¯è¿„ä»Šä¸ºæ­¢æŠ¥å‘Šçš„æœ€é«˜å€¼ï¼Œæ¯”æœ€å¼ºä»£ç†åŸºçº¿é«˜å‡º13.4ä¸ªç™¾åˆ†ç‚¹ï¼Œé¢†å…ˆå‰æ²¿çš„å¤§å‹è¯­è¨€æ¨¡å‹æœ€å¤šè¾¾18.1ä¸ªç™¾åˆ†ç‚¹ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶å‡å°‘äº†53.5%çš„ä»¤ç‰Œä½¿ç”¨é‡å’Œ43.7%çš„ä»£ç†æ­¥éª¤ã€‚åœ¨SuperGPQAå’ŒTRQAä¸Šçš„ç»“æœè¯å®äº†å…¶åœ¨ä¸åŒé¢†åŸŸçš„ç¨³å¥æ€§ã€‚é”™è¯¯åˆ†æè¡¨æ˜ï¼Œæ¨ç†å¤±è´¥å’ŒçŸ¥è¯†å·®è·åœ¨è¶…è¿‡85%çš„æƒ…å†µä¸‹åŒæ—¶å‘ç”Ÿï¼Œè€Œå¤šæ ·æ€§åˆ†ææ˜¾ç¤ºå­˜åœ¨ä¸€ä¸ªæ˜ç¡®çš„äºŒåˆ†æ³•ï¼šæ£€ç´¢ä»»åŠ¡å—ç›Šäºè§£å†³æ–¹æ¡ˆçš„å¤šæ ·æ€§ï¼Œè€Œæ¨ç†ä»»åŠ¡åˆ™å€¾å‘äºå…±è¯†ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œéšå¼å¢å¼ºå’Œç»“æ„åŒ–ç»†åŒ–å¦‚ä½•å…‹æœæ˜¾å¼å·¥å…·ä½¿ç”¨å’Œç»Ÿä¸€èšåˆçš„æ— æ•ˆæ€§ã€‚ç›¸å…³ä»£ç å¯è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/tangxiangru/Eigen-1%E3%80%82">https://github.com/tangxiangru/Eigen-1ã€‚</a></p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç§‘å­¦æ¨ç†æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—è¿›å±•ï¼Œä½†ä»å­˜åœ¨ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šé¢å¤–æ ‡è®°å’Œæ­¥éª¤çš„â€œå·¥å…·ç¨â€ä»¥åŠå¤šä»£ç†ç®¡é“çš„å¹³å‡æ•ˆåº”ã€‚</li>
<li>æå‡ºä¸€ç§ç»“åˆéšå¼æ£€ç´¢å’Œç»“æ„åŒ–åä½œçš„ç»Ÿä¸€æ¡†æ¶ï¼Œè§£å†³ä¸Šè¿°æŒ‘æˆ˜ã€‚</li>
<li>æ¡†æ¶ä¸­çš„ç›‘è§†å™¨åŸºç¡€æ£€ç´¢æ¨¡å—åœ¨ä»¤ç‰Œçº§åˆ«æ“ä½œï¼Œå‡å°‘å¤–éƒ¨çŸ¥è¯†ä¸æ¨ç†ä¹‹é—´çš„å¹²æ‰°ã€‚</li>
<li>é€šè¿‡åˆ†å±‚è§£å†³æ–¹æ¡ˆç»†åŒ–å’Œè´¨é‡æ„ŸçŸ¥è¿­ä»£æ¨ç†ï¼Œæé«˜è§£å†³æ–¹æ¡ˆçš„è´¨é‡å’Œæ•ˆç‡ã€‚</li>
<li>åœ¨Humanityâ€™s Last Examä»»åŠ¡ä¸Šè¾¾åˆ°48.3%çš„å‡†ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•å’Œå¤§å‹è¯­è¨€æ¨¡å‹ã€‚</li>
<li>é”™è¯¯åˆ†ææ˜¾ç¤ºæ¨ç†å¤±è´¥å’ŒçŸ¥è¯†å·®è·ç»å¸¸åŒæ—¶å‘ç”Ÿï¼Œè€Œå¤šæ ·æ€§åˆ†ææ­ç¤ºå‡ºè§£å†³æ–¹æ¡ˆå¤šæ ·æ€§ä¸æ¨ç†ä»»åŠ¡å…±è¯†ä¹‹é—´çš„å¹³è¡¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21193">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9bff588bf2f845bb230f58bfe527cba0" align="middle">
<img src="https://picx.zhimg.com/v2-7ff3bc4d2de06bdecfb2efd0e63bc7bf" align="middle">
<img src="https://picx.zhimg.com/v2-aa1eb57e8ca4a53950dc0e667763ac0a" align="middle">
<img src="https://picx.zhimg.com/v2-cf21faff35809d36c0d2cefbb412ec60" align="middle">
<img src="https://picx.zhimg.com/v2-bf5c86e8d96d122821067678190a9dac" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="ToMPO-Training-LLM-Strategic-Decision-Making-from-a-Multi-Agent-Perspective"><a href="#ToMPO-Training-LLM-Strategic-Decision-Making-from-a-Multi-Agent-Perspective" class="headerlink" title="ToMPO: Training LLM Strategic Decision Making from a Multi-Agent   Perspective"></a>ToMPO: Training LLM Strategic Decision Making from a Multi-Agent   Perspective</h2><p><strong>Authors:Yiwen Zhang, Ziang Chen, Fanqi Kong, Yizhe Huang, Xue Feng</strong></p>
<p>Large Language Models (LLMs) have been used to make decisions in complex scenarios, where they need models to think deeply, reason logically, and decide wisely. Many existing studies focus solely on multi-round conversations in social tasks or simulated environments, neglecting the various types of decisions and their interdependence. Current reinforcement learning methods struggle to consider the strategies of others during training. To address these issues, we first define a strategic decision-making problem that includes two types of decisions and their temporal dependencies. Furthermore, we propose <strong>T</strong>heory <strong>o</strong>f <strong>M</strong>ind <strong>P</strong>olicy <strong>O</strong>ptimization <strong>(ToMPO)</strong> algorithm to optimize the perception of other individual strategies and the game situation trends. Compared to the Group Relative Policy Optimization (GRPO) algorithm, ToMPO enhances the LLMâ€™s strategic decision-making mainly by: 1) generating rollouts based on reasoning the strategies of other individuals, 2) estimating advantages at both the graph-level and sample-level, and 3) balancing global and partial rewards. The ToMPO algorithm outperforms the GRPO method by 35% in terms of model output compliance and cooperative outcomes. Additionally, when compared to models with parameter sizes 100 times larger, it shows an 18% improvement. This demonstrates the effectiveness of the ToMPO algorithm in enhancing the modelâ€™s strategic decision-making capabilities. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²è¢«åº”ç”¨äºå¤æ‚åœºæ™¯ä¸­çš„å†³ç­–ï¼Œè¿™äº›åœºæ™¯éœ€è¦æ¨¡å‹è¿›è¡Œæ·±åº¦æ€è€ƒã€é€»è¾‘æ¨æ–­å’Œæ˜æ™ºå†³ç­–ã€‚è®¸å¤šç°æœ‰ç ”ç©¶ä»…ä¸“æ³¨äºç¤¾ä¼šä»»åŠ¡æˆ–æ¨¡æ‹Ÿç¯å¢ƒä¸­çš„å¤šè½®å¯¹è¯ï¼Œå¿½è§†äº†å„ç§ç±»å‹çš„å†³ç­–åŠå…¶ç›¸äº’ä¾èµ–æ€§ã€‚å½“å‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¾ˆéš¾è€ƒè™‘åˆ°ä»–äººçš„ç­–ç•¥ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬é¦–å…ˆå®šä¹‰äº†ä¸€ä¸ªæˆ˜ç•¥å†³ç­–é—®é¢˜ï¼ŒåŒ…æ‹¬ä¸¤ç§ç±»å‹çš„å†³ç­–åŠå…¶æ—¶é—´ä¾èµ–æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†<strong>ToMPOï¼ˆæ€ç»´ç­–ç•¥ä¼˜åŒ–ç†è®ºï¼‰ç®—æ³•</strong>ï¼Œä»¥ä¼˜åŒ–å¯¹å…¶ä»–ä¸ªä½“ç­–ç•¥å’Œæ¸¸æˆå±€åŠ¿è¶‹åŠ¿çš„æ„ŸçŸ¥ã€‚ä¸ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ç®—æ³•ç›¸æ¯”ï¼ŒToMPOä¸»è¦é€šè¿‡ä»¥ä¸‹æ–¹å¼å¢å¼ºLLMçš„æˆ˜ç•¥å†³ç­–èƒ½åŠ›ï¼š1ï¼‰åŸºäºæ¨ç†å…¶ä»–ä¸ªä½“çš„ç­–ç•¥ç”Ÿæˆæ»šåŠ¨ç»“æœï¼Œ2ï¼‰åœ¨å›¾å½¢çº§åˆ«å’Œæ ·æœ¬çº§åˆ«ä¼°è®¡ä¼˜åŠ¿ï¼Œ3ï¼‰å¹³è¡¡å…¨å±€å’Œå±€éƒ¨å¥–åŠ±ã€‚åœ¨æ¨¡å‹è¾“å‡ºç¬¦åˆåº¦å’Œåˆä½œç»“æœæ–¹é¢ï¼ŒToMPOç®—æ³•æ¯”GRPOæ–¹æ³•é«˜å‡º35%ã€‚æ­¤å¤–ï¼Œä¸å‚æ•°è§„æ¨¡å¤§100å€çš„æ¨¡å‹ç›¸æ¯”ï¼Œå…¶è¡¨ç°å‡ºäº†18%çš„æ”¹è¿›ã€‚è¿™è¯æ˜äº†ToMPOç®—æ³•åœ¨æé«˜æ¨¡å‹æˆ˜ç•¥å†³ç­–èƒ½åŠ›æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21134v1">PDF</a> 22 pages, 14 figures</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤æ‚åœºæ™¯ä¸­çš„å†³ç­–èƒ½åŠ›å—åˆ°å¹¿æ³›å…³æ³¨ã€‚ç°æœ‰ç ”ç©¶å¤šèšç„¦äºç¤¾ä¼šä»»åŠ¡ä¸­çš„å¤šè½®å¯¹è¯æˆ–æ¨¡æ‹Ÿç¯å¢ƒï¼Œå¿½è§†äº†ä¸åŒç±»å‹çš„å†³ç­–åŠå…¶ç›¸äº’ä¾èµ–æ€§ã€‚é’ˆå¯¹ç°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•çš„ä¸è¶³ï¼Œæœ¬æ–‡å®šä¹‰äº†ä¸€ç§åŒ…å«ä¸¤ç§ç±»å‹å†³ç­–åŠå…¶æ—¶é—´ä¾èµ–æ€§çš„æˆ˜ç•¥å†³ç­–é—®é¢˜ã€‚åŒæ—¶ï¼Œæå‡ºäº†å¿ƒæ™ºç­–ç•¥ä¼˜åŒ–ï¼ˆToMPOï¼‰ç®—æ³•ï¼Œä»¥ä¼˜åŒ–å¯¹å…¶ä»–ä¸ªä½“ç­–ç•¥å’Œæ¸¸æˆå±€åŠ¿è¶‹åŠ¿çš„æ„ŸçŸ¥ã€‚ç›¸è¾ƒäºç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ç®—æ³•ï¼ŒToMPOä¸»è¦é€šè¿‡ç”ŸæˆåŸºäºå…¶ä»–ä¸ªä½“ç­–ç•¥æ¨ç†çš„æ»šåŠ¨è¾“å‡ºã€ä¼°è®¡å›¾å½¢å’Œæ ·æœ¬çº§åˆ«çš„ä¼˜åŠ¿ä»¥åŠå¹³è¡¡å…¨å±€å’Œå±€éƒ¨å¥–åŠ±æ¥å¢å¼ºLLMçš„æˆ˜ç•¥å†³ç­–èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒToMPOç®—æ³•åœ¨æ¨¡å‹è¾“å‡ºåˆè§„æ€§å’Œåˆä½œç»“æœæ–¹é¢ä¼˜äºGRPOæ–¹æ³•ï¼Œç›¸è¾ƒäºå‚æ•°è§„æ¨¡å¤§100å€çš„æ¨¡å‹ä¹Ÿæœ‰æ˜¾è‘—æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤æ‚åœºæ™¯ä¸­çš„å†³ç­–èƒ½åŠ›é‡è¦ã€‚</li>
<li>ç°æœ‰ç ”ç©¶å¤šèšç„¦äºç¤¾ä¼šä»»åŠ¡ä¸­çš„å¯¹è¯æ¨¡æ‹Ÿï¼Œå¿½ç•¥äº†ä¸åŒç±»å‹å†³ç­–çš„ç›¸äº’ä¾èµ–æ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŒ…å«ä¸¤ç§ç±»å‹å†³ç­–åŠå…¶æ—¶é—´ä¾èµ–æ€§çš„æˆ˜ç•¥å†³ç­–é—®é¢˜å®šä¹‰ã€‚</li>
<li>ä»‹ç»äº†å¿ƒæ™ºç­–ç•¥ä¼˜åŒ–ï¼ˆToMPOï¼‰ç®—æ³•ï¼Œç”¨äºä¼˜åŒ–å¯¹å…¶ä»–ä¸ªä½“ç­–ç•¥å’Œæ¸¸æˆå±€åŠ¿çš„æ„ŸçŸ¥ã€‚</li>
<li>ToMPOç®—æ³•é€šè¿‡ç”ŸæˆåŸºäºå…¶ä»–ä¸ªä½“ç­–ç•¥çš„æ»šåŠ¨è¾“å‡ºã€ä¼°è®¡å›¾å½¢å’Œæ ·æœ¬çº§åˆ«çš„ä¼˜åŠ¿æ¥å¢å¼ºLLMçš„æˆ˜ç•¥å†³ç­–èƒ½åŠ›ã€‚</li>
<li>ToMPOç®—æ³•åœ¨æ¨¡å‹è¾“å‡ºåˆè§„æ€§å’Œåˆä½œç»“æœæ–¹é¢ä¼˜äºGroup Relative Policy Optimizationï¼ˆGRPOï¼‰ç®—æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21134">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-674b984e17296e33db2b16ba758eb09d" align="middle">
<img src="https://picx.zhimg.com/v2-52bd13bf0cbe16dfd12bf59b1eaf68fe" align="middle">
<img src="https://picx.zhimg.com/v2-72210afc4dc35a39691f4d859382e28d" align="middle">
<img src="https://picx.zhimg.com/v2-1d89946a1fd385d6aebeda5862f84f78" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="EvoMail-Self-Evolving-Cognitive-Agents-for-Adaptive-Spam-and-Phishing-Email-Defense"><a href="#EvoMail-Self-Evolving-Cognitive-Agents-for-Adaptive-Spam-and-Phishing-Email-Defense" class="headerlink" title="EvoMail: Self-Evolving Cognitive Agents for Adaptive Spam and Phishing   Email Defense"></a>EvoMail: Self-Evolving Cognitive Agents for Adaptive Spam and Phishing   Email Defense</h2><p><strong>Authors:Wei Huang, De-Tian Chu, Lin-Yuan Bai, Wei Kang, Hai-Tao Zhang, Bo Li, Zhi-Mo Han, Jing Ge, Hai-Feng Lin</strong></p>
<p>Modern email spam and phishing attacks have evolved far beyond keyword blacklists or simple heuristics. Adversaries now craft multi-modal campaigns that combine natural-language text with obfuscated URLs, forged headers, and malicious attachments, adapting their strategies within days to bypass filters. Traditional spam detection systems, which rely on static rules or single-modality models, struggle to integrate heterogeneous signals or to continuously adapt, leading to rapid performance degradation.   We propose EvoMail, a self-evolving cognitive agent framework for robust detection of spam and phishing. EvoMail first constructs a unified heterogeneous email graph that fuses textual content, metadata (headers, senders, domains), and embedded resources (URLs, attachments). A Cognitive Graph Neural Network enhanced by a Large Language Model (LLM) performs context-aware reasoning across these sources to identify coordinated spam campaigns. Most critically, EvoMail engages in an adversarial self-evolution loop: a â€˜â€™red-teamâ€™â€™ agent generates novel evasion tactics â€“ such as character obfuscation or AI-generated phishing text â€“ while the â€˜â€™blue-teamâ€™â€™ detector learns from failures, compresses experiences into a memory module, and reuses them for future reasoning.   Extensive experiments on real-world datasets (Enron-Spam, Ling-Spam, SpamAssassin, and TREC) and synthetic adversarial variants demonstrate that EvoMail consistently outperforms state-of-the-art baselines in detection accuracy, adaptability to evolving spam tactics, and interpretability of reasoning traces. These results highlight EvoMailâ€™s potential as a resilient and explainable defense framework against next-generation spam and phishing threats. </p>
<blockquote>
<p>ç°ä»£ç”µå­é‚®ä»¶åƒåœ¾é‚®ä»¶å’Œé’“é±¼æ”»å‡»å·²ç»è¿œè¿œè¶…è¶Šäº†å…³é”®è¯é»‘åå•æˆ–ç®€å•å¯å‘å¼æ–¹æ³•ã€‚ç°åœ¨ï¼Œæ”»å‡»è€…ä¼šåˆ¶é€ å¤šæ¨¡å¼æ´»åŠ¨ï¼Œå°†è‡ªç„¶è¯­è¨€æ–‡æœ¬ä¸æ¨¡ç³ŠURLã€ä¼ªé€ æ ‡é¢˜å’Œæ¶æ„é™„ä»¶ç›¸ç»“åˆï¼Œå¹¶åœ¨å‡ å¤©å†…è°ƒæ•´ä»–ä»¬çš„ç­–ç•¥ä»¥ç»•è¿‡è¿‡æ»¤å™¨ã€‚ä¼ ç»Ÿåƒåœ¾é‚®ä»¶æ£€æµ‹ç³»ç»Ÿä¾èµ–äºé™æ€è§„åˆ™æˆ–å•æ¨¡æ€æ¨¡å‹ï¼Œéš¾ä»¥æ•´åˆå¼‚æ„ä¿¡å·æˆ–æŒç»­é€‚åº”ï¼Œå¯¼è‡´æ€§èƒ½è¿…é€Ÿä¸‹é™ã€‚æˆ‘ä»¬æå‡ºäº†EvoMailï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºç¨³å¥æ£€æµ‹åƒåœ¾é‚®ä»¶å’Œé’“é±¼çš„è‡ªè¿›åŒ–è®¤çŸ¥ä»£ç†æ¡†æ¶ã€‚EvoMailé¦–å…ˆæ„å»ºä¸€ä¸ªç»Ÿä¸€çš„å¼‚æ„ç”µå­é‚®ä»¶å›¾ï¼Œèåˆäº†æ–‡æœ¬å†…å®¹ã€å…ƒæ•°æ®ï¼ˆæ ‡é¢˜ã€å‘é€è€…ã€åŸŸåï¼‰å’ŒåµŒå…¥å¼èµ„æºï¼ˆURLã€é™„ä»¶ï¼‰ã€‚ä¸€ä¸ªç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¢å¼ºè®¤çŸ¥å›¾ç¥ç»ç½‘ç»œåœ¨è¿™ç±»æ¥æºä¸­è¿›è¡Œä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¨ç†ï¼Œä»¥è¯†åˆ«åè°ƒçš„åƒåœ¾é‚®ä»¶æ´»åŠ¨ã€‚æœ€é‡è¦çš„æ˜¯ï¼ŒEvoMailå‚ä¸äº†ä¸€ä¸ªå¯¹æŠ—æ€§è‡ªæˆ‘è¿›åŒ–å¾ªç¯ï¼šâ€œçº¢é˜Ÿâ€ä»£ç†ç”Ÿæˆæ–°çš„èº²é¿æŠ€å·§ï¼Œå¦‚å­—ç¬¦æ¨¡ç³Šæˆ–AIç”Ÿæˆçš„é’“é±¼æ–‡æœ¬ï¼Œè€Œâ€œè“é˜Ÿâ€æ£€æµ‹å™¨ä»å¤±è´¥ä¸­å­¦ä¹ ï¼Œå°†ç»éªŒå‹ç¼©åˆ°å†…å­˜æ¨¡å—ä¸­ï¼Œå¹¶é‡æ–°ç”¨äºæœªæ¥çš„æ¨ç†ã€‚åœ¨çœŸå®æ•°æ®é›†ï¼ˆå¦‚Enron-Spamã€Ling-Spamã€SpamAssassinå’ŒTRECï¼‰ä»¥åŠåˆæˆå¯¹æŠ—æ€§å˜ç§ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒEvoMailåœ¨æ£€æµ‹ç²¾åº¦ã€é€‚åº”ä¸æ–­å˜åŒ–çš„åƒåœ¾é‚®ä»¶ç­–ç•¥ä»¥åŠæ¨ç†ç—•è¿¹çš„å¯è§£é‡Šæ€§æ–¹é¢å‡ä¼˜äºæœ€æ–°åŸºçº¿ã€‚è¿™äº›ç»“æœçªæ˜¾äº†EvoMailä½œä¸ºæŠµå¾¡æ–°ä¸€ä»£åƒåœ¾é‚®ä»¶å’Œé’“é±¼å¨èƒçš„åšéŸ§ä¸”å¯è§£é‡Šæ€§å¼ºçš„é˜²å¾¡æ¡†æ¶çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21129v1">PDF</a> </p>
<p><strong>Summary</strong><br>ç°ä»£ç”µå­é‚®ä»¶åƒåœ¾é‚®ä»¶å’Œé’“é±¼æ”»å‡»å·²ç»è¶…è¶Šäº†å…³é”®è¯é»‘åå•æˆ–ç®€å•å¯å‘å¼æ–¹æ³•ã€‚å¯¹æ‰‹ç°åœ¨é‡‡ç”¨å¤šæ¨¡å¼æ´»åŠ¨ï¼Œç»“åˆè‡ªç„¶è¯­è¨€æ–‡æœ¬ã€æ¨¡ç³Šç½‘å€ã€ä¼ªé€ æ ‡é¢˜å’Œæ¶æ„é™„ä»¶ï¼Œå¹¶åœ¨å‡ å¤©å†…è°ƒæ•´ç­–ç•¥ç»•è¿‡è¿‡æ»¤å™¨ã€‚ä¼ ç»Ÿçš„åƒåœ¾é‚®ä»¶æ£€æµ‹ç³»ç»Ÿä¾èµ–äºé™æ€è§„åˆ™æˆ–å•æ¨¡æ€æ¨¡å‹ï¼Œéš¾ä»¥æ•´åˆå¼‚æ„ä¿¡å·æˆ–æŒç»­é€‚åº”ï¼Œå¯¼è‡´æ€§èƒ½è¿…é€Ÿä¸‹é™ã€‚æˆ‘ä»¬æå‡ºEvoMailï¼Œä¸€ç§è‡ªè¿›åŒ–è®¤çŸ¥ä»£ç†æ¡†æ¶ï¼Œç”¨äºç¨³å¥åœ°æ£€æµ‹åƒåœ¾é‚®ä»¶å’Œé’“é±¼é‚®ä»¶ã€‚EvoMailé¦–å…ˆæ„å»ºä¸€ä¸ªç»Ÿä¸€çš„å¼‚æ„ç”µå­é‚®ä»¶å›¾ï¼Œèåˆäº†æ–‡æœ¬å†…å®¹ã€å…ƒæ•°æ®ï¼ˆæ ‡é¢˜ã€å‘é€è€…ã€åŸŸåï¼‰å’ŒåµŒå…¥å¼èµ„æºï¼ˆç½‘å€ã€é™„ä»¶ï¼‰ã€‚ä¸€ä¸ªç”±å¤§å‹è¯­è¨€æ¨¡å‹å¢å¼ºçš„è®¤çŸ¥å›¾ç¥ç»ç½‘ç»œåœ¨è¿™äº›æ¥æºä¸Šæ‰§è¡Œä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¨ç†ï¼Œä»¥è¯†åˆ«ååŒçš„åƒåœ¾é‚®ä»¶æ´»åŠ¨ã€‚æœ€é‡è¦çš„æ˜¯ï¼ŒEvoMailå‚ä¸å¯¹æŠ—æ€§è‡ªè¿›åŒ–å¾ªç¯ï¼šçº¢é˜Ÿä»£ç†ç”Ÿæˆæ–°çš„è§„é¿ç­–ç•¥ï¼Œå¦‚å­—ç¬¦æ¨¡ç³Šæˆ–AIç”Ÿæˆçš„é’“é±¼æ–‡æœ¬ï¼Œè€Œè“é˜Ÿæ£€æµ‹å™¨ä»å¤±è´¥ä¸­å­¦ä¹ ï¼Œå°†ç»éªŒå‹ç¼©åˆ°è®°å¿†æ¨¡å—ä¸­å¹¶é‡å¤ç”¨äºæœªæ¥æ¨ç†ã€‚åœ¨çœŸå®æ•°æ®é›†ï¼ˆå¦‚Enron-Spamã€Ling-Spamã€SpamAssassinå’ŒTRECï¼‰å’Œåˆæˆå¯¹æŠ—å˜ä½“ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒEvoMailåœ¨æ£€æµ‹å‡†ç¡®æ€§ã€é€‚åº”ä¸æ–­å˜åŒ–çš„åƒåœ¾é‚®ä»¶ç­–ç•¥ä»¥åŠæ¨ç†ç—•è¿¹çš„å¯è§£é‡Šæ€§æ–¹é¢å‡ä¼˜äºæœ€æ–°åŸºçº¿ã€‚è¿™äº›ç»“æœçªæ˜¾äº†EvoMailä½œä¸ºå¯¹æŠ—ä¸‹ä¸€ä»£åƒåœ¾é‚®ä»¶å’Œé’“é±¼å¨èƒçš„åšéŸ§ä¸”å¯è§£é‡Šæ€§å¼ºçš„é˜²å¾¡æ¡†æ¶çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°ä»£åƒåœ¾é‚®ä»¶å’Œé’“é±¼æ”»å‡»å·²ç»è¶…è¶Šç®€å•çš„æ£€æµ‹æœºåˆ¶ï¼Œé‡‡ç”¨å¤šæ¨¡å¼ç­–ç•¥ç»“åˆæ–‡æœ¬ã€ç½‘å€å’Œé™„ä»¶ç­‰ã€‚</li>
<li>ä¼ ç»Ÿæ£€æµ‹ç³»ç»Ÿä¾èµ–äºé™æ€è§„åˆ™å’Œå•æ¨¡æ€æ¨¡å‹ï¼Œéš¾ä»¥é€‚åº”æ–°å¨èƒå¹¶å®¹æ˜“æ€§èƒ½ä¸‹é™ã€‚</li>
<li>EvoMailæ˜¯ä¸€ä¸ªè‡ªè¿›åŒ–è®¤çŸ¥ä»£ç†æ¡†æ¶ï¼Œèåˆå¼‚æ„ä¿¡å·å¦‚æ–‡æœ¬ã€å…ƒæ•°æ®å’ŒåµŒå…¥å¼èµ„æºæ¥æ£€æµ‹åƒåœ¾é‚®ä»¶ã€‚</li>
<li>EvoMailé‡‡ç”¨è®¤çŸ¥å›¾ç¥ç»ç½‘ç»œå’Œå¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¨ç†ã€‚</li>
<li>EvoMailå…·æœ‰å¯¹æŠ—æ€§è‡ªæˆ‘è¿›åŒ–èƒ½åŠ›ï¼Œèƒ½ç”Ÿæˆå¹¶åº”å¯¹æ–°å‹è§„é¿ç­–ç•¥ã€‚</li>
<li>å¹¿æ³›å®éªŒè¯æ˜EvoMailåœ¨æ£€æµ‹å‡†ç¡®æ€§ã€é€‚åº”æ€§å’Œå¯è§£é‡Šæ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21129">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6b74985e45300cff79996203278e7d18" align="middle">
<img src="https://picx.zhimg.com/v2-731f0b8d6864d010ad570b0b207903a9" align="middle">
<img src="https://picx.zhimg.com/v2-d09ece7f79cfe56ba7f7a2cb740fd8c4" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Which-Cultural-Lens-Do-Models-Adopt-On-Cultural-Positioning-Bias-and-Agentic-Mitigation-in-LLMs"><a href="#Which-Cultural-Lens-Do-Models-Adopt-On-Cultural-Positioning-Bias-and-Agentic-Mitigation-in-LLMs" class="headerlink" title="Which Cultural Lens Do Models Adopt? On Cultural Positioning Bias and   Agentic Mitigation in LLMs"></a>Which Cultural Lens Do Models Adopt? On Cultural Positioning Bias and   Agentic Mitigation in LLMs</h2><p><strong>Authors:Yixin Wan, Xingrun Chen, Kai-Wei Chang</strong></p>
<p>Large language models (LLMs) have unlocked a wide range of downstream generative applications. However, we found that they also risk perpetuating subtle fairness issues tied to culture, positioning their generations from the perspectives of the mainstream US culture while demonstrating salient externality towards non-mainstream ones. In this work, we identify and systematically investigate this novel culture positioning bias, in which an LLMâ€™s default generative stance aligns with a mainstream view and treats other cultures as outsiders. We propose the CultureLens benchmark with 4000 generation prompts and 3 evaluation metrics for quantifying this bias through the lens of a culturally situated interview script generation task, in which an LLM is positioned as an onsite reporter interviewing local people across 10 diverse cultures. Empirical evaluation on 5 state-of-the-art LLMs reveals a stark pattern: while models adopt insider tones in over 88 percent of US-contexted scripts on average, they disproportionately adopt mainly outsider stances for less dominant cultures. To resolve these biases, we propose 2 inference-time mitigation methods: a baseline prompt-based Fairness Intervention Pillars (FIP) method, and a structured Mitigation via Fairness Agents (MFA) framework consisting of 2 pipelines: (1) MFA-SA (Single-Agent) introduces a self-reflection and rewriting loop based on fairness guidelines. (2) MFA-MA (Multi-Agent) structures the process into a hierarchy of specialized agents: a Planner Agent(initial script generation), a Critique Agent (evaluates initial script against fairness pillars), and a Refinement Agent (incorporates feedback to produce a polished, unbiased script). Empirical results showcase the effectiveness of agent-based methods as a promising direction for mitigating biases in generative LLMs. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²ç»è§£é”äº†ä¼—å¤šä¸‹æ¸¸ç”Ÿæˆå¼åº”ç”¨ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°å®ƒä»¬ä¹Ÿæœ‰ç»´æŒç»†å¾®çš„å…¬å¹³é—®é¢˜çš„é£é™©ï¼Œè¿™äº›é—®é¢˜ä¸æ–‡åŒ–æœ‰å…³ï¼Œå®ƒä»¬ä»ä¸»æµç¾å›½æ–‡åŒ–çš„è§’åº¦å‡ºå‘æ¥å®šä½å…¶ç”Ÿæˆçš„å†…å®¹ï¼ŒåŒæ—¶è¡¨ç°å‡ºå¯¹éä¸»æµæ–‡åŒ–çš„æ˜æ˜¾å¤–éƒ¨æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¯†åˆ«å¹¶ç³»ç»Ÿåœ°ç ”ç©¶äº†è¿™ç§æ–°å‹æ–‡åŒ–å®šä½åè§ï¼ŒLLMçš„é»˜è®¤ç”Ÿæˆç«‹åœºç¬¦åˆä¸»æµè§‚ç‚¹ï¼Œå¹¶å°†å…¶ä»–æ–‡åŒ–è§†ä¸ºå¤–æ¥è€…ã€‚æˆ‘ä»¬æå‡ºäº†CultureLensåŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«4000ä¸ªç”Ÿæˆæç¤ºå’Œ3ä¸ªè¯„ä¼°æŒ‡æ ‡ï¼Œé€šè¿‡æ–‡åŒ–æƒ…å¢ƒä¸‹çš„é‡‡è®¿å‰§æœ¬ç”Ÿæˆä»»åŠ¡æ¥é‡åŒ–è¿™ç§åè§ï¼Œåœ¨è¿™ä¸ªä»»åŠ¡ä¸­ï¼ŒLLMè¢«å®šä½ä¸ºç°åœºè®°è€…ï¼Œé‡‡è®¿æ¥è‡ª10ç§ä¸åŒæ–‡åŒ–çš„å½“åœ°äººã€‚å¯¹5ä¸ªæœ€å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„å®è¯è¯„ä¼°æ­ç¤ºäº†ä¸€ä¸ªé²œæ˜çš„æ¨¡å¼ï¼šå°½ç®¡è¿™äº›æ¨¡å‹åœ¨å¹³å‡è¶…è¿‡88%çš„ç¾å›½è¯­å¢ƒå‰§æœ¬ä¸­é‡‡ç”¨äº†å†…éƒ¨äººçš„è¯­æ°”ï¼Œä½†å®ƒä»¬å¯¹éä¸»å¯¼æ–‡åŒ–çš„å¤–éƒ¨äººç«‹åœºå´å å¾ˆå¤§æ¯”ä¾‹ã€‚ä¸ºäº†è§£å†³è¿™äº›åè§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§æ¨ç†æ—¶é—´ç¼“è§£æ–¹æ³•ï¼šåŸºäºæç¤ºçš„å…¬å¹³å¹²é¢„åŸåˆ™ï¼ˆFIPï¼‰æ–¹æ³•å’Œé€šè¿‡å…¬å¹³ä»£ç†ï¼ˆMFAï¼‰çš„ç»“æ„åŒ–ç¼“è§£æ–¹æ³•ï¼ŒåŒ…æ‹¬ä¸¤ä¸ªç®¡é“ï¼šï¼ˆ1ï¼‰MFA-SAï¼ˆå•ä»£ç†ï¼‰å¼•å…¥åŸºäºå…¬å¹³å‡†åˆ™çš„è‡ªæˆ‘åæ€å’Œé‡å†™å¾ªç¯ã€‚ï¼ˆ2ï¼‰MFA-MAï¼ˆå¤šä»£ç†ï¼‰å°†è¿‡ç¨‹ç»“æ„åŒ–ä¸ºä¸“é—¨ä»£ç†çš„å±‚æ¬¡ç»“æ„ï¼šä¸€ä¸ªè®¡åˆ’ä»£ç†ï¼ˆåˆå§‹å‰§æœ¬ç”Ÿæˆï¼‰ï¼Œä¸€ä¸ªæ‰¹åˆ¤ä»£ç†ï¼ˆè¯„ä¼°åˆå§‹å‰§æœ¬æ˜¯å¦ç¬¦åˆå…¬å¹³åŸåˆ™ï¼‰ï¼Œå’Œä¸€ä¸ªç²¾ç‚¼ä»£ç†ï¼ˆç»“åˆåé¦ˆä»¥äº§ç”Ÿç»è¿‡æŠ›å…‰çš„æ— åè§å‰§æœ¬ï¼‰ã€‚å®è¯ç»“æœå±•ç¤ºäº†åŸºäºä»£ç†çš„æ–¹æ³•ä½œä¸ºå‡è½»å¤§å‹ç”Ÿæˆå¼è¯­è¨€æ¨¡å‹ä¸­åè§çš„æœ‰å‰é€”çš„æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21080v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ºä¸‹æ¸¸ç”Ÿæˆå¼åº”ç”¨æ‰“å¼€äº†å¹¿æ³›çš„å¯èƒ½æ€§ï¼Œä½†åŒæ—¶ä¹Ÿå­˜åœ¨å¾®å¦™çš„å…¬å¹³æ€§é—®é¢˜ï¼Œå³æ¨¡å‹å€¾å‘ä»ä¸»æµç¾å›½æ–‡åŒ–çš„è§†è§’ç”Ÿæˆå†…å®¹ï¼Œå¿½è§†éä¸»æµæ–‡åŒ–ã€‚æœ¬ç ”ç©¶é’ˆå¯¹è¿™ä¸€æ–°å‹æ–‡åŒ–å®šä½åè§è¿›è¡Œç³»ç»Ÿç ”ç©¶ï¼Œå¹¶æå‡ºCultureLensåŸºå‡†æµ‹è¯•ï¼Œé€šè¿‡æ¨¡æ‹Ÿè·¨æ–‡åŒ–è®¿è°ˆåœºæ™¯æ¥é‡åŒ–åè§ç¨‹åº¦ã€‚å®è¯è¯„ä¼°æ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨æ¨¡æ‹Ÿç¾å›½æ–‡åŒ–èƒŒæ™¯ä¸‹çš„è„šæœ¬ä¸­æ›´å€¾å‘é‡‡å–å†…éƒ¨äººè§†è§’ï¼Œè€Œå¯¹éä¸»æµæ–‡åŒ–åˆ™æ›´å€¾å‘é‡‡å–å¤–éƒ¨äººè§†è§’ã€‚ä¸ºè§£å†³åè§é—®é¢˜ï¼Œæœ¬ç ”ç©¶æå‡ºä¸¤ç§æ¨ç†æ—¶é—´ç¼“è§£æ–¹æ³•ï¼šåŸºäºæç¤ºçš„å…¬å¹³å¹²é¢„åŸåˆ™ï¼ˆFIPï¼‰å’Œé€šè¿‡å…¬å¹³æ€§ä»£ç†ï¼ˆMFAï¼‰è¿›è¡Œç»“æ„åŒ–ç¼“è§£ã€‚å®è¯ç»“æœè¡¨æ˜åŸºäºä»£ç†çš„æ–¹æ³•åœ¨ç¼“è§£ç”Ÿæˆå¼LLMåè§æ–¹é¢å±•ç°å‡ºè‰¯å¥½å‰æ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¸‹æ¸¸ç”Ÿæˆå¼åº”ç”¨ä¸­æœ‰å¹¿æ³›ç”¨é€”ï¼Œä½†ä¹Ÿå­˜åœ¨æ–‡åŒ–å®šä½åè§ã€‚</li>
<li>LLMå€¾å‘äºä»ä¸»æµç¾å›½æ–‡åŒ–çš„è§†è§’ç”Ÿæˆå†…å®¹ï¼Œå¿½è§†éä¸»æµæ–‡åŒ–ã€‚</li>
<li>æå‡ºCultureLensåŸºå‡†æµ‹è¯•ï¼Œé€šè¿‡æ¨¡æ‹Ÿè·¨æ–‡åŒ–è®¿è°ˆåœºæ™¯æ¥é‡åŒ–è¿™ç§åè§ã€‚</li>
<li>å®è¯è¯„ä¼°æ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨æ¨¡æ‹Ÿä¸åŒæ–‡åŒ–èƒŒæ™¯ä¸‹çš„è„šæœ¬ç”Ÿæˆä¸­ï¼Œå­˜åœ¨å¯¹ä¸»æµæ–‡åŒ–å’Œéä¸»æµæ–‡åŒ–çš„ä¸åŒç«‹åœºã€‚</li>
<li>ä¸ºè§£å†³åè§é—®é¢˜ï¼Œç ”ç©¶æå‡ºä¸¤ç§æ¨ç†æ—¶é—´ç¼“è§£æ–¹æ³•ï¼šFIPå’ŒMFAã€‚</li>
<li>MFAåŒ…æ‹¬å•ä»£ç†å’Œå¤šä»£ç†ä¸¤ç§æ–¹æ³•ï¼Œé€šè¿‡è‡ªæˆ‘åæ€ã€é‡å†™å’Œå¼•å…¥ä¸“ä¸šä»£ç†æ¥çº æ­£åè§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21080">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8ffb6cb0d30aceea6ff498e312e4f05f" align="middle">
<img src="https://picx.zhimg.com/v2-06c7700e52be1bef9470224ed6b293f6" align="middle">
<img src="https://picx.zhimg.com/v2-a2e256c83029bd92ff6583edb7df706d" align="middle">
<img src="https://picx.zhimg.com/v2-ca65829fc9be527f279a30c6ecd03be6" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Recon-Act-A-Self-Evolving-Multi-Agent-Browser-Use-System-via-Web-Reconnaissance-Tool-Generation-and-Task-Execution"><a href="#Recon-Act-A-Self-Evolving-Multi-Agent-Browser-Use-System-via-Web-Reconnaissance-Tool-Generation-and-Task-Execution" class="headerlink" title="Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web   Reconnaissance, Tool Generation, and Task Execution"></a>Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web   Reconnaissance, Tool Generation, and Task Execution</h2><p><strong>Authors:Kaiwen He, Zhiwei Wang, Chenyi Zhuang, Jinjie Gu</strong></p>
<p>Recent years, multimodal models have made remarkable strides and pave the way for intelligent browser use agents. However, when solving tasks on real world webpages in multi-turn, long-horizon trajectories, current agents still suffer from disordered action sequencing and excessive trial and error during execution. This paper introduces Recon-Act, a self-evolving multi-agent framework grounded in Reconnaissance-Action behavioral paradigm. The system comprises a Reconnaissance Team and an Action Team: the former conducts comparative analysis and tool generation, while the latter handles intent decomposition, tool orchestration, and execution. By contrasting the erroneous trajectories with successful ones, the Reconnaissance Team infers remedies, and abstracts them into a unified notion of generalized tools, either expressed as hints or as rule-based codes, and register to the tool archive in real time. The Action Team reinference the process empowered with these targeting tools, thus establishing a closed-loop training pipeline of data-tools-action-feedback. Following the 6 level implementation roadmap proposed in this work, we have currently reached Level 3 (with limited human-in-the-loop intervention). Leveraging generalized tools obtained through reconnaissance, Recon-Act substantially improves adaptability to unseen websites and solvability on long-horizon tasks, and achieves state-of-the-art performance on the challenging VisualWebArena dataset. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œå¤šæ¨¡æ€æ¨¡å‹å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ï¼Œä¸ºæ™ºèƒ½æµè§ˆå™¨ä½¿ç”¨ä»£ç†çš„åº”ç”¨å¼€è¾Ÿäº†é“è·¯ã€‚ç„¶è€Œï¼Œåœ¨å¤„ç†ç°å®ä¸–ç•Œç½‘é¡µçš„å¤šè½®ã€é•¿å‘¨æœŸè½¨è¿¹çš„ä»»åŠ¡æ—¶ï¼Œå½“å‰ä»£ç†ä»ç„¶å—åˆ°åŠ¨ä½œåºåˆ—æ··ä¹±å’Œæ‰§è¡Œè¿‡ç¨‹ä¸­çš„è¿‡åº¦è¯•é”™çš„å½±å“ã€‚æœ¬æ–‡ä»‹ç»äº†Recon-Actï¼Œä¸€ä¸ªåŸºäºä¾¦å¯Ÿ-è¡ŒåŠ¨è¡Œä¸ºèŒƒå¼çš„è‡ªæˆ‘è¿›åŒ–çš„å¤šä»£ç†æ¡†æ¶ã€‚è¯¥ç³»ç»ŸåŒ…æ‹¬ä¸€ä¸ªä¾¦å¯Ÿé˜Ÿå’Œä¸€ä¸ªè¡ŒåŠ¨é˜Ÿï¼šå‰è€…è¿›è¡Œæ¯”è¾ƒåˆ†æçš„å·¥å…·ç”Ÿæˆï¼Œåè€…å¤„ç†æ„å›¾åˆ†è§£ã€å·¥å…·ç¼–æ’å’Œæ‰§è¡Œã€‚é€šè¿‡å¯¹æ¯”é”™è¯¯çš„è½¨è¿¹å’ŒæˆåŠŸçš„è½¨è¿¹ï¼Œä¾¦å¯Ÿé˜Ÿæ¨æ–­å‡ºè¡¥æ•‘æªæ–½ï¼Œå¹¶å°†å…¶æŠ½è±¡ä¸ºé€šç”¨å·¥å…·çš„ç»Ÿä¸€æ¦‚å¿µï¼Œè¿™äº›å·¥å…·å¯ä»¥ä»¥æç¤ºæˆ–åŸºäºè§„åˆ™çš„ä»£ç å½¢å¼è¡¨è¾¾ï¼Œå¹¶å®æ—¶æ³¨å†Œåˆ°å·¥å…·åº“ä¸­ã€‚è¡ŒåŠ¨é˜Ÿåˆ©ç”¨è¿™äº›æœ‰é’ˆå¯¹æ€§çš„å·¥å…·æ¥åŠ å¼ºæ¨ç†è¿‡ç¨‹ï¼Œä»è€Œå»ºç«‹æ•°æ®-å·¥å…·-è¡ŒåŠ¨-åé¦ˆçš„é—­ç¯è®­ç»ƒç®¡é“ã€‚éµå¾ªæœ¬å·¥ä½œä¸­æå‡ºçš„6çº§å®æ–½è·¯çº¿å›¾ï¼Œæˆ‘ä»¬ç›®å‰å·²è¾¾åˆ°Level 3ï¼ˆæœ‰é™çš„åŠè‡ªåŠ¨åŒ–å¹²é¢„ï¼‰ã€‚é€šè¿‡ä¾¦å¯Ÿè·å¾—çš„é€šç”¨å·¥å…·ï¼ŒRecon-Actå¤§å¤§æé«˜äº†å¯¹æœªè§ç½‘ç«™çš„é€‚åº”æ€§å’Œè§£å†³é•¿æœŸä»»åŠ¡çš„èƒ½åŠ›ï¼Œå¹¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„VisualWebArenaæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21072v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†Recon-Actï¼Œä¸€ç§åŸºäºä¾¦å¯Ÿ-è¡ŒåŠ¨è¡Œä¸ºèŒƒå¼çš„è‡ªè¿›åŒ–å¤šæ™ºèƒ½ä½“æ¡†æ¶ã€‚å®ƒåŒ…å«ä¾¦å¯Ÿå›¢é˜Ÿå’Œè¡ŒåŠ¨å›¢é˜Ÿä¸¤éƒ¨åˆ†ï¼Œåˆ†åˆ«è´Ÿè´£æ¯”è¾ƒåˆ†æã€å·¥å…·ç”Ÿæˆä»¥åŠæ„å›¾åˆ†è§£ã€å·¥å…·ç¼–æ’ä¸æ‰§è¡Œç­‰ä»»åŠ¡ã€‚é€šè¿‡é”™è¯¯è½¨è¿¹ä¸æˆåŠŸè½¨è¿¹çš„å¯¹æ¯”ï¼Œä¾¦å¯Ÿå›¢é˜Ÿæ¨æ–­å‡ºæ”¹è¿›æªæ–½ï¼Œå¹¶æŠ½è±¡ä¸ºé€šç”¨å·¥å…·ï¼Œå®æ—¶æ³¨å†Œè‡³å·¥å…·åº“ã€‚è¡ŒåŠ¨å›¢é˜Ÿåˆ©ç”¨è¿™äº›å·¥å…·å¼ºåŒ–æ¨ç†è¿‡ç¨‹ï¼Œå»ºç«‹ä»æ•°æ®-å·¥å…·-è¡ŒåŠ¨-åé¦ˆçš„é—­ç¯è®­ç»ƒç®¡é“ã€‚ç›®å‰éµå¾ªè¯¥è®ºæ–‡æå‡ºçš„å…­çº§å®æ–½è·¯çº¿å›¾ï¼Œå·²è¾¾æˆLevel 3é˜¶æ®µï¼ˆæœ‰é™çš„äººæœºäº¤äº’ï¼‰ã€‚é€šè¿‡ä¾¦å¯Ÿè·å¾—çš„é€šç”¨å·¥å…·ï¼ŒRecon-Actå¤§å¤§æé«˜äº†å¯¹æœªè§ç½‘ç«™çš„é€‚åº”æ€§å’Œé•¿æœŸä»»åŠ¡çš„è§£å†³èƒ½åŠ›ï¼Œå¹¶åœ¨æŒ‘æˆ˜æ€§çš„VisualWebArenaæ•°æ®é›†ä¸Šå®ç°äº†æœ€ä½³æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€æ¨¡å‹åœ¨æ™ºèƒ½æµè§ˆå™¨ä»£ç†æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚</li>
<li>å½“å‰ä»£ç†åœ¨å¤„ç†å¤šå›åˆã€é•¿æœŸä»»åŠ¡æ—¶ä»å­˜åœ¨è¡ŒåŠ¨åºåˆ—ç´Šä¹±å’Œæ‰§è¡Œä¸­è¿‡å¤šçš„è¯•é”™é—®é¢˜ã€‚</li>
<li>Recon-Actæ˜¯ä¸€ä¸ªåŸºäºä¾¦å¯Ÿ-è¡ŒåŠ¨è¡Œä¸ºèŒƒå¼çš„è‡ªè¿›åŒ–å¤šæ™ºèƒ½ä½“æ¡†æ¶ã€‚</li>
<li>ä¾¦å¯Ÿå›¢é˜Ÿè´Ÿè´£å¯¹æ¯”åˆ†æï¼Œç”Ÿæˆé€šç”¨å·¥å…·å¹¶å®æ—¶æ³¨å†Œè‡³å·¥å…·åº“ã€‚</li>
<li>è¡ŒåŠ¨å›¢é˜Ÿåˆ©ç”¨è¿™äº›é€šç”¨å·¥å…·å¼ºåŒ–æ¨ç†è¿‡ç¨‹ï¼Œå»ºç«‹é—­ç¯è®­ç»ƒç®¡é“ã€‚</li>
<li>ç›®å‰å·²ç»å®ç°äº†Level 3é˜¶æ®µçš„äººæœºäº¤äº’ï¼Œåˆ©ç”¨ä¾¦å¯Ÿè·å¾—çš„é€šç”¨å·¥å…·æé«˜äº†å¯¹æœªè§ç½‘ç«™çš„é€‚åº”æ€§å’Œé•¿æœŸä»»åŠ¡çš„è§£å†³èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21072">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d4037fde1541fa992ab367db26bc7a80" align="middle">
<img src="https://picx.zhimg.com/v2-ee9347c1555be653bfddb8501cd81b7d" align="middle">
<img src="https://picx.zhimg.com/v2-955b16d3f791ef0eeeb07fd284d96eaa" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="MAIFormer-Multi-Agent-Inverted-Transformer-for-Flight-Trajectory-Prediction"><a href="#MAIFormer-Multi-Agent-Inverted-Transformer-for-Flight-Trajectory-Prediction" class="headerlink" title="MAIFormer: Multi-Agent Inverted Transformer for Flight Trajectory   Prediction"></a>MAIFormer: Multi-Agent Inverted Transformer for Flight Trajectory   Prediction</h2><p><strong>Authors:Seokbin Yoon, Keumjin Lee</strong></p>
<p>Flight trajectory prediction for multiple aircraft is essential and provides critical insights into how aircraft navigate within current air traffic flows. However, predicting multi-agent flight trajectories is inherently challenging. One of the major difficulties is modeling both the individual aircraft behaviors over time and the complex interactions between flights. Generating explainable prediction outcomes is also a challenge. Therefore, we propose a Multi-Agent Inverted Transformer, MAIFormer, as a novel neural architecture that predicts multi-agent flight trajectories. The proposed framework features two key attention modules: (i) masked multivariate attention, which captures spatio-temporal patterns of individual aircraft, and (ii) agent attention, which models the social patterns among multiple agents in complex air traffic scenes. We evaluated MAIFormer using a real-world automatic dependent surveillance-broadcast flight trajectory dataset from the terminal airspace of Incheon International Airport in South Korea. The experimental results show that MAIFormer achieves the best performance across multiple metrics and outperforms other methods. In addition, MAIFormer produces prediction outcomes that are interpretable from a human perspective, which improves both the transparency of the model and its practical utility in air traffic control. </p>
<blockquote>
<p>å¯¹äºå¤šæ¶é£æœºçš„é£è¡Œè½¨è¿¹é¢„æµ‹éå¸¸é‡è¦ï¼Œå®ƒæä¾›äº†å¯¹å½“å‰ç©ºä¸­äº¤é€šæµé‡ä¸­é£æœºå¦‚ä½•å¯¼èˆªçš„å…³é”®æ´å¯Ÿã€‚ç„¶è€Œï¼Œé¢„æµ‹å¤šæ™ºèƒ½ä½“é£è¡Œè½¨è¿¹å…·æœ‰å†…åœ¨çš„æŒ‘æˆ˜æ€§ã€‚ä¸»è¦çš„å›°éš¾ä¹‹ä¸€æ˜¯å»ºæ¨¡é£æœºéšæ—¶é—´å˜åŒ–çš„ä¸ªä½“è¡Œä¸ºä»¥åŠèˆªç­ä¹‹é—´çš„å¤æ‚äº¤äº’ã€‚ç”Ÿæˆå¯è§£é‡Šçš„é¢„æµ‹ç»“æœä¹Ÿæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºMAIFormerçš„å¤šæ™ºèƒ½ä½“åå‘Transformerä½œä¸ºé¢„æµ‹å¤šæ™ºèƒ½ä½“é£è¡Œè½¨è¿¹çš„æ–°å‹ç¥ç»ç½‘ç»œæ¶æ„ã€‚è¯¥æ¡†æ¶å…·æœ‰ä¸¤ä¸ªå…³é”®æ³¨æ„åŠ›æ¨¡å—ï¼šï¼ˆiï¼‰æ©ç å¤šå…ƒæ³¨æ„åŠ›ï¼Œç”¨äºæ•æ‰å•ä¸ªé£æœºçš„æ—¶ç©ºæ¨¡å¼ï¼›ï¼ˆiiï¼‰æ™ºèƒ½ä½“æ³¨æ„åŠ›ï¼Œç”¨äºæ¨¡æ‹Ÿå¤æ‚ç©ºä¸­äº¤é€šåœºæ™¯ä¸­å¤šä¸ªæ™ºèƒ½ä½“ä¹‹é—´çš„ç¤¾äº¤æ¨¡å¼ã€‚æˆ‘ä»¬ä½¿ç”¨éŸ©å›½ä»å·å›½é™…æœºåœºç»ˆç«¯ç©ºåŸŸçš„è‡ªåŠ¨ç›¸å…³ç›‘è§†å¹¿æ’­é£è¡Œè½¨è¿¹æ•°æ®é›†å¯¹MAIFormerè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMAIFormeråœ¨å¤šæŒ‡æ ‡æ–¹é¢å®ç°äº†æœ€ä½³æ€§èƒ½å¹¶è¶…è¶Šäº†å…¶ä»–æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒMAIFormeräº§ç”Ÿçš„é¢„æµ‹ç»“æœå¯ä»¥ä»äººç±»è§’åº¦è¿›è¡Œè§£é‡Šï¼Œè¿™æé«˜äº†æ¨¡å‹çš„é€æ˜åº¦åŠå…¶åœ¨èˆªç©ºäº¤é€šç®¡åˆ¶ä¸­çš„å®é™…åº”ç”¨ä»·å€¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21004v1">PDF</a> 8 pages, 7 figures, submitted for IEEE Transactions on Intelligent   Transportation System</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤šä»£ç†é€†å˜æ¢å™¨ï¼ˆMAIFormerï¼‰çš„é£è¡Œè½¨è¿¹é¢„æµ‹æŠ€æœ¯å¯¹äºç°ä»£èˆªç©ºäº¤é€šæ§åˆ¶è‡³å…³é‡è¦ã€‚è¯¥æŠ€æœ¯é€šè¿‡ä¸¤ä¸ªå…³é”®æ³¨æ„åŠ›æ¨¡å—â€”â€”æ©ç å¤šå…ƒæ³¨æ„åŠ›å’Œä»£ç†æ³¨æ„åŠ›ï¼Œå®ç°å¯¹ä¸ªä½“é£æœºè¡Œä¸ºåŠå…¶é—´å¤æ‚äº¤äº’çš„å»ºæ¨¡ã€‚åˆ©ç”¨éŸ©å›½ä»å·å›½é™…æœºåœºç»ˆç«¯ç©ºåŸŸçš„å®æ—¶è‡ªåŠ¨ç›¸å…³ç›‘è§†å¹¿æ’­é£è¡Œè½¨è¿¹æ•°æ®é›†è¿›è¡Œçš„è¯„ä¼°è¡¨æ˜ï¼ŒMAIFormeråœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šè¡¨ç°æœ€ä½³ï¼Œé¢„æµ‹ç»“æœå¯¹äººç±»å¯è§£é‡Šï¼Œæé«˜äº†æ¨¡å‹çš„é€æ˜åº¦å’Œå®ç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é£è¡Œè½¨è¿¹é¢„æµ‹å¯¹äºèˆªç©ºäº¤é€šæ§åˆ¶è‡³å…³é‡è¦ï¼Œä¸ºå¤šé£æœºäº¤äº’æä¾›å…³é”®æ´å¯Ÿã€‚</li>
<li>å¤šä»£ç†é£è¡Œè½¨è¿¹é¢„æµ‹å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œéœ€å»ºæ¨¡ä¸ªä½“é£æœºè¡Œä¸ºåŠæ—¶ç©ºå¤æ‚äº¤äº’ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ç¥ç»æ¶æ„â€”â€”å¤šä»£ç†é€†å˜æ¢å™¨ï¼ˆMAIFormerï¼‰è¿›è¡Œé¢„æµ‹ã€‚</li>
<li>MAIFormeråŒ…å«ä¸¤ä¸ªå…³é”®æ³¨æ„åŠ›æ¨¡å—ï¼šæ©ç å¤šå…ƒæ³¨æ„åŠ›å’Œä»£ç†æ³¨æ„åŠ›ã€‚</li>
<li>æ©ç å¤šå…ƒæ³¨æ„åŠ›æ•æ‰ä¸ªä½“é£æœºçš„æ—¶ç©ºæ¨¡å¼ï¼Œä»£ç†æ³¨æ„åŠ›å»ºæ¨¡å¤šä»£ç†é—´çš„ç¤¾ä¼šæ¨¡å¼ã€‚</li>
<li>åœ¨ä»å·å›½é™…æœºåœºçš„å®é™…æ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒMAIFormeråœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šè¡¨ç°æœ€ä½³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21004">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-88e60f1568c536bbc13cf0118d5c0b89" align="middle">
<img src="https://picx.zhimg.com/v2-5f25d247a6210b598fdd10021637c705" align="middle">
<img src="https://picx.zhimg.com/v2-f5db25b6d9a3c19e02f8b5aef95b3260" align="middle">
<img src="https://picx.zhimg.com/v2-7a694136927fa0333673fa1aebae8c63" align="middle">
<img src="https://picx.zhimg.com/v2-a772e1cb8caf12934e65abba8f36d666" align="middle">
<img src="https://picx.zhimg.com/v2-6b55b727558b94c7ab26b1acfc3e9e88" align="middle">
<img src="https://picx.zhimg.com/v2-83155efccf23cb15e28937be89a65fe3" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="CORE-Full-Path-Evaluation-of-LLM-Agents-Beyond-Final-State"><a href="#CORE-Full-Path-Evaluation-of-LLM-Agents-Beyond-Final-State" class="headerlink" title="CORE: Full-Path Evaluation of LLM Agents Beyond Final State"></a>CORE: Full-Path Evaluation of LLM Agents Beyond Final State</h2><p><strong>Authors:Panagiotis Michelakis, Yiannis Hadjiyiannis, Dimitrios Stamoulis</strong></p>
<p>Evaluating AI agents that solve real-world tasks through function-call sequences remains an open challenge. Existing agentic benchmarks often reduce evaluation to a binary judgment of the final state, overlooking critical aspects such as safety, efficiency, and intermediate correctness. We propose a framework based on deterministic finite automata (DFAs) that encodes tasks as sets of valid tool-use paths, enabling principled assessment of agent behavior in diverse world models. Building on this foundation, we introduce CORE, a suite of five metrics, namely Path Correctness, Path Correctness - Kendallâ€™s tau Composite, Prefix Criticality, Harmful-Call Rate, and Efficiency, that quantify alignment with expected execution patterns. Across diverse worlds, our method reveals important performance differences between agents that would otherwise appear equivalent under traditional final-state evaluation schemes. </p>
<blockquote>
<p>è¯„ä¼°é€šè¿‡å‡½æ•°è°ƒç”¨åºåˆ—è§£å†³ç°å®ä»»åŠ¡çš„AIä»£ç†ä»ç„¶æ˜¯ä¸€ä¸ªå¼€æ”¾æ€§çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„ä»£ç†åŸºå‡†æµ‹è¯•é€šå¸¸å°†è¯„ä¼°ç®€åŒ–ä¸ºæœ€ç»ˆçŠ¶æ€çš„äºŒå…ƒåˆ¤æ–­ï¼Œå¿½ç•¥äº†å®‰å…¨ã€æ•ˆç‡å’Œä¸­é—´è¿‡ç¨‹æ­£ç¡®æ€§ç­‰é‡è¦æ–¹é¢ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºç¡®å®šæ€§æœ‰é™è‡ªåŠ¨æœºï¼ˆDFAï¼‰çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†ä»»åŠ¡ç¼–ç ä¸ºæœ‰æ•ˆçš„å·¥å…·ä½¿ç”¨è·¯å¾„é›†ï¼Œä»è€Œèƒ½å¤Ÿå¯¹ä»£ç†åœ¨ä¸åŒä¸–ç•Œæ¨¡å‹ä¸­çš„è¡Œä¸ºè¿›è¡Œæœ‰åŸåˆ™çš„è¯„ä»·ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¼•å…¥äº†COREï¼Œè¿™æ˜¯ä¸€å¥—äº”ä¸ªæŒ‡æ ‡ï¼Œå³è·¯å¾„æ­£ç¡®æ€§ã€è·¯å¾„æ­£ç¡®æ€§â€”â€”è‚¯å¾·å°”tauå¤åˆæŒ‡æ ‡ã€å‰ç¼€å…³é”®æ€§ã€æœ‰å®³è°ƒç”¨ç‡å’Œæ•ˆç‡ï¼Œè¿™äº›æŒ‡æ ‡å¯ä»¥é‡åŒ–ä¸é¢„æœŸæ‰§è¡Œæ¨¡å¼çš„å¯¹é½ç¨‹åº¦ã€‚åœ¨æˆ‘ä»¬çš„æ–¹æ³•ä¸­ï¼Œä¸åŒçš„ä¸–ç•Œæ¨¡å‹æ­ç¤ºäº†ä»£ç†ä¹‹é—´é‡è¦çš„æ€§èƒ½å·®å¼‚ï¼Œè€Œè¿™äº›ä»£ç†åœ¨ä¼ ç»Ÿçš„æœ€ç»ˆçŠ¶æ€è¯„ä¼°æ–¹æ¡ˆä¸‹çœ‹èµ·æ¥æ˜¯ç­‰æ•ˆçš„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.20998v1">PDF</a> Accepted: LAW 2025 Workshop NeurIPS 2025</p>
<p><strong>æ€»ç»“</strong><br>åœ¨è¯„ä»·é€šè¿‡å‡½æ•°è°ƒç”¨åºåˆ—è§£å†³çœŸå®ä»»åŠ¡çš„AIä»£ç†æ—¶ä»å­˜åœ¨æŒ‘æˆ˜ã€‚ç°æœ‰çš„ä»£ç†åŸºå‡†æµ‹è¯•é€šå¸¸å°†è¯„ä»·ç®€åŒ–ä¸ºæœ€ç»ˆçŠ¶æ€çš„äºŒå…ƒåˆ¤æ–­ï¼Œå¿½ç•¥äº†å®‰å…¨ã€æ•ˆç‡å’Œä¸­é—´è¿‡ç¨‹æ­£ç¡®æ€§ç­‰é‡è¦æ–¹é¢ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäºç¡®å®šæ€§æœ‰é™è‡ªåŠ¨æœºï¼ˆDFAï¼‰çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†ä»»åŠ¡ç¼–ç ä¸ºæœ‰æ•ˆçš„å·¥å…·ä½¿ç”¨è·¯å¾„é›†ï¼Œä»è€Œèƒ½å¤Ÿåœ¨ä¸åŒçš„ä¸–ç•Œæ¨¡å‹ä¸­è¯„ä¼°ä»£ç†çš„è¡Œä¸ºã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¼•å…¥äº†COREæŒ‡æ ‡å¥—ä»¶ï¼ŒåŒ…æ‹¬è·¯å¾„æ­£ç¡®æ€§ã€è·¯å¾„æ­£ç¡®æ€§-è‚¯å¾·å°”tauå¤åˆæŒ‡æ ‡ã€å‰ç¼€é‡è¦æ€§ã€æœ‰å®³è°ƒç”¨ç‡å’Œæ•ˆç‡ç­‰äº”ä¸ªæŒ‡æ ‡ï¼Œä»¥é‡åŒ–å…¶ä¸é¢„æœŸæ‰§è¡Œæ¨¡å¼çš„å¯¹é½ç¨‹åº¦ã€‚åœ¨ä¸åŒçš„ä¸–ç•Œä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ­ç¤ºäº†ä»£ç†ä¹‹é—´é‡è¦çš„æ€§èƒ½å·®å¼‚ï¼Œè¿™äº›å·®å¼‚åœ¨ä¼ ç»Ÿæœ€ç»ˆçŠ¶æ€è¯„ä¼°æ–¹æ¡ˆä¸‹å¯èƒ½ä¼šè¢«å¿½è§†ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>AIä»£ç†çš„è¯„ä»·ä»é¢ä¸´æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨è§£å†³çœŸå®ä¸–ç•Œä»»åŠ¡æ—¶éœ€è¦è€ƒè™‘å¤šä¸ªå› ç´ å¦‚å®‰å…¨æ€§ã€æ•ˆç‡å’Œä¸­é—´è¿‡ç¨‹æ­£ç¡®æ€§ã€‚</li>
<li>ç°æœ‰ä»£ç†åŸºå‡†æµ‹è¯•ä¸»è¦å…³æ³¨æœ€ç»ˆçŠ¶æ€çš„äºŒå…ƒåˆ¤æ–­ï¼Œå¿½ç•¥äº†å…¶ä»–é‡è¦æ–¹é¢ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºç¡®å®šæ€§æœ‰é™è‡ªåŠ¨æœºçš„æ¡†æ¶æ¥ç¼–ç ä»»åŠ¡ä½œä¸ºæœ‰æ•ˆçš„å·¥å…·ä½¿ç”¨è·¯å¾„é›†ã€‚</li>
<li>å¼•å…¥COREæŒ‡æ ‡å¥—ä»¶ä»¥é‡åŒ–ä»£ç†è¡Œä¸ºä¸é¢„æœŸæ‰§è¡Œæ¨¡å¼çš„å¯¹é½ç¨‹åº¦ã€‚åŒ…æ‹¬è·¯å¾„æ­£ç¡®æ€§ã€è‚¯å¾·å°”tauå¤åˆæŒ‡æ ‡ç­‰äº”ä¸ªæŒ‡æ ‡ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨ä¸åŒçš„ä¸–ç•Œæ¨¡å‹ä¸­è¯„ä¼°ä»£ç†çš„è¡Œä¸ºã€‚</li>
<li>é€šè¿‡è¯¥æ–¹æ³•å’ŒæŒ‡æ ‡å¥—ä»¶ï¼Œèƒ½å¤Ÿæ­ç¤ºä¼ ç»Ÿæœ€ç»ˆçŠ¶æ€è¯„ä¼°æ–¹æ¡ˆä¸‹å¯èƒ½è¢«å¿½è§†çš„ä»£ç†æ€§èƒ½å·®å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.20998">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-db55adc21655be630c8430399bd99389" align="middle">
<img src="https://picx.zhimg.com/v2-79687582e1257da3a14fe85418dbf14b" align="middle">
<img src="https://picx.zhimg.com/v2-8c6833ff4f3ca51c8f91f454f29d2369" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="i-LAVA-Insights-on-Low-Latency-Voice-2-Voice-Architecture-for-Agents"><a href="#i-LAVA-Insights-on-Low-Latency-Voice-2-Voice-Architecture-for-Agents" class="headerlink" title="i-LAVA: Insights on Low Latency Voice-2-Voice Architecture for Agents"></a>i-LAVA: Insights on Low Latency Voice-2-Voice Architecture for Agents</h2><p><strong>Authors:Anupam Purwar, Aditya Choudhary</strong></p>
<p>We experiment with a low-latency, end-to-end voice-to-voice communication model to optimize it for real-time conversational applications. By analyzing components essential to voice to voice (V-2-V) system viz. automatic speech recognition (ASR), text-to-speech (TTS), and dialog management, our work analyzes how to reduce processing time while maintaining high-quality interactions to identify the levers for optimizing V-2-V system. Our work identifies that TTS component which generates life-like voice, full of emotions including natural pauses and exclamations has highest impact on Real time factor (RTF). The experimented V-2-V architecture utilizes CSM1b has the capability to understand tone as well as context of conversation by ingesting both audio and text of prior exchanges to generate contextually accurate speech. We explored optimization of Residual Vector Quantization (RVQ) iterations by the TTS decoder which come at a cost of decrease in the quality of voice generated. Our experimental evaluations also demonstrate that for V-2-V implementations based on CSM most important optimizations can be brought by reducing the number of RVQ Iterations along with the codebooks used in Mimi. </p>
<blockquote>
<p>æˆ‘ä»¬å®éªŒäº†ä¸€ç§ä½å»¶è¿Ÿã€ç«¯åˆ°ç«¯çš„è¯­éŸ³åˆ°è¯­éŸ³é€šä¿¡æ¨¡å‹ï¼Œä»¥ä¼˜åŒ–å…¶é€‚ç”¨äºå®æ—¶å¯¹è¯åº”ç”¨ã€‚é€šè¿‡åˆ†æè¯­éŸ³åˆ°è¯­éŸ³ï¼ˆV-2-Vï¼‰ç³»ç»Ÿæ‰€å¿…éœ€çš„å…³é”®ç»„ä»¶ï¼ŒåŒ…æ‹¬è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ã€æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰å’Œå¯¹è¯ç®¡ç†ï¼Œæˆ‘ä»¬çš„å·¥ä½œåˆ†æäº†å¦‚ä½•åœ¨ä¿æŒé«˜è´¨é‡äº¤äº’çš„åŒæ—¶å‡å°‘å¤„ç†æ—¶é—´ï¼Œä»¥è¯†åˆ«ä¼˜åŒ–V-2-Vç³»ç»Ÿçš„å…³é”®å› ç´ ã€‚æˆ‘ä»¬çš„å·¥ä½œå‘ç°ï¼Œæ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ç»„ä»¶å¯¹å®æ—¶å› å­ï¼ˆRTFï¼‰çš„å½±å“æœ€å¤§ï¼Œè¯¥ç»„ä»¶å¯ç”Ÿæˆé€¼çœŸçš„è¯­éŸ³ï¼Œå……æ»¡æƒ…æ„Ÿï¼ŒåŒ…æ‹¬è‡ªç„¶åœé¡¿å’Œæ„Ÿå¹ã€‚æ‰€è¯•éªŒçš„V-2-Væ¶æ„åˆ©ç”¨CSM1bï¼Œé€šè¿‡æ‘„å–å…ˆå‰çš„éŸ³é¢‘å’Œæ–‡æœ¬äº¤æ¢ï¼Œç†è§£å¯¹è¯çš„è¯­è°ƒä»¥åŠä¸Šä¸‹æ–‡è¯­å¢ƒï¼Œä»è€Œç”Ÿæˆä¸Šä¸‹æ–‡å‡†ç¡®çš„è¯­éŸ³ã€‚æˆ‘ä»¬æ¢ç´¢äº†é€šè¿‡TTSè§£ç å™¨ä¼˜åŒ–å‰©ä½™å‘é‡é‡åŒ–ï¼ˆRVQï¼‰è¿­ä»£çš„æ–¹æ³•ï¼Œä½†è¿™ä¼šå¯¼è‡´ç”Ÿæˆçš„è¯­éŸ³è´¨é‡ä¸‹é™ã€‚æˆ‘ä»¬çš„å®éªŒè¯„ä¼°è¿˜è¡¨æ˜ï¼Œå¯¹äºåŸºäºCSMçš„V-2-Vå®ç°ï¼Œæœ€é‡è¦çš„ä¼˜åŒ–å¯ä»¥é€šè¿‡å‡å°‘RVQè¿­ä»£æ¬¡æ•°ä»¥åŠMimiä¸­ä½¿ç”¨çš„ä»£ç æœ¬æ•°é‡æ¥å®ç°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.20971v1">PDF</a> This paper analyzes a low-latency, end-to-end voice-to-voice (V-2-V)   architecture, identifying that the Text-to-Speech (TTS) component has the   highest impact on real-time performance. By reducing the number of Residual   Vector Quantization (RVQ) iterations in the TTS model, latency can be   effectively halved, creating a direct trade-off between conversational speed   and audio quality</p>
<p><strong>Summary</strong><br>     æœ¬ç ”ç©¶é€šè¿‡å®éªŒä½å»¶è¿Ÿã€ç«¯åˆ°ç«¯çš„è¯­éŸ³åˆ°è¯­éŸ³é€šä¿¡æ¨¡å‹ï¼Œé’ˆå¯¹å®æ—¶ä¼šè¯åº”ç”¨è¿›è¡Œä¼˜åŒ–ã€‚é€šè¿‡åˆ†æè¯­éŸ³åˆ°è¯­éŸ³ç³»ç»Ÿï¼ˆV-2-Vï¼‰çš„å…³é”®ç»„ä»¶ï¼Œå¦‚è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ã€æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰å’Œå¯¹è¯ç®¡ç†ï¼Œç ”ç©¶å¦‚ä½•åœ¨ä¿æŒé«˜è´¨é‡äº¤äº’çš„åŒæ—¶å‡å°‘å¤„ç†æ—¶é—´ï¼Œä»¥æ‰¾åˆ°ä¼˜åŒ–V-2-Vç³»ç»Ÿçš„å…³é”®æ‰‹æ®µã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒTTSç»„ä»¶å¯¹å®æ—¶å› ç´ ï¼ˆRTFï¼‰çš„å½±å“æœ€å¤§ï¼Œèƒ½å¤Ÿç”Ÿæˆå……æ»¡æƒ…æ„Ÿçš„é€¼çœŸè¯­éŸ³ï¼ŒåŒ…æ‹¬è‡ªç„¶åœé¡¿å’Œæ„Ÿå¹ã€‚å®éªŒæ€§çš„V-2-Væ¶æ„åˆ©ç”¨CSM1bï¼Œèƒ½å¤Ÿé€šè¿‡æ‘„å–å…ˆå‰çš„éŸ³é¢‘å’Œæ–‡æœ¬äº¤æ¢æ¥ç†è§£è¯­è°ƒä»¥åŠå¯¹è¯çš„ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆè¯­å¢ƒå‡†ç¡®çš„è¯­éŸ³ã€‚æœ¬ç ”ç©¶è¿˜æ¢ç´¢äº†é€šè¿‡å‡å°‘TTSè§£ç å™¨çš„å‰©ä½™çŸ¢é‡é‡åŒ–ï¼ˆRVQï¼‰è¿­ä»£æ¬¡æ•°æ¥ä¼˜åŒ–V-2-Vå®ç°ï¼Œä½†è¿™å¯èƒ½ä¼šå¯¼è‡´ç”Ÿæˆçš„è¯­éŸ³è´¨é‡ä¸‹é™ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶é€šè¿‡å®éªŒä½å»¶è¿Ÿçš„ç«¯åˆ°ç«¯è¯­éŸ³åˆ°è¯­éŸ³é€šä¿¡æ¨¡å‹æ¥ä¼˜åŒ–å®æ—¶ä¼šè¯åº”ç”¨ã€‚</li>
</ol>
<p>  ç ”ç©¶äº†V-2-Vç³»ç»Ÿçš„å…³é”®ç»„ä»¶ï¼ˆASRã€TTSå’Œå¯¹è¯ç®¡ç†ï¼‰ä»¥å®ç°æ€§èƒ½çš„ä¼˜åŒ–ã€‚ </p>
<ol start="2">
<li><p>TTSç»„ä»¶å¯¹å®æ—¶å› ç´ ï¼ˆRTFï¼‰çš„å½±å“æœ€å¤§ï¼Œå› ä¸ºå®ƒèƒ½å¤Ÿç”Ÿæˆå……æ»¡æƒ…æ„Ÿçš„é€¼çœŸè¯­éŸ³ã€‚<br>  é€šè¿‡å®éªŒå‘ç°å……æ»¡æƒ…æ„Ÿçš„è¯­éŸ³åˆæˆæ˜¯ç³»ç»Ÿå®æ—¶æ€§èƒ½çš„å…³é”®æ‰€åœ¨ã€‚ </p>
</li>
<li><p>å®éªŒæ€§çš„V-2-Væ¶æ„åˆ©ç”¨CSMæŠ€æœ¯èƒ½ç†è§£å¯¹è¯çš„è¯­å¢ƒå’Œè¯­è°ƒï¼Œæé«˜äº†è¯­éŸ³äº¤äº’çš„è‡ªç„¶æ€§å’Œå‡†ç¡®æ€§ã€‚<br>  è¿™æ„å‘³ç€ç³»ç»Ÿå¯ä»¥æ ¹æ®å…ˆå‰çš„å¯¹è¯å†…å®¹æ¥ç”Ÿæˆæ›´åˆé€‚çš„å“åº”ã€‚ </p>
</li>
<li><p>ç ”ç©¶é€šè¿‡å‡å°‘TTSè§£ç å™¨çš„RVQè¿­ä»£æ¬¡æ•°æ¥ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½ï¼Œä½†è¿™å¯èƒ½ä¼šå¯¹è¯­éŸ³è´¨é‡äº§ç”Ÿå½±å“ã€‚<br>  è¡¨æ˜åœ¨ä¼˜åŒ–å¤„ç†é€Ÿåº¦çš„åŒæ—¶éœ€è¦æƒè¡¡è¯­éŸ³è´¨é‡çš„æŸå¤±ã€‚ </p>
</li>
<li><p>è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰åœ¨å¤„ç†è¿‡ç¨‹ä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼Œå®ƒçš„æ€§èƒ½ç›´æ¥å½±å“åˆ°ç³»ç»Ÿå¯¹è¯­éŸ³ä¿¡å·çš„ç†è§£èƒ½åŠ›ã€‚<br>  è¿™è¡¨æ˜éœ€è¦é«˜æ•ˆå‡†ç¡®çš„ASRç®—æ³•æ¥æé«˜ç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½ã€‚ </p>
</li>
<li><p>å¯¹è¯ç®¡ç†åœ¨å®æ—¶äº¤äº’ä¸­è‡³å…³é‡è¦ï¼Œç›´æ¥å½±å“ç³»ç»Ÿå“åº”ç”¨æˆ·çš„æ–¹å¼å’Œç”¨æˆ·æ»¡æ„åº¦ã€‚<br>  é«˜æ•ˆçš„å¯¹è¯ç®¡ç†èƒ½å¤Ÿç¡®ä¿ç³»ç»Ÿçš„å“åº”æ›´åŠ æµç•…å’Œè‡ªç„¶ã€‚</p>
</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.20971">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3bb81516e8015be4b3e8144c6c180994" align="middle">
<img src="https://picx.zhimg.com/v2-3cbb1be5f6f4abfe46e04380b855efe8" align="middle">
<img src="https://picx.zhimg.com/v2-01288a991ef3f2796f87fa445020472c" align="middle">
<img src="https://picx.zhimg.com/v2-73080709ee9ddccebf7778fd101a721c" align="middle">
<img src="https://picx.zhimg.com/v2-b57654b72585c80284a6f451fa33f172" align="middle">
<img src="https://picx.zhimg.com/v2-5b79dcef8256e74f28cbd8cbd4af3a5a" align="middle">
<img src="https://picx.zhimg.com/v2-e94936736293e3c4c16cb9c549985aa1" align="middle">
<img src="https://picx.zhimg.com/v2-04da26b77e97dedca53121eaf10c46f0" align="middle">
<img src="https://picx.zhimg.com/v2-f172e27dd6f3e845c2d74b84595f16d0" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Learning-to-Summarize-by-Learning-to-Quiz-Adversarial-Agentic-Collaboration-for-Long-Document-Summarization"><a href="#Learning-to-Summarize-by-Learning-to-Quiz-Adversarial-Agentic-Collaboration-for-Long-Document-Summarization" class="headerlink" title="Learning to Summarize by Learning to Quiz: Adversarial Agentic   Collaboration for Long Document Summarization"></a>Learning to Summarize by Learning to Quiz: Adversarial Agentic   Collaboration for Long Document Summarization</h2><p><strong>Authors:Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch</strong></p>
<p>Long document summarization remains a significant challenge for current large language models (LLMs), as existing approaches commonly struggle with information loss, factual inconsistencies, and coherence issues when processing excessively long documents. We propose SummQ, a novel adversarial multi-agent framework that addresses these limitations through collaborative intelligence between specialized agents operating in two complementary domains: summarization and quizzing. Our approach employs summary generators and reviewers that work collaboratively to create and evaluate comprehensive summaries, while quiz generators and reviewers create comprehension questions that serve as continuous quality checks for the summarization process. This adversarial dynamic, enhanced by an examinee agent that validates whether the generated summary contains the information needed to answer the quiz questions, enables iterative refinement through multifaceted feedback mechanisms. We evaluate SummQ on three widely used long document summarization benchmarks. Experimental results demonstrate that our framework significantly outperforms existing state-of-the-art methods across ROUGE and BERTScore metrics, as well as in LLM-as-a-Judge and human evaluations. Our comprehensive analyses reveal the effectiveness of the multi-agent collaboration dynamics, the influence of different agent configurations, and the impact of the quizzing mechanism. This work establishes a new approach for long document summarization that uses adversarial agentic collaboration to improve summarization quality. </p>
<blockquote>
<p>é•¿æ–‡æ¡£æ‘˜è¦ä»ç„¶æ˜¯å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é¢ä¸´çš„ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è¿‡é•¿æ–‡æ¡£æ—¶ï¼Œé€šå¸¸ä¼šé¢ä¸´ä¿¡æ¯ä¸¢å¤±ã€äº‹å®ä¸ä¸€è‡´å’Œè¿è´¯æ€§é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†SummQï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹å¯¹æŠ—æ€§å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œå®ƒé€šè¿‡ä¸¤ä¸ªäº’è¡¥é¢†åŸŸä¸­çš„æ™ºèƒ½ä½“ä¹‹é—´çš„åä½œæ™ºèƒ½æ¥è§£å†³è¿™äº›å±€é™æ€§ï¼šæ‘˜è¦å’Œæµ‹éªŒã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨æ‘˜è¦ç”Ÿæˆå™¨å’Œè¯„å®¡å‘˜è¿›è¡Œåä½œï¼Œä»¥åˆ›å»ºå’Œè¯„ä¼°å…¨é¢çš„æ‘˜è¦ï¼ŒåŒæ—¶æµ‹éªŒç”Ÿæˆå™¨å’Œè¯„å®¡å‘˜åˆ›å»ºç†è§£é—®é¢˜ï¼Œä½œä¸ºæ‘˜è¦è¿‡ç¨‹çš„æŒç»­è´¨é‡æ£€æŸ¥ã€‚è¿™ç§å¯¹æŠ—æ€§åŠ¨æ€é€šè¿‡è¢«æµ‹è¯•æ™ºèƒ½ä½“å¾—åˆ°å¢å¼ºï¼ŒéªŒè¯ç”Ÿæˆçš„æ‘˜è¦æ˜¯å¦åŒ…å«å›ç­”æµ‹éªŒé—®é¢˜æ‰€éœ€çš„ä¿¡æ¯ï¼Œé€šè¿‡å¤šæ–¹é¢çš„åé¦ˆæœºåˆ¶å®ç°è¿­ä»£æ”¹è¿›ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªå¹¿æ³›ä½¿ç”¨çš„é•¿æ–‡æ¡£æ‘˜è¦åŸºå‡†æµ‹è¯•ä¸Šå¯¹SummQè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨ROUGEå’ŒBERTScoreæŒ‡æ ‡ä»¥åŠLLM-as-a-Judgeå’Œäººç±»è¯„ä¼°ä¸­å‡æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„ç»¼åˆåˆ†ææ­ç¤ºäº†å¤šæ™ºèƒ½ä½“åä½œåŠ¨æ€çš„æœ‰æ•ˆæ€§ã€ä¸åŒæ™ºèƒ½ä½“é…ç½®çš„å½±å“ä»¥åŠæµ‹éªŒæœºåˆ¶çš„ä½œç”¨ã€‚è¿™é¡¹å·¥ä½œä¸ºé•¿æ–‡æ¡£æ‘˜è¦æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œé‡‡ç”¨å¯¹æŠ—æ€§æ™ºèƒ½åä½œæ¥æé«˜æ‘˜è¦è´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.20900v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºSummQçš„æ–°å‹å¯¹æŠ—æ€§å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œç”¨äºè§£å†³é•¿æ–‡æ¡£æ‘˜è¦ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ä¿¡æ¯ä¸¢å¤±ã€äº‹å®æ€§ä¸ä¸€è‡´å’Œè¿è´¯æ€§é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¸¤ä¸ªäº’è¡¥é¢†åŸŸçš„æ™ºèƒ½ä½“ä¹‹é—´çš„åä½œæ™ºèƒ½å®ç°æ‘˜è¦ç”Ÿæˆå’Œè¯„ä¼°ï¼ŒåŒæ—¶é€šè¿‡é—®ç­”ç”Ÿæˆå’Œè¯„ä¼°æ¥æŒç»­æ£€æŸ¥æ‘˜è¦è´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSummQåœ¨å¹¿æ³›ä½¿ç”¨çš„é•¿æ–‡æ¡£æ‘˜è¦è¯„ä¼°æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰å…ˆè¿›æŠ€æœ¯ã€‚æ­¤å·¥ä½œé‡‡ç”¨å¯¹æŠ—æ€§æ™ºèƒ½ä½“åä½œçš„æ–¹æ³•æé«˜äº†æ‘˜è¦è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†é•¿æ–‡æ¡£æ‘˜è¦æ—¶é¢ä¸´ä¿¡æ¯ä¸¢å¤±ã€äº‹å®æ€§ä¸ä¸€è‡´å’Œè¿è´¯æ€§é—®é¢˜ç­‰æŒ‘æˆ˜ã€‚</li>
<li>SummQæ˜¯ä¸€ç§æ–°å‹å¯¹æŠ—æ€§å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è¿™äº›é—®é¢˜ã€‚</li>
<li>SummQåŒ…å«æ‘˜è¦ç”Ÿæˆå™¨å’Œè¯„ä¼°å™¨ï¼Œé€šè¿‡åä½œç”Ÿæˆå¹¶è¯„ä¼°æ‘˜è¦ã€‚</li>
<li>SummQè¿˜åŒ…æ‹¬é—®ç­”ç”Ÿæˆå™¨å’Œè¯„ä¼°å™¨ï¼Œä½œä¸ºå¯¹æ‘˜è¦è´¨é‡çš„æŒç»­æ£€æŸ¥ã€‚</li>
<li>SummQé€šè¿‡å¤šæ™ºèƒ½ä½“åä½œåŠ¨æ€å®ç°è¿­ä»£ä¼˜åŒ–ï¼Œé€šè¿‡å¤šæ–¹é¢çš„åé¦ˆæœºåˆ¶è¿›è¡Œæ”¹è¿›ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒSummQåœ¨å¤šä¸ªé•¿æ–‡æ¡£æ‘˜è¦è¯„ä¼°æŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.20900">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4ab1f06816396253f20bb8cddfe64698" align="middle">
<img src="https://picx.zhimg.com/v2-e0d5900374554ad37a901982ed34ab44" align="middle">
<img src="https://picx.zhimg.com/v2-0b6cb4f2f980d70c5d90ebebbbdd3a23" align="middle">
<img src="https://picx.zhimg.com/v2-a0eecab70232b3c7b20088486830d8a0" align="middle">
<img src="https://picx.zhimg.com/v2-93f977d60e8013edcc864ed29db39bdd" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Adaptive-Learning-in-Spatial-Agent-Based-Models-for-Climate-Risk-Assessment-A-Geospatial-Framework-with-Evolutionary-Economic-Agents"><a href="#Adaptive-Learning-in-Spatial-Agent-Based-Models-for-Climate-Risk-Assessment-A-Geospatial-Framework-with-Evolutionary-Economic-Agents" class="headerlink" title="Adaptive Learning in Spatial Agent-Based Models for Climate Risk   Assessment: A Geospatial Framework with Evolutionary Economic Agents"></a>Adaptive Learning in Spatial Agent-Based Models for Climate Risk   Assessment: A Geospatial Framework with Evolutionary Economic Agents</h2><p><strong>Authors:Yara Mohajerani</strong></p>
<p>Climate risk assessment requires modelling complex interactions between spatially heterogeneous hazards and adaptive economic systems. We present a novel geospatial agent-based model that integrates climate hazard data with evolutionary learning for economic agents. Our framework combines Mesa-based spatial modelling with CLIMADA climate impact assessment, introducing adaptive learning behaviours that allow firms to evolve strategies for budget allocation, pricing, wages, and risk adaptation through fitness-based selection and mutation. We demonstrate the framework using riverine flood projections under RCP8.5 until 2100, showing that evolutionary adaptation enables firms to converge with baseline (no hazard) production levels after decades of disruption due to climate stress. Our results reveal systemic risks where even agents that are not directly exposed to floods face impacts through supply chain disruptions, with the end-of-century average price of goods 5.6% higher under RCP8.5 compared to the baseline. This open-source framework provides financial institutions and companies with tools to quantify both direct and cascading climate risks while evaluating cost-effective adaptation strategies. </p>
<blockquote>
<p>æ°”å€™é£é™©è¯„ä¼°éœ€è¦æ¨¡æ‹Ÿç©ºé—´å¼‚è´¨æ€§å±å®³ä¸è‡ªé€‚åº”ç»æµç³»ç»Ÿä¹‹é—´çš„å¤æ‚äº¤äº’ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹åŸºäºåœ°ç†ç©ºé—´çš„ä¸»ä½“æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å°†æ°”å€™å±å®³æ•°æ®ä¸ä¸»ä½“çš„è¿›åŒ–å­¦ä¹ ç›¸ç»“åˆï¼Œç”¨äºè¯„ä¼°ç»æµç³»ç»Ÿã€‚æˆ‘ä»¬çš„æ¡†æ¶ç»“åˆäº†åŸºäºæ¢…è¨çš„ç©ºé—´å»ºæ¨¡ä¸CLIMADAæ°”å€™å½±å“è¯„ä¼°ï¼Œå¼•å…¥äº†è‡ªé€‚åº”å­¦ä¹ è¡Œä¸ºï¼Œä½¿ä¼ä¸šèƒ½å¤Ÿé€šè¿‡åŸºäºé€‚åº”åº¦çš„é€‰æ‹©å’Œå˜å¼‚æ¥è¿›åŒ–ç­–ç•¥ï¼Œä¸ºé¢„ç®—åˆ†é…ã€å®šä»·ã€å·¥èµ„å’Œé£é™©é€‚åº”åˆ¶å®šç­–ç•¥ã€‚æˆ‘ä»¬ä»¥RCP8.5æƒ…æ™¯ä¸‹ç›´è‡³2100å¹´çš„æ²³æµæ´ªæ°´é¢„æµ‹ä¸ºä¾‹æ¥å±•ç¤ºè¯¥æ¡†æ¶çš„åº”ç”¨ï¼Œè¡¨æ˜é€šè¿‡å‡ åå¹´çš„æ°”å€™å‹åŠ›å¸¦æ¥çš„ç ´ååï¼Œè¿›åŒ–é€‚åº”ä½¿ä¼ä¸šèƒ½å¤Ÿæ”¶æ•›åˆ°åŸºçº¿ï¼ˆæ— å±å®³ï¼‰çš„ç”Ÿäº§æ°´å¹³ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œå³ä½¿åœ¨ä¾›åº”é“¾ä¸­æ–­çš„æƒ…å†µä¸‹ï¼Œæ²¡æœ‰ç›´æ¥æš´éœ²äºæ´ªæ°´ä¸­çš„ä¸»ä½“ä¹Ÿä¼šå—åˆ°å½±å“ï¼Œåˆ°ä¸–çºªæœ«æœŸçš„å•†å“å¹³å‡ä»·æ ¼è¾ƒåŸºçº¿æ°´å¹³åœ¨RCP8.5æƒ…æ™¯ä¸‹é«˜å‡º5.6%ã€‚è¿™ä¸€å¼€æºæ¡†æ¶ä¸ºé‡‘èæœºæ„å’Œä¼ä¸šæä¾›äº†é‡åŒ–ç›´æ¥å’Œè¿é”æ°”å€™é£é™©çš„å·¥å…·ï¼ŒåŒæ—¶è¯„ä¼°æˆæœ¬æ•ˆç›Šé«˜çš„é€‚åº”ç­–ç•¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18633v1">PDF</a> Submitted and accepted to Tackling Climate Change with Machine   Learning workshop at NeurIPS 2025. 5 pages, 1 figure. Source code and   documentation available at   <a target="_blank" rel="noopener" href="https://github.com/yaramohajerani/spatial-climate-ABM">https://github.com/yaramohajerani/spatial-climate-ABM</a></p>
<p><strong>Summary</strong>ï¼šæ°”å€™é£é™©è¯„ä¼°éœ€è¦æ¨¡æ‹Ÿç©ºé—´å¼‚è´¨æ€§å±å®³å’Œé€‚åº”æ€§ç»æµç³»ç»Ÿä¹‹é—´çš„å¤æ‚äº¤äº’ä½œç”¨ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹åœ°ç†ç©ºé—´ä¸»ä½“æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆäº†æ°”å€™å±å®³æ•°æ®ä¸è¿›åŒ–å­¦ä¹ æœºåˆ¶ï¼Œä¸ºç»æµä¸»ä½“æä¾›è¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»“åˆäº†åŸºäºæ¢…è¨çš„ç©ºé—´å»ºæ¨¡ä¸æ°”å€™å½±å“è¯„ä¼°CLIMADAï¼Œå¼•å…¥é€‚åº”æ€§å­¦ä¹ è¡Œä¸ºï¼Œä½¿ä¼ä¸šèƒ½å¤Ÿæ ¹æ®å¥åº·åº¦é€‰æ‹©å˜å¼‚è¿›åŒ–ç­–ç•¥æ¥åˆ¶å®šé¢„ç®—åˆ†é…ã€å®šä»·ã€å·¥èµ„åŠé£é™©é€‚åº”ç­–ç•¥ã€‚ä»¥RCP8.5æƒ…æ™¯ä¸‹çš„æ²³æµæ´ªæ°´é¢„æµ‹ä¸ºä¾‹ï¼Œç ”ç©¶æ˜¾ç¤ºï¼Œç»è¿‡å‡ åå¹´çš„æ°”å€™å˜åŒ–å‹åŠ›åï¼Œé€šè¿‡æ¼”åŒ–é€‚åº”ç­–ç•¥ä¼ä¸šçš„ç”Ÿäº§æ°´å¹³ä¼šè¶‹å‘äºåŸºå‡†çº¿çš„æ°´å¹³ï¼ˆæ²¡æœ‰å±å®³æ—¶ï¼‰ã€‚æœ¬æ¡†æ¶æ­ç¤ºå‡ºç³»ç»Ÿæ€§é£é™©ä¸­çš„å‹åŠ›ä¸é™äºç›´æ¥å—å½±å“çš„å®ä½“ä¼ä¸šä¹Ÿä¼šå—åˆ°å½±å“ã€‚è¯¥ç ”ç©¶æå‡ºçš„å¼€æ”¾æºä»£ç æ¡†æ¶æœ‰åŠ©äºé‡‘èæœºæ„å’Œä¼ä¸šå®šé‡è¯„ä¼°æ°”å€™é£é™©ä¸ä¾›åº”é“¾æ–­è£‚å¼•å‘çš„è¿é”ååº”ï¼ŒåŒæ—¶è¯„ä¼°æˆæœ¬æ•ˆç›Šé«˜çš„é€‚åº”ç­–ç•¥ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>æ°”å€™é£é™©è¯„ä¼°éœ€è¦æ¨¡æ‹Ÿå¤æ‚äº¤äº’ä½œç”¨ï¼ŒåŒ…æ‹¬ç©ºé—´å¼‚è´¨æ€§å±å®³å’Œé€‚åº”æ€§ç»æµç³»ç»Ÿã€‚</li>
<li>æå‡ºä¸€ç§æ–°å‹åœ°ç†ç©ºé—´ä¸»ä½“æ¨¡å‹ï¼Œæ•´åˆæ°”å€™å±å®³æ•°æ®ä¸è¿›åŒ–å­¦ä¹ æœºåˆ¶ã€‚</li>
<li>æ¡†æ¶ç»“åˆäº†ç©ºé—´å»ºæ¨¡ä¸æ°”å€™å½±å“è¯„ä¼°CLIMADAã€‚</li>
<li>å¼•å…¥é€‚åº”æ€§å­¦ä¹ è¡Œä¸ºï¼Œä½¿ä¼ä¸šèƒ½æ ¹æ®å¥åº·åº¦è°ƒæ•´ç­–ç•¥ä»¥é€‚åº”å„ç§æŒ‘æˆ˜ã€‚</li>
<li>ä»¥æ²³æµæ´ªæ°´é¢„æµ‹ä¸ºä¾‹ï¼Œå±•ç¤ºäº†è¿›åŒ–é€‚åº”ç­–ç•¥åœ¨åº”å¯¹æ°”å€™å˜åŒ–ä¸­çš„ä½œç”¨ã€‚</li>
<li>ç³»ç»Ÿæ€§é£é™©åŒ…æ‹¬ä¾›åº”é“¾æ–­è£‚å¯¼è‡´çš„è¿é”ååº”ï¼Œå³ä½¿éç›´æ¥å—å½±å“çš„å®ä½“ä¼ä¸šä¹Ÿä¼šå—åˆ°å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18633">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bb59b9385c6b5591850071eff42645b7" align="middle">
<img src="https://picx.zhimg.com/v2-72e61ec82ad86b607a3f77cc572b4fc4" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Aegis-Automated-Error-Generation-and-Identification-for-Multi-Agent-Systems"><a href="#Aegis-Automated-Error-Generation-and-Identification-for-Multi-Agent-Systems" class="headerlink" title="Aegis: Automated Error Generation and Identification for Multi-Agent   Systems"></a>Aegis: Automated Error Generation and Identification for Multi-Agent   Systems</h2><p><strong>Authors:Fanqi Kong, Ruijie Zhang, Huaxiao Yin, Guibin Zhang, Xiaofei Zhang, Ziang Chen, Zhaowei Zhang, Xiaoyuan Zhang, Song-Chun Zhu, Xue Feng</strong></p>
<p>As Multi-Agent Systems (MAS) become increasingly autonomous and complex, understanding their error modes is critical for ensuring their reliability and safety. However, research in this area has been severely hampered by the lack of large-scale, diverse datasets with precise, ground-truth error labels. To address this bottleneck, we introduce \textbf{AEGIS}, a novel framework for \textbf{A}utomated \textbf{E}rror \textbf{G}eneration and \textbf{I}dentification for Multi-Agent \textbf{S}ystems. By systematically injecting controllable and traceable errors into initially successful trajectories, we create a rich dataset of realistic failures. This is achieved using a context-aware, LLM-based adaptive manipulator that performs sophisticated attacks like prompt injection and response corruption to induce specific, predefined error modes. We demonstrate the value of our dataset by exploring three distinct learning paradigms for the error identification task: Supervised Fine-Tuning, Reinforcement Learning, and Contrastive Learning. Our comprehensive experiments show that models trained on AEGIS data achieve substantial improvements across all three learning paradigms. Notably, several of our fine-tuned models demonstrate performance competitive with or superior to proprietary systems an order of magnitude larger, validating our automated data generation framework as a crucial resource for developing more robust and interpretable multi-agent systems. Our project website is available at <a target="_blank" rel="noopener" href="https://kfq20.github.io/AEGIS-Website">https://kfq20.github.io/AEGIS-Website</a>. </p>
<blockquote>
<p>éšç€å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰çš„è‡ªä¸»æ€§å’Œå¤æ‚æ€§ä¸æ–­æé«˜ï¼Œç†è§£å®ƒä»¬çš„é”™è¯¯æ¨¡å¼å¯¹äºç¡®ä¿å®ƒä»¬çš„å¯é æ€§å’Œå®‰å…¨æ€§è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹å¤§è§„æ¨¡ã€å¤šæ ·åŒ–çš„ç²¾ç¡®åœ°é¢çœŸå®é”™è¯¯æ ‡ç­¾æ•°æ®é›†ï¼Œè¿™ä¸€é¢†åŸŸçš„ç ”ç©¶å—åˆ°äº†ä¸¥é‡é˜»ç¢ã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç“¶é¢ˆé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†\textbf{AEGIS}ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è‡ªåŠ¨åŒ–é”™è¯¯ç”Ÿæˆå’Œè¯†åˆ«çš„æ–°å‹æ¡†æ¶ã€‚æˆ‘ä»¬é€šè¿‡ç³»ç»Ÿæ€§åœ°åœ¨åˆå§‹æˆåŠŸè½¨è¿¹ä¸­æ³¨å…¥å¯æ§å’Œå¯è¿½è¸ªçš„é”™è¯¯ï¼Œåˆ›å»ºäº†ä¸€ä¸ªä¸°å¯Œçš„ç°å®å¤±è´¥æ•°æ®é›†ã€‚è¿™æ˜¯é€šè¿‡åŸºäºä¸Šä¸‹æ–‡æ„ŸçŸ¥ã€å¤§å‹è¯­è¨€æ¨¡å‹çš„è‡ªé€‚åº”æ“çºµå™¨å®ç°çš„ï¼Œè¯¥æ“çºµå™¨æ‰§è¡Œè¯¸å¦‚æç¤ºæ³¨å…¥å’Œå“åº”è…è´¥ä¹‹ç±»çš„å¤æ‚æ”»å‡»ï¼Œä»¥äº§ç”Ÿç‰¹å®šçš„é¢„å®šä¹‰é”™è¯¯æ¨¡å¼ã€‚æˆ‘ä»¬é€šè¿‡æ¢ç´¢é”™è¯¯è¯†åˆ«ä»»åŠ¡çš„ä¸‰ç§ç‹¬ç‰¹å­¦ä¹ èŒƒå¼æ¥è¯æ˜æˆ‘ä»¬æ•°æ®é›†çš„ä»·å€¼ï¼šæœ‰ç›‘ç£å¾®è°ƒã€å¼ºåŒ–å­¦ä¹ å’Œå¯¹æ¯”å­¦ä¹ ã€‚æˆ‘ä»¬çš„å…¨é¢å®éªŒè¡¨æ˜ï¼Œåœ¨AEGISæ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹åœ¨è¿™ä¸‰ç§å­¦ä¹ èŒƒå¼ä¸­éƒ½å–å¾—äº†é‡å¤§æ”¹è¿›ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬å¾®è°ƒçš„å‡ ä¸ªæ¨¡å‹çš„æ€§èƒ½ä¸æˆ–ä¼˜äºä¸€ä¸ªæ•°é‡çº§æ›´å¤§çš„ä¸“æœ‰ç³»ç»Ÿï¼Œè¿™éªŒè¯äº†æˆ‘ä»¬çš„è‡ªåŠ¨åŒ–æ•°æ®ç”Ÿæˆæ¡†æ¶å¯¹äºå¼€å‘æ›´ç¨³å¥å’Œå¯è§£é‡Šçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ˜¯ä¸€ä¸ªè‡³å…³é‡è¦çš„èµ„æºã€‚æˆ‘ä»¬çš„é¡¹ç›®ç½‘ç«™å¯åœ¨<a target="_blank" rel="noopener" href="https://kfq20.github.io/AEGIS-Website%E8%AE%BF%E9%97%AE%E3%80%82">https://kfq20.github.io/AEGIS-Websiteè®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.14295v3">PDF</a> </p>
<p><strong>Summary</strong><br>    å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè‡ªä¸»æ€§å’Œå¤æ‚æ€§æå‡çš„æƒ…å†µä¸‹ï¼Œå…¶é”™è¯¯æ¨¡å¼çš„ç†è§£å¯¹ä¿éšœå…¶å¯é æ€§å’Œå®‰å…¨æ€§è‡³å…³é‡è¦ã€‚ä½†æ­¤é¢†åŸŸç ”ç©¶å—é™äºç¼ºä¹å¤§è§„æ¨¡å¤šæ ·æ•°æ®é›†ï¼Œå…·æœ‰ç²¾ç¡®åœ°é¢çœŸå®é”™è¯¯æ ‡ç­¾ã€‚ä¸ºè§£å†³æ­¤ç“¶é¢ˆï¼Œæå‡ºAEGISæ¡†æ¶ï¼Œé€šè¿‡ç³»ç»Ÿæ³¨å…¥å¯æ§å¯è¿½è¸ªé”™è¯¯è‡³åˆå§‹æˆåŠŸè½¨è¿¹ï¼Œåˆ›å»ºä¸°å¯Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿé”™è¯¯æ•°æ®é›†ã€‚é‡‡ç”¨è¯­å¢ƒæ„ŸçŸ¥ã€åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„è‡ªé€‚åº”æ“çºµå™¨å®ç°å¤æ‚æ”»å‡»ï¼Œå¦‚æç¤ºæ³¨å…¥å’Œå“åº”è…è´¥ä»¥äº§ç”Ÿç‰¹å®šé¢„è®¾é”™è¯¯æ¨¡å¼ã€‚é€šè¿‡ä¸‰ç§å­¦ä¹ èŒƒå¼éªŒè¯æ•°æ®é›†ä»·å€¼ã€‚å®éªŒæ˜¾ç¤ºï¼Œåœ¨AEGISæ•°æ®è®­ç»ƒçš„æ¨¡å‹åœ¨æ‰€æœ‰å­¦ä¹ èŒƒå¼ä¸­å–å¾—å®è´¨æ€§æ”¹è¿›ï¼Œéƒ¨åˆ†å¾®è°ƒæ¨¡å‹æ€§èƒ½ç”šè‡³ä¼˜äºå¤§è®¢å•ç§æœ‰ç³»ç»Ÿï¼ŒéªŒè¯äº†è‡ªåŠ¨åŒ–æ•°æ®ç”Ÿæˆæ¡†æ¶çš„é‡è¦æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰çš„é”™è¯¯æ¨¡å¼ç†è§£å¯¹å…¶å¯é æ€§å’Œå®‰å…¨æ€§è‡³å…³é‡è¦ã€‚</li>
<li>å½“å‰ç ”ç©¶å—é™äºç¼ºä¹å…·æœ‰ç²¾ç¡®åœ°é¢çœŸå®é”™è¯¯æ ‡ç­¾çš„å¤§è§„æ¨¡ã€å¤šæ ·åŒ–æ•°æ®é›†ã€‚</li>
<li>AEGISæ¡†æ¶ç”¨äºè‡ªåŠ¨ç”Ÿæˆå’Œè¯†åˆ«å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„é”™è¯¯ã€‚</li>
<li>AEGISé€šè¿‡æ³¨å…¥å¯æ§å’Œå¯è¿½è¸ªçš„é”™è¯¯åˆ°åˆå§‹æˆåŠŸè½¨è¿¹æ¥åˆ›å»ºæ•°æ®é›†ã€‚</li>
<li>é‡‡ç”¨è¯­å¢ƒæ„ŸçŸ¥ã€åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„è‡ªé€‚åº”æ“çºµå™¨å®ç°å¤æ‚æ”»å‡»ä»¥äº§ç”Ÿé”™è¯¯ã€‚</li>
<li>ä¸‰ç§å­¦ä¹ èŒƒå¼åœ¨AEGISæ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒéªŒè¯ï¼ŒåŒ…æ‹¬ç›‘ç£å¾®è°ƒã€å¼ºåŒ–å­¦ä¹ å’Œå¯¹æ¯”å­¦ä¹ ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.14295">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-50375d61413c4c77fd0136095395dffc" align="middle">
<img src="https://picx.zhimg.com/v2-1585bc3b7d45926a9b8842b30bd379e8" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="WebExplorer-Explore-and-Evolve-for-Training-Long-Horizon-Web-Agents"><a href="#WebExplorer-Explore-and-Evolve-for-Training-Long-Horizon-Web-Agents" class="headerlink" title="WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents"></a>WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents</h2><p><strong>Authors:Junteng Liu, Yunji Li, Chi Zhang, Jingyang Li, Aili Chen, Ke Ji, Weiyu Cheng, Zijia Wu, Chengyu Du, Qidi Xu, Jiayuan Song, Zhengmao Zhu, Wenhu Chen, Pengyu Zhao, Junxian He</strong></p>
<p>The paradigm of Large Language Models (LLMs) has increasingly shifted toward agentic applications, where web browsing capabilities are fundamental for retrieving information from diverse online sources. However, existing open-source web agents either demonstrate limited information-seeking abilities on complex tasks or lack transparent implementations. In this work, we identify that the key challenge lies in the scarcity of challenging data for information seeking. To address this limitation, we introduce WebExplorer: a systematic data generation approach using model-based exploration and iterative, long-to-short query evolution. This method creates challenging query-answer pairs that require multi-step reasoning and complex web navigation. By leveraging our curated high-quality dataset, we successfully develop advanced web agent WebExplorer-8B through supervised fine-tuning followed by reinforcement learning. Our model supports 128K context length and up to 100 tool calling turns, enabling long-horizon problem solving. Across diverse information-seeking benchmarks, WebExplorer-8B achieves the state-of-the-art performance at its scale. Notably, as an 8B-sized model, WebExplorer-8B is able to effectively search over an average of 16 turns after RL training, achieving higher accuracy than WebSailor-72B on BrowseComp-en&#x2F;zh and attaining the best performance among models up to 100B parameters on WebWalkerQA and FRAMES. Beyond these information-seeking tasks, our model also achieves strong generalization on the HLE benchmark even though it is only trained on knowledge-intensive QA data. These results highlight our approach as a practical path toward long-horizon web agents. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„èŒƒå¼è¶Šæ¥è¶Šè½¬å‘ä»£ç†åº”ç”¨ï¼Œå…¶ä¸­ç½‘é¡µæµè§ˆèƒ½åŠ›å¯¹äºä»å„ç§åœ¨çº¿æ¥æºæ£€ç´¢ä¿¡æ¯è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¼€æºç½‘ç»œä»£ç†è¦ä¹ˆåœ¨å¤æ‚ä»»åŠ¡ä¸Šè¡¨ç°å‡ºæœ‰é™çš„ä¿¡æ¯æœç´¢èƒ½åŠ›ï¼Œè¦ä¹ˆç¼ºä¹é€æ˜çš„å®ç°ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å‘ç°å…³é”®æŒ‘æˆ˜åœ¨äºç¼ºä¹ä¿¡æ¯æœç´¢çš„æŒ‘æˆ˜æ€§æ•°æ®ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†WebExplorerï¼šä¸€ç§åŸºäºæ¨¡å‹æ¢ç´¢å’Œæ•°æ®è¿­ä»£ã€ä»é•¿åˆ°çŸ­çš„æŸ¥è¯¢è¿›åŒ–çš„ç³»ç»Ÿæ•°æ®ç”Ÿæˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ›å»ºéœ€è¦å¤šæ­¥éª¤æ¨ç†å’Œå¤æ‚ç½‘ç»œå¯¼èˆªçš„æŒ‘æˆ˜æ€§æŸ¥è¯¢ç­”æ¡ˆå¯¹ã€‚é€šè¿‡åˆ©ç”¨æˆ‘ä»¬ç²¾å¿ƒç­–åˆ’çš„é«˜è´¨é‡æ•°æ®é›†ï¼Œæˆ‘ä»¬æˆåŠŸåœ°å¼€å‘äº†å…ˆè¿›çš„ç½‘ç»œä»£ç†WebExplorer-8Bï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒåé‡‡ç”¨å¼ºåŒ–å­¦ä¹ ã€‚æˆ‘ä»¬çš„æ¨¡å‹æ”¯æŒ12ä¸‡8åƒæ¬¡çš„ä¸Šä¸‹æ–‡é•¿åº¦å’Œæœ€å¤šè¾¾10ä¸‡æ¬¡çš„å·¥å…·è°ƒç”¨å›åˆï¼Œå¯å®ç°é•¿æœŸè§„åˆ’çš„é—®é¢˜è§£å†³ã€‚åœ¨å¤šç§ä¿¡æ¯æœç´¢åŸºå‡†æµ‹è¯•ä¸­ï¼ŒWebExplorer-8Båœ¨å…¶è§„æ¨¡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä½œä¸ºä¸€ä¸ªè§„æ¨¡ä¸º8Bçš„æ¨¡å‹ï¼ŒWebExplorer-8Båœ¨ç»è¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒåèƒ½å¤Ÿåœ¨å¹³å‡è¶…è¿‡16è½®å†…è¿›è¡Œæœ‰æ•ˆæœç´¢ï¼Œåœ¨BrowseComp-en&#x2F;zhä¸Šçš„å‡†ç¡®åº¦é«˜äºWebSailor-72Bï¼Œå¹¶åœ¨WebWalkerQAå’ŒFRAMESä¸Šçš„æ€§èƒ½è¡¨ç°è¾¾åˆ°äº†å‚æ•°åœ¨ä¸è¶…è¿‡ç™¾äº¿çš„æ¨¡å‹ä¸­çš„æœ€ä½³æ°´å¹³ã€‚é™¤äº†è¿™äº›ä¿¡æ¯æœç´¢ä»»åŠ¡ä¹‹å¤–ï¼Œå³ä½¿åœ¨åªæ¥å—äº†çŸ¥è¯†å¯†é›†å‹é—®ç­”æ•°æ®è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨HLEåŸºå‡†æµ‹è¯•ä¸Šä¹Ÿè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›ç»“æœçªæ˜¾äº†æˆ‘ä»¬çš„æ–¹æ³•ä½œä¸ºå®ç°é•¿æœŸç½‘ç»œä»£ç†çš„å®é™…é€”å¾„çš„å¯è¡Œæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06501v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨é¢å‘ä»£ç†åº”ç”¨æ—¶çš„æŒ‘æˆ˜åŠè§£å†³æ–¹æ¡ˆã€‚é’ˆå¯¹ç°æœ‰å¼€æºç½‘ç»œä»£ç†åœ¨ä¿¡æ¯æœç´¢æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†WebExploreræ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡æ¨¡å‹æ¢ç´¢ã€è¿­ä»£å¼é•¿çŸ­æŸ¥è¯¢æ¼”åŒ–ï¼Œç”Ÿæˆå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ç­”æ¡ˆå¯¹ï¼Œå¹¶å‘å±•äº†WebExplorer-8Bç½‘ç»œä»£ç†ã€‚è¯¥æ¨¡å‹æ”¯æŒé•¿è¯­å¢ƒå’Œå¤šæ¬¡å·¥å…·è°ƒç”¨ï¼Œèƒ½åœ¨å¤šç§ä¿¡æ¯æœç´¢åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£è¶Šæ¥è¶Šå¤šåœ°åº”ç”¨äºä»£ç†åº”ç”¨ï¼Œå…¶ä¸­ç½‘ç»œæµè§ˆèƒ½åŠ›å¯¹äºä»å„ç§åœ¨çº¿æ¥æºæ£€ç´¢ä¿¡æ¯è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰å¼€æºç½‘ç»œä»£ç†åœ¨é¢å¯¹å¤æ‚ä»»åŠ¡æ—¶ï¼Œä¿¡æ¯æœç´¢èƒ½åŠ›æœ‰é™ï¼Œä¸”å®æ–½ä¸å¤Ÿé€æ˜ã€‚</li>
<li>WebExploreræ–¹æ³•é€šè¿‡æ¨¡å‹æ¢ç´¢å’ŒæŸ¥è¯¢è¿­ä»£ï¼Œè§£å†³äº†ä¿¡æ¯æœç´¢ä¸­çš„å…³é”®æŒ‘æˆ˜ï¼Œç”Ÿæˆå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ç­”æ¡ˆå¯¹ã€‚</li>
<li>WebExplorer-8Bç½‘ç»œä»£ç†çš„æˆåŠŸå¼€å‘å¾—ç›Šäºç²¾å¿ƒç­–åˆ’çš„é«˜è´¨é‡æ•°æ®é›†ã€‚</li>
<li>WebExplorer-8Bæ¨¡å‹æ”¯æŒé•¿è¯­å¢ƒå’Œå¤šæ¬¡å·¥å…·è°ƒç”¨ï¼Œå®ç°äº†é•¿å‘¨æœŸé—®é¢˜è§£å†³ã€‚</li>
<li>åœ¨å¤šç§ä¿¡æ¯æœç´¢åŸºå‡†æµ‹è¯•ä¸­ï¼ŒWebExplorer-8Bè¾¾åˆ°äº†æœ€ä½³æ€§èƒ½ï¼Œç”šè‡³è¶…è¶Šäº†ä¸€äº›æ›´å¤§è§„æ¨¡æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06501">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0e3e6ebfa04529d2de1948f51ff2eafd" align="middle">
<img src="https://picx.zhimg.com/v2-273efab020c08ef4882dd8020756fed0" align="middle">
<img src="https://picx.zhimg.com/v2-dad0a05ae16265106b1a7181ac268551" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="JudgeAgent-Knowledge-wise-and-Dynamic-LLM-Evaluation-with-Agent-as-Interviewer"><a href="#JudgeAgent-Knowledge-wise-and-Dynamic-LLM-Evaluation-with-Agent-as-Interviewer" class="headerlink" title="JudgeAgent: Knowledge-wise and Dynamic LLM Evaluation with   Agent-as-Interviewer"></a>JudgeAgent: Knowledge-wise and Dynamic LLM Evaluation with   Agent-as-Interviewer</h2><p><strong>Authors:Zhichao Shi, Xuhui Jiang, Chengjin Xu, Cangli Yao, Zhenxin Huang, Shengjie Ma, Yinghan Shen, Jian Guo, Yuanzhuo Wang</strong></p>
<p>Current evaluation paradigms for large language models (LLMs) suffer from overestimated or biased evaluation and mismatched question difficulty, leading to incomplete evaluations of LLMâ€™s knowledge and capability boundaries, which hinder LLMâ€™s effective application and optimization. To address these challenges, we propose Agent-as-Interviewer, a dynamic evaluation paradigm that employs LLM agents to conduct multi-turn interactions for evaluation. Unlike current benchmarking or dynamic interaction paradigms, Agent-as-Interviewer utilizes agents to call knowledge tools for wider and deeper knowledge in the dynamic multi-turn question generation, achieving more complete evaluations of the LLMâ€™s knowledge boundaries. It also leverages agents to plan query strategies for adjustment of the question difficulty levels, enhancing the difficulty control to match the actual capabilities of target LLMs. Based on this paradigm, we develop JudgeAgent, a knowledge-wise dynamic evaluation framework that employs knowledge-driven synthesis as the agentâ€™s tool, and uses difficulty scoring as strategy guidance, thereby finally providing valuable suggestions to help targets optimize themselves. Extensive experiments validate the effectiveness of JudgeAgentâ€™s suggestions, demonstrating that Agent-as-Interviewer can accurately identify the knowledge and capability boundaries of target models. The source code is available on <a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/JudgeAgent">https://anonymous.4open.science/r/JudgeAgent</a>. </p>
<blockquote>
<p>å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¯„ä»·èŒƒå¼å­˜åœ¨è¿‡åº¦ä¼°è®¡æˆ–åå‘è¯„ä»·ä»¥åŠé—®é¢˜éš¾åº¦ä¸åŒ¹é…çš„é—®é¢˜ï¼Œå¯¼è‡´å¯¹LLMçš„çŸ¥è¯†å’Œèƒ½åŠ›è¾¹ç•Œè¯„ä»·ä¸å®Œæ•´ï¼Œé˜»ç¢äº†LLMçš„æœ‰æ•ˆåº”ç”¨å’Œä¼˜åŒ–ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†â€œAgent-as-Interviewerâ€åŠ¨æ€è¯„ä»·èŒƒå¼ï¼Œè¯¥èŒƒå¼é‡‡ç”¨LLMä»£ç†è¿›è¡Œå¤šè½®äº’åŠ¨è¿›è¡Œè¯„ä»·ã€‚ä¸ç°æœ‰çš„åŸºå‡†æµ‹è¯•æˆ–åŠ¨æ€äº¤äº’èŒƒå¼ä¸åŒï¼ŒAgent-as-Intervieweråˆ©ç”¨ä»£ç†è°ƒç”¨çŸ¥è¯†å·¥å…·è¿›è¡Œæ›´å¹¿æ³›å’Œæ·±å…¥çš„çŸ¥è¯†åŠ¨æ€å¤šè½®é—®é¢˜ç”Ÿæˆï¼Œå®ç°å¯¹LLMçŸ¥è¯†è¾¹ç•Œçš„æ›´å®Œæ•´è¯„ä»·ã€‚å®ƒè¿˜åˆ©ç”¨ä»£ç†è§„åˆ’æŸ¥è¯¢ç­–ç•¥æ¥è°ƒæ•´é—®é¢˜éš¾åº¦çº§åˆ«ï¼Œå¢å¼ºéš¾åº¦æ§åˆ¶ä»¥åŒ¹é…ç›®æ ‡LLMçš„å®é™…èƒ½åŠ›ã€‚åŸºäºè¿™ä¸€èŒƒå¼ï¼Œæˆ‘ä»¬å¼€å‘äº†JudgeAgentçŸ¥è¯†å‹åŠ¨æ€è¯„ä»·æ¡†æ¶ï¼Œé‡‡ç”¨çŸ¥è¯†é©±åŠ¨åˆæˆä½œä¸ºä»£ç†å·¥å…·ï¼Œä½¿ç”¨éš¾åº¦è¯„åˆ†ä½œä¸ºç­–ç•¥æŒ‡å¯¼ï¼Œæœ€ç»ˆä¸ºç›®æ ‡æä¾›æœ‰ä»·å€¼çš„å»ºè®®ä»¥å¸®åŠ©å…¶ä¼˜åŒ–è‡ªèº«ã€‚å¤§é‡å®éªŒéªŒè¯äº†JudgeAgentå»ºè®®çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜Agent-as-Interviewerèƒ½å¤Ÿå‡†ç¡®è¯†åˆ«ç›®æ ‡æ¨¡å‹çš„çŸ¥è¯†å’Œèƒ½åŠ›è¾¹ç•Œã€‚æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/JudgeAgent%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://anonymous.4open.science/r/JudgeAgentä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.02097v2">PDF</a> </p>
<p><strong>Summary</strong>ï¼šå½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¯„ä»·ä½“ç³»å­˜åœ¨é«˜ä¼°ã€åè§ã€é—®é¢˜éš¾åº¦ä¸åŒ¹é…ç­‰é—®é¢˜ï¼Œæ— æ³•å…¨é¢è¯„ä¼°LLMçš„çŸ¥è¯†å’Œèƒ½åŠ›è¾¹ç•Œï¼Œåˆ¶çº¦äº†LLMçš„æœ‰æ•ˆåº”ç”¨å’Œä¼˜åŒ–ã€‚ä¸ºæ­¤ï¼Œæå‡ºAgent-as-IntervieweråŠ¨æ€è¯„ä»·ä½“ç³»ï¼Œåˆ©ç”¨LLMä»£ç†è¿›è¡Œå¤šè½®äº’åŠ¨è¯„ä»·ã€‚è¯¥ä½“ç³»é€šè¿‡ä»£ç†è°ƒç”¨çŸ¥è¯†å·¥å…·å®ç°æ›´å¹¿æ³›ã€æ›´æ·±å…¥çš„çŸ¥è¯†åŠ¨æ€å¤šè½®é—®é¢˜ç”Ÿæˆï¼Œæ›´å…¨é¢åœ°è¯„ä¼°LLMçš„çŸ¥è¯†è¾¹ç•Œï¼›åŒæ—¶ï¼Œåˆ©ç”¨ä»£ç†åˆ¶å®šæŸ¥è¯¢ç­–ç•¥ï¼Œè°ƒæ•´é—®é¢˜éš¾åº¦ï¼Œæ›´å¥½åœ°åŒ¹é…ç›®æ ‡LLMçš„å®é™…èƒ½åŠ›ã€‚åŸºäºè¯¥ä½“ç³»ï¼Œå¼€å‘äº†JudgeAgentçŸ¥è¯†åŠ¨æ€è¯„ä»·ä½“ç³»ï¼Œé‡‡ç”¨çŸ¥è¯†é©±åŠ¨åˆæˆä½œä¸ºä»£ç†å·¥å…·ï¼Œéš¾åº¦è¯„åˆ†ä½œä¸ºç­–ç•¥æŒ‡å¯¼ï¼Œä¸ºç›®æ ‡æ¨¡å‹æä¾›ä¼˜åŒ–å»ºè®®ã€‚å®éªŒéªŒè¯JudgeAgentçš„æœ‰æ•ˆæ€§ï¼Œè¡¨æ˜Agent-as-Interviewerèƒ½å‡†ç¡®è¯†åˆ«ç›®æ ‡æ¨¡å‹çš„çŸ¥è¯†å’Œèƒ½åŠ›è¾¹ç•Œã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¯„ä»·ä½“ç³»å­˜åœ¨é—®é¢˜ï¼Œå¦‚é«˜ä¼°ã€åè§åŠé—®é¢˜éš¾åº¦ä¸åŒ¹é…ç­‰ã€‚</li>
<li>Agent-as-IntervieweråŠ¨æ€è¯„ä»·ä½“ç³»é€šè¿‡LLMä»£ç†è¿›è¡Œå¤šè½®äº’åŠ¨è¯„ä»·ï¼Œè§£å†³è¿™äº›é—®é¢˜ã€‚</li>
<li>è¯¥ä½“ç³»åˆ©ç”¨ä»£ç†è°ƒç”¨çŸ¥è¯†å·¥å…·å®ç°æ›´å¹¿æ³›å’Œæ·±å…¥çš„çŸ¥è¯†åŠ¨æ€å¤šè½®é—®é¢˜ç”Ÿæˆã€‚</li>
<li>Agent-as-Interviewerèƒ½æ›´å…¨é¢åœ°è¯„ä¼°LLMçš„çŸ¥è¯†è¾¹ç•Œã€‚</li>
<li>ä»£ç†åˆ¶å®šæŸ¥è¯¢ç­–ç•¥ï¼Œè°ƒæ•´é—®é¢˜éš¾åº¦ï¼Œä»¥åŒ¹é…ç›®æ ‡LLMçš„å®é™…èƒ½åŠ›ã€‚</li>
<li>JudgeAgentçŸ¥è¯†åŠ¨æ€è¯„ä»·ä½“ç³»é‡‡ç”¨çŸ¥è¯†é©±åŠ¨åˆæˆå’Œéš¾åº¦è¯„åˆ†ç­–ç•¥ï¼Œæä¾›ä¼˜åŒ–å»ºè®®ã€‚</li>
<li>å®éªŒéªŒè¯JudgeAgentçš„æœ‰æ•ˆæ€§ï¼Œèƒ½å‡†ç¡®è¯†åˆ«ç›®æ ‡æ¨¡å‹çš„çŸ¥è¯†å’Œèƒ½åŠ›è¾¹ç•Œã€‚æºä»£ç å·²å…¬å¼€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.02097">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-14adcac58fd0a3c31635c3b4da14016b" align="middle">
<img src="https://picx.zhimg.com/v2-ac0a7f2d34f0f2dda2ad5d1910c485ee" align="middle">
<img src="https://picx.zhimg.com/v2-b97d93b669b300ca42ee9cc242573797" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="R-D-Agent-Quant-A-Multi-Agent-Framework-for-Data-Centric-Factors-and-Model-Joint-Optimization"><a href="#R-D-Agent-Quant-A-Multi-Agent-Framework-for-Data-Centric-Factors-and-Model-Joint-Optimization" class="headerlink" title="R&amp;D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and   Model Joint Optimization"></a>R&amp;D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and   Model Joint Optimization</h2><p><strong>Authors:Yuante Li, Xu Yang, Xiao Yang, Minrui Xu, Xisen Wang, Weiqing Liu, Jiang Bian</strong></p>
<p>Financial markets pose fundamental challenges for asset return prediction due to their high dimensionality, non-stationarity, and persistent volatility. Despite advances in large language models and multi-agent systems, current quantitative research pipelines suffer from limited automation, weak interpretability, and fragmented coordination across key components such as factor mining and model innovation. In this paper, we propose R&amp;D-Agent for Quantitative Finance, in short RD-Agent(Q), the first data-centric multi-agent framework designed to automate the full-stack research and development of quantitative strategies via coordinated factor-model co-optimization. RD-Agent(Q) decomposes the quant process into two iterative stages: a Research stage that dynamically sets goal-aligned prompts, formulates hypotheses based on domain priors, and maps them to concrete tasks, and a Development stage that employs a code-generation agent, Co-STEER, to implement task-specific code, which is then executed in real-market backtests. The two stages are connected through a feedback stage that thoroughly evaluates experimental outcomes and informs subsequent iterations, with a multi-armed bandit scheduler for adaptive direction selection. Empirically, RD-Agent(Q) achieves up to 2X higher annualized returns than classical factor libraries using 70% fewer factors, and outperforms state-of-the-art deep time-series models on real markets. Its joint factor-model optimization delivers a strong balance between predictive accuracy and strategy robustness. Our code is available at: <a target="_blank" rel="noopener" href="https://github.com/microsoft/RD-Agent">https://github.com/microsoft/RD-Agent</a>. </p>
<blockquote>
<p>é‡‘èå¸‚åœºç”±äºå…¶é«˜ç»´æ€§ã€éç¨³å®šæ€§å’ŒæŒç»­æ³¢åŠ¨æ€§ï¼Œå¯¹èµ„äº§å›æŠ¥é¢„æµ‹æ„æˆäº†æ ¹æœ¬æ€§æŒ‘æˆ˜ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹å’Œå¤šå…ƒä»£ç†ç³»ç»Ÿæœ‰æ‰€è¿›å±•ï¼Œä½†ç›®å‰çš„å®šé‡ç ”ç©¶ç®¡é“åœ¨è‡ªåŠ¨åŒ–ã€å¯è§£é‡Šæ€§æ–¹é¢å­˜åœ¨å±€é™ï¼Œä¸”åœ¨å› å­æŒ–æ˜å’Œæ¨¡å‹åˆ›æ–°ç­‰å…³é”®ç»„ä»¶ä¹‹é—´çš„åè°ƒç¢ç‰‡åŒ–ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†é’ˆå¯¹é‡‘èé‡åŒ–çš„R&amp;D-Agentï¼Œç®€ç§°RD-Agentï¼ˆQï¼‰ï¼Œè¿™æ˜¯é¦–ä¸ªä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„å¤šä»£ç†æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡åè°ƒçš„å› å­æ¨¡å‹ååŒä¼˜åŒ–æ¥è‡ªåŠ¨åŒ–å®šé‡ç­–ç•¥çš„å…¨æ ˆç ”å‘ã€‚RD-Agentï¼ˆQï¼‰å°†é‡åŒ–è¿‡ç¨‹åˆ†è§£ä¸ºä¸¤ä¸ªè¿­ä»£é˜¶æ®µï¼šç ”ç©¶é˜¶æ®µåŠ¨æ€è®¾ç½®ç›®æ ‡å¯¹é½çš„æç¤ºï¼ŒåŸºäºé¢†åŸŸå…ˆéªŒåˆ¶å®šå‡è®¾ï¼Œå¹¶å°†å…¶æ˜ å°„ä¸ºå…·ä½“ä»»åŠ¡ï¼›å¼€å‘é˜¶æ®µåˆ™åˆ©ç”¨ä»£ç ç”Ÿæˆä»£ç†Co-STEERæ¥æ‰§è¡Œç‰¹å®šä»»åŠ¡çš„ä»£ç ï¼Œéšååœ¨çœŸå®å¸‚åœºä¸­è¿›è¡Œå›æµ‹ã€‚ä¸¤ä¸ªé˜¶æ®µé€šè¿‡åé¦ˆé˜¶æ®µè¿æ¥ï¼Œè¯¥é˜¶æ®µå¯¹å®éªŒç»“æœè¿›è¡Œå…¨é¢è¯„ä¼°å¹¶ä¸ºåç»­è¿­ä»£æä¾›ä¿¡æ¯ï¼ŒåŒæ—¶ä½¿ç”¨å¤šè‡‚åŒªå¾’è°ƒåº¦å™¨è¿›è¡Œè‡ªé€‚åº”æ–¹å‘é€‰æ‹©ã€‚å®è¯è¡¨æ˜ï¼ŒRD-Agentï¼ˆQï¼‰ä½¿ç”¨70%æ›´å°‘çš„å› ç´ å®ç°äº†é«˜è¾¾ä¸¤å€äºä¼ ç»Ÿå› ç´ åº“çš„å¹´åŒ–æ”¶ç›Šç‡ï¼Œå¹¶ä¸”åœ¨çœŸå®å¸‚åœºä¸Šä¼˜äºæœ€æ–°æ·±åº¦æ—¶é—´åºåˆ—æ¨¡å‹ã€‚å…¶è”åˆå› å­æ¨¡å‹ä¼˜åŒ–åœ¨é¢„æµ‹ç²¾åº¦å’Œç­–ç•¥ç¨³å¥æ€§ä¹‹é—´è¾¾åˆ°äº†è‰¯å¥½çš„å¹³è¡¡ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/microsoft/RD-Agent%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/microsoft/RD-Agentä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15155v2">PDF</a> 42 pages,11figures, NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†é’ˆå¯¹é‡‘èå¸‚åœºçš„é‡åŒ–ç­–ç•¥ç ”å‘å¤šæ™ºèƒ½ä½“æ¡†æ¶RD-Agent(Q)ã€‚è¯¥æ¡†æ¶é€šè¿‡ååŒä¼˜åŒ–å› å­æ¨¡å‹ï¼Œå®ç°é‡åŒ–ç­–ç•¥çš„è‡ªåŠ¨åŒ–ç ”å‘ã€‚æ¡†æ¶åŒ…å«ç ”ç©¶é˜¶æ®µå’Œå‘å±•é˜¶æ®µä¸¤ä¸ªè¿­ä»£é˜¶æ®µï¼Œåˆ†åˆ«è´Ÿè´£è®¾å®šç›®æ ‡æç¤ºã€å½¢æˆåŸºäºé¢†åŸŸå…ˆéªŒçš„å‡è®¾å’Œè½¬åŒ–ä¸ºå®é™…ä»»åŠ¡ä»£ç å¹¶æ‰§è¡Œå®ç›˜æµ‹è¯•ï¼Œä¸”ä¸¤ä¸ªé˜¶æ®µé—´è®¾æœ‰åé¦ˆç¯èŠ‚æ¥è¯„ä¼°å®éªŒç»“æœå¹¶æŒ‡å¯¼åç»­è¿­ä»£æ–¹å‘ã€‚ç»éªŒå®è¯æ˜¾ç¤ºï¼ŒRD-Agent(Q)èƒ½å®ç°ç›¸è¾ƒäºä¼ ç»Ÿå› å­åº“æ›´é«˜çš„å¹´åŒ–å›æŠ¥å¹¶æ˜¾è‘—ä¼˜äºç°æœ‰çš„æ—¶é—´åºåˆ—æ¨¡å‹ã€‚ç›®å‰è¯¥ä»£ç å·²å¼€æºäºGitHubå¾®è½¯RD-Agenté¡¹ç›®ä¸­ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RD-Agent(Q)æ˜¯ä¸€ä¸ªé’ˆå¯¹é‡‘èå¸‚åœºçš„é‡åŒ–ç­–ç•¥ç ”å‘çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°é‡åŒ–ç­–ç•¥çš„è‡ªåŠ¨åŒ–ç ”å‘ã€‚</li>
<li>è¯¥æ¡†æ¶é€šè¿‡ååŒä¼˜åŒ–å› å­æ¨¡å‹æ¥æé«˜é¢„æµ‹èµ„äº§å›æŠ¥çš„å‡†ç¡®æ€§ã€‚</li>
<li>RD-Agent(Q)åŒ…å«ç ”ç©¶é˜¶æ®µå’Œå‘å±•é˜¶æ®µä¸¤ä¸ªè¿­ä»£é˜¶æ®µï¼Œç ”ç©¶é˜¶æ®µåŠ¨æ€è®¾ç½®ç›®æ ‡æç¤ºå’Œå‡è®¾ï¼Œå‘å±•é˜¶æ®µåˆ™è´Ÿè´£ç”Ÿæˆä»»åŠ¡ç‰¹å®šä»£ç å¹¶åœ¨å®é™…å¸‚åœºä¸­è¿›è¡Œæµ‹è¯•ã€‚</li>
<li>åé¦ˆç¯èŠ‚å½»åº•è¯„ä¼°å®éªŒç»“æœå¹¶æŒ‡å¯¼åç»­è¿­ä»£æ–¹å‘ï¼ŒåŒæ—¶é€šè¿‡å¤šæ™ºèƒ½ä½“ååŒæå‡å®éªŒæ•ˆç‡å’Œç»“æœè´¨é‡ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒRD-Agent(Q)å®ç°äº†é«˜è¾¾ä¸¤å€çš„å¹´åŒ–å›æŠ¥ç‡ï¼Œç›¸è¾ƒäºä¼ ç»Ÿå› å­åº“ä½¿ç”¨æ›´å°‘çš„å› ç´ æ•°é‡ã€‚</li>
<li>RD-Agent(Q)åœ¨å®é™…å¸‚åœºè¡¨ç°ä¼˜äºç›®å‰æœ€å…ˆè¿›çš„æ·±åº¦æ—¶é—´åºåˆ—æ¨¡å‹ã€‚å…¶å¹³è¡¡çš„é¢„æµ‹ç²¾åº¦å’Œç­–ç•¥ç¨³å¥æ€§å¸¦æ¥äº†å“è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15155">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-61e71778d073bc62bfc4925095a71e4e" align="middle">
<img src="https://picx.zhimg.com/v2-da7049b52bc19b08cb677b353508632d" align="middle">
<img src="https://picx.zhimg.com/v2-bd9a53ec2196bb61eed4334328d19062" align="middle">
<img src="https://picx.zhimg.com/v2-dce81b0ca6ad8f2bef601de9122f7de8" align="middle">
<img src="https://picx.zhimg.com/v2-ab5aa58635c02d678a48e233ce6023c0" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="MASS-Muli-agent-simulation-scaling-for-portfolio-construction"><a href="#MASS-Muli-agent-simulation-scaling-for-portfolio-construction" class="headerlink" title="MASS: Muli-agent simulation scaling for portfolio construction"></a>MASS: Muli-agent simulation scaling for portfolio construction</h2><p><strong>Authors:Taian Guo, Haiyang Shen, JinSheng Huang, Zhengyang Mao, Junyu Luo, Binqi Chen, Zhuoru Chen, Luchen Liu, Bingyu Xia, Xuhui Liu, Yun Ma, Ming Zhang</strong></p>
<p>The application of LLM-based agents in financial investment has shown significant promise, yet existing approaches often require intermediate steps like predicting individual stock movements or rely on predefined, static workflows. These limitations restrict their adaptability and effectiveness in constructing optimal portfolios. In this paper, we introduce the Multi-Agent Scaling Simulation (MASS), a novel framework that leverages multi-agent simulation for direct, end-to-end portfolio construction. At its core, MASS employs a backward optimization process to dynamically learn the optimal distribution of heterogeneous agents, enabling the system to adapt to evolving market regimes. A key finding enabled by our framework is the exploration of the scaling effect for portfolio construction: we demonstrate that as the number of agents increases exponentially (up to 512), the aggregated decisions yield progressively higher excess returns. Extensive experiments on a challenging, self-collected dataset from the 2023 Chinese A-share market show that MASS consistently outperforms seven state-of-the-art baselines. Further backtesting, stability analyses and the experiment on data leakage concerns validate its enhanced profitability and robustness. We have open-sourced our code, dataset, and training snapshots at <a target="_blank" rel="noopener" href="https://github.com/gta0804/MASS/">https://github.com/gta0804/MASS/</a> to foster further research. </p>
<blockquote>
<p>åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†åœ¨é‡‘èæŠ•èµ„ä¸­çš„åº”ç”¨å‰æ™¯å¹¿é˜”ï¼Œä½†ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦é¢„æµ‹ä¸ªè‚¡èµ°åŠ¿ç­‰ä¸­é—´æ­¥éª¤ï¼Œæˆ–è€…ä¾èµ–äºé¢„å®šä¹‰ã€é™æ€çš„å·¥ä½œæµç¨‹ã€‚è¿™äº›é™åˆ¶å½±å“äº†å®ƒä»¬åœ¨æ„å»ºæœ€ä¼˜æŠ•èµ„ç»„åˆæ—¶çš„é€‚åº”æ€§å’Œæœ‰æ•ˆæ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†å¤šæ™ºèƒ½ä½“è§„æ¨¡ä»¿çœŸï¼ˆMASSï¼‰è¿™ä¸€æ–°å‹æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨å¤šæ™ºèƒ½ä½“ä»¿çœŸè¿›è¡Œç›´æ¥ç«¯åˆ°ç«¯çš„æŠ•èµ„ç»„åˆæ„å»ºã€‚å…¶æ ¸å¿ƒæ˜¯MASSé‡‡ç”¨é€†å‘ä¼˜åŒ–è¿‡ç¨‹æ¥åŠ¨æ€å­¦ä¹ å¼‚è´¨æ™ºèƒ½ä½“çš„æœ€ä½³åˆ†å¸ƒï¼Œä½¿ç³»ç»Ÿèƒ½å¤Ÿé€‚åº”ä¸æ–­å˜åŒ–çš„å¸‚åœºçŠ¶å†µã€‚æˆ‘ä»¬çš„æ¡†æ¶æ‰€å¸¦æ¥çš„ä¸€ä¸ªå…³é”®å‘ç°æ˜¯æ¢ç´¢æŠ•èµ„ç»„åˆæ„å»ºä¸­çš„è§„æ¨¡æ•ˆåº”ï¼šæˆ‘ä»¬è¯æ˜éšç€æ™ºèƒ½ä½“æ•°é‡çš„æŒ‡æ•°å¢é•¿ï¼ˆæœ€å¤šè‡³512ä¸ªï¼‰ï¼Œæ™ºèƒ½ä½“é›†ä½“åšå‡ºçš„å†³ç­–äº§ç”Ÿçš„è¶…é¢å›æŠ¥é€æ¸å¢åŠ ã€‚åœ¨æ¥è‡ª2023å¹´ä¸­å›½Aè‚¡å¸‚åœºè‡ªæˆ‘æ”¶é›†çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒMASSæŒç»­ä¼˜äºä¸ƒç§æœ€æ–°æŠ€æœ¯æ°´å¹³çš„åŸºçº¿ã€‚è¿›ä¸€æ­¥çš„åå‘æµ‹è¯•ã€ç¨³å®šæ€§åˆ†æå’Œæ•°æ®æ³„éœ²é—®é¢˜å®éªŒéªŒè¯äº†å…¶ç›ˆåˆ©èƒ½åŠ›å’Œç¨³å¥æ€§çš„æå‡ã€‚æˆ‘ä»¬å·²åœ¨<a target="_blank" rel="noopener" href="https://github.com/gta0804/MASS/%E5%BC%80%E6%BA%90%E6%88%91%E4%BB%AC%E7%9A%84%E4%BB%A3%E7%A0%81%E3%80%81%E6%95%B0%E6%8D%AE%E9%9B%86%E5%92%8C%E5%9F%B9%E8%AE%AD%E5%BF%AB%E7%85%A7%EF%BC%8C%E4%BB%A5%E4%BF%83%E8%BF%9B%E8%BF%9B%E4%B8%80%E6%AD%A5%E7%9A%84%E7%A0%94%E7%A9%B6%E3%80%82">https://github.com/gta0804/MASS/å¼€æºæˆ‘ä»¬çš„ä»£ç ã€æ•°æ®é›†å’ŒåŸ¹è®­å¿«ç…§ï¼Œä»¥ä¿ƒè¿›è¿›ä¸€æ­¥çš„ç ”ç©¶ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.10278v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“æ¨¡æ‹Ÿï¼ˆMASSï¼‰çš„æ–°å…´æ¡†æ¶ï¼Œç”¨äºç›´æ¥ç«¯åˆ°ç«¯çš„æŠ•èµ„ç»„åˆæ„å»ºã€‚è¯¥æ¡†æ¶åˆ©ç”¨åå‘ä¼˜åŒ–è¿‡ç¨‹åŠ¨æ€å­¦ä¹ å¼‚è´¨æ™ºèƒ½ä½“çš„æœ€ä¼˜åˆ†å¸ƒï¼Œä»¥é€‚åº”ä¸æ–­å˜åŒ–çš„å¸‚åœºç¯å¢ƒã€‚å®éªŒè¡¨æ˜ï¼Œéšç€æ™ºèƒ½ä½“æ•°é‡çš„å¢åŠ ï¼Œå†³ç­–èšåˆäº§ç”Ÿçš„è¶…é¢å›æŠ¥é€æ¸æé«˜ã€‚åœ¨2023å¹´ä¸­å›½Aè‚¡å¸‚åœºæ•°æ®é›†çš„æµ‹è¯•ä¸­ï¼ŒMASSæ¡†æ¶è¡¨ç°ä¼˜äºå…¶ä»–å…ˆè¿›æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“æ¨¡æ‹Ÿï¼ˆMASSï¼‰æ¡†æ¶ç”¨äºç›´æ¥ç«¯åˆ°ç«¯çš„æŠ•èµ„ç»„åˆæ„å»ºã€‚</li>
<li>è¯¥æ¡†æ¶é‡‡ç”¨åå‘ä¼˜åŒ–è¿‡ç¨‹æ¥åŠ¨æ€å­¦ä¹ æ™ºèƒ½ä½“çš„æœ€ä¼˜åˆ†å¸ƒã€‚</li>
<li>æ™ºèƒ½ä½“çš„å¢åŠ å¯å¸¦æ¥æ›´é«˜çš„è¶…é¢å›æŠ¥ã€‚</li>
<li>åœ¨ä¸­å›½Aè‚¡å¸‚åœºæ•°æ®é›†çš„æµ‹è¯•ä¸­ï¼ŒMASSè¡¨ç°ä¼˜å¼‚ï¼Œä¸”å¼€æºäº†ä»£ç å’Œæ•°æ®é›†ä»¥ä¿ƒè¿›è¿›ä¸€æ­¥ç ”ç©¶ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½é€‚åº”ä¸æ–­å˜åŒ–çš„å¸‚åœºç¯å¢ƒã€‚</li>
<li>é€šè¿‡å®éªŒéªŒè¯äº†MASSçš„ç›ˆåˆ©èƒ½åŠ›å’Œç¨³å¥æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.10278">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8d2a863be5354974aa0b57636ecda3bb" align="middle">
<img src="https://picx.zhimg.com/v2-19ebf2992fadd6d0b2a7728c485088b2" align="middle">
<img src="https://picx.zhimg.com/v2-0c89d9f6fd99472ff392a86195d0b15d" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-28/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-28/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-28/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-5950756b11116580223586885ae08372" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-28  RePro Leveraging Large Language Models for Semi-Automated Reproduction   of Networking Research Results
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-28/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-841c4ac40fb96c2b1c0d5a52a7cd602b" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-28  SciReasoner Laying the Scientific Reasoning Ground Across Disciplines
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32306k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
