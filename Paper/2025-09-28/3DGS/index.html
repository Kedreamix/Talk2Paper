<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-28  Gaussian splatting holography">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-d2865c189a251d46fd0c4be9ce253c50')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-28
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-16
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    19.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    79 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-28-æ›´æ–°"><a href="#2025-09-28-æ›´æ–°" class="headerlink" title="2025-09-28 æ›´æ–°"></a>2025-09-28 æ›´æ–°</h1><h2 id="Gaussian-splatting-holography"><a href="#Gaussian-splatting-holography" class="headerlink" title="Gaussian splatting holography"></a>Gaussian splatting holography</h2><p><strong>Authors:Shuhe Zhang, Liangcai Cao</strong></p>
<p>In-line holography offers high space-bandwidth product imaging with a simplified lens-free optical system. However, in-line holographic reconstruction is troubled by twin images arising from the Hermitian symmetry of complex fields. Twin images disrupt the reconstruction in solving the ill-posed phase retrieval problem. The known parameters are less than the unknown parameters, causing phase ambiguities. State-of-the-art deep-learning or non-learning methods face challenges in balancing data fidelity with twin-image disturbance. We propose the Gaussian splatting holography (GSH) for twin-image-suppressed holographic reconstruction. GSH uses Gaussian splatting for optical field representation and compresses the number of unknown parameters by a maximum of 15 folds, transforming the original ill-posed phase retrieval into a well-posed one with reduced phase ambiguities. Additionally, the Gaussian splatting tends to form sharp patterns rather than those with noisy twin-image backgrounds as each Gaussian has a spatially slow-varying profile. Experiments show that GSH achieves constraint-free recovery for in-line holography with accuracy comparable to state-of-the-art constraint-based methods, with an average peak signal-to-noise ratio equal to 26 dB, and structure similarity equal to 0.8. Combined with total variation, GSH can be further improved, obtaining a peak signal-to-noise ratio of 31 dB, and a high compression ability of up to 15 folds. </p>
<blockquote>
<p>å†…è”å…¨æ¯æœ¯é€šè¿‡ç®€åŒ–çš„æ— é€é•œå…‰å­¦ç³»ç»Ÿæä¾›é«˜ç©ºé—´å¸¦å®½ç§¯æˆåƒã€‚ç„¶è€Œï¼Œå†…è”å…¨æ¯é‡å»ºå—åˆ°æ¥è‡ªå¤åœºHermitianå¯¹ç§°æ€§çš„å­ªç”Ÿå›¾åƒçš„å›°æ‰°ã€‚å­ªç”Ÿå›¾åƒç ´åäº†è§£å†³ä¸é€‚å®šç›¸ä½æ£€ç´¢é—®é¢˜æ—¶çš„é‡å»ºã€‚å·²çŸ¥å‚æ•°å°‘äºæœªçŸ¥å‚æ•°ï¼Œå¯¼è‡´ç›¸ä½æ¨¡ç³Šã€‚ç°æœ‰çš„æœ€å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æˆ–éå­¦ä¹ æ–¹æ³•åœ¨å¹³è¡¡æ•°æ®ä¿çœŸä¸å­ªç”Ÿå›¾åƒå¹²æ‰°æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºé«˜æ–¯æ–‘ç‚¹å…¨æ¯æœ¯ï¼ˆGSHï¼‰ç”¨äºæŠ‘åˆ¶å­ªç”Ÿå›¾åƒçš„å…¨æ¯é‡å»ºã€‚GSHä½¿ç”¨é«˜æ–¯æ–‘ç‚¹è¿›è¡Œå…‰å­¦åœºè¡¨ç¤ºï¼Œå¹¶é€šè¿‡æœ€å¤šå‡å°‘15å€æœªçŸ¥å‚æ•°çš„æ•°é‡ï¼Œå°†åŸå§‹çš„ä¸é€‚å®šç›¸ä½æ£€ç´¢é—®é¢˜è½¬å˜ä¸ºå…·æœ‰è¾ƒå°‘ç›¸ä½æ¨¡ç³Šçš„è‰¯å¥½å®šä½é—®é¢˜ã€‚æ­¤å¤–ï¼Œé«˜æ–¯æ–‘ç‚¹å€¾å‘äºå½¢æˆæ¸…æ™°çš„å›¾æ¡ˆï¼Œè€Œä¸æ˜¯å¸¦æœ‰å˜ˆæ‚å­ªç”Ÿå›¾åƒèƒŒæ™¯çš„å›¾æ¡ˆï¼Œå› ä¸ºæ¯ä¸ªé«˜æ–¯éƒ½å…·æœ‰ç©ºé—´ç¼“æ…¢å˜åŒ–çš„è½®å»“ã€‚å®éªŒè¡¨æ˜ï¼ŒGSHå®ç°äº†å†…è”å…¨æ¯å›¾çš„çº¦æŸè‡ªç”±æ¢å¤ï¼Œå…¶å‡†ç¡®æ€§å¯ä¸æœ€å…ˆè¿›çš„åŸºäºçº¦æŸçš„æ–¹æ³•ç›¸åª²ç¾ï¼Œå¹³å‡å³°å€¼ä¿¡å™ªæ¯”è¾¾åˆ°26åˆ†è´ï¼Œç»“æ„ç›¸ä¼¼æ€§ä¸º0.8ã€‚ç»“åˆå…¨å˜ï¼ŒGSHå¯ä»¥è¿›ä¸€æ­¥æ”¹è¿›ï¼Œè·å¾—å³°å€¼ä¿¡å™ªæ¯”31åˆ†è´ï¼Œå¹¶å…·å¤‡é«˜è¾¾15å€çš„å‡ºè‰²å‹ç¼©èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.20774v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    å…¨æ¯æˆåƒæŠ€æœ¯åˆ©ç”¨æ— é€é•œå…‰å­¦ç³»ç»Ÿå®ç°é«˜ç©ºé—´å¸¦å®½äº§å“æˆåƒã€‚ç„¶è€Œï¼Œå…¨æ¯é‡å»ºå—åˆ°å¤åœºHermiteå¯¹ç§°æ€§çš„å›°æ‰°ï¼Œå¯¼è‡´å‡ºç°é•œåƒå¹²æ‰°é—®é¢˜ã€‚ç”±äºå·²çŸ¥å‚æ•°å°‘äºæœªçŸ¥å‚æ•°ï¼Œç›¸ä½é‡å»ºå˜å¾—ä¸æ˜ç¡®ã€‚æœ€æ–°çš„æ·±åº¦å­¦ä¹ æ–¹æ³•æˆ–éå­¦ä¹ æ–¹æ³•åœ¨å¹³è¡¡æ•°æ®ä¿çœŸåº¦å’Œé•œåƒå¹²æ‰°æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºé«˜æ–¯å–·æº…å…¨æ¯æœ¯ï¼ˆGSHï¼‰ç”¨äºæŠ‘åˆ¶é•œåƒå¹²æ‰°çš„å…¨æ¯é‡å»ºã€‚GSHåˆ©ç”¨é«˜æ–¯å–·æº…è¡¨ç¤ºå…‰å­¦åœºï¼Œå°†æœªçŸ¥å‚æ•°æ•°é‡æœ€å¤šå‡å°‘15å€ï¼Œå°†åŸæ¥çš„ç—…æ€ç›¸ä½æ£€ç´¢é—®é¢˜è½¬åŒ–ä¸ºå…·æœ‰è¾ƒå°‘ç›¸ä½æ¨¡ç³Šçš„è‰¯å¥½ç›¸ä½æ£€ç´¢é—®é¢˜ã€‚æ­¤å¤–ï¼Œé«˜æ–¯å–·æº…å€¾å‘äºå½¢æˆæ¸…æ™°æ¨¡å¼ï¼Œé¿å…å™ªå£°è¾ƒå¤§çš„é•œåƒèƒŒæ™¯å¹²æ‰°ã€‚å®éªŒè¡¨æ˜ï¼ŒGSHå®ç°æ— çº¦æŸåœ¨çº¿å…¨æ¯æ¢å¤ï¼Œå‡†ç¡®ç‡ä¸å…ˆè¿›çš„çº¦æŸæ–¹æ³•ç›¸å½“ï¼Œå¹³å‡å³°å€¼ä¿¡å™ªæ¯”è¾¾åˆ°26åˆ†è´ï¼Œç»“æ„ç›¸ä¼¼æ€§ä¸º0.8ã€‚ä¸æ€»å˜å·®ç›¸ç»“åˆæ—¶ï¼ŒGSHæ€§èƒ½è¿›ä¸€æ­¥æå‡ï¼Œå³°å€¼ä¿¡å™ªæ¯”å¯è¾¾31åˆ†è´ï¼Œå‹ç¼©èƒ½åŠ›é«˜è¾¾15å€ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>åœ¨å…¨æ¯æˆåƒä¸­ï¼Œé•œåƒå¹²æ‰°é—®é¢˜æ˜¯ç”±äºå¤åœºçš„Hermiteå¯¹ç§°æ€§å¼•èµ·çš„ã€‚</li>
<li>å·²çŸ¥å‚æ•°å°‘äºæœªçŸ¥å‚æ•°å¯¼è‡´ç›¸ä½é‡å»ºå˜å¾—ä¸æ˜ç¡®ã€‚</li>
<li>é«˜æ–¯å–·æº…å…¨æ¯æœ¯ï¼ˆGSHï¼‰é€šè¿‡å‡å°‘æœªçŸ¥å‚æ•°æ•°é‡æ¥ç®€åŒ–å…¨æ¯é‡å»ºé—®é¢˜ã€‚</li>
<li>GSHå¯å°†ç—…æ€ç›¸ä½æ£€ç´¢é—®é¢˜è½¬åŒ–ä¸ºè‰¯å¥½ç›¸ä½æ£€ç´¢é—®é¢˜ï¼Œé™ä½ç›¸ä½æ¨¡ç³Šã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGSHåœ¨åœ¨çº¿å…¨æ¯æ¢å¤æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå‡†ç¡®ç‡ä¸ç°æœ‰æ–¹æ³•ç›¸å½“ã€‚</li>
<li>ç»“åˆæ€»å˜å·®æŠ€æœ¯æ—¶ï¼ŒGSHçš„å³°å€¼ä¿¡å™ªæ¯”å’Œå‹ç¼©èƒ½åŠ›å¾—åˆ°è¿›ä¸€æ­¥æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.20774">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fff92a5568841fa148f727c9dcd2f2e9" align="middle">
<img src="https://picx.zhimg.com/v2-97ee81314b77f0b6264531eaa01d1832" align="middle">
<img src="https://picx.zhimg.com/v2-123fa47eebd9c6ebe121c2983327ac9f" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="SeHDR-Single-Exposure-HDR-Novel-View-Synthesis-via-3D-Gaussian-Bracketing"><a href="#SeHDR-Single-Exposure-HDR-Novel-View-Synthesis-via-3D-Gaussian-Bracketing" class="headerlink" title="SeHDR: Single-Exposure HDR Novel View Synthesis via 3D Gaussian   Bracketing"></a>SeHDR: Single-Exposure HDR Novel View Synthesis via 3D Gaussian   Bracketing</h2><p><strong>Authors:Yiyu Li, Haoyuan Wang, Ke Xu, Gerhard Petrus Hancke, Rynson W. H. Lau</strong></p>
<p>This paper presents SeHDR, a novel high dynamic range 3D Gaussian Splatting (HDR-3DGS) approach for generating HDR novel views given multi-view LDR images. Unlike existing methods that typically require the multi-view LDR input images to be captured from different exposures, which are tedious to capture and more likely to suffer from errors (e.g., object motion blurs and calibration&#x2F;alignment inaccuracies), our approach learns the HDR scene representation from multi-view LDR images of a single exposure. Our key insight to this ill-posed problem is that by first estimating Bracketed 3D Gaussians (i.e., with different exposures) from single-exposure multi-view LDR images, we may then be able to merge these bracketed 3D Gaussians into an HDR scene representation. Specifically, SeHDR first learns base 3D Gaussians from single-exposure LDR inputs, where the spherical harmonics parameterize colors in a linear color space. We then estimate multiple 3D Gaussians with identical geometry but varying linear colors conditioned on exposure manipulations. Finally, we propose the Differentiable Neural Exposure Fusion (NeEF) to integrate the base and estimated 3D Gaussians into HDR Gaussians for novel view rendering. Extensive experiments demonstrate that SeHDR outperforms existing methods as well as carefully designed baselines. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†SeHDRï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„é«˜åŠ¨æ€èŒƒå›´3Dé«˜æ–¯æ‹¼è´´ï¼ˆHDR-3DGSï¼‰æ–¹æ³•ï¼Œç”¨äºæ ¹æ®å¤šè§†è§’LDRå›¾åƒç”ŸæˆHDRæ–°é¢–è§†å›¾ã€‚ä¸é€šå¸¸éœ€è¦ä»ä¸åŒæ›å…‰çš„å¤šè§†è§’LDRè¾“å…¥å›¾åƒæ•è·ç°æœ‰æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ä»å•æ›å…‰çš„å¤šè§†è§’LDRå›¾åƒä¸­å­¦ä¹ HDRåœºæ™¯è¡¨ç¤ºã€‚å¯¹äºè¿™ä¸ªä¸é€‚å®šé—®é¢˜çš„å…³é”®è§è§£æ˜¯ï¼Œé¦–å…ˆé€šè¿‡ä¼°è®¡å•æ›å…‰å¤šè§†è§’LDRå›¾åƒçš„æ‹¬å·3Dé«˜æ–¯ï¼ˆå³å…·æœ‰ä¸åŒæ›å…‰çš„ï¼‰æ¥åˆå¹¶è¿™äº›æ‹¬å·ä¸­çš„3Dé«˜æ–¯å€¼ï¼Œç„¶åå°†å…¶åˆå¹¶æˆHDRåœºæ™¯è¡¨ç¤ºã€‚å…·ä½“æ¥è¯´ï¼ŒSeHDRé¦–å…ˆä»å•æ›å…‰LDRè¾“å…¥ä¸­å­¦ä¹ åŸºç¡€3Dé«˜æ–¯å€¼ï¼Œå…¶ä¸­çƒé¢è°æ³¢åœ¨çº¿æ€§é¢œè‰²ç©ºé—´ä¸­æè¿°é¢œè‰²ã€‚ç„¶åï¼Œæˆ‘ä»¬ä¼°è®¡å…·æœ‰ç›¸åŒå‡ ä½•å½¢çŠ¶ä½†éšæ›å…‰æ“ä½œå˜åŒ–çš„ä¸åŒçº¿æ€§é¢œè‰²çš„å¤šä¸ª3Dé«˜æ–¯å€¼ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†å¯åŒºåˆ†çš„ç¥ç»æ›å…‰èåˆï¼ˆNeEFï¼‰æ–¹æ³•ï¼Œå°†åŸºç¡€å’Œä¼°è®¡çš„3Dé«˜æ–¯å€¼é›†æˆåˆ°HDRé«˜æ–¯å€¼ä¸­ï¼Œç”¨äºæ–°çš„è§†å›¾æ¸²æŸ“ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSeHDRçš„æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•å’Œç²¾å¿ƒè®¾è®¡çš„åŸºçº¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.20400v1">PDF</a> ICCV 2025 accepted paper</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºSeHDRçš„æ–°å‹é«˜åŠ¨æ€èŒƒå›´ä¸‰ç»´é«˜æ–¯ç‚¹å–·ç»˜æŠ€æœ¯ï¼ˆHDR-3DGSï¼‰ï¼Œå¯ä»å¤šè§†è§’çš„ä½åŠ¨æ€èŒƒå›´å›¾åƒç”Ÿæˆé«˜åŠ¨æ€èŒƒå›´çš„æ–°è§†è§’å›¾åƒã€‚ä¸å…¶ä»–æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸éœ€è¦ä»ä¸åŒæ›å…‰çš„å¤šè§†è§’LDRå›¾åƒä¸­è·å–è¾“å…¥ï¼Œé¿å…äº†æ•æ‰æ—¶çš„ç¹çå’Œå¯èƒ½å‡ºç°çš„è¯¯å·®ï¼ˆå¦‚ç‰©ä½“è¿åŠ¨æ¨¡ç³Šå’Œæ ¡å‡†&#x2F;å¯¹é½ä¸å‡†ç¡®ï¼‰ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯ï¼Œé¦–å…ˆé€šè¿‡å•æ›å…‰å¤šè§†è§’LDRå›¾åƒä¼°è®¡ä¸åŒæ›å…‰çš„æ‹¬å·ä¸‰ç»´é«˜æ–¯ï¼Œç„¶åå°†å…¶åˆå¹¶ä¸ºHDRåœºæ™¯è¡¨ç¤ºã€‚å…·ä½“æ¥è¯´ï¼ŒSeHDRé¦–å…ˆä»å•æ›å…‰LDRè¾“å…¥ä¸­å­¦ä¹ åŸºç¡€ä¸‰ç»´é«˜æ–¯ï¼Œä½¿ç”¨çƒé¢è°æ³¢åœ¨çº¿æ€§è‰²å½©ç©ºé—´ä¸­æè¿°é¢œè‰²ã€‚ç„¶åï¼Œæˆ‘ä»¬ä¼°è®¡å…·æœ‰ç›¸åŒå‡ ä½•å½¢çŠ¶ä½†ä¸åŒçº¿æ€§é¢œè‰²çš„å¤šä¸ªä¸‰ç»´é«˜æ–¯ï¼Œå¹¶æ ¹æ®æ›å…‰è°ƒæ•´è¿›è¡Œè°ƒæ•´ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†å¯å¾®ç¥ç»æ›å…‰èåˆï¼ˆNeEFï¼‰æŠ€æœ¯ï¼Œå°†åŸºç¡€ä¼°è®¡çš„ä¸‰ç»´é«˜æ–¯èåˆä¸ºHDRé«˜æ–¯ï¼Œç”¨äºæ–°å‹è§†è§’æ¸²æŸ“ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSeHDRåœ¨æ€§èƒ½ä¸Šä¼˜äºç°æœ‰æ–¹æ³•å’Œç²¾å¿ƒè®¾è®¡çš„åŸºçº¿ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>SeHDRæ˜¯ä¸€ç§æ–°å‹HDR-3DGSæŠ€æœ¯ï¼Œå¯ä»å¤šè§†è§’LDRå›¾åƒç”ŸæˆHDRæ–°è§†è§’ã€‚</li>
<li>ä¸å…¶ä»–æ–¹æ³•ä¸åŒï¼ŒSeHDRä»å•æ›å…‰çš„å¤šè§†è§’LDRå›¾åƒä¸­å­¦ä¹ HDRåœºæ™¯è¡¨ç¤ºï¼Œç®€åŒ–æ•æ‰è¿‡ç¨‹å¹¶å‡å°‘è¯¯å·®ã€‚</li>
<li>SeHDRé€šè¿‡å­¦ä¹ åŸºç¡€ä¸‰ç»´é«˜æ–¯å’Œä¼°è®¡çš„ä¸åŒæ›å…‰ä¸‰ç»´é«˜æ–¯æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>åˆ©ç”¨çƒé¢è°æ³¢åœ¨çº¿æ€§è‰²å½©ç©ºé—´ä¸­æè¿°é¢œè‰²ã€‚</li>
<li>å¼•å…¥å¯å¾®ç¥ç»æ›å…‰èåˆï¼ˆNeEFï¼‰æŠ€æœ¯ï¼Œå°†åŸºç¡€ä¸ä¼°è®¡çš„ä¸‰ç»´é«˜æ–¯èåˆä¸ºHDRé«˜æ–¯ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒSeHDRåœ¨æ€§èƒ½ä¸Šä¼˜äºç°æœ‰æ–¹æ³•å’ŒåŸºçº¿ã€‚</li>
<li>SeHDRä¸ºç”ŸæˆHDRæ–°è§†è§’æä¾›äº†ä¸€ç§æœ‰æ•ˆã€é«˜æ€§èƒ½çš„æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.20400">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fb5779edacc87019e680c09ed77f7bdf" align="middle">
<img src="https://picx.zhimg.com/v2-231f23815eaa9bcb695bcf5189af6b05" align="middle">
<img src="https://picx.zhimg.com/v2-d3c8ff06d5e6b02c27d742dfd4e0fb3f" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="4D-Driving-Scene-Generation-With-Stereo-Forcing"><a href="#4D-Driving-Scene-Generation-With-Stereo-Forcing" class="headerlink" title="4D Driving Scene Generation With Stereo Forcing"></a>4D Driving Scene Generation With Stereo Forcing</h2><p><strong>Authors:Hao Lu, Zhuang Ma, Guangfeng Jiang, Wenhang Ge, Bohan Li, Yuzhan Cai, Wenzhao Zheng, Yunpeng Zhang, Yingcong Chen</strong></p>
<p>Current generative models struggle to synthesize dynamic 4D driving scenes that simultaneously support temporal extrapolation and spatial novel view synthesis (NVS) without per-scene optimization. Bridging generation and novel view synthesis remains a major challenge. We present PhiGenesis, a unified framework for 4D scene generation that extends video generation techniques with geometric and temporal consistency. Given multi-view image sequences and camera parameters, PhiGenesis produces temporally continuous 4D Gaussian splatting representations along target 3D trajectories. In its first stage, PhiGenesis leverages a pre-trained video VAE with a novel range-view adapter to enable feed-forward 4D reconstruction from multi-view images. This architecture supports single-frame or video inputs and outputs complete 4D scenes including geometry, semantics, and motion. In the second stage, PhiGenesis introduces a geometric-guided video diffusion model, using rendered historical 4D scenes as priors to generate future views conditioned on trajectories. To address geometric exposure bias in novel views, we propose Stereo Forcing, a novel conditioning strategy that integrates geometric uncertainty during denoising. This method enhances temporal coherence by dynamically adjusting generative influence based on uncertainty-aware perturbations. Our experimental results demonstrate that our method achieves state-of-the-art performance in both appearance and geometric reconstruction, temporal generation and novel view synthesis (NVS) tasks, while simultaneously delivering competitive performance in downstream evaluations. Homepage is at \href{<a target="_blank" rel="noopener" href="https://jiangxb98.github.io/PhiGensis%7D%7BPhiGensis%7D">https://jiangxb98.github.io/PhiGensis}{PhiGensis}</a>. </p>
<blockquote>
<p>å½“å‰ç”Ÿæˆæ¨¡å‹åœ¨åˆæˆåŠ¨æ€å››ç»´é©¾é©¶åœºæ™¯æ–¹é¢é¢ä¸´æŒ‘æˆ˜ï¼Œè¿™äº›åœºæ™¯éœ€è¦åŒæ—¶æ”¯æŒæ—¶é—´å¤–æ¨å’Œç©ºé—´æ–°é¢–è§†å›¾åˆæˆï¼ˆNVSï¼‰ï¼Œè€Œæ— éœ€é’ˆå¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œä¼˜åŒ–ã€‚ç”Ÿæˆå’Œæ–°é¢–è§†å›¾åˆæˆä¹‹é—´çš„æ¡¥æ¢ä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†PhiGenesisï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå››ç»´åœºæ™¯ç”Ÿæˆçš„ç»Ÿä¸€æ¡†æ¶ï¼Œå®ƒç»“åˆäº†è§†é¢‘ç”ŸæˆæŠ€æœ¯ï¼Œå®ç°äº†å‡ ä½•å’Œæ—¶é—´ä¸€è‡´æ€§ã€‚ç»™å®šå¤šè§†å›¾å›¾åƒåºåˆ—å’Œç›¸æœºå‚æ•°ï¼ŒPhiGenesiså¯ä»¥æ²¿ç€ç›®æ ‡ä¸‰ç»´è½¨è¿¹ç”Ÿæˆæ—¶é—´ä¸Šè¿ç»­çš„å››ç»´é«˜æ–¯æº…å°„è¡¨ç¤ºã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼ŒPhiGenesisåˆ©ç”¨é¢„è®­ç»ƒçš„è§†é¢‘VAEå’Œæ–°é¢–çš„èŒƒå›´è§†å›¾é€‚é…å™¨ï¼Œå®ç°ä»å¤šè§†å›¾å›¾åƒçš„å‰é¦ˆå››ç»´é‡å»ºã€‚æ­¤æ¶æ„æ”¯æŒå•å¸§æˆ–è§†é¢‘è¾“å…¥ï¼Œå¹¶è¾“å‡ºå®Œæ•´çš„å››ç»´åœºæ™¯ï¼ŒåŒ…æ‹¬å‡ ä½•ã€è¯­ä¹‰å’Œè¿åŠ¨ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼ŒPhiGenesiså¼•å…¥äº†ä¸€ä¸ªå—å‡ ä½•æŒ‡å¯¼çš„è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œä½¿ç”¨æ¸²æŸ“çš„å†å²å››ç»´åœºæ™¯ä½œä¸ºå…ˆéªŒæ¥æ ¹æ®è½¨è¿¹ç”Ÿæˆæœªæ¥è§†å›¾ã€‚ä¸ºäº†è§£å†³æ–°é¢–è§†å›¾ä¸­çš„å‡ ä½•æ›å…‰åå·®é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç«‹ä½“å¼ºåˆ¶ï¼ˆStereo Forcingï¼‰è¿™ä¸€æ–°é¢–çš„æ¡ä»¶ç­–ç•¥ï¼Œå®ƒåœ¨å»å™ªè¿‡ç¨‹ä¸­æ•´åˆäº†å‡ ä½•ä¸ç¡®å®šæ€§ã€‚è¿™ç§æ–¹æ³•é€šè¿‡æ ¹æ®ä¸ç¡®å®šæ€§æ„ŸçŸ¥æ‰°åŠ¨åŠ¨æ€è°ƒæ•´ç”Ÿæˆå½±å“ï¼Œå¢å¼ºäº†æ—¶é—´è¿è´¯æ€§ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤–è§‚å’Œå‡ ä½•é‡å»ºã€æ—¶é—´ç”Ÿæˆå’Œæ–°é¢–è§†å›¾åˆæˆï¼ˆNVSï¼‰ä»»åŠ¡æ–¹é¢è¾¾åˆ°äº†æœ€æ–°æ€§èƒ½æ°´å¹³ï¼ŒåŒæ—¶åœ¨ä¸‹æ¸¸è¯„ä¼°ä¸­è¡¨ç°å‡ºç«äº‰åŠ›ã€‚ä¸»é¡µæ˜¯<a target="_blank" rel="noopener" href="https://jiangxb98.github.io/PhiGensis">PhiGenesis</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.20251v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºPhiGenesisçš„ç»Ÿä¸€æ¡†æ¶ï¼Œç”¨äº4Dåœºæ™¯ç”Ÿæˆã€‚è¯¥æ¡†æ¶æ‰©å±•äº†è§†é¢‘ç”ŸæˆæŠ€æœ¯ï¼Œå…·æœ‰å‡ ä½•å’Œæ—¶é—´ä¸€è‡´æ€§ã€‚PhiGenesiså¯ä»¥ä»å¤šè§†è§’å›¾åƒåºåˆ—å’Œç›¸æœºå‚æ•°å‡ºå‘ï¼Œç”Ÿæˆæ—¶é—´ä¸Šè¿ç»­çš„4Dé«˜æ–¯æ‘Šé“ºè¡¨ç¤ºï¼Œæ²¿ç€ç›®æ ‡3Dè½¨è¿¹ã€‚å®ƒé‡‡ç”¨é¢„è®­ç»ƒçš„è§†é¢‘VAEå’Œæ–°å‹èŒƒå›´è§†å›¾é€‚é…å™¨ï¼Œæ”¯æŒå•å¸§æˆ–è§†é¢‘è¾“å…¥ï¼Œå¹¶è¾“å‡ºå®Œæ•´çš„4Dåœºæ™¯ï¼ŒåŒ…æ‹¬å‡ ä½•ã€è¯­ä¹‰å’Œè¿åŠ¨ã€‚ç¬¬äºŒé˜¶æ®µå¼•å…¥äº†å‡ ä½•æŒ‡å¯¼çš„è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œä½¿ç”¨æ¸²æŸ“çš„å†å²4Dåœºæ™¯ä½œä¸ºå…ˆéªŒæ¥ç”Ÿæˆæœªæ¥è§†å›¾ã€‚ä¸ºè§£å†³æ–°å‹è§†å›¾ä¸­çš„å‡ ä½•æ›å…‰åå·®ï¼Œæå‡ºäº†Stereo Forcingè¿™ä¸€æ–°å‹æ¡ä»¶ç­–ç•¥ï¼Œåœ¨é™å™ªè¿‡ç¨‹ä¸­æ•´åˆå‡ ä½•ä¸ç¡®å®šæ€§ã€‚æ­¤æ–¹æ³•é€šè¿‡åŸºäºä¸ç¡®å®šæ€§æ„ŸçŸ¥æ‰°åŠ¨çš„åŠ¨æ€è°ƒæ•´ç”Ÿæˆå½±å“ï¼Œå¢å¼ºäº†æ—¶é—´è¿è´¯æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PhiGenesisæ˜¯ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œç”¨äº4Dåœºæ™¯ç”Ÿæˆï¼Œç»“åˆäº†è§†é¢‘ç”ŸæˆæŠ€æœ¯ä¸å‡ ä½•å’Œæ—¶é—´çš„ä¸€è‡´æ€§ã€‚</li>
<li>åˆ©ç”¨å¤šè§†è§’å›¾åƒåºåˆ—å’Œç›¸æœºå‚æ•°ç”Ÿæˆ4Dé«˜æ–¯æ‘Šé“ºè¡¨ç¤ºã€‚</li>
<li>é‡‡ç”¨é¢„è®­ç»ƒçš„è§†é¢‘VAEå’ŒèŒƒå›´è§†å›¾é€‚é…å™¨è¿›è¡Œ4Dé‡å»ºã€‚</li>
<li>æ”¯æŒå•å¸§æˆ–è§†é¢‘è¾“å…¥ï¼Œè¾“å‡ºåŒ…æ‹¬å‡ ä½•ã€è¯­ä¹‰å’Œè¿åŠ¨çš„å®Œæ•´4Dåœºæ™¯ã€‚</li>
<li>å¼•å…¥å‡ ä½•æŒ‡å¯¼çš„è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œä½¿ç”¨å†å²4Dåœºæ™¯ä½œä¸ºæœªæ¥è§†å›¾çš„å…ˆéªŒã€‚</li>
<li>æå‡ºStereo Forcingç­–ç•¥æ¥è§£å†³æ–°å‹è§†å›¾ä¸­çš„å‡ ä½•æ›å…‰åå·®ã€‚</li>
<li>é€šè¿‡åŠ¨æ€è°ƒæ•´åŸºäºä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„æ‰°åŠ¨å¢å¼ºæ—¶é—´è¿è´¯æ€§ï¼Œè¾¾åˆ°å…ˆè¿›æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.20251">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-82664f4f0d8c3114c482d82cdcf2aed4" align="middle">
<img src="https://picx.zhimg.com/v2-91265e34f81bf6c2676c3c343be743d1" align="middle">
<img src="https://picx.zhimg.com/v2-b326c26539bbae1c06efb1b231f6c241" align="middle">
<img src="https://picx.zhimg.com/v2-885b7eeefee57f6ec5147f64bb016e9c" align="middle">
<img src="https://picx.zhimg.com/v2-90f77a423f1976bd31cc905a6f4ff750" align="middle">
<img src="https://picx.zhimg.com/v2-d2865c189a251d46fd0c4be9ce253c50" align="middle">
<img src="https://picx.zhimg.com/v2-b554aa4c2f4d4fb6ff6a5634a36bbe19" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="PU-Gaussian-Point-Cloud-Upsampling-using-3D-Gaussian-Representation"><a href="#PU-Gaussian-Point-Cloud-Upsampling-using-3D-Gaussian-Representation" class="headerlink" title="PU-Gaussian: Point Cloud Upsampling using 3D Gaussian Representation"></a>PU-Gaussian: Point Cloud Upsampling using 3D Gaussian Representation</h2><p><strong>Authors:Mahmoud Khater, Mona Strauss, Philipp von Olshausen, Alexander Reiterer</strong></p>
<p>Point clouds produced by 3D sensors are often sparse and noisy, posing challenges for tasks requiring dense and high-fidelity 3D representations. Prior work has explored both implicit feature-based upsampling and distance-function learning to address this, but often at the expense of geometric interpretability or robustness to input sparsity. To overcome these limitations, we propose PU-Gaussian, a novel upsampling network that models the local neighborhood around each point using anisotropic 3D Gaussian distributions. These Gaussians capture the underlying geometric structure, allowing us to perform upsampling explicitly in the local geometric domain by direct point sampling. The sampling process generates a dense, but coarse, point cloud. A subsequent refinement network adjusts the coarse output to produce a more uniform distribution and sharper edges. We perform extensive testing on the PU1K and PUGAN datasets, demonstrating that PU-Gaussian achieves state-of-the-art performance. We make code and model weights publicly available at <a target="_blank" rel="noopener" href="https://github.com/mvg-inatech/PU-Gaussian.git">https://github.com/mvg-inatech/PU-Gaussian.git</a>. </p>
<blockquote>
<p>ç”±3Dä¼ æ„Ÿå™¨äº§ç”Ÿçš„ç‚¹äº‘é€šå¸¸æ˜¯ç¨€ç–ä¸”å˜ˆæ‚çš„ï¼Œè¿™ç»™éœ€è¦å¯†é›†å’Œé«˜ä¿çœŸåº¦çš„3Dè¡¨ç¤ºçš„ä»»åŠ¡å¸¦æ¥äº†æŒ‘æˆ˜ã€‚æ—©æœŸçš„å·¥ä½œå·²ç»æ¢ç´¢äº†åŸºäºéšç‰¹å¾çš„ä¸Šé‡‡æ ·å’Œè·ç¦»å‡½æ•°å­¦ä¹ æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†è¿™å¾€å¾€ä»¥ç‰ºç‰²å‡ ä½•è§£é‡Šæ€§æˆ–å¯¹è¾“å…¥ç¨€ç–æ€§çš„ç¨³å¥æ€§ä¸ºä»£ä»·ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†PU-Gaussianï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„ä¸Šé‡‡æ ·ç½‘ç»œï¼Œå®ƒåˆ©ç”¨å„å‘å¼‚æ€§çš„3Dé«˜æ–¯åˆ†å¸ƒå¯¹æ¯ä¸ªç‚¹çš„å±€éƒ¨é‚»åŸŸè¿›è¡Œå»ºæ¨¡ã€‚è¿™äº›é«˜æ–¯æ•°æ•æ‰äº†æ½œåœ¨çš„å‡ ä½•ç»“æ„ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨å±€éƒ¨å‡ ä½•åŸŸä¸­é€šè¿‡ç›´æ¥ç‚¹é‡‡æ ·æ˜¾å¼æ‰§è¡Œä¸Šé‡‡æ ·ã€‚é‡‡æ ·è¿‡ç¨‹ç”Ÿæˆä¸€ä¸ªå¯†é›†ä½†ç²—ç³™çš„ç‚¹äº‘ã€‚éšåçš„ç»†åŒ–ç½‘ç»œè°ƒæ•´ç²—ç•¥è¾“å‡ºï¼Œä»¥äº§ç”Ÿæ›´å‡åŒ€çš„åˆ†éƒ¨ç‡å’Œæ›´æ¸…æ™°çš„è¾¹ç¼˜ã€‚æˆ‘ä»¬åœ¨PU1Kå’ŒPUGANæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„æµ‹è¯•ï¼Œè¯æ˜äº†PU-Gaussianå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬å°†ä»£ç å’Œæ¨¡å‹æƒé‡å…¬å¼€å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/mvg-inatech/PU-Gaussian.git%E4%B8%8A%E3%80%82">https://github.com/mvg-inatech/PU-Gaussian.gitä¸Šã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.20207v1">PDF</a> Accepted for the ICCV 2025 e2e3D Workshop. To be published in the   Proceedings of the IEEE&#x2F;CVF International Conference on Computer Vision   Workshops (ICCVW)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºPU-Gaussiançš„æ–°å‹ç‚¹äº‘ä¸Šé‡‡æ ·ç½‘ç»œï¼Œé€šè¿‡åˆ©ç”¨å„å‘å¼‚æ€§çš„ä¸‰ç»´é«˜æ–¯åˆ†å¸ƒå¯¹ç‚¹äº‘çš„å±€éƒ¨é‚»åŸŸè¿›è¡Œå»ºæ¨¡ï¼Œè§£å†³äº†ç¨€ç–å’Œå™ªå£°ç‚¹äº‘å¸¦æ¥çš„æŒ‘æˆ˜ã€‚è¯¥ç½‘ç»œé€šè¿‡ç›´æ¥ç‚¹é‡‡æ ·åœ¨å±€éƒ¨å‡ ä½•åŸŸä¸­æ‰§è¡Œä¸Šé‡‡æ ·ï¼Œç”Ÿæˆå¯†é›†ä½†ç²—ç³™çš„ç‚¹äº‘ã€‚éšåï¼Œä¸€ä¸ªç²¾ç‚¼ç½‘ç»œå¯¹ç²—è¾“å‡ºè¿›è¡Œè°ƒæ•´ï¼Œä»¥äº§ç”Ÿæ›´å‡åŒ€åˆ†å¸ƒå’Œæ›´æ¸…æ™°è¾¹ç¼˜çš„ç‚¹äº‘ã€‚åœ¨PU1Kå’ŒPUGANæ•°æ®é›†ä¸Šçš„æµ‹è¯•è¡¨æ˜ï¼ŒPU-Gaussianè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PU-Gaussianç½‘ç»œè§£å†³äº†ç‚¹äº‘ç¨€ç–å’Œå™ªå£°é—®é¢˜ã€‚</li>
<li>è¯¥ç½‘ç»œåˆ©ç”¨å„å‘å¼‚æ€§çš„ä¸‰ç»´é«˜æ–¯åˆ†å¸ƒå¯¹ç‚¹äº‘çš„å±€éƒ¨é‚»åŸŸè¿›è¡Œå»ºæ¨¡ã€‚</li>
<li>é€šè¿‡ç›´æ¥ç‚¹é‡‡æ ·åœ¨å±€éƒ¨å‡ ä½•åŸŸä¸­æ‰§è¡Œä¸Šé‡‡æ ·ï¼Œç”Ÿæˆå¯†é›†ä½†ç²—ç³™çš„ç‚¹äº‘ã€‚</li>
<li>æœ‰ä¸€ä¸ªåç»­çš„ç½‘ç»œç”¨äºè°ƒæ•´ç²—è¾“å‡ºï¼Œäº§ç”Ÿæ›´å‡åŒ€åˆ†å¸ƒå’Œæ›´æ¸…æ™°è¾¹ç¼˜çš„ç‚¹äº‘ã€‚</li>
<li>åœ¨PU1Kå’ŒPUGANæ•°æ®é›†ä¸Šçš„æµ‹è¯•è¡¨æ˜ï¼ŒPU-Gaussianæ€§èƒ½è¾¾åˆ°æœ€æ–°æ°´å¹³ã€‚</li>
<li>å…¬å¼€äº†ä»£ç å’Œæ¨¡å‹æƒé‡ä»¥ä¾›ä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.20207">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9c153da9eca07ad291bf8d4b1d51579d" align="middle">
<img src="https://picx.zhimg.com/v2-7fd9b74372a97da24dab59fbb6ec80e4" align="middle">
<img src="https://picx.zhimg.com/v2-57ffd162b3c8e26c36c3e66f40e30d06" align="middle">
<img src="https://picx.zhimg.com/v2-97bb4fe5ea9fad38b800de941fc2cddc" align="middle">
<img src="https://picx.zhimg.com/v2-985451e438efde79ad345b7510308671" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="GS-RoadPatching-Inpainting-Gaussians-via-3D-Searching-and-Placing-for-Driving-Scenes"><a href="#GS-RoadPatching-Inpainting-Gaussians-via-3D-Searching-and-Placing-for-Driving-Scenes" class="headerlink" title="GS-RoadPatching: Inpainting Gaussians via 3D Searching and Placing for   Driving Scenes"></a>GS-RoadPatching: Inpainting Gaussians via 3D Searching and Placing for   Driving Scenes</h2><p><strong>Authors:Guo Chen, Jiarun Liu, Sicong Du, Chenming Wu, Deqi Li, Shi-Sheng Huang, Guofeng Zhang, Sheng Yang</strong></p>
<p>This paper presents GS-RoadPatching, an inpainting method for driving scene completion by referring to completely reconstructed regions, which are represented by 3D Gaussian Splatting (3DGS). Unlike existing 3DGS inpainting methods that perform generative completion relying on 2D perspective-view-based diffusion or GAN models to predict limited appearance or depth cues for missing regions, our approach enables substitutional scene inpainting and editing directly through the 3DGS modality, extricating it from requiring spatial-temporal consistency of 2D cross-modals and eliminating the need for time-intensive retraining of Gaussians. Our key insight is that the highly repetitive patterns in driving scenes often share multi-modal similarities within the implicit 3DGS feature space and are particularly suitable for structural matching to enable effective 3DGS-based substitutional inpainting. Practically, we construct feature-embedded 3DGS scenes to incorporate a patch measurement method for abstracting local context at different scales and, subsequently, propose a structural search method to find candidate patches in 3D space effectively. Finally, we propose a simple yet effective substitution-and-fusion optimization for better visual harmony. We conduct extensive experiments on multiple publicly available datasets to demonstrate the effectiveness and efficiency of our proposed method in driving scenes, and the results validate that our method achieves state-of-the-art performance compared to the baseline methods in terms of both quality and interoperability. Additional experiments in general scenes also demonstrate the applicability of the proposed 3D inpainting strategy. The project page and code are available at: <a target="_blank" rel="noopener" href="https://shanzhaguoo.github.io/GS-RoadPatching/">https://shanzhaguoo.github.io/GS-RoadPatching/</a> </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†GS-RoadPatchingï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡å‚è€ƒç”±ä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰è¡¨ç¤ºçš„å®Œå…¨é‡å»ºåŒºåŸŸæ¥å®Œæˆé©¾é©¶åœºæ™¯è¡¥å…¨çš„å†…å¡«æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿçš„ä¾èµ–äºäºŒç»´é€è§†è§†å›¾æ‰©æ•£æˆ–ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰æ¨¡å‹é¢„æµ‹ç¼ºå¤±åŒºåŸŸçš„æœ‰é™å¤–è§‚æˆ–æ·±åº¦çº¿ç´¢çš„3DGSå†…å¡«æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿç›´æ¥é€šè¿‡3DGSæ¨¡å¼è¿›è¡Œæ›¿ä»£åœºæ™¯å†…å¡«å’Œç¼–è¾‘ï¼Œæ— éœ€ä¾èµ–äºŒç»´è·¨æ¨¡æ€çš„æ—¶ç©ºä¸€è‡´æ€§ï¼Œå¹¶æ¶ˆé™¤äº†å¯¹é«˜æ–¯æ¨¡å‹è€—æ—¶è€—åŠ›çš„é‡æ–°è®­ç»ƒéœ€æ±‚ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯ï¼Œé©¾é©¶åœºæ™¯ä¸­é«˜åº¦é‡å¤çš„æ¨¡å¼åœ¨éšå¼ä¸‰ç»´é«˜æ–¯æ‹¼è´´ç‰¹å¾ç©ºé—´å†…é€šå¸¸å…·æœ‰å¤šæ¨¡æ€ç›¸ä¼¼æ€§ï¼Œéå¸¸é€‚åˆç»“æ„åŒ¹é…ï¼Œä»¥å®ç°æœ‰æ•ˆçš„åŸºäºä¸‰ç»´é«˜æ–¯æ‹¼è´´çš„æ›¿ä»£æ€§å†…å¡«ã€‚åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬æ„å»ºäº†ç‰¹å¾åµŒå…¥çš„3DGSåœºæ™¯ï¼Œå¹¶å¼€å‘äº†ä¸€ç§è´´ç‰‡æµ‹é‡æ–¹æ³•ï¼Œä»¥åœ¨ä¸åŒå°ºåº¦ä¸ŠæŠ½è±¡å±€éƒ¨ä¸Šä¸‹æ–‡ï¼Œç„¶åæå‡ºäº†ä¸€ç§ç»“æ„æœç´¢æ–¹æ³•ï¼Œä»¥åœ¨ä¸‰ç»´ç©ºé—´ä¸­æ‰¾åˆ°æœ‰æ•ˆçš„å€™é€‰è´´ç‰‡ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ›¿ä»£å’Œèåˆä¼˜åŒ–æ–¹æ³•ï¼Œä»¥å®ç°æ›´å¥½çš„è§†è§‰å’Œè°ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªå…¬å¼€æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒï¼Œä»¥è¯æ˜æˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨é©¾é©¶åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§å’Œæ•ˆç‡ã€‚ç»“æœéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨è´¨é‡å’Œå¯æ“ä½œæ€§æ–¹é¢å‡è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ã€‚åœ¨ä¸€èˆ¬åœºæ™¯ä¸­çš„é¢å¤–å®éªŒä¹Ÿè¯æ˜äº†æ‰€æå‡ºçš„3Då†…å¡«ç­–ç•¥çš„åº”ç”¨æ€§ã€‚é¡¹ç›®é¡µé¢å’Œä»£ç å¯é€šè¿‡ä»¥ä¸‹é“¾æ¥è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://shanzhaguoo.github.io/GS-RoadPatching/">https://shanzhaguoo.github.io/GS-RoadPatching/</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.19937v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†GS-RoadPatchingæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºä¸‰ç»´é«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰çš„é©¾é©¶åœºæ™¯è¡¥å…¨æ–¹æ³•ã€‚ä¸åŒäºä¾èµ–äºŒç»´é€è§†è§†è§’æ‰©æ•£æˆ–GANæ¨¡å‹çš„ç°æœ‰3DGSè¡¥å…¨æ–¹æ³•ï¼ŒGS-RoadPatchingç›´æ¥åœ¨3DGSæ¨¡å¼ä¸‹è¿›è¡Œæ›¿ä»£åœºæ™¯è¡¥å…¨å’Œç¼–è¾‘ï¼Œæ— éœ€äºŒç»´è·¨æ¨¡æ€çš„ç©ºé—´æ—¶é—´ä¸€è‡´æ€§ï¼Œå¹¶æ¶ˆé™¤äº†é«˜æ–¯é‡è®­ç»ƒçš„æ—¶é—´å¯†é›†éœ€æ±‚ã€‚å…¶ä¸»è¦æ€æƒ³æ˜¯åˆ©ç”¨é©¾é©¶åœºæ™¯ä¸­é«˜åº¦é‡å¤æ¨¡å¼çš„éšå¼å¤šæ¨¡æ€ç›¸ä¼¼æ€§è¿›è¡Œç»“æ„åŒ¹é…ï¼Œå®ç°æœ‰æ•ˆçš„åŸºäºç»“æ„åŒ¹é…çš„æ›¿ä»£è¡¥å…¨ã€‚æœ¬æ–‡æ„å»ºç‰¹å¾åµŒå…¥çš„3DGSåœºæ™¯ï¼Œé‡‡ç”¨è¡¥ä¸æµ‹é‡æ–¹æ³•åœ¨ä¸åŒå°ºåº¦ä¸ŠæŠ½è±¡å±€éƒ¨ä¸Šä¸‹æ–‡ï¼Œå¹¶æå‡ºä¸€ç§æœ‰æ•ˆçš„ç»“æ„æœç´¢æ–¹æ³•ï¼Œåœ¨ä¸‰ç»´ç©ºé—´ä¸­æ‰¾åˆ°å€™é€‰è¡¥ä¸ã€‚æœ€åï¼Œé€šè¿‡å¤§é‡å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨é©¾é©¶åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§å’Œé«˜æ•ˆæ€§ï¼Œè¾¾åˆ°å½“å‰é¢†å…ˆæ°´å¹³ã€‚æ­¤å¤–ï¼Œåœ¨ä¸€èˆ¬åœºæ™¯ä¸­çš„å®éªŒä¹Ÿè¯æ˜äº†è¯¥æ–¹æ³•çš„é€‚ç”¨æ€§ã€‚ç›¸å…³å†…å®¹å’Œä»£ç å¯é€šè¿‡é“¾æ¥è®¿é—®ï¼š[shanzhaguoo.github.io&#x2F;GS-RoadPatching&#x2F;]æŸ¥çœ‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>GS-RoadPatchingæ˜¯ä¸€ç§åŸºäºä¸‰ç»´é«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰çš„é©¾é©¶åœºæ™¯è¡¥å…¨æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•ç›´æ¥åœ¨3DGSæ¨¡å¼ä¸‹è¿›è¡Œæ›¿ä»£åœºæ™¯è¡¥å…¨å’Œç¼–è¾‘ï¼Œé¿å…äºŒç»´è·¨æ¨¡æ€çš„ç©ºé—´æ—¶é—´ä¸€è‡´æ€§é—®é¢˜ã€‚</li>
<li>ä¸»è¦åˆ©ç”¨é©¾é©¶åœºæ™¯ä¸­é«˜åº¦é‡å¤æ¨¡å¼çš„éšå¼å¤šæ¨¡æ€ç›¸ä¼¼æ€§è¿›è¡Œç»“æ„åŒ¹é…ä»¥å®ç°æœ‰æ•ˆè¡¥å…¨ã€‚</li>
<li>æ„å»ºç‰¹å¾åµŒå…¥çš„3DGSåœºæ™¯å¹¶é‡‡ç”¨è¡¥ä¸æµ‹é‡æ–¹æ³•åœ¨ä¸åŒå°ºåº¦ä¸ŠæŠ½è±¡å±€éƒ¨ä¸Šä¸‹æ–‡ã€‚</li>
<li>æå‡ºç»“æ„æœç´¢æ–¹æ³•å’Œæ›¿ä»£èåˆä¼˜åŒ–æŠ€æœ¯æ¥å¯»æ‰¾åˆé€‚çš„è¡¥ä¸å¹¶è¿›è¡Œè§†è§‰èåˆã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.19937">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-92cf377951a9d6ada899befcaae1161b" align="middle">
<img src="https://picx.zhimg.com/v2-618886cb1f082e4b4cd40f168097fb6b" align="middle">
<img src="https://picx.zhimg.com/v2-67faef39d25538c7f655a3217a8ce5da" align="middle">
<img src="https://picx.zhimg.com/v2-9b6540e0810e2969c0201d2640ad0b6e" align="middle">
<img src="https://picx.zhimg.com/v2-99def8b932f4c26aaea16fc1708b80eb" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="PolGS-Polarimetric-Gaussian-Splatting-for-Fast-Reflective-Surface-Reconstruction"><a href="#PolGS-Polarimetric-Gaussian-Splatting-for-Fast-Reflective-Surface-Reconstruction" class="headerlink" title="PolGS: Polarimetric Gaussian Splatting for Fast Reflective Surface   Reconstruction"></a>PolGS: Polarimetric Gaussian Splatting for Fast Reflective Surface   Reconstruction</h2><p><strong>Authors:Yufei Han, Bowen Tie, Heng Guo, Youwei Lyu, Si Li, Boxin Shi, Yunpeng Jia, Zhanyu Ma</strong></p>
<p>Efficient shape reconstruction for surfaces with complex reflectance properties is crucial for real-time virtual reality. While 3D Gaussian Splatting (3DGS)-based methods offer fast novel view rendering by leveraging their explicit surface representation, their reconstruction quality lags behind that of implicit neural representations, particularly in the case of recovering surfaces with complex reflective reflectance. To address these problems, we propose PolGS, a Polarimetric Gaussian Splatting model allowing fast reflective surface reconstruction in 10 minutes. By integrating polarimetric constraints into the 3DGS framework, PolGS effectively separates specular and diffuse components, enhancing reconstruction quality for challenging reflective materials. Experimental results on the synthetic and real-world dataset validate the effectiveness of our method. </p>
<blockquote>
<p>å¯¹äºå…·æœ‰å¤æ‚åå°„å±æ€§çš„è¡¨é¢è¿›è¡Œé«˜æ•ˆå½¢çŠ¶é‡å»ºå¯¹å®æ—¶è™šæ‹Ÿç°å®è‡³å…³é‡è¦ã€‚è™½ç„¶åŸºäºä¸‰ç»´é«˜æ–¯è´´å›¾ï¼ˆ3DGSï¼‰çš„æ–¹æ³•é€šè¿‡åˆ©ç”¨å…¶æ˜ç¡®çš„è¡¨é¢è¡¨ç¤ºå®ç°äº†å¿«é€Ÿçš„æ–°è§†è§’æ¸²æŸ“ï¼Œä½†åœ¨é‡å»ºè´¨é‡æ–¹é¢ä»è½åäºéšå¼ç¥ç»è¡¨ç¤ºï¼Œç‰¹åˆ«æ˜¯åœ¨æ¢å¤å…·æœ‰å¤æ‚åå°„åå°„çš„è¡¨é¢æ—¶ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†PolGSï¼Œä¸€ç§æåæ ‡é«˜æ–¯è´´å›¾æ¨¡å‹ï¼Œå¯åœ¨10åˆ†é’Ÿå†…å¿«é€Ÿé‡å»ºåå°„è¡¨é¢ã€‚é€šè¿‡å°†æåæ ‡çº¦æŸé›†æˆåˆ°3DGSæ¡†æ¶ä¸­ï¼ŒPolGSæœ‰æ•ˆåœ°åˆ†ç¦»äº†é•œé¢åå°„å’Œæ¼«åå°„æˆåˆ†ï¼Œæé«˜äº†å¯¹å…·æœ‰æŒ‘æˆ˜æ€§çš„åå°„ææ–™çš„é‡å»ºè´¨é‡ã€‚åœ¨åˆæˆæ•°æ®é›†å’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.19726v1">PDF</a> Accepted by ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹å…·æœ‰å¤æ‚åå°„å±æ€§çš„è¡¨é¢è¿›è¡Œé«˜æ•ˆå½¢çŠ¶é‡å»ºçš„é‡è¦æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å®æ—¶è™šæ‹Ÿç°å®é¢†åŸŸã€‚é’ˆå¯¹ç°æœ‰æŠ€æœ¯å¦‚åŸºäºä¸‰ç»´é«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰çš„æ–¹æ³•åœ¨é‡å»ºè´¨é‡ä¸Šå­˜åœ¨çš„ç¼ºé™·ï¼Œæå‡ºäº†ä¸€ç§åä¸ºPolGSçš„æåæ ‡é«˜æ–¯å–·æº…æ¨¡å‹ã€‚è¯¥æ¨¡å‹é€šè¿‡å°†æåæ ‡çº¦æŸèå…¥3DGSæ¡†æ¶ï¼ŒæˆåŠŸåˆ†ç¦»äº†é•œé¢åå°„å’Œæ¼«åå°„æˆåˆ†ï¼Œæœ‰æ•ˆæå‡äº†å¤æ‚åå°„ææ–™çš„é‡å»ºè´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºä¼˜å¼‚æ•ˆæœï¼Œå¯åœ¨ååˆ†é’Ÿå†…å®ç°å¿«é€Ÿåå°„è¡¨é¢é‡å»ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>PolGSæ¨¡å‹è§£å†³äº†å…·æœ‰å¤æ‚åå°„å±æ€§çš„è¡¨é¢åœ¨è™šæ‹Ÿç°å®ä¸­çš„é«˜æ•ˆå½¢çŠ¶é‡å»ºé—®é¢˜ã€‚</li>
<li>é€šè¿‡ç»“åˆæåæ ‡çº¦æŸåˆ°ä¸‰ç»´é«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰æ¡†æ¶ä¸­ï¼Œæå‡äº†é‡å»ºè´¨é‡ã€‚</li>
<li>PolGSæ¨¡å‹èƒ½æœ‰æ•ˆåˆ†ç¦»é•œé¢åå°„å’Œæ¼«åå°„æˆåˆ†ï¼Œç‰¹åˆ«é€‚ç”¨äºå¤„ç†å¤æ‚åå°„ææ–™ã€‚</li>
<li>PolGSæ¨¡å‹å¯å®ç°å¿«é€Ÿåå°„è¡¨é¢é‡å»ºï¼Œå¤„ç†æ—¶é—´ä»…éœ€ååˆ†é’Ÿã€‚</li>
<li>å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ¨¡å‹åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šéƒ½æœ‰è‰¯å¥½è¡¨ç°ã€‚</li>
<li>è¯¥æ¨¡å‹çš„æå‡ºæ¨åŠ¨äº†è™šæ‹Ÿç°å®é¢†åŸŸä¸­çš„è¡¨é¢é‡å»ºæŠ€æœ¯å‘å‰å‘å±•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.19726">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ca613cebf073827bce799c79adfaf649" align="middle">
<img src="https://picx.zhimg.com/v2-271dae328e44bbba367bb5b4ebcebd87" align="middle">
<img src="https://picx.zhimg.com/v2-1705d1a59472b1eed106799727c1f888" align="middle">
<img src="https://picx.zhimg.com/v2-1376d3bcb7ed2999a830beb743c090f7" align="middle">
<img src="https://picx.zhimg.com/v2-72677b1b9d5cde643fbeb37ad4c52422" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="VolSplat-Rethinking-Feed-Forward-3D-Gaussian-Splatting-with-Voxel-Aligned-Prediction"><a href="#VolSplat-Rethinking-Feed-Forward-3D-Gaussian-Splatting-with-Voxel-Aligned-Prediction" class="headerlink" title="VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with   Voxel-Aligned Prediction"></a>VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with   Voxel-Aligned Prediction</h2><p><strong>Authors:Weijie Wang, Yeqing Chen, Zeyu Zhang, Hengyu Liu, Haoxiao Wang, Zhiyuan Feng, Wenkang Qin, Zheng Zhu, Donny Y. Chen, Bohan Zhuang</strong></p>
<p>Feed-forward 3D Gaussian Splatting (3DGS) has emerged as a highly effective solution for novel view synthesis. Existing methods predominantly rely on a pixel-aligned Gaussian prediction paradigm, where each 2D pixel is mapped to a 3D Gaussian. We rethink this widely adopted formulation and identify several inherent limitations: it renders the reconstructed 3D models heavily dependent on the number of input views, leads to view-biased density distributions, and introduces alignment errors, particularly when source views contain occlusions or low texture. To address these challenges, we introduce VolSplat, a new multi-view feed-forward paradigm that replaces pixel alignment with voxel-aligned Gaussians. By directly predicting Gaussians from a predicted 3D voxel grid, it overcomes pixel alignmentâ€™s reliance on error-prone 2D feature matching, ensuring robust multi-view consistency. Furthermore, it enables adaptive control over Gaussian density based on 3D scene complexity, yielding more faithful Gaussian point clouds, improved geometric consistency, and enhanced novel-view rendering quality. Experiments on widely used benchmarks including RealEstate10K and ScanNet demonstrate that VolSplat achieves state-of-the-art performance while producing more plausible and view-consistent Gaussian reconstructions. In addition to superior results, our approach establishes a more scalable framework for feed-forward 3D reconstruction with denser and more robust representations, paving the way for further research in wider communities. The video results, code and trained models are available on our project page: <a target="_blank" rel="noopener" href="https://lhmd.top/volsplat">https://lhmd.top/volsplat</a>. </p>
<blockquote>
<p>å‰é¦ˆä¸‰ç»´é«˜æ–¯å±•å¸ƒï¼ˆ3DGSï¼‰å·²æˆä¸ºä¸€ç§ç”¨äºåˆæˆæ–°è§†è§’çš„é«˜æ•ˆè§£å†³æ–¹æ¡ˆã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºåƒç´ å¯¹é½çš„é«˜æ–¯é¢„æµ‹èŒƒå¼ï¼Œå…¶ä¸­æ¯ä¸ªäºŒç»´åƒç´ è¢«æ˜ å°„åˆ°ä¸‰ç»´é«˜æ–¯ä¸Šã€‚æˆ‘ä»¬é‡æ–°æ€è€ƒè¿™ä¸€å¹¿æ³›åº”ç”¨çš„æ–¹æ³•å¹¶å‘ç°äº†å‡ ä¸ªå›ºæœ‰çš„å±€é™æ€§ï¼šå®ƒä½¿å¾—é‡å»ºçš„3Dæ¨¡å‹ä¸¥é‡ä¾èµ–äºè¾“å…¥è§†è§’çš„æ•°é‡ï¼Œå¯¼è‡´è§†è§’åå‘çš„å¯†åº¦åˆ†å¸ƒï¼Œå¹¶åœ¨æºè§†è§’åŒ…å«é®æŒ¡æˆ–ä½çº¹ç†æ—¶å¼•å…¥å¯¹é½è¯¯å·®ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†VolSplatï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„å‰é¦ˆå¤šè§†è§’èŒƒå¼ï¼Œå®ƒç”¨ä½“ç´ å¯¹é½çš„é«˜æ–¯æ›¿æ¢äº†åƒç´ å¯¹é½ã€‚é€šè¿‡ç›´æ¥ä»é¢„æµ‹çš„3Dä½“ç´ ç½‘æ ¼é¢„æµ‹é«˜æ–¯å€¼ï¼Œå®ƒå…‹æœäº†åƒç´ å¯¹é½å¯¹å®¹æ˜“å‡ºç°é”™è¯¯çš„äºŒç»´ç‰¹å¾åŒ¹é…çš„ä¾èµ–ï¼Œç¡®ä¿äº†ç¨³å¥çš„å¤šè§†è§’ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œå®ƒå¯ä»¥æ ¹æ®3Dåœºæ™¯çš„å¤æ‚æ€§å¯¹é«˜æ–¯å¯†åº¦è¿›è¡Œè‡ªé€‚åº”æ§åˆ¶ï¼Œäº§ç”Ÿæ›´çœŸå®çš„é«˜æ–¯ç‚¹äº‘ã€æ”¹è¿›å‡ ä½•ä¸€è‡´æ€§å’Œæé«˜æ–°é¢–è§†è§’çš„æ¸²æŸ“è´¨é‡ã€‚åœ¨åŒ…æ‹¬RealEstate10Kå’ŒScanNetåœ¨å†…çš„å¸¸ç”¨åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒVolSplatè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶äº§ç”Ÿäº†æ›´åˆç†å’Œè§†è§’ä¸€è‡´çš„é«˜æ–¯é‡å»ºã€‚é™¤äº†ä¼˜è¶Šçš„ç»“æœå¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ºå‰é¦ˆä¸‰ç»´é‡å»ºå»ºç«‹äº†ä¸€ä¸ªæ›´å¯æ‰©å±•çš„æ¡†æ¶ï¼Œå…·æœ‰æ›´å¯†é›†å’Œæ›´ç¨³å¥çš„è¡¨ç¤ºå½¢å¼ï¼Œä¸ºæ›´å¹¿æ³›çš„ç¤¾åŒºä¸­çš„è¿›ä¸€æ­¥ç ”ç©¶é“ºå¹³äº†é“è·¯ã€‚è§†é¢‘ç»“æœã€ä»£ç å’Œè®­ç»ƒæ¨¡å‹å¯åœ¨æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://lhmd.top/volsplat%E3%80%82">https://lhmd.top/volsplatã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.19297v1">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://lhmd.top/volsplat">https://lhmd.top/volsplat</a>, Code:   <a target="_blank" rel="noopener" href="https://github.com/ziplab/VolSplat">https://github.com/ziplab/VolSplat</a></p>
<p><strong>Summary</strong><br>     åŸºäºå‰é¦ˆçš„3Dé«˜æ–¯ç‚¹äº‘ï¼ˆ3DGSï¼‰å·²æˆä¸ºæœ‰æ•ˆçš„è§†ç‚¹åˆæˆè§£å†³æ–¹æ¡ˆã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–åƒç´ å¯¹é½çš„é«˜æ–¯é¢„æµ‹æ¨¡å¼ï¼Œå­˜åœ¨ä¾èµ–è¾“å…¥è§†è§’æ•°é‡ã€è§†è§’å¯†åº¦åˆ†å¸ƒåå·®åŠå¯¹é½è¯¯å·®ç­‰é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºVolSplatï¼Œé‡‡ç”¨ä½“ç´ å¯¹é½é«˜æ–¯çš„æ–°èŒƒå¼ï¼Œé¢„æµ‹ä¸‰ç»´ä½“ç´ ç½‘æ ¼ä¸Šçš„é«˜æ–¯åˆ†å¸ƒï¼Œå…‹æœåƒç´ å¯¹é½çš„ç¼ºé™·ï¼Œå®ç°å¤šè§†è§’ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œå®ƒå¯æ ¹æ®ä¸‰ç»´åœºæ™¯çš„å¤æ‚æ€§è‡ªé€‚åº”æ§åˆ¶é«˜æ–¯å¯†åº¦ï¼Œæé«˜å‡ ä½•ä¸€è‡´æ€§åŠæ–°è§†è§’æ¸²æŸ“è´¨é‡ã€‚åœ¨å¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å“è¶Šï¼Œå®ç°æ›´é€¼çœŸã€è§†è§’ä¸€è‡´çš„é«˜æ–¯é‡å»ºã€‚åŒæ—¶å»ºç«‹å¯æ‰©å±•çš„æ¡†æ¶ï¼Œä¸ºè¿›ä¸€æ­¥çš„ç‚¹äº‘é‡å»ºç ”ç©¶é“ºå¹³é“è·¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°æœ‰åŸºäºåƒç´ å¯¹é½çš„3DGSå­˜åœ¨ä¾èµ–è¾“å…¥è§†è§’æ•°é‡ã€è§†è§’å¯†åº¦åˆ†å¸ƒåå·®åŠå¯¹é½è¯¯å·®ç­‰é—®é¢˜ã€‚</li>
<li>VolSplaté‡‡ç”¨ä½“ç´ å¯¹é½é«˜æ–¯çš„æ–°èŒƒå¼ï¼Œå…‹æœäº†åƒç´ å¯¹é½çš„ç¼ºé™·ï¼Œå®ç°æ›´ç¨³å®šçš„å¤šè§†è§’ä¸€è‡´æ€§ã€‚</li>
<li>VolSplatæ ¹æ®ä¸‰ç»´åœºæ™¯çš„å¤æ‚æ€§è‡ªé€‚åº”æ§åˆ¶é«˜æ–¯å¯†åº¦ï¼Œæé«˜å‡ ä½•ä¸€è‡´æ€§åŠæ–°è§†è§’æ¸²æŸ“è´¨é‡ã€‚</li>
<li>VolSplatåœ¨åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å“è¶Šï¼Œå®ç°äº†æ›´é€¼çœŸã€è§†è§’ä¸€è‡´çš„é«˜æ–¯é‡å»ºï¼Œæ€§èƒ½è¶…è¶Šç°æœ‰æŠ€æœ¯ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.19297">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9793958c56a57fd64d90ce133614c132" align="middle">
<img src="https://picx.zhimg.com/v2-fb0f3126a327c619f44347569b95eee3" align="middle">
<img src="https://picx.zhimg.com/v2-8d91bb6c1d222f7dd683f6928f964607" align="middle">
<img src="https://picx.zhimg.com/v2-6a56313ea70206b46e6cb8878773900c" align="middle">
<img src="https://picx.zhimg.com/v2-eab02a07b1bf0e5ac6d2d5af237d2bde" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Lyra-Generative-3D-Scene-Reconstruction-via-Video-Diffusion-Model-Self-Distillation"><a href="#Lyra-Generative-3D-Scene-Reconstruction-via-Video-Diffusion-Model-Self-Distillation" class="headerlink" title="Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model   Self-Distillation"></a>Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model   Self-Distillation</h2><p><strong>Authors:Sherwin Bahmani, Tianchang Shen, Jiawei Ren, Jiahui Huang, Yifeng Jiang, Haithem Turki, Andrea Tagliasacchi, David B. Lindell, Zan Gojcic, Sanja Fidler, Huan Ling, Jun Gao, Xuanchi Ren</strong></p>
<p>The ability to generate virtual environments is crucial for applications ranging from gaming to physical AI domains such as robotics, autonomous driving, and industrial AI. Current learning-based 3D reconstruction methods rely on the availability of captured real-world multi-view data, which is not always readily available. Recent advancements in video diffusion models have shown remarkable imagination capabilities, yet their 2D nature limits the applications to simulation where a robot needs to navigate and interact with the environment. In this paper, we propose a self-distillation framework that aims to distill the implicit 3D knowledge in the video diffusion models into an explicit 3D Gaussian Splatting (3DGS) representation, eliminating the need for multi-view training data. Specifically, we augment the typical RGB decoder with a 3DGS decoder, which is supervised by the output of the RGB decoder. In this approach, the 3DGS decoder can be purely trained with synthetic data generated by video diffusion models. At inference time, our model can synthesize 3D scenes from either a text prompt or a single image for real-time rendering. Our framework further extends to dynamic 3D scene generation from a monocular input video. Experimental results show that our framework achieves state-of-the-art performance in static and dynamic 3D scene generation. </p>
<blockquote>
<p>ç”Ÿæˆè™šæ‹Ÿç¯å¢ƒçš„èƒ½åŠ›å¯¹äºä»æ¸¸æˆåˆ°ç‰©ç†äººå·¥æ™ºèƒ½é¢†åŸŸï¼ˆå¦‚æœºå™¨äººæŠ€æœ¯ã€è‡ªåŠ¨é©¾é©¶å’Œå·¥ä¸šäººå·¥æ™ºèƒ½ï¼‰çš„åº”ç”¨è‡³å…³é‡è¦ã€‚å½“å‰åŸºäºå­¦ä¹ çš„3Dé‡å»ºæ–¹æ³•ä¾èµ–äºæ•è·çš„å®æ—¶å¤šè§†è§’æ•°æ®çš„å¯ç”¨æ€§ï¼Œè€Œè¿™å¹¶éæ€»æ˜¯è½»æ˜“å¯å¾—ã€‚è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æœ€æ–°è¿›å±•è¡¨ç°å‡ºäº†æƒŠäººçš„æƒ³è±¡åŠ›èƒ½åŠ›ï¼Œä½†å®ƒä»¬çš„2Dæ€§è´¨é™åˆ¶äº†å…¶åœ¨æœºå™¨äººéœ€è¦å¯¼èˆªå’Œä¸ç¯å¢ƒäº¤äº’çš„æ¨¡æ‹Ÿä¸­çš„åº”ç”¨ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è‡ªè’¸é¦æ¡†æ¶ï¼Œæ—¨åœ¨å°†è§†é¢‘æ‰©æ•£æ¨¡å‹ä¸­çš„éšå¼3DçŸ¥è¯†è’¸é¦æˆæ˜ç¡®çš„3Dé«˜æ–¯å¹³é“ºï¼ˆ3DGSï¼‰è¡¨ç¤ºï¼Œä»è€Œæ— éœ€å¤šè§†è§’è®­ç»ƒæ•°æ®ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç”¨3DGSè§£ç å™¨æ‰©å……äº†å…¸å‹çš„RGBè§£ç å™¨ï¼Œè¯¥è§£ç å™¨ç”±RGBè§£ç å™¨çš„è¾“å‡ºè¿›è¡Œç›‘ç£ã€‚åœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œ3DGSè§£ç å™¨å¯ä»¥ä»…ä½¿ç”¨ç”±è§†é¢‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„åˆæˆæ•°æ®è¿›è¡Œè®­ç»ƒã€‚åœ¨æ¨ç†æ—¶é—´ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥ä»æ–‡æœ¬æç¤ºæˆ–å•å¼ å›¾åƒä¸­åˆæˆ3Dåœºæ™¯ï¼Œä»¥è¿›è¡Œå®æ—¶æ¸²æŸ“ã€‚æˆ‘ä»¬çš„æ¡†æ¶è¿›ä¸€æ­¥æ‰©å±•åˆ°åŸºäºå•ç›®è¾“å…¥è§†é¢‘çš„åŠ¨æ€3Dåœºæ™¯ç”Ÿæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨é™æ€å’ŒåŠ¨æ€3Dåœºæ™¯ç”Ÿæˆæ–¹é¢è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.19296v1">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://research.nvidia.com/labs/toronto-ai/lyra/">https://research.nvidia.com/labs/toronto-ai/lyra/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè‡ªè’¸é¦æŠ€æœ¯çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿå°†è§†é¢‘æ‰©æ•£æ¨¡å‹ä¸­çš„éšæ€§ä¸‰ç»´çŸ¥è¯†è½¬åŒ–ä¸ºæ˜¾å¼ä¸‰ç»´é«˜æ–¯é£æº…ï¼ˆ3DGSï¼‰è¡¨ç¤ºå½¢å¼ï¼Œä»è€Œå®ç°æ— éœ€å¤šè§†è§’è®­ç»ƒæ•°æ®çš„ä¸‰ç»´åœºæ™¯ç”Ÿæˆã€‚è¯¥æ¡†æ¶é€šè¿‡å¢åŠ ä¸€ä¸ªä¸‰ç»´é«˜æ–¯é£æº…è§£ç å™¨æ¥æ‰©å±•ä¼ ç»Ÿçš„RGBè§£ç å™¨ï¼Œä½¿å…¶å¯ä»¥ä»æ–‡æœ¬æç¤ºæˆ–å•å¹…å›¾åƒä¸­åˆæˆä¸‰ç»´åœºæ™¯ï¼Œæ”¯æŒå®æ—¶æ¸²æŸ“å’Œä»å•ç›®è¾“å…¥è§†é¢‘ä¸­ç”ŸæˆåŠ¨æ€ä¸‰ç»´åœºæ™¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨é™æ€å’ŒåŠ¨æ€ä¸‰ç»´åœºæ™¯ç”Ÿæˆæ–¹é¢è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>è¯¥æ¡†æ¶èƒ½å¤Ÿå°†è§†é¢‘æ‰©æ•£æ¨¡å‹ä¸­çš„éšæ€§ä¸‰ç»´çŸ¥è¯†è½¬åŒ–ä¸ºæ˜¾å¼ä¸‰ç»´é«˜æ–¯é£æº…ï¼ˆ3DGSï¼‰è¡¨ç¤ºå½¢å¼ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºè‡ªè’¸é¦æŠ€æœ¯çš„æ¡†æ¶ï¼Œä¸éœ€è¦å¤šè§†è§’è®­ç»ƒæ•°æ®ã€‚</li>
<li>é€šè¿‡å¢åŠ ä¸€ä¸ªä¸‰ç»´é«˜æ–¯é£æº…è§£ç å™¨æ¥æ‰©å±•ä¼ ç»Ÿçš„RGBè§£ç å™¨ï¼Œä»¥å®ç°æ›´å¥½çš„ä¸‰ç»´åœºæ™¯ç”Ÿæˆã€‚</li>
<li>æ”¯æŒä»æ–‡æœ¬æç¤ºæˆ–å•å¹…å›¾åƒä¸­åˆæˆä¸‰ç»´åœºæ™¯ï¼Œå¹¶èƒ½å¤Ÿå®ç°å®æ—¶æ¸²æŸ“ã€‚</li>
<li>èƒ½å¤Ÿä»å•ç›®è¾“å…¥è§†é¢‘ä¸­ç”ŸæˆåŠ¨æ€ä¸‰ç»´åœºæ™¯ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.19296">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-74e03d2958e791f851ff3cf6981d9211" align="middle">
<img src="https://picx.zhimg.com/v2-917fdaee759f1fad519ef9536b017a70" align="middle">
<img src="https://picx.zhimg.com/v2-f1fc2b81389fc2d1c3422dae6fd8ea5a" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Seeing-Through-Reflections-Advancing-3D-Scene-Reconstruction-in-Mirror-Containing-Environments-with-Gaussian-Splatting"><a href="#Seeing-Through-Reflections-Advancing-3D-Scene-Reconstruction-in-Mirror-Containing-Environments-with-Gaussian-Splatting" class="headerlink" title="Seeing Through Reflections: Advancing 3D Scene Reconstruction in   Mirror-Containing Environments with Gaussian Splatting"></a>Seeing Through Reflections: Advancing 3D Scene Reconstruction in   Mirror-Containing Environments with Gaussian Splatting</h2><p><strong>Authors:Zijing Guo, Yunyang Zhao, Lin Wang</strong></p>
<p>Mirror-containing environments pose unique challenges for 3D reconstruction and novel view synthesis (NVS), as reflective surfaces introduce view-dependent distortions and inconsistencies. While cutting-edge methods such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) excel in typical scenes, their performance deteriorates in the presence of mirrors. Existing solutions mainly focus on handling mirror surfaces through symmetry mapping but often overlook the rich information carried by mirror reflections. These reflections offer complementary perspectives that can fill in absent details and significantly enhance reconstruction quality. To advance 3D reconstruction in mirror-rich environments, we present MirrorScene3D, a comprehensive dataset featuring diverse indoor scenes, 1256 high-quality images, and annotated mirror masks, providing a benchmark for evaluating reconstruction methods in reflective settings. Building on this, we propose ReflectiveGS, an extension of 3D Gaussian Splatting that utilizes mirror reflections as complementary viewpoints rather than simple symmetry artifacts, enhancing scene geometry and recovering absent details. Experiments on MirrorScene3D show that ReflectiveGaussian outperforms existing methods in SSIM, PSNR, LPIPS, and training speed, setting a new benchmark for 3D reconstruction in mirror-rich environments. </p>
<blockquote>
<p>åŒ…å«é•œå­çš„ç¯å¢ƒä¸ºä¸‰ç»´é‡å»ºå’Œæ–°é¢–è§†å›¾åˆæˆï¼ˆNVSï¼‰å¸¦æ¥äº†ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼Œå› ä¸ºåå°„è¡¨é¢å¼•å…¥äº†è§†å›¾ç›¸å…³çš„å¤±çœŸå’Œä¸ä¸€è‡´æ€§ã€‚è™½ç„¶æœ€å‰æ²¿çš„æ–¹æ³•ï¼Œå¦‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œä¸‰ç»´é«˜æ–¯å–·ç»˜ï¼ˆ3DGSï¼‰åœ¨å…¸å‹åœºæ™¯ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨å­˜åœ¨é•œå­çš„æƒ…å†µä¸‹ï¼Œå®ƒä»¬çš„æ€§èƒ½ä¼šä¸‹é™ã€‚ç°æœ‰è§£å†³æ–¹æ¡ˆä¸»è¦é€šè¿‡å¯¹ç§°æ˜ å°„å¤„ç†é•œå­è¡¨é¢ï¼Œä½†å¾€å¾€å¿½ç•¥äº†é•œå­åå°„æ‰€æºå¸¦çš„ä¸°å¯Œä¿¡æ¯ã€‚è¿™äº›åå°„æä¾›äº†å¯ä»¥è¡¥å……çš„è§†è§’ï¼Œå¯ä»¥å¡«è¡¥ç¼ºå¤±çš„ç»†èŠ‚ï¼Œå¹¶æ˜¾è‘—æé«˜é‡å»ºè´¨é‡ã€‚ä¸ºäº†æ¨è¿›åœ¨é•œå­ä¸°å¯Œçš„ç¯å¢ƒä¸­çš„ä¸‰ç»´é‡å»ºï¼Œæˆ‘ä»¬æ¨å‡ºäº†MirrorScene3Dæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å¤šæ ·åŒ–çš„å®¤å†…åœºæ™¯ã€1256å¼ é«˜è´¨é‡å›¾åƒå’Œæ³¨é‡Šçš„é•œå­æ©è†œï¼Œä¸ºåå°„ç¯å¢ƒä¸­é‡å»ºæ–¹æ³•çš„è¯„ä¼°æä¾›äº†åŸºå‡†ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†ReflectiveGSï¼Œå®ƒæ˜¯ä¸‰ç»´é«˜æ–¯å–·ç»˜çš„ä¸€ä¸ªæ‰©å±•ï¼Œåˆ©ç”¨é•œå­åå°„ä½œä¸ºè¡¥å……è§†è§’ï¼Œè€Œä¸æ˜¯ç®€å•çš„å¯¹ç§°äº§ç‰©ï¼Œä»è€Œå¢å¼ºåœºæ™¯å‡ ä½•å¹¶æ¢å¤ç¼ºå¤±çš„ç»†èŠ‚ã€‚åœ¨MirrorScene3Dä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒReflectiveGaussianåœ¨SSIMã€PSNRã€LPIPSå’Œè®­ç»ƒé€Ÿåº¦ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºé•œå­ä¸°å¯Œçš„ç¯å¢ƒä¸­çš„ä¸‰ç»´é‡å»ºè®¾å®šäº†æ–°çš„åŸºå‡†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18956v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†åœ¨å«æœ‰é•œå­çš„ç¯å¢ƒä¸­è¿›è¡Œ3Dé‡å»ºå’Œæ–°å‹è§†å›¾åˆæˆé¢ä¸´çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¦‚Neural Radiance Fieldså’Œ3D Gaussian Splattingåœ¨å¤„ç†é•œå­æ—¶æ€§èƒ½ä¸‹é™ã€‚æ–‡ç« æå‡ºäº†MirrorScene3Dæ•°æ®é›†å’ŒReflectiveGSæ–¹æ³•ï¼Œåˆ©ç”¨é•œå­åå°„ä½œä¸ºè¡¥å……è§†è§’ï¼Œæé«˜åœºæ™¯å‡ ä½•å’Œæ¢å¤ç¼ºå¤±ç»†èŠ‚çš„èƒ½åŠ›ï¼Œä¸ºåœ¨é•œå­ä¸°å¯Œçš„ç¯å¢ƒä¸­è¿›è¡Œ3Dé‡å»ºè®¾ç«‹äº†æ–°çš„åŸºå‡†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é•œå­åŒ…å«çš„ç¯å¢ƒå¯¹3Dé‡å»ºå’Œæ–°å‹è§†å›¾åˆæˆå¸¦æ¥ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œå› åå°„è¡¨é¢å¼•å…¥è§†å›¾ä¾èµ–çš„å¤±çœŸå’Œä¸ä¸€è‡´æ€§ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨é•œå­å­˜åœ¨æ—¶æ€§èƒ½ä¸‹é™ï¼Œä¸»è¦é€šè¿‡å¯¹ç§°æ˜ å°„å¤„ç†é•œå­è¡¨é¢ï¼Œä½†å¿½è§†äº†é•œå­åå°„æ‰€æºå¸¦çš„ä¸°å¯Œä¿¡æ¯ã€‚</li>
<li>MirrorScene3Dæ•°æ®é›†æä¾›å®¤å†…åœºæ™¯çš„å¤šæ ·åŒ–å›¾åƒå’Œæ ‡æ³¨çš„é•œå­æ©è†œï¼Œä¸ºè¯„ä¼°åå°„è®¾ç½®ä¸­çš„é‡å»ºæ–¹æ³•æä¾›äº†åŸºå‡†ã€‚</li>
<li>ReflectiveGSæ–¹æ³•åˆ©ç”¨é•œå­åå°„ä½œä¸ºè¡¥å……è§†è§’ï¼Œæé«˜åœºæ™¯å‡ ä½•å’Œæ¢å¤ç¼ºå¤±ç»†èŠ‚çš„èƒ½åŠ›ã€‚</li>
<li>ReflectiveGSæ˜¯3D Gaussian Splattingçš„æ‰©å±•ï¼Œå¯ä»¥æ›´å¥½åœ°åˆ©ç”¨é•œå­åå°„ä¿¡æ¯ã€‚</li>
<li>åœ¨MirrorScene3Dä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒReflectiveGaussianåœ¨SSIMã€PSNRã€LPIPSå’Œè®­ç»ƒé€Ÿåº¦ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18956">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-59ef441157f520f0d170006ac31fc7fd" align="middle">
<img src="https://picx.zhimg.com/v2-dacb7f30185d0ad15a107c6e4d34b02b" align="middle">
<img src="https://picx.zhimg.com/v2-f81cdbf33669c68eb401663d50edadd4" align="middle">
<img src="https://picx.zhimg.com/v2-10d7da124699a6f4627ec89f45d97718" align="middle">
<img src="https://picx.zhimg.com/v2-89684003f438d8b81377651af5552a03" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="DeblurSplat-SfM-free-3D-Gaussian-Splatting-with-Event-Camera-for-Robust-Deblurring"><a href="#DeblurSplat-SfM-free-3D-Gaussian-Splatting-with-Event-Camera-for-Robust-Deblurring" class="headerlink" title="DeblurSplat: SfM-free 3D Gaussian Splatting with Event Camera for Robust   Deblurring"></a>DeblurSplat: SfM-free 3D Gaussian Splatting with Event Camera for Robust   Deblurring</h2><p><strong>Authors:Pengteng Li, Yunfan Lu, Pinhao Song, Weiyu Guo, Huizai Yao, F. Richard Yu, Hui Xiong</strong></p>
<p>In this paper, we propose the first Structure-from-Motion (SfM)-free deblurring 3D Gaussian Splatting method via event camera, dubbed DeblurSplat. We address the motion-deblurring problem in two ways. First, we leverage the pretrained capability of the dense stereo module (DUSt3R) to directly obtain accurate initial point clouds from blurred images. Without calculating camera poses as an intermediate result, we avoid the cumulative errors transfer from inaccurate camera poses to the initial point cloudsâ€™ positions. Second, we introduce the event stream into the deblur pipeline for its high sensitivity to dynamic change. By decoding the latent sharp images from the event stream and blurred images, we can provide a fine-grained supervision signal for scene reconstruction optimization. Extensive experiments across a range of scenes demonstrate that DeblurSplat not only excels in generating high-fidelity novel views but also achieves significant rendering efficiency compared to the SOTAs in deblur 3D-GS. </p>
<blockquote>
<p>åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºäº‹ä»¶ç›¸æœºçš„æ— ç»“æ„ä»è¿åŠ¨ï¼ˆSfMï¼‰çš„æ¨¡ç³Š3Dé«˜æ–¯ç‚¹äº‘æ•£æ’­æ–¹æ³•ï¼Œåä¸ºDeblurSplatã€‚æˆ‘ä»¬é‡‡ç”¨ä¸¤ç§æ–¹æ³•è§£å†³è¿åŠ¨å»æ¨¡ç³Šé—®é¢˜ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬åˆ©ç”¨å¯†é›†ç«‹ä½“æ¨¡å—ï¼ˆDUSt3Rï¼‰çš„é¢„è®­ç»ƒèƒ½åŠ›ï¼Œç›´æ¥ä»æ¨¡ç³Šå›¾åƒä¸­è·å–ç²¾ç¡®çš„ç‚¹äº‘åˆå§‹ä½ç½®ã€‚æ— éœ€è®¡ç®—ç›¸æœºå§¿æ€ä½œä¸ºä¸­é—´ç»“æœï¼Œä»è€Œé¿å…äº†ç”±ä¸å‡†ç¡®çš„ç›¸æœºå§¿æ€å¯¹åˆå§‹ç‚¹äº‘ä½ç½®é€ æˆçš„ç´¯ç§¯è¯¯å·®ä¼ é€’ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å°†äº‹ä»¶æµå¼•å…¥å»æ¨¡ç³Šæµç¨‹ä¸­ï¼Œåˆ©ç”¨å…¶å¯¹åŠ¨æ€å˜åŒ–çš„é«˜çµæ•åº¦ã€‚é€šè¿‡è§£ç äº‹ä»¶æµå’Œæ¨¡ç³Šå›¾åƒä¸­çš„æ½œåœ¨æ¸…æ™°å›¾åƒï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºåœºæ™¯é‡å»ºä¼˜åŒ–æä¾›ç²¾ç»†çš„ç›‘ç£ä¿¡å·ã€‚åœ¨å¤šä¸ªåœºæ™¯çš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDeblurSplatä¸ä»…åœ¨ç”Ÿæˆé«˜ä¿çœŸæ–°è§†è§’æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œè€Œä¸”åœ¨å»æ¨¡ç³Š3D-GSçš„æ¸²æŸ“æ•ˆç‡æ–¹é¢ä¹Ÿæœ‰æ˜¾è‘—æé«˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18898v1">PDF</a> </p>
<p><strong>Summary</strong><br>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºäº‹ä»¶ç›¸æœºçš„æ— ç»“æ„ä»è¿åŠ¨ï¼ˆSfMï¼‰çš„3Dé«˜æ–¯æ‰©å±•å»æ¨¡ç³Šæ–¹æ³•ï¼Œåä¸ºDeblurSplatã€‚å®ƒé€šè¿‡ä¸¤ç§æ–¹å¼è§£å†³è¿åŠ¨å»æ¨¡ç³Šé—®é¢˜ï¼šä¸€æ˜¯åˆ©ç”¨å¯†é›†ç«‹ä½“æ¨¡å—ï¼ˆDUSt3Rï¼‰çš„é¢„è®­ç»ƒèƒ½åŠ›ç›´æ¥ä»æ¨¡ç³Šå›¾åƒä¸­è·å–ç²¾ç¡®åˆå§‹ç‚¹äº‘ï¼›äºŒæ˜¯å°†äº‹ä»¶æµå¼•å…¥å»æ¨¡ç³Šç®¡é“ï¼Œé€šè¿‡è§£ç äº‹ä»¶æµå’Œæ¨¡ç³Šå›¾åƒä¸­çš„æ½œåœ¨å°–é”å›¾åƒï¼Œä¸ºåœºæ™¯é‡å»ºä¼˜åŒ–æä¾›ç²¾ç»†çš„ç›‘ç£ä¿¡å·ã€‚å®éªŒè¡¨æ˜ï¼ŒDeblurSplatä¸ä»…åœ¨é«˜ä¿çœŸåº¦ç”Ÿæˆæ–°å‹è§†å›¾æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œè€Œä¸”åœ¨3D-GSå»æ¨¡ç³Šæ–¹é¢ä¸å½“å‰æœ€ä½³æŠ€æœ¯ç›¸æ¯”å®ç°äº†æ˜¾è‘—çš„æ¸²æŸ“æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†é¦–ä¸ªåŸºäºäº‹ä»¶ç›¸æœºçš„æ— ç»“æ„ä»è¿åŠ¨ï¼ˆSfMï¼‰å»æ¨¡ç³Š3Dé«˜æ–¯æ‰©å±•æ–¹æ³•ï¼Œåä¸ºDeblurSplatã€‚</li>
<li>åˆ©ç”¨å¯†é›†ç«‹ä½“æ¨¡å—ï¼ˆDUSt3Rï¼‰çš„é¢„è®­ç»ƒèƒ½åŠ›ç›´æ¥ä»æ¨¡ç³Šå›¾åƒè·å–ç²¾ç¡®åˆå§‹ç‚¹äº‘ï¼Œé¿å…äº†å› ç›¸æœºå§¿æ€è®¡ç®—ä¸å‡†ç¡®å¯¼è‡´çš„è¯¯å·®ä¼ é€’ã€‚</li>
<li>å¼•å…¥äº‹ä»¶æµåˆ°å»æ¨¡ç³Šæµç¨‹ä¸­ï¼Œåˆ©ç”¨å…¶å¯¹äºåŠ¨æ€å˜åŒ–çš„é«˜æ•æ„Ÿæ€§ã€‚</li>
<li>é€šè¿‡è§£ç äº‹ä»¶æµå’Œæ¨¡ç³Šå›¾åƒä¸­çš„æ½œåœ¨å°–é”å›¾åƒï¼Œä¸ºåœºæ™¯é‡å»ºä¼˜åŒ–æä¾›ç²¾ç»†ç›‘ç£ä¿¡å·ã€‚</li>
<li>DeblurSplatèƒ½å¤Ÿç”Ÿæˆé«˜ä¿çœŸåº¦çš„æ–°å‹è§†å›¾ã€‚</li>
<li>ä¸å½“å‰æœ€ä½³æŠ€æœ¯ç›¸æ¯”ï¼ŒDeblurSplatåœ¨å»æ¨¡ç³Š3D-GSæ–¹é¢å®ç°äº†æ˜¾è‘—çš„æ¸²æŸ“æ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18898">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a172d79a0e75866d8450b8db7081033d" align="middle">
<img src="https://picx.zhimg.com/v2-6e68157f252cbb7f903b4fab30ee40d0" align="middle">
<img src="https://picx.zhimg.com/v2-a42cb0d50434bd853c5bbdd06766ed39" align="middle">
<img src="https://picx.zhimg.com/v2-061cec6493bb220b6954bad6e7363dd8" align="middle">
<img src="https://picx.zhimg.com/v2-5add0e33d4c8afcb060b9315273f69c3" align="middle">
<img src="https://picx.zhimg.com/v2-6e6eac6276fd370b8d1dec08f0386a15" align="middle">
<img src="https://picx.zhimg.com/v2-b3da04b0bf1625c3f8f126f6570b54f7" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="FixingGS-Enhancing-3D-Gaussian-Splatting-via-Training-Free-Score-Distillation"><a href="#FixingGS-Enhancing-3D-Gaussian-Splatting-via-Training-Free-Score-Distillation" class="headerlink" title="FixingGS: Enhancing 3D Gaussian Splatting via Training-Free Score   Distillation"></a>FixingGS: Enhancing 3D Gaussian Splatting via Training-Free Score   Distillation</h2><p><strong>Authors:Zhaorui Wang, Yi Gu, Deming Zhou, Renjing Xu</strong></p>
<p>Recently, 3D Gaussian Splatting (3DGS) has demonstrated remarkable success in 3D reconstruction and novel view synthesis. However, reconstructing 3D scenes from sparse viewpoints remains highly challenging due to insufficient visual information, which results in noticeable artifacts persisting across the 3D representation. To address this limitation, recent methods have resorted to generative priors to remove artifacts and complete missing content in under-constrained areas. Despite their effectiveness, these approaches struggle to ensure multi-view consistency, resulting in blurred structures and implausible details. In this work, we propose FixingGS, a training-free method that fully exploits the capabilities of the existing diffusion model for sparse-view 3DGS reconstruction enhancement. At the core of FixingGS is our distillation approach, which delivers more accurate and cross-view coherent diffusion priors, thereby enabling effective artifact removal and inpainting. In addition, we propose an adaptive progressive enhancement scheme that further refines reconstructions in under-constrained regions. Extensive experiments demonstrate that FixingGS surpasses existing state-of-the-art methods with superior visual quality and reconstruction performance. Our code will be released publicly. </p>
<blockquote>
<p>è¿‘æœŸï¼Œ3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰åœ¨3Dé‡å»ºå’Œæ–°å‹è§†è§’åˆæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚ç„¶è€Œï¼Œä»ç¨€ç–è§†è§’é‡å»º3Dåœºæ™¯ä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ï¼Œå› ä¸ºè§†è§‰ä¿¡æ¯ä¸è¶³ï¼Œå¯¼è‡´3Dè¡¨ç¤ºä¸­æŒç»­å­˜åœ¨æ˜æ˜¾çš„ä¼ªå½±ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæœ€è¿‘çš„æ–¹æ³•é‡‡ç”¨ç”Ÿæˆå…ˆéªŒæ¥æ¶ˆé™¤ä¼ªå½±å¹¶å®Œæˆçº¦æŸä¸è¶³åŒºåŸŸçš„ç¼ºå¤±å†…å®¹ã€‚å°½ç®¡è¿™äº›æ–¹æ³•å¾ˆæœ‰æ•ˆï¼Œä½†å®ƒä»¬å¾ˆéš¾ä¿è¯å¤šè§†è§’çš„ä¸€è‡´æ€§ï¼Œå¯¼è‡´ç»“æ„æ¨¡ç³Šå’Œä¸åˆ‡å®é™…çš„ç»†èŠ‚ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†FixinGSï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„æ–¹æ³•ï¼Œå……åˆ†åˆ©ç”¨ç°æœ‰æ‰©æ•£æ¨¡å‹çš„æ½œåŠ›ï¼Œç”¨äºç¨€ç–è§†è§’çš„3DGSé‡å»ºå¢å¼ºã€‚FixinGSçš„æ ¸å¿ƒæ˜¯æˆ‘ä»¬çš„è’¸é¦æ–¹æ³•ï¼Œå®ƒæä¾›äº†æ›´å‡†ç¡®å’Œè·¨è§†è§’ä¸€è‡´æ€§çš„æ‰©æ•£å…ˆéªŒï¼Œä»è€Œå®ç°äº†æœ‰æ•ˆçš„ä¼ªå½±æ¶ˆé™¤å’Œè¡¥å…¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§è‡ªé€‚åº”æ¸è¿›å¢å¼ºæ–¹æ¡ˆï¼Œè¿›ä¸€æ­¥æ”¹è¿›äº†çº¦æŸä¸è¶³åŒºåŸŸçš„é‡å»ºã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒFixinGSè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå…·æœ‰ä¼˜è¶Šçš„è§†è§‰è´¨é‡å’Œé‡å»ºæ€§èƒ½ã€‚æˆ‘ä»¬çš„ä»£ç å°†å…¬å¼€å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18759v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>3DGSåœ¨ä¸‰ç»´é‡å»ºå’Œæ–°å‹è§†è§’åˆæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œä½†ä»æœªçº¦æŸè§†è§’é‡å»ºä¸‰ç»´åœºæ™¯ä»å­˜åœ¨æŒ‘æˆ˜ï¼Œå› ä¸ºç¼ºä¹è¶³å¤Ÿçš„è§†è§‰ä¿¡æ¯å¯¼è‡´é‡å»ºç»“æœä¸­ä»å­˜åœ¨æ˜¾è‘—çš„äººå·¥ç—•è¿¹ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•é‡‡ç”¨ç”Ÿæˆå…ˆéªŒæ¥æ¶ˆé™¤äººå·¥ç—•è¿¹å¹¶å®Œæˆç¼ºå¤±å†…å®¹çš„å¡«å……ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•éš¾ä»¥ç¡®ä¿å¤šè§†è§’çš„ä¸€è‡´æ€§ï¼Œå¯¼è‡´ç»“æ„æ¨¡ç³Šå’Œä¸åˆ‡å®é™…çš„ç»†èŠ‚ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§æ— éœ€è®­ç»ƒçš„ FixingGS æ–¹æ³•ï¼Œå……åˆ†åˆ©ç”¨ç°æœ‰æ‰©æ•£æ¨¡å‹çš„æ½œåŠ›è¿›è¡Œç¨€ç–è§†è§’çš„ 3DGS é‡å»ºå¢å¼ºã€‚å…¶æ ¸å¿ƒåœ¨äºè’¸é¦æ³•ï¼Œå¯ç”Ÿæˆæ›´å‡†ç¡®ä¸”è·¨è§†è§’ä¸€è‡´çš„æ‰©æ•£å…ˆéªŒï¼Œä»è€Œå®ç°æœ‰æ•ˆçš„äººå·¥ç—•è¿¹å»é™¤å’Œè¡¥å…¨ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§è‡ªé€‚åº”æ¸è¿›å¢å¼ºæ–¹æ¡ˆï¼Œè¿›ä¸€æ­¥æ”¹è¿›äº†é‡å»ºç»“æœçš„ä¸è¶³çº¦æŸåŒºåŸŸã€‚å®éªŒè¯æ˜ï¼ŒFixingGS åœ¨è§†è§‰è´¨é‡å’Œé‡å»ºæ€§èƒ½ä¸Šè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSåœ¨ä¸‰ç»´é‡å»ºå’Œæ–°å‹è§†è§’åˆæˆä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚</li>
<li>ä»ç¨€ç–è§†è§’é‡å»ºä¸‰ç»´åœºæ™¯ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºç¼ºä¹è¶³å¤Ÿçš„è§†è§‰ä¿¡æ¯ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä½¿ç”¨ç”Ÿæˆå…ˆéªŒå»é™¤äººå·¥ç—•è¿¹å¹¶å¡«å……ç¼ºå¤±å†…å®¹ï¼Œä½†éš¾ä»¥ç¡®ä¿å¤šè§†è§’ä¸€è‡´æ€§ã€‚</li>
<li>FixingGSæ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„æ–¹æ³•ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ½œåŠ›å¢å¼ºç¨€ç–è§†è§’çš„3DGSé‡å»ºã€‚</li>
<li>FixingGSçš„æ ¸å¿ƒåœ¨äºç”Ÿæˆæ›´å‡†ç¡®å’Œè·¨è§†è§’ä¸€è‡´çš„æ‰©æ•£å…ˆéªŒï¼Œä»¥å®ç°æ›´å¥½çš„äººå·¥ç—•è¿¹å»é™¤å’Œè¡¥å…¨ã€‚</li>
<li>FixingGSè¿˜é‡‡ç”¨è‡ªé€‚åº”æ¸è¿›å¢å¼ºæ–¹æ¡ˆæ”¹è¿›äº†é‡å»ºç»“æœçš„ä¸è¶³çº¦æŸåŒºåŸŸã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒFixingGSåœ¨è§†è§‰è´¨é‡å’Œé‡å»ºæ€§èƒ½ä¸Šè¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18759">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-865b4128d5c09e11a2af033baefa0d45" align="middle">
<img src="https://picx.zhimg.com/v2-d50cc46063359360260d649dec67b215" align="middle">
<img src="https://picx.zhimg.com/v2-e888594cd5af2a09cb50359122784cbc" align="middle">
<img src="https://picx.zhimg.com/v2-6b7a7aad654e4ca94902e53630bc2914" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="SINGER-An-Onboard-Generalist-Vision-Language-Navigation-Policy-for-Drones"><a href="#SINGER-An-Onboard-Generalist-Vision-Language-Navigation-Policy-for-Drones" class="headerlink" title="SINGER: An Onboard Generalist Vision-Language Navigation Policy for   Drones"></a>SINGER: An Onboard Generalist Vision-Language Navigation Policy for   Drones</h2><p><strong>Authors:Maximilian Adang, JunEn Low, Ola Shorinwa, Mac Schwager</strong></p>
<p>Large vision-language models have driven remarkable progress in open-vocabulary robot policies, e.g., generalist robot manipulation policies, that enable robots to complete complex tasks specified in natural language. Despite these successes, open-vocabulary autonomous drone navigation remains an unsolved challenge due to the scarcity of large-scale demonstrations, real-time control demands of drones for stabilization, and lack of reliable external pose estimation modules. In this work, we present SINGER for language-guided autonomous drone navigation in the open world using only onboard sensing and compute. To train robust, open-vocabulary navigation policies, SINGER leverages three central components: (i) a photorealistic language-embedded flight simulator with minimal sim-to-real gap using Gaussian Splatting for efficient data generation, (ii) an RRT-inspired multi-trajectory generation expert for collision-free navigation demonstrations, and these are used to train (iii) a lightweight end-to-end visuomotor policy for real-time closed-loop control. Through extensive hardware flight experiments, we demonstrate superior zero-shot sim-to-real transfer of our policy to unseen environments and unseen language-conditioned goal objects. When trained on ~700k-1M observation action pairs of language conditioned visuomotor data and deployed on hardware, SINGER outperforms a velocity-controlled semantic guidance baseline by reaching the query 23.33% more on average, and maintains the query in the field of view 16.67% more on average, with 10% fewer collisions. </p>
<blockquote>
<p>å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹å·²ç»æ¨åŠ¨äº†å¼€æ”¾è¯æ±‡æœºå™¨äººç­–ç•¥çš„å·¨å¤§è¿›æ­¥ï¼Œä¾‹å¦‚é€šç”¨æœºå™¨äººæ“ä½œç­–ç•¥ï¼Œè¿™äº›ç­–ç•¥ä½¿æœºå™¨äººèƒ½å¤Ÿå®Œæˆè‡ªç„¶è¯­è¨€æŒ‡å®šçš„å¤æ‚ä»»åŠ¡ã€‚å°½ç®¡å–å¾—äº†è¿™äº›æˆåŠŸï¼Œä½†ç”±äºç¼ºä¹å¤§è§„æ¨¡æ¼”ç¤ºã€æ— äººæœºç¨³å®šæ§åˆ¶çš„å®æ—¶éœ€æ±‚ä»¥åŠå¯é çš„å¤–éƒ¨å§¿æ€ä¼°è®¡æ¨¡å—çš„ç¼ºå¤±ï¼Œå¼€æ”¾è¯æ±‡çš„è‡ªä¸»æ— äººæœºå¯¼èˆªä»ç„¶æ˜¯ä¸€ä¸ªæœªè§£å†³çš„æŒ‘æˆ˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†SINGERï¼Œä¸€ç§ä»…ä½¿ç”¨æœºè½½ä¼ æ„Ÿå™¨å’Œè®¡ç®—è®¾å¤‡è¿›è¡Œå¼€æ”¾ä¸–ç•Œè¯­è¨€æŒ‡å¯¼çš„è‡ªä¸»æ— äººæœºå¯¼èˆªçš„æ–¹æ³•ã€‚ä¸ºäº†è®­ç»ƒç¨³å¥çš„å¼€æ”¾è¯æ±‡å¯¼èˆªç­–ç•¥ï¼ŒSINGERåˆ©ç”¨ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šï¼ˆiï¼‰ä½¿ç”¨é«˜æ–¯æ‹¼è´´æ³•ç”Ÿæˆé«˜æ•ˆæ•°æ®çš„é€¼çœŸçš„è¯­è¨€åµŒå…¥é£è¡Œæ¨¡æ‹Ÿå™¨ï¼Œå…¶æ¨¡æ‹Ÿä¸ç°å®çš„å·®è·æœ€å°åŒ–ï¼›ï¼ˆiiï¼‰ä¸€ç§å—RRTå¯å‘çš„å¤šè½¨è¿¹ç”Ÿæˆä¸“å®¶ï¼Œç”¨äºå®ç°æ— ç¢°æ’å¯¼èˆªæ¼”ç¤ºï¼›è¿™äº›è¢«ç”¨æ¥è®­ç»ƒï¼ˆiiiï¼‰ä¸€ä¸ªè½»é‡çº§çš„ç«¯åˆ°ç«¯è§†è§‰è¿åŠ¨ç­–ç•¥ï¼Œç”¨äºå®æ—¶é—­ç¯æ§åˆ¶ã€‚é€šè¿‡å¤§é‡çš„ç¡¬ä»¶é£è¡Œå®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„ç­–ç•¥åœ¨æœªè§è¿‡çš„ç¯å¢ƒå’Œæœªè§è¿‡çš„è¯­è¨€æ¡ä»¶ç›®æ ‡å¯¹è±¡ä¸Šçš„é›¶æ ·æœ¬æ¨¡æ‹Ÿåˆ°ç°å®è½¬ç§»ä¼˜è¶Šæ€§ã€‚å½“åœ¨çº¦70ä¸‡è‡³1ç™¾ä¸‡çš„è¯­è¨€æ¡ä»¶è§†è§‰è¿åŠ¨æ•°æ®è§‚å¯ŸåŠ¨ä½œå¯¹ä¸Šè®­ç»ƒï¼Œå¹¶éƒ¨ç½²åœ¨ç¡¬ä»¶ä¸Šï¼ŒSINGERçš„è¡¨ç°ä¼˜äºé€Ÿåº¦æ§åˆ¶çš„è¯­ä¹‰æŒ‡å¯¼åŸºå‡†ï¼Œå¹³å‡åˆ°è¾¾æŸ¥è¯¢ç›®æ ‡çš„æ¬¡æ•°é«˜å‡º23.33%ï¼Œå¹³å‡ä¿æŒæŸ¥è¯¢ç›®æ ‡åœ¨è§†é‡ä¸­çš„æ—¶é—´é«˜å‡º16.67%ï¼Œç¢°æ’æ¬¡æ•°å‡å°‘äº†10%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18610v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åˆ©ç”¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹å®ç°æ— äººæœºè‡ªä¸»å¯¼èˆªçš„æ–°è¿›å±•ã€‚é€šè¿‡ä½¿ç”¨ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šçœŸå®è¯­è¨€åµŒå…¥é£è¡Œæ¨¡æ‹Ÿå™¨ã€åŸºäºRRTçš„å¤šè½¨è¿¹ç”Ÿæˆä¸“å®¶ä»¥åŠè½»é‡çº§ç«¯åˆ°ç«¯è§†è§‰è¿åŠ¨ç­–ç•¥ï¼Œå®ç°äº†é›¶æ ·æœ¬æ¨¡æ‹Ÿåˆ°çœŸå®ç¯å¢ƒçš„è¿ç§»ï¼Œå¹¶åœ¨ç¡¬ä»¶é£è¡Œå®éªŒä¸­å±•ç°å‡ºå“è¶Šæ€§èƒ½ã€‚è¯¥ç­–ç•¥åœ¨æœªçŸ¥ç¯å¢ƒå’ŒæœªçŸ¥è¯­è¨€ç›®æ ‡å¯¹è±¡ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œæé«˜äº†ç›®æ ‡åˆ°è¾¾ç‡å’Œè§†é‡ä¿æŒç‡ï¼Œå¹¶å‡å°‘äº†ç¢°æ’ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹æ¨åŠ¨äº†å¼€æ”¾è¯æ±‡æœºå™¨äººç­–ç•¥çš„æ˜¾è‘—è¿›æ­¥ã€‚</li>
<li>å¼€æ”¾ä¸–ç•Œä¸­çš„æ— äººæœºè‡ªä¸»å¯¼èˆªä»æ˜¯æŒ‘æˆ˜ï¼Œå› ä¸ºç¼ºä¹å¤§è§„æ¨¡æ¼”ç¤ºã€å®æ—¶æ§åˆ¶éœ€æ±‚å’Œå¯é çš„å¤–éƒ¨å§¿æ€ä¼°è®¡æ¨¡å—ã€‚</li>
<li>SINGERé€šè¿‡ä½¿ç”¨çœŸå®è¯­è¨€åµŒå…¥é£è¡Œæ¨¡æ‹Ÿå™¨è§£å†³æ— äººæœºå¯¼èˆªé—®é¢˜ï¼Œå…·å¤‡é²æ£’æ€§å’Œå¼€æ”¾è¯æ±‡å¯¼èˆªç­–ç•¥ã€‚</li>
<li>è¯¥æ¨¡æ‹Ÿå™¨åˆ©ç”¨é«˜æ–¯æ–‘ç‚¹æ³•é«˜æ•ˆç”Ÿæˆæ•°æ®ï¼Œå‡å°‘æ¨¡æ‹Ÿä¸ç°å®çš„å·®è·ã€‚</li>
<li>ä½¿ç”¨åŸºäºRRTçš„å¤šè½¨è¿¹ç”Ÿæˆä¸“å®¶ä¸ºæ— ç¢°æ’å¯¼èˆªæä¾›æ¼”ç¤ºã€‚</li>
<li>è®­ç»ƒè½»é‡çº§ç«¯åˆ°ç«¯è§†è§‰è¿åŠ¨ç­–ç•¥ç”¨äºå®æ—¶é—­ç¯æ§åˆ¶ã€‚</li>
<li>åœ¨ç¡¬ä»¶é£è¡Œå®éªŒä¸­ï¼ŒSINGERç­–ç•¥è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä¼˜äºé€Ÿåº¦æ§åˆ¶çš„è¯­ä¹‰æŒ‡å¯¼åŸºçº¿ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18610">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5cb01b03d4790ca3464f91cf3d544cd7" align="middle">
<img src="https://picx.zhimg.com/v2-4148faccd160cb1517697105849c8c45" align="middle">
<img src="https://picx.zhimg.com/v2-b3ee31c2586d4ab2a0ef8285c9ac6587" align="middle">
<img src="https://picx.zhimg.com/v2-098a3be45cb3842ab800ed89eb7a9f12" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Event-guided-3D-Gaussian-Splatting-for-Dynamic-Human-and-Scene-Reconstruction"><a href="#Event-guided-3D-Gaussian-Splatting-for-Dynamic-Human-and-Scene-Reconstruction" class="headerlink" title="Event-guided 3D Gaussian Splatting for Dynamic Human and Scene   Reconstruction"></a>Event-guided 3D Gaussian Splatting for Dynamic Human and Scene   Reconstruction</h2><p><strong>Authors:Xiaoting Yin, Hao Shi, Kailun Yang, Jiajun Zhai, Shangwei Guo, Lin Wang, Kaiwei Wang</strong></p>
<p>Reconstructing dynamic humans together with static scenes from monocular videos remains difficult, especially under fast motion, where RGB frames suffer from motion blur. Event cameras exhibit distinct advantages, e.g., microsecond temporal resolution, making them a superior sensing choice for dynamic human reconstruction. Accordingly, we present a novel event-guided human-scene reconstruction framework that jointly models human and scene from a single monocular event camera via 3D Gaussian Splatting. Specifically, a unified set of 3D Gaussians carries a learnable semantic attribute; only Gaussians classified as human undergo deformation for animation, while scene Gaussians stay static. To combat blur, we propose an event-guided loss that matches simulated brightness changes between consecutive renderings with the event stream, improving local fidelity in fast-moving regions. Our approach removes the need for external human masks and simplifies managing separate Gaussian sets. On two benchmark datasets, ZJU-MoCap-Blur and MMHPSD-Blur, it delivers state-of-the-art human-scene reconstruction, with notable gains over strong baselines in PSNR&#x2F;SSIM and reduced LPIPS, especially for high-speed subjects. </p>
<blockquote>
<p>ä»å•ç›®è§†é¢‘ä¸­é‡å»ºåŠ¨æ€äººä½“å’Œé™æ€åœºæ™¯ä»ç„¶å…·æœ‰ä¸€å®šçš„æŒ‘æˆ˜æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å¿«é€Ÿè¿åŠ¨æƒ…å†µä¸‹ï¼ŒRGBå¸§ä¼šå—åˆ°è¿åŠ¨æ¨¡ç³Šçš„å½±å“ã€‚äº‹ä»¶ç›¸æœºå…·æœ‰ç‹¬ç‰¹çš„ä¼˜åŠ¿ï¼Œä¾‹å¦‚å¾®ç§’çº§çš„æ—¶åºåˆ†è¾¨ç‡ï¼Œä½¿å…¶æˆä¸ºåŠ¨æ€äººä½“é‡å»ºçš„å‡ºè‰²æ„ŸçŸ¥é€‰æ‹©ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„äº‹ä»¶å¼•å¯¼äººä½“-åœºæ™¯é‡å»ºæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡3Dé«˜æ–¯å–·æ¶‚æŠ€æœ¯ï¼Œåˆ©ç”¨å•ä¸ªå•ç›®äº‹ä»¶ç›¸æœºå¯¹äººä½“å’Œåœºæ™¯è¿›è¡Œè”åˆå»ºæ¨¡ã€‚å…·ä½“æ¥è¯´ï¼Œä¸€ç»„ç»Ÿä¸€çš„3Dé«˜æ–¯æºå¸¦å¯å­¦ä¹ çš„è¯­ä¹‰å±æ€§ï¼›åªæœ‰è¢«åˆ†ç±»ä¸ºäººç±»çš„é«˜æ–¯æ‰ä¼šå‘ç”Ÿå˜å½¢ä»¥å®ç°åŠ¨ç”»æ•ˆæœï¼Œè€Œåœºæ™¯é«˜æ–¯ä¿æŒä¸å˜ã€‚ä¸ºäº†å¯¹æŠ—æ¨¡ç³Šï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§äº‹ä»¶å¼•å¯¼æŸå¤±ï¼Œè¯¥æŸå¤±åŒ¹é…è¿ç»­æ¸²æŸ“ä¹‹é—´çš„æ¨¡æ‹Ÿäº®åº¦å˜åŒ–ä¸äº‹ä»¶æµï¼Œæé«˜äº†å¿«é€Ÿç§»åŠ¨åŒºåŸŸçš„å±€éƒ¨ä¿çœŸåº¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ¶ˆé™¤äº†å¯¹å¤–éƒ¨äººä½“æ©è†œçš„éœ€æ±‚ï¼Œå¹¶ç®€åŒ–äº†å•ç‹¬ç®¡ç†é«˜æ–¯é›†çš„è¿‡ç¨‹ã€‚åœ¨ZJU-MoCap-Blurå’ŒMMHPSD-Blurä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šï¼Œå®ƒå®ç°äº†æœ€å…ˆè¿›çš„äººä½“-åœºæ™¯é‡å»ºï¼Œåœ¨PSNR&#x2F;SSIMä¸Šæœ‰æ˜¾è‘—çš„æ”¶ç›Šï¼Œå¹¶ä¸”é™ä½äº†LPIPSï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜é€Ÿä¸»é¢˜ä¸Šè¡¨ç°å°¤ä¸ºå‡ºè‰²ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18566v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºäº‹ä»¶å¼•å¯¼çš„äººç±»åœºæ™¯é‡å»ºæ¡†æ¶ï¼Œé€šè¿‡å•ç›®äº‹ä»¶ç›¸æœºå¯¹åŠ¨æ€äººç±»å’Œé™æ€åœºæ™¯è¿›è¡Œå»ºæ¨¡ã€‚é‡‡ç”¨åŠ¨æ€ä¸é™æ€çš„åˆ†ç¦»è¡¨ç¤ºæ–¹å¼ï¼Œå¹¶ç»“åˆä¸‰ç»´é«˜æ–¯å½¢æ€æ¨¡æ¿ï¼Œæå‡äº†åŠ¨æ€äººç±»åœºæ™¯é‡å»ºçš„å‡†ç¡®åº¦ã€‚æå‡ºçš„äº‹ä»¶å¼•å¯¼æŸå¤±å‡½æ•°å¯æœ‰æ•ˆè§£å†³å¿«é€Ÿè¿åŠ¨åŒºåŸŸä¸­çš„æ¨¡ç³Šé—®é¢˜ã€‚è¯¥æ–¹æ³•ç®€åŒ–äº†ä»»åŠ¡ï¼Œå‡å°‘äº†å•ç‹¬çš„é«˜æ–¯é›†ç®¡ç†ï¼Œå¹¶ä¸”åœ¨ZJU-MoCap-Blurå’ŒMMHPSD-Bluræ•°æ®é›†ä¸Šå®ç°äº†æœ€ä¼˜çš„é‡å»ºæ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨äº‹ä»¶ç›¸æœºçš„ä¼˜åŠ¿è¿›è¡ŒåŠ¨æ€äººç±»åœºæ™¯é‡å»ºã€‚</li>
<li>æå‡ºä¸€ç§æ–°é¢–çš„äº‹ä»¶å¼•å¯¼çš„äººç±»åœºæ™¯é‡å»ºæ¡†æ¶ï¼Œé€šè¿‡å•ä¸€äº‹ä»¶ç›¸æœºå¯¹äººå’Œåœºæ™¯è¿›è¡Œå»ºæ¨¡ã€‚</li>
<li>é‡‡ç”¨ä¸‰ç»´é«˜æ–¯å½¢æ€æ¨¡æ¿è¿›è¡ŒåŠ¨æ€ä¸é™æ€åˆ†ç¦»è¡¨ç¤ºï¼Œç®€åŒ–åŠ¨ç”»è¿‡ç¨‹å¹¶æå‡é‡å»ºç²¾åº¦ã€‚</li>
<li>ä¸ºè§£å†³å¿«é€Ÿè¿åŠ¨åŒºåŸŸçš„æ¨¡ç³Šé—®é¢˜ï¼Œå¼•å…¥äº‹ä»¶å¼•å¯¼çš„æŸå¤±å‡½æ•°ï¼Œé€šè¿‡åŒ¹é…è¿ç»­æ¸²æŸ“çš„äº®åº¦å˜åŒ–ä¸äº‹ä»¶æµå®ç°ã€‚</li>
<li>ä¸éœ€è¦å¤–éƒ¨äººç±»æ©è†œï¼Œç®€åŒ–äº†ç®¡ç†ç‹¬ç«‹é«˜æ–¯é›†çš„è¿‡ç¨‹ã€‚</li>
<li>åœ¨ä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†æœ€ä¼˜çš„é‡å»ºæ•ˆæœï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜é€Ÿè¿åŠ¨ä¸»ä½“ä¸Šè¡¨ç°çªå‡ºã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18566">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ed73fa86bb1f0115e2addba1200fd750" align="middle">
<img src="https://picx.zhimg.com/v2-d6f5c4fa428221af56bca01e4d84305b" align="middle">
<img src="https://picx.zhimg.com/v2-fe647ec9625d0d562d0f9163aa59abd1" align="middle">
<img src="https://picx.zhimg.com/v2-8555562a87e5ad40955df604045b9695" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="BridgeSplat-Bidirectionally-Coupled-CT-and-Non-Rigid-Gaussian-Splatting-for-Deformable-Intraoperative-Surgical-Navigation"><a href="#BridgeSplat-Bidirectionally-Coupled-CT-and-Non-Rigid-Gaussian-Splatting-for-Deformable-Intraoperative-Surgical-Navigation" class="headerlink" title="BridgeSplat: Bidirectionally Coupled CT and Non-Rigid Gaussian Splatting   for Deformable Intraoperative Surgical Navigation"></a>BridgeSplat: Bidirectionally Coupled CT and Non-Rigid Gaussian Splatting   for Deformable Intraoperative Surgical Navigation</h2><p><strong>Authors:Maximilian Fehrentz, Alexander Winkler, Thomas Heiliger, Nazim Haouchine, Christian Heiliger, Nassir Navab</strong></p>
<p>We introduce BridgeSplat, a novel approach for deformable surgical navigation that couples intraoperative 3D reconstruction with preoperative CT data to bridge the gap between surgical video and volumetric patient data. Our method rigs 3D Gaussians to a CT mesh, enabling joint optimization of Gaussian parameters and mesh deformation through photometric supervision. By parametrizing each Gaussian relative to its parent mesh triangle, we enforce alignment between Gaussians and mesh and obtain deformations that can be propagated back to update the CT. We demonstrate BridgeSplatâ€™s effectiveness on visceral pig surgeries and synthetic data of a human liver under simulation, showing sensible deformations of the preoperative CT on monocular RGB data. Code, data, and additional resources can be found at <a target="_blank" rel="noopener" href="https://maxfehrentz.github.io/ct-informed-splatting/">https://maxfehrentz.github.io/ct-informed-splatting/</a> . </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†BridgeSplatï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å˜å½¢æ‰‹æœ¯å¯¼èˆªæ–¹æ³•ã€‚å®ƒå°†æœ¯ä¸­3Dé‡å»ºä¸æœ¯å‰CTæ•°æ®ç›¸ç»“åˆï¼Œä»¥å¼¥æ‰‹æœ¯è§†é¢‘å’Œæ‚£è€…ä½“ç§¯æ•°æ®ä¹‹é—´çš„é¸¿æ²Ÿã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†3Dé«˜æ–¯æ˜ å°„åˆ°CTç½‘æ ¼ä¸Šï¼Œé€šè¿‡å…‰åº¦ç›‘ç£å®ç°é«˜æ–¯å‚æ•°å’Œç½‘æ ¼å˜å½¢çš„è”åˆä¼˜åŒ–ã€‚é€šè¿‡å°†æ¯ä¸ªé«˜æ–¯ç›¸å¯¹äºå…¶çˆ¶ç½‘æ ¼ä¸‰è§’å½¢è¿›è¡Œå‚æ•°åŒ–ï¼Œæˆ‘ä»¬å¼ºåˆ¶é«˜æ–¯å’Œç½‘æ ¼ä¹‹é—´çš„å¯¹é½ï¼Œå¹¶è·å–å¯ä»¥ä¼ æ’­å›ä»¥æ›´æ–°CTçš„å˜å½¢ã€‚æˆ‘ä»¬åœ¨æ¨¡æ‹Ÿçš„çŒªå†…è„æ‰‹æœ¯å’Œæ¨¡æ‹Ÿçš„äººç±»è‚è„åˆæˆæ•°æ®ä¸Šå±•ç¤ºäº†BridgeSplatçš„æœ‰æ•ˆæ€§ï¼Œåœ¨å•ç›®RGBæ•°æ®ä¸Šæ˜¾ç¤ºå‡ºæœ¯å‰CTçš„æ•æ„Ÿå˜å½¢ã€‚ä»£ç ã€æ•°æ®å’Œé™„åŠ èµ„æºå¯ä»¥åœ¨<a target="_blank" rel="noopener" href="https://maxfehrentz.github.io/ct-informed-splatting/%E6%89%BE%E5%88%B0%E3%80%82">https://maxfehrentz.github.io/ct-informed-splatting/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18501v1">PDF</a> Accepted at MICCAI 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†BridgeSplatè¿™ä¸€æ–°å‹çš„å¯å˜å½¢æ‰‹æœ¯å¯¼èˆªæŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯ç»“åˆäº†æœ¯ä¸­ä¸‰ç»´é‡å»ºä¸æœ¯å‰CTæ•°æ®ï¼Œä»è€Œæ‹‰è¿‘æ‰‹æœ¯è§†é¢‘ä¸ç—…äººä¸‰ç»´ä½“ç§¯æ•°æ®ä¹‹é—´çš„è·ç¦»ã€‚BridgeSplatå°†3Dé«˜æ–¯åº”ç”¨äºCTç½‘æ ¼ä¸Šï¼Œä½¿å¾—å¯ä»¥é€šè¿‡å…‰å…‰åº¦ç›‘æ§åŒæ—¶ä¼˜åŒ–é«˜æ–¯å‚æ•°å’Œç½‘æ ¼å˜å½¢ã€‚é€šè¿‡ç›¸å¯¹å…¶æ¯ç½‘æ ¼ä¸‰è§’å½¢å‚æ•°åŒ–æ¯ä¸ªé«˜æ–¯ï¼Œç¡®ä¿äº†é«˜æ–¯ä¸ç½‘æ ¼ä¹‹é—´çš„å¯¹é½ï¼Œä»è€Œå–å¾—èƒ½å›æº¯è‡³CTæ›´æ–°çš„å˜å½¢æ•ˆæœã€‚è¯¥æ–¹æ³•å¯¹çŒªçš„è…¹è…”å†…æ‰‹æœ¯åŠæ¨¡æ‹Ÿæ¡ä»¶ä¸‹çš„äººä½“è‚è„åˆæˆæ•°æ®æœ‰å¾ˆå¥½çš„åº”ç”¨æ•ˆæœï¼Œè¯æ˜å¯ä»¥åœ¨å•è‰²RGBæ•°æ®ä¸Šå¯¹æœ¯å‰CTè¿›è¡Œæœ‰æ•ˆå˜å½¢å¤„ç†ã€‚æœ‰å…³ä»£ç ã€æ•°æ®å’Œé¢å¤–èµ„æºå¯ä»¥åœ¨ç½‘ç«™ä¸ŠæŸ¥é˜…ï¼ˆé“¾æ¥å·²æä¾›ï¼‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹æ˜¯æ–‡æœ¬ä¸­çš„å…³é”®è¦ç‚¹ï¼š</p>
<ul>
<li>BridgeSplatæ˜¯ä¸€ç§æ–°å‹çš„å¯å˜å½¢æ‰‹æœ¯å¯¼èˆªæŠ€æœ¯ã€‚</li>
<li>è¯¥æŠ€æœ¯ç»“åˆäº†æœ¯ä¸­ä¸‰ç»´é‡å»ºä¸æœ¯å‰CTæ•°æ®ï¼Œç”¨äºæé«˜æ‰‹æœ¯è¿‡ç¨‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>BridgeSplaté‡‡ç”¨çš„é«˜æ–¯ä¼˜åŒ–æ–¹æ³•ä½¿å¾—åœ¨æ‰‹æœ¯è¿‡ç¨‹ä¸­èƒ½åŒæ—¶ä¼˜åŒ–é«˜æ–¯å‚æ•°å’Œç½‘æ ¼å˜å½¢ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18501">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9faf73a090769f59a4e112d7fbe0e9c9" align="middle">
<img src="https://picx.zhimg.com/v2-1053d17b5bb91c9f6fc1a5f32fa461dd" align="middle">
<img src="https://picx.zhimg.com/v2-f128e5417567fb019b885b5c9534bf75" align="middle">
<img src="https://picx.zhimg.com/v2-8c92f9b2a746b5f57277a8234cb4130a" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="EmbodiedSplat-Personalized-Real-to-Sim-to-Real-Navigation-with-Gaussian-Splats-from-a-Mobile-Device"><a href="#EmbodiedSplat-Personalized-Real-to-Sim-to-Real-Navigation-with-Gaussian-Splats-from-a-Mobile-Device" class="headerlink" title="EmbodiedSplat: Personalized Real-to-Sim-to-Real Navigation with Gaussian   Splats from a Mobile Device"></a>EmbodiedSplat: Personalized Real-to-Sim-to-Real Navigation with Gaussian   Splats from a Mobile Device</h2><p><strong>Authors:Gunjan Chhablani, Xiaomeng Ye, Muhammad Zubair Irshad, Zsolt Kira</strong></p>
<p>The field of Embodied AI predominantly relies on simulation for training and evaluation, often using either fully synthetic environments that lack photorealism or high-fidelity real-world reconstructions captured with expensive hardware. As a result, sim-to-real transfer remains a major challenge. In this paper, we introduce EmbodiedSplat, a novel approach that personalizes policy training by efficiently capturing the deployment environment and fine-tuning policies within the reconstructed scenes. Our method leverages 3D Gaussian Splatting (GS) and the Habitat-Sim simulator to bridge the gap between realistic scene capture and effective training environments. Using iPhone-captured deployment scenes, we reconstruct meshes via GS, enabling training in settings that closely approximate real-world conditions. We conduct a comprehensive analysis of training strategies, pre-training datasets, and mesh reconstruction techniques, evaluating their impact on sim-to-real predictivity in real-world scenarios. Experimental results demonstrate that agents fine-tuned with EmbodiedSplat outperform both zero-shot baselines pre-trained on large-scale real-world datasets (HM3D) and synthetically generated datasets (HSSD), achieving absolute success rate improvements of 20% and 40% on real-world Image Navigation task. Moreover, our approach yields a high sim-vs-real correlation (0.87-0.97) for the reconstructed meshes, underscoring its effectiveness in adapting policies to diverse environments with minimal effort. Project page: <a target="_blank" rel="noopener" href="https://gchhablani.github.io/embodied-splat">https://gchhablani.github.io/embodied-splat</a>. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½å®ä½“é¢†åŸŸä¸»è¦ä¾èµ–æ¨¡æ‹Ÿè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼Œé€šå¸¸ä½¿ç”¨ç¼ºä¹é€¼çœŸæ„Ÿçš„å…¨åˆæˆç¯å¢ƒæˆ–ä½¿ç”¨æ˜‚è´µçš„ç¡¬ä»¶æ•æ‰çš„é«˜ä¿çœŸç°å®ä¸–ç•Œé‡å»ºã€‚å› æ­¤ï¼Œæ¨¡æ‹Ÿåˆ°ç°å®çš„è½¬ç§»ä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†EmbodiedSplatï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡é«˜æ•ˆæ•è·éƒ¨ç½²ç¯å¢ƒå¹¶åœ¨é‡å»ºåœºæ™¯ä¸­å¯¹ç­–ç•¥è¿›è¡Œå¾®è°ƒæ¥ä¸ªæ€§åŒ–ç­–ç•¥è®­ç»ƒçš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨3Dé«˜æ–¯å–·ç»˜ï¼ˆGSï¼‰å’Œ Habitat-Simæ¨¡æ‹Ÿå™¨æ¥å¼¥åˆç°å®åœºæ™¯æ•æ‰å’Œæœ‰æ•ˆè®­ç»ƒç¯å¢ƒä¹‹é—´çš„å·®è·ã€‚æˆ‘ä»¬ä½¿ç”¨iPhoneæ•è·çš„éƒ¨ç½²åœºæ™¯ï¼Œé€šè¿‡GSé‡å»ºç½‘æ ¼ï¼Œèƒ½å¤Ÿåœ¨æ¥è¿‘çœŸå®ä¸–ç•Œæ¡ä»¶çš„è®¾ç½®ä¸­è¿›è¡ŒåŸ¹è®­ã€‚æˆ‘ä»¬å¯¹è®­ç»ƒç­–ç•¥ã€é¢„è®­ç»ƒæ•°æ®é›†å’Œç½‘æ ¼é‡å»ºæŠ€æœ¯è¿›è¡Œäº†ç»¼åˆåˆ†æï¼Œè¯„ä¼°äº†å®ƒä»¬åœ¨ç°å®åœºæ™¯ä¸­æ¨¡æ‹Ÿåˆ°ç°å®çš„é¢„æµ‹èƒ½åŠ›çš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨EmbodiedSplatè¿›è¡Œå¾®è°ƒçš„ä»£ç†åœ¨çœŸå®ä¸–ç•Œçš„å›¾åƒå¯¼èˆªä»»åŠ¡ä¸Šä¼˜äºé›¶åŸºå‡†é¢„è®­ç»ƒçš„å¤§å‹ç°å®ä¸–ç•Œæ•°æ®é›†ï¼ˆHM3Dï¼‰å’Œåˆæˆæ•°æ®é›†ï¼ˆHSSDï¼‰ï¼ŒæˆåŠŸç‡æé«˜äº†20%å’Œ40%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯¹é‡å»ºç½‘æ ¼çš„æ¨¡æ‹Ÿä¸çœŸå®ç›¸å…³æ€§é«˜è¾¾0.87-0.97ï¼Œçªæ˜¾äº†å…¶åœ¨é€‚åº”å„ç§ç¯å¢ƒå¹¶æœ€å°åŒ–åŠªåŠ›è°ƒæ•´ç­–ç•¥æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://gchhablani.github.io/embodied-splat%E3%80%82">https://gchhablani.github.io/embodied-splatã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17430v2">PDF</a> 16 pages, 18 figures, paper accepted at ICCV, 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºEmbodiedSplatçš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡é«˜æ•ˆæ•æ‰éƒ¨ç½²ç¯å¢ƒå¹¶å¯¹æ”¿ç­–è¿›è¡Œå¾®è°ƒï¼Œè§£å†³äº†æ¨¡æ‹Ÿåˆ°ç°å®çš„è½¬ç§»é—®é¢˜ã€‚è¯¥æ–¹æ³•åˆ©ç”¨3Dé«˜æ–¯æ¶‚æ•·ï¼ˆGSï¼‰å’Œæ –æ¯åœ°æ¨¡æ‹Ÿå™¨ï¼Œç¼©å°äº†çœŸå®åœºæ™¯æ•æ‰å’Œæœ‰æ•ˆè®­ç»ƒç¯å¢ƒä¹‹é—´çš„å·®è·ã€‚é€šè¿‡iPhoneæ•æ‰çš„éƒ¨ç½²åœºæ™¯è¿›è¡Œç½‘æ ¼é‡å»ºï¼Œä½¿è®­ç»ƒç¯å¢ƒæ›´è´´è¿‘çœŸå®ä¸–ç•Œæ¡ä»¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨EmbodiedSplatè¿›è¡Œå¾®è°ƒçš„ä»£ç†åœ¨ç°å®ä¸–ç•Œå›¾åƒå¯¼èˆªä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºé¢„è®­ç»ƒçš„å¤§å‹ç°å®ä¸–ç•Œæ•°æ®é›†å’Œåˆæˆæ•°æ®é›†ï¼ŒæˆåŠŸç‡æé«˜äº†20%å’Œ40%ã€‚è¯¥æ–¹æ³•è¿˜å®ç°äº†é«˜æ¨¡æ‹Ÿä¸çœŸå®ç›¸å…³æ€§ï¼Œè¡¨æ˜å…¶é€‚åº”ä¸åŒç¯å¢ƒå¹¶æœ€å°åŒ–åŠªåŠ›è°ƒæ•´æ”¿ç­–çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>EmbodiedSplatæ–¹æ³•ä¸ªæ€§åŒ–æ”¿ç­–è®­ç»ƒï¼Œé€šè¿‡æ•æ‰éƒ¨ç½²ç¯å¢ƒå¹¶å¾®è°ƒæ”¿ç­–ï¼Œè§£å†³æ¨¡æ‹Ÿåˆ°ç°å®çš„è½¬ç§»é—®é¢˜ã€‚</li>
<li>åˆ©ç”¨3Dé«˜æ–¯æ¶‚æ•·ï¼ˆGSï¼‰å’Œæ –æ¯åœ°æ¨¡æ‹Ÿå™¨ï¼Œå®ç°çœŸå®åœºæ™¯æ•æ‰å’Œè®­ç»ƒç¯å¢ƒä¹‹é—´çš„æ¡¥æ¢ã€‚</li>
<li>é€šè¿‡iPhoneæ•æ‰çš„éƒ¨ç½²åœºæ™¯è¿›è¡Œç½‘æ ¼é‡å»ºï¼Œä½¿è®­ç»ƒæ›´æ¥è¿‘çœŸå®ä¸–ç•Œæ¡ä»¶ã€‚</li>
<li>å…¨é¢çš„ç­–ç•¥åˆ†æï¼ŒåŒ…æ‹¬è®­ç»ƒç­–ç•¥ã€é¢„è®­ç»ƒæ•°æ®é›†å’Œç½‘æ ¼é‡å»ºæŠ€æœ¯ï¼Œå¯¹æ¨¡æ‹Ÿåˆ°ç°å®çš„é¢„æµ‹èƒ½åŠ›è¿›è¡Œè¯„ä¼°ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨EmbodiedSplatçš„ä»£ç†åœ¨ç°å®ä¸–ç•Œä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æ–¹æ³•ï¼ŒæˆåŠŸç‡æ˜¾è‘—æé«˜ã€‚</li>
<li>EmbodiedSplatæ–¹æ³•å®ç°äº†é«˜æ¨¡æ‹Ÿä¸çœŸå®çš„ç›¸å…³æ€§ï¼Œè¡¨æ˜å…¶é€‚åº”å„ç§ç¯å¢ƒçš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17430">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-240d926c05b977ef3e92d5492f1f6d09" align="middle">
<img src="https://picx.zhimg.com/v2-b884f6399ce1b4d179e260a58c79e304" align="middle">
<img src="https://picx.zhimg.com/v2-11f758a15307d54bd9e799151836f869" align="middle">
<img src="https://picx.zhimg.com/v2-f18b57bac1e1ef3d71e774964df448f2" align="middle">
<img src="https://picx.zhimg.com/v2-b8a6c602d7ec0706dbcf6f29b2c07aa1" align="middle">
<img src="https://picx.zhimg.com/v2-62cfcbefc4801fb0a4af2f1a4f9ddfb6" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="HyRF-Hybrid-Radiance-Fields-for-Memory-efficient-and-High-quality-Novel-View-Synthesis"><a href="#HyRF-Hybrid-Radiance-Fields-for-Memory-efficient-and-High-quality-Novel-View-Synthesis" class="headerlink" title="HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel   View Synthesis"></a>HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel   View Synthesis</h2><p><strong>Authors:Zipeng Wang, Dan Xu</strong></p>
<p>Recently, 3D Gaussian Splatting (3DGS) has emerged as a powerful alternative to NeRF-based approaches, enabling real-time, high-quality novel view synthesis through explicit, optimizable 3D Gaussians. However, 3DGS suffers from significant memory overhead due to its reliance on per-Gaussian parameters to model view-dependent effects and anisotropic shapes. While recent works propose compressing 3DGS with neural fields, these methods struggle to capture high-frequency spatial variations in Gaussian properties, leading to degraded reconstruction of fine details. We present Hybrid Radiance Fields (HyRF), a novel scene representation that combines the strengths of explicit Gaussians and neural fields. HyRF decomposes the scene into (1) a compact set of explicit Gaussians storing only critical high-frequency parameters and (2) grid-based neural fields that predict remaining properties. To enhance representational capacity, we introduce a decoupled neural field architecture, separately modeling geometry (scale, opacity, rotation) and view-dependent color. Additionally, we propose a hybrid rendering scheme that composites Gaussian splatting with a neural field-predicted background, addressing limitations in distant scene representation. Experiments demonstrate that HyRF achieves state-of-the-art rendering quality while reducing model size by over 20 times compared to 3DGS and maintaining real-time performance. Our project page is available at <a target="_blank" rel="noopener" href="https://wzpscott.github.io/hyrf/">https://wzpscott.github.io/hyrf/</a>. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œ3Dé«˜æ–¯æ‰©å±•ï¼ˆ3DGSï¼‰ä½œä¸ºä¸€ç§å¼ºå¤§çš„æ›¿ä»£NeRFçš„æ–¹æ³•å‡ºç°ï¼Œå®ƒé€šè¿‡æ˜ç¡®çš„ã€å¯ä¼˜åŒ–çš„3Dé«˜æ–¯å®ç°å®æ—¶é«˜è´¨é‡çš„æ–°è§†è§’åˆæˆã€‚ç„¶è€Œï¼Œç”±äº3DGSä¾èµ–äºé«˜æ–¯å‚æ•°æ¥æ¨¡æ‹Ÿè§†è§’ç›¸å…³çš„æ•ˆæœå’Œå„å‘å¼‚æ€§å½¢çŠ¶ï¼Œå› æ­¤å­˜åœ¨è¾ƒå¤§çš„å†…å­˜å¼€é”€ã€‚è™½ç„¶æœ€è¿‘çš„å·¥ä½œæå‡ºä½¿ç”¨ç¥ç»ç½‘ç»œå¯¹3DGSè¿›è¡Œå‹ç¼©ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨æ•è·é«˜æ–¯å±æ€§çš„é«˜é¢‘ç©ºé—´å˜åŒ–æ–¹é¢è¡¨ç°è¾ƒå·®ï¼Œå¯¼è‡´ç²¾ç»†ç»†èŠ‚çš„é‡å»ºé€€åŒ–ã€‚æˆ‘ä»¬æå‡ºäº†æ··åˆè¾å°„åœºï¼ˆHyRFï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆæ˜¾å¼é«˜æ–¯å’Œç¥ç»ç½‘ç»œä¼˜ç‚¹çš„æ–°å‹åœºæ™¯è¡¨ç¤ºæ–¹æ³•ã€‚HyRFå°†åœºæ™¯åˆ†è§£ä¸ºï¼ˆ1ï¼‰ä¸€ç»„ç´§å‡‘çš„æ˜¾å¼é«˜æ–¯ï¼Œä»…å­˜å‚¨å…³é”®çš„é«˜é¢‘å‚æ•°ï¼Œï¼ˆ2ï¼‰åŸºäºç½‘æ ¼çš„ç¥ç»ç½‘ç»œåœºï¼Œé¢„æµ‹å…¶ä½™å±æ€§ã€‚ä¸ºäº†å¢å¼ºè¡¨ç¤ºèƒ½åŠ›ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåˆ†ç¦»çš„ç¥ç»ç½‘ç»œä½“ç³»ç»“æ„ï¼Œåˆ†åˆ«æ¨¡æ‹Ÿå‡ ä½•ï¼ˆå°ºåº¦ã€ä¸é€æ˜åº¦ã€æ—‹è½¬ï¼‰å’Œè§†è§’ç›¸å…³çš„é¢œè‰²ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆæ¸²æŸ“æ–¹æ¡ˆï¼Œå°†é«˜æ–¯æ‰©å±•ä¸ç¥ç»ç½‘ç»œé¢„æµ‹çš„èƒŒæ™¯è¿›è¡Œç»„åˆï¼Œè§£å†³è¿œè·ç¦»åœºæ™¯è¡¨ç¤ºçš„å±€é™æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒHyRFåœ¨è¾¾åˆ°æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡çš„åŒæ—¶ï¼Œä¸3DGSç›¸æ¯”å°†æ¨¡å‹å¤§å°ç¼©å°äº†è¶…è¿‡20å€ï¼Œå¹¶ä¿æŒå®æ—¶æ€§èƒ½ã€‚æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢å¯åœ¨<a target="_blank" rel="noopener" href="https://wzpscott.github.io/hyrf/%E6%89%BE%E5%88%B0%E3%80%82">https://wzpscott.github.io/hyrf/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17083v2">PDF</a> Accepted at NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Hybrid Radiance Fieldsï¼ˆHyRFï¼‰æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯ç»“åˆäº†æ˜¾å¼é«˜æ–¯å’Œç¥ç»åœºçš„ä¼˜ç‚¹ï¼Œç”¨äºå®æ—¶é«˜è´¨é‡çš„æ–°å‹è§†å›¾åˆæˆã€‚é’ˆå¯¹ç°æœ‰æŠ€æœ¯çš„å†…å­˜å¼€é”€å¤§å’Œå¯¹é«˜é¢‘ç©ºé—´å˜åŒ–æ•æ‰èƒ½åŠ›å¼±çš„é—®é¢˜ï¼ŒHyRFé€šè¿‡åˆ†è§£åœºæ™¯ä¸ºå…³é”®çš„é«˜é¢‘å‚æ•°æ˜¾å¼é«˜æ–¯å’ŒåŸºäºç½‘æ ¼çš„ç¥ç»åœºè¿›è¡Œé¢„æµ‹æ¥è§£å†³ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†å»è€¦çš„ç¥ç»åœºæ¶æ„å’Œæ··åˆæ¸²æŸ“æ–¹æ¡ˆï¼Œä»¥æé«˜è¡¨ç°åŠ›å’Œè§£å†³è¿œè·ç¦»åœºæ™¯è¡¨ç¤ºçš„é™åˆ¶ã€‚å®éªŒè¡¨æ˜ï¼ŒHyRFè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ï¼ŒåŒæ—¶æ¨¡å‹å¤§å°å‡å°‘äº†è¶…è¿‡20å€ï¼Œä¸”ä¿æŒäº†å®æ—¶æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3DGSå·²æˆä¸ºNeRFåŸºæ–¹æ³•çš„å¼ºå¤§æ›¿ä»£æ–¹æ¡ˆï¼Œå¯å®ç°å®æ—¶é«˜è´¨é‡çš„æ–°å‹è§†å›¾åˆæˆã€‚</li>
<li>3DGSå­˜åœ¨å†…å­˜å¼€é”€å¤§çš„é—®é¢˜ï¼Œä¾èµ–äºé«˜æ–¯å‚æ•°æ¨¡æ‹Ÿè§†å›¾ç›¸å…³æ•ˆåº”å’Œå½¢çŠ¶ã€‚</li>
<li>ç°æœ‰å‹ç¼©æ–¹æ³•éš¾ä»¥æ•æ‰é«˜æ–¯å±æ€§çš„é«˜é¢‘ç©ºé—´å˜åŒ–ï¼Œå¯¼è‡´ç²¾ç»†ç»†èŠ‚é‡å»ºé€€åŒ–ã€‚</li>
<li>HyRFç»“åˆäº†æ˜¾å¼é«˜æ–¯å’Œç¥ç»åœºçš„ä¼˜ç‚¹ï¼Œåˆ†è§£åœºæ™¯ä¸ºé«˜é¢‘å‚æ•°æ˜¾å¼é«˜æ–¯å’ŒåŸºäºç½‘æ ¼çš„ç¥ç»åœºé¢„æµ‹ã€‚</li>
<li>å¼•å…¥å»è€¦çš„ç¥ç»åœºæ¶æ„ï¼Œåˆ†åˆ«æ¨¡æ‹Ÿå‡ ä½•å’Œè§†å›¾ç›¸å…³é¢œè‰²ï¼Œæé«˜è¡¨ç°åŠ›ã€‚</li>
<li>æå‡ºæ··åˆæ¸²æŸ“æ–¹æ¡ˆï¼Œè§£å†³è¿œè·ç¦»åœºæ™¯è¡¨ç¤ºçš„é™åˆ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17083">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e6de2c14c3fada49ecef3df765ff1dbc" align="middle">
<img src="https://picx.zhimg.com/v2-d02592ac4473bc388a274f9989394a3d" align="middle">
<img src="https://picx.zhimg.com/v2-4a83be3a634fed56dd535ea757c0b253" align="middle">
<img src="https://picx.zhimg.com/v2-7a871bfd24a47a759cf52edeebb5c8d6" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="MEGS-2-Memory-Efficient-Gaussian-Splatting-via-Spherical-Gaussians-and-Unified-Pruning"><a href="#MEGS-2-Memory-Efficient-Gaussian-Splatting-via-Spherical-Gaussians-and-Unified-Pruning" class="headerlink" title="MEGS$^{2}$: Memory-Efficient Gaussian Splatting via Spherical Gaussians   and Unified Pruning"></a>MEGS$^{2}$: Memory-Efficient Gaussian Splatting via Spherical Gaussians   and Unified Pruning</h2><p><strong>Authors:Jiarui Chen, Yikeng Chen, Yingshuang Zou, Ye Huang, Peng Wang, Yuan Liu, Yujing Sun, Wenping Wang</strong></p>
<p>3D Gaussian Splatting (3DGS) has emerged as a dominant novel-view synthesis technique, but its high memory consumption severely limits its applicability on edge devices. A growing number of 3DGS compression methods have been proposed to make 3DGS more efficient, yet most only focus on storage compression and fail to address the critical bottleneck of rendering memory. To address this problem, we introduce MEGS$^{2}$, a novel memory-efficient framework that tackles this challenge by jointly optimizing two key factors: the total primitive number and the parameters per primitive, achieving unprecedented memory compression. Specifically, we replace the memory-intensive spherical harmonics with lightweight, arbitrarily oriented spherical Gaussian lobes as our color representations. More importantly, we propose a unified soft pruning framework that models primitive-number and lobe-number pruning as a single constrained optimization problem. Experiments show that MEGS$^{2}$ achieves a 50% static VRAM reduction and a 40% rendering VRAM reduction compared to existing methods, while maintaining comparable rendering quality. Project page: <a target="_blank" rel="noopener" href="https://megs-2.github.io/">https://megs-2.github.io/</a> </p>
<blockquote>
<p>3Dé«˜æ–¯å»¶å±•ï¼ˆ3DGSï¼‰ä½œä¸ºä¸€ç§æ–°å…´çš„ä¸»å¯¼è§†å›¾åˆæˆæŠ€æœ¯å¤‡å—å…³æ³¨ï¼Œä½†å…¶é«˜å†…å­˜æ¶ˆè€—ä¸¥é‡é™åˆ¶äº†å…¶åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„åº”ç”¨ã€‚è¶Šæ¥è¶Šå¤šçš„3DGSå‹ç¼©æ–¹æ³•è¢«æå‡ºä»¥æé«˜3DGSçš„æ•ˆç‡ï¼Œä½†å¤§å¤šæ•°æ–¹æ³•åªå…³æ³¨å­˜å‚¨å‹ç¼©ï¼Œæœªèƒ½è§£å†³æ¸²æŸ“å†…å­˜çš„å…³é”®ç“¶é¢ˆé—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†MEGS$^{2}$ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å†…å­˜é«˜æ•ˆæ¡†æ¶ï¼Œé€šè¿‡è”åˆä¼˜åŒ–ä¸¤ä¸ªå…³é”®å› ç´ ï¼šæ€»åŸºå…ƒæ•°é‡å’Œæ¯ä¸ªåŸºå…ƒçš„å‚æ•°ï¼Œæ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œå®ç°äº†å‰æ‰€æœªæœ‰çš„å†…å­˜å‹ç¼©ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç”¨è½»é‡çº§çš„ä»»æ„æ–¹å‘çƒé¢é«˜æ–¯æ³¢ç“£æ›¿ä»£äº†å†…å­˜å¯†é›†å‹çš„çƒé¢è°æ³¢ä½œä¸ºæˆ‘ä»¬çš„é¢œè‰²è¡¨ç¤ºã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„è½¯ä¿®å‰ªæ¡†æ¶ï¼Œå°†åŸºå…ƒæ•°é‡å’Œæ³¢ç“£æ•°é‡ä¿®å‰ªå»ºæ¨¡ä¸ºä¸€ä¸ªå¸¦æœ‰çº¦æŸçš„ä¼˜åŒ–é—®é¢˜ã€‚å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMEGS$^{2}$å®ç°äº†50%çš„é™æ€VRAMå‡å°‘å’Œ40%çš„æ¸²æŸ“VRAMå‡å°‘ï¼ŒåŒæ—¶ä¿æŒäº†ç›¸å½“çš„æ¸²æŸ“è´¨é‡ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://megs-2.github.io/">https://megs-2.github.io/</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.07021v2">PDF</a> 20 pages, 8 figures. Project page at <a target="_blank" rel="noopener" href="https://megs-2.github.io/">https://megs-2.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>3D Gaussian Splattingï¼ˆ3DGSï¼‰æ˜¯ä¸€ç§æ–°å…´çš„ä¸»æµè§†å›¾åˆæˆæŠ€æœ¯ï¼Œä½†å…¶é«˜å†…å­˜æ¶ˆè€—ä¸¥é‡é™åˆ¶äº†å…¶åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„åº”ç”¨ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†MEGS^2è®°å¿†æ•ˆç‡æ¡†æ¶ï¼Œé€šè¿‡åŒæ—¶ä¼˜åŒ–åŸå§‹æ€»æ•°å’Œæ¯ä¸ªåŸå§‹å‚æ•°ä¸¤ä¸ªå…³é”®å› ç´ ï¼Œå®ç°äº†å‰æ‰€æœªæœ‰çš„å†…å­˜å‹ç¼©ã€‚é‡‡ç”¨è½»é‡çº§ã€ä»»æ„å®šå‘çƒé¢é«˜æ–¯æ³¢ç“£ä»£æ›¿å†…å­˜å¯†é›†å‹çƒé¢è°æ³¢ä½œä¸ºé¢œè‰²è¡¨ç¤ºï¼Œå¹¶æå‡ºç»Ÿä¸€çš„è½¯ä¿®å‰ªæ¡†æ¶ï¼Œå°†åŸå§‹æ•°é‡æ³¢ç“£æ•°å’Œä¿®å‰ªæ•°å»ºæ¨¡ä¸ºä¸€ä¸ªçº¦æŸä¼˜åŒ–é—®é¢˜ã€‚å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMEGS^2å¯å®ç°é™æ€VRAMå‡å°‘50%ï¼Œæ¸²æŸ“VRAMå‡å°‘40%ï¼ŒåŒæ—¶ä¿æŒç›¸å½“çš„æ¸²æŸ“è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3DGSå·²æˆä¸ºä¸»æµè§†å›¾åˆæˆæŠ€æœ¯ï¼Œä½†å†…å­˜æ¶ˆè€—è¾ƒé«˜ï¼Œé™åˆ¶äº†å…¶åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„åº”ç”¨ã€‚</li>
<li>MEGS^2æ¡†æ¶æ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ï¼Œé€šè¿‡è”åˆä¼˜åŒ–åŸå§‹æ€»æ•°å’Œæ¯ä¸ªåŸå§‹å‚æ•°å®ç°é«˜æ•ˆå†…å­˜ä½¿ç”¨ã€‚</li>
<li>MEGS^2é‡‡ç”¨è½»é‡çº§çƒé¢é«˜æ–¯æ³¢ç“£æ›¿æ¢å†…å­˜å¯†é›†å‹çƒé¢è°æ³¢ä½œä¸ºé¢œè‰²è¡¨ç¤ºã€‚</li>
<li>å¼•å…¥ç»Ÿä¸€çš„è½¯ä¿®å‰ªæ¡†æ¶ï¼Œå°†åŸå§‹æ•°é‡æ³¢ç“£æ•°å’Œä¿®å‰ªæ•°å»ºæ¨¡ä¸ºçº¦æŸä¼˜åŒ–é—®é¢˜ã€‚</li>
<li>MEGS^2å®ç°äº†é™æ€VRAMå’Œæ¸²æŸ“VRAMçš„æ˜¾è‘—å‡å°‘ï¼Œåˆ†åˆ«è¾¾åˆ°äº†50%å’Œ40%çš„ç¼©å‡ã€‚</li>
<li>MEGS^2åœ¨ä¿æŒè¾ƒé«˜æ¸²æŸ“è´¨é‡çš„åŒæ—¶å®ç°äº†å†…å­˜çš„ä¼˜åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.07021">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f0e757abd095a610a60828f1c2c7c02f" align="middle">
<img src="https://picx.zhimg.com/v2-0d725c19167b3b029f2250facbc76ee1" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Temporal-Smoothness-Aware-Rate-Distortion-Optimized-4D-Gaussian-Splatting"><a href="#Temporal-Smoothness-Aware-Rate-Distortion-Optimized-4D-Gaussian-Splatting" class="headerlink" title="Temporal Smoothness-Aware Rate-Distortion Optimized 4D Gaussian   Splatting"></a>Temporal Smoothness-Aware Rate-Distortion Optimized 4D Gaussian   Splatting</h2><p><strong>Authors:Hyeongmin Lee, Kyungjune Baek</strong></p>
<p>Dynamic 4D Gaussian Splatting (4DGS) effectively extends the high-speed rendering capabilities of 3D Gaussian Splatting (3DGS) to represent volumetric videos. However, the large number of Gaussians, substantial temporal redundancies, and especially the absence of an entropy-aware compression framework result in large storage requirements. Consequently, this poses significant challenges for practical deployment, efficient edge-device processing, and data transmission. In this paper, we introduce a novel end-to-end RD-optimized compression framework tailored for 4DGS, aiming to enable flexible, high-fidelity rendering across varied computational platforms. Leveraging Fully Explicit Dynamic Gaussian Splatting (Ex4DGS), one of the state-of-the-art 4DGS methods, as our baseline, we start from the existing 3DGS compression methods for compatibility while effectively addressing additional challenges introduced by the temporal axis. In particular, instead of storing motion trajectories independently per point, we employ a wavelet transform to reflect the real-world smoothness prior, significantly enhancing storage efficiency. This approach yields significantly improved compression ratios and provides a user-controlled balance between compression efficiency and rendering quality. Extensive experiments demonstrate the effectiveness of our method, achieving up to 91$\times$ compression compared to the original Ex4DGS model while maintaining high visual fidelity. These results highlight the applicability of our framework for real-time dynamic scene rendering in diverse scenarios, from resource-constrained edge devices to high-performance environments. The source code is available at <a target="_blank" rel="noopener" href="https://github.com/HyeongminLEE/RD4DGS">https://github.com/HyeongminLEE/RD4DGS</a>. </p>
<blockquote>
<p>åŠ¨æ€å››ç»´é«˜æ–¯æ˜ å°„ï¼ˆ4DGSï¼‰æœ‰æ•ˆåœ°å°†ä¸‰ç»´é«˜æ–¯æ˜ å°„ï¼ˆ3DGSï¼‰çš„é«˜é€Ÿæ¸²æŸ“èƒ½åŠ›æ‰©å±•åˆ°ä½“ç§¯è§†é¢‘è¡¨ç¤ºã€‚ç„¶è€Œï¼Œå¤§é‡çš„é«˜æ–¯ã€å¤§é‡çš„æ—¶é—´å†—ä½™ä»¥åŠç¼ºä¹ç†µæ„ŸçŸ¥å‹ç¼©æ¡†æ¶å¯¼è‡´å­˜å‚¨éœ€æ±‚å·¨å¤§ã€‚å› æ­¤ï¼Œè¿™ç»™å®é™…éƒ¨ç½²ã€é«˜æ•ˆçš„è¾¹ç¼˜è®¾å¤‡å¤„ç†å’Œæ•°æ®ä¼ è¾“å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é’ˆå¯¹4DGSå¼•å…¥äº†ä¸€ç§æ–°å‹ç«¯åˆ°ç«¯RDä¼˜åŒ–å‹ç¼©æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°åœ¨å„ç§è®¡ç®—å¹³å°ä¸Šçš„çµæ´»ã€é«˜ä¿çœŸæ¸²æŸ“ã€‚æˆ‘ä»¬ä»¥ç›®å‰æœ€å…ˆè¿›çš„åŠ¨æ€é«˜æ–¯æ˜ å°„æ–¹æ³•ä¹‹ä¸€çš„å…¨æ˜¾å¼åŠ¨æ€é«˜æ–¯æ˜ å°„ï¼ˆEx4DGSï¼‰ä¸ºåŸºçº¿ï¼Œä»ç°æœ‰çš„å…¼å®¹æ€§è‰¯å¥½çš„ä¸‰ç»´é«˜æ–¯æ˜ å°„å‹ç¼©æ–¹æ³•å‡ºå‘ï¼Œæœ‰æ•ˆè§£å†³äº†ç”±æ—¶é—´è½´å¼•å…¥çš„é¢å¤–æŒ‘æˆ˜ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬æ²¡æœ‰åƒä¼ ç»Ÿæ–¹æ³•é‚£æ ·ç‹¬ç«‹å­˜å‚¨æ¯ä¸ªç‚¹çš„è¿åŠ¨è½¨è¿¹ï¼Œè€Œæ˜¯é‡‡ç”¨å°æ³¢å˜æ¢æ¥åæ˜ ç°å®ä¸–ç•Œä¸­çš„å¹³æ»‘å…ˆéªŒçŸ¥è¯†ï¼Œä»è€Œæ˜¾è‘—æé«˜å­˜å‚¨æ•ˆç‡ã€‚è¿™ç§æ–¹æ³•å®ç°äº†æ˜¾è‘—çš„å‹ç¼©æ¯”ï¼Œå¹¶åœ¨å‹ç¼©æ•ˆç‡å’Œæ¸²æŸ“è´¨é‡ä¹‹é—´æä¾›äº†ç”¨æˆ·å¯æ§çš„å¹³è¡¡ã€‚å¤§é‡å®éªŒè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œä¸åŸå§‹Ex4DGSæ¨¡å‹ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†é«˜è¾¾91å€çš„å‹ç¼©ï¼ŒåŒæ—¶ä¿æŒäº†é«˜åº¦çš„è§†è§‰ä¿çœŸåº¦ã€‚è¿™äº›ç»“æœçªæ˜¾äº†æˆ‘ä»¬çš„æ¡†æ¶åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡åˆ°é«˜æ€§èƒ½ç¯å¢ƒçš„å„ç§åœºæ™¯ä¸­å®æ—¶åŠ¨æ€åœºæ™¯æ¸²æŸ“çš„é€‚ç”¨æ€§ã€‚æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/HyeongminLEE/RD4DGS%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/HyeongminLEE/RD4DGSæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.17336v2">PDF</a> 24 pages, 10 figures, NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹åŠ¨æ€å››ç»´é«˜æ–¯ç‚¹ç»˜ï¼ˆ4DGSï¼‰çš„ç«¯åˆ°ç«¯ä¼˜åŒ–å‹ç¼©æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ—¨åœ¨å®ç°è·¨ä¸åŒè®¡ç®—å¹³å°çš„é«˜ä¿çœŸæ¸²æŸ“ï¼Œé€šè¿‡åˆ©ç”¨å°æ³¢å˜æ¢æ¥åæ˜ ç°å®ä¸–ç•Œä¸­çš„å¹³æ»‘å…ˆéªŒä¿¡æ¯ï¼Œæé«˜äº†å­˜å‚¨æ•ˆç‡ï¼Œå®ç°äº†é«˜å‹ç¼©æ¯”å’Œé«˜è§†è§‰ä¿çœŸåº¦çš„å¹³è¡¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŠ¨æ€å››ç»´é«˜æ–¯ç‚¹ç»˜ï¼ˆ4DGSï¼‰æ‰©å±•äº†ä¸‰ç»´é«˜æ–¯ç‚¹ç»˜ï¼ˆ3DGSï¼‰çš„é«˜é€Ÿæ¸²æŸ“èƒ½åŠ›ï¼Œä»¥è¡¨ç¤ºä½“ç§¯è§†é¢‘ã€‚</li>
<li>ç°æœ‰æŠ€æœ¯é¢ä¸´çš„æŒ‘æˆ˜åŒ…æ‹¬å¤§é‡é«˜æ–¯ã€æ—¶é—´å†—ä½™å’Œç¼ºä¹ç†µæ„ŸçŸ¥å‹ç¼©æ¡†æ¶å¯¼è‡´çš„å­˜å‚¨éœ€æ±‚å¤§ã€‚</li>
<li>æ–°æ¡†æ¶æ—¨åœ¨è§£å†³è¿™äº›é—®é¢˜å¹¶å®ç°çµæ´»çš„ã€é«˜ä¿çœŸåº¦çš„è·¨å¹³å°æ¸²æŸ“ã€‚</li>
<li>é€šè¿‡åˆ©ç”¨å°æ³¢å˜æ¢åæ˜ ç°å®ä¸–ç•Œå¹³æ»‘åº¦å…ˆéªŒä¿¡æ¯ï¼Œæé«˜å­˜å‚¨æ•ˆç‡ã€‚</li>
<li>å®ç°æ˜¾è‘—æ”¹è¿›çš„å‹ç¼©æ¯”å’Œç”¨æˆ·æ§åˆ¶çš„å‹ç¼©æ•ˆç‡å’Œæ¸²æŸ“è´¨é‡ä¹‹é—´çš„å¹³è¡¡ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸åŸå§‹Ex4DGSæ¨¡å‹ç›¸æ¯”ï¼Œæ–°æ–¹æ³•å¯å®ç°é«˜è¾¾91å€çš„å‹ç¼©ï¼ŒåŒæ—¶ä¿æŒé«˜è§†è§‰ä¿çœŸåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.17336">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-56ad927da2261cbf683e7e46ce95ab5a" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="DWTGS-Rethinking-Frequency-Regularization-for-Sparse-view-3D-Gaussian-Splatting"><a href="#DWTGS-Rethinking-Frequency-Regularization-for-Sparse-view-3D-Gaussian-Splatting" class="headerlink" title="DWTGS: Rethinking Frequency Regularization for Sparse-view 3D Gaussian   Splatting"></a>DWTGS: Rethinking Frequency Regularization for Sparse-view 3D Gaussian   Splatting</h2><p><strong>Authors:Hung Nguyen, Runfa Li, An Le, Truong Nguyen</strong></p>
<p>Sparse-view 3D Gaussian Splatting (3DGS) presents significant challenges in reconstructing high-quality novel views, as it often overfits to the widely-varying high-frequency (HF) details of the sparse training views. While frequency regularization can be a promising approach, its typical reliance on Fourier transforms causes difficult parameter tuning and biases towards detrimental HF learning. We propose DWTGS, a framework that rethinks frequency regularization by leveraging wavelet-space losses that provide additional spatial supervision. Specifically, we supervise only the low-frequency (LF) LL subbands at multiple DWT levels, while enforcing sparsity on the HF HH subband in a self-supervised manner. Experiments across benchmarks show that DWTGS consistently outperforms Fourier-based counterparts, as this LF-centric strategy improves generalization and reduces HF hallucinations. </p>
<blockquote>
<p>ç¨€ç–è§†è§’çš„3Dé«˜æ–¯é£æº…ï¼ˆ3DGSï¼‰åœ¨é‡å»ºé«˜è´¨é‡æ–°é¢–è§†è§’æ–¹é¢å­˜åœ¨é‡å¤§æŒ‘æˆ˜ï¼Œå› ä¸ºå®ƒç»å¸¸è¿‡åº¦æ‹Ÿåˆç¨€ç–è®­ç»ƒè§†è§’ä¸­å¹¿æ³›å˜åŒ–çš„é«˜é¢‘ï¼ˆHFï¼‰ç»†èŠ‚ã€‚è™½ç„¶é¢‘ç‡æ­£åˆ™åŒ–å¯èƒ½æ˜¯ä¸€ç§æœ‰å‰é€”çš„æ–¹æ³•ï¼Œä½†å®ƒé€šå¸¸ä¾èµ–äºå‚…é‡Œå¶å˜æ¢ï¼Œå¯¼è‡´å‚æ•°è°ƒæ•´å›°éš¾ï¼Œå¹¶åå‘äºæœ‰å®³çš„é«˜é¢‘å­¦ä¹ ã€‚æˆ‘ä»¬æå‡ºäº†DWTGSï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨å°æ³¢ç©ºé—´æŸå¤±é‡æ–°æ€è€ƒé¢‘ç‡æ­£åˆ™åŒ–çš„æ¡†æ¶ï¼Œå®ƒæä¾›äº†é¢å¤–çš„ç©ºé—´ç›‘ç£ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨å¤šä¸ªDWTçº§åˆ«ä»…ç›‘ç£ä½é¢‘ï¼ˆLFï¼‰LLå­å¸¦ï¼ŒåŒæ—¶ä»¥è‡ªæˆ‘ç›‘ç£çš„æ–¹å¼åœ¨é«˜é¢‘HHå­å¸¦ä¸Šå¼ºåˆ¶æ‰§è¡Œç¨€ç–æ€§ã€‚è·¨åŸºå‡†çš„å®éªŒè¡¨æ˜ï¼ŒDWTGSå§‹ç»ˆä¼˜äºåŸºäºå‚…ç«‹å¶çš„å¯¹åº”æ–¹æ³•ï¼Œå› ä¸ºè¿™ç§ä»¥LFä¸ºä¸­å¿ƒçš„ç­–ç•¥æé«˜äº†æ³›åŒ–èƒ½åŠ›å¹¶å‡å°‘äº†é«˜é¢‘å¹»è§‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.15690v2">PDF</a> Accepted to VCIP 2025</p>
<p><strong>Summary</strong></p>
<p>åŸºäºç¨€ç–è§†è§’çš„3Dé«˜æ–¯å–·ç»˜ï¼ˆ3DGSï¼‰åœ¨é‡å»ºé«˜è´¨é‡æ–°è§†è§’æ—¶é¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼Œæ˜“å¯¹ç¨€ç–è®­ç»ƒè§†è§’ä¸­å˜åŒ–å¤šç«¯çš„é«˜é¢‘ç»†èŠ‚äº§ç”Ÿè¿‡æ‹Ÿåˆç°è±¡ã€‚è™½ç„¶é¢‘ç‡æ­£åˆ™åŒ–æ˜¯ä¸€ç§æœ‰å‰é€”çš„æ–¹æ³•ï¼Œä½†å…¶é€šå¸¸ä¾èµ–äºå‚…é‡Œå¶å˜æ¢ï¼Œå¯¼è‡´å‚æ•°è°ƒæ•´å›°éš¾ä¸”åå‘æœ‰å®³çš„é«˜é¢‘å­¦ä¹ ã€‚æœ¬ç ”ç©¶æå‡ºDWTGSæ¡†æ¶ï¼Œé‡æ–°æ€è€ƒé¢‘ç‡æ­£åˆ™åŒ–ï¼Œåˆ©ç”¨å°æ³¢ç©ºé—´æŸå¤±æä¾›é¢å¤–çš„ç©ºé—´ç›‘ç£ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨å¤šä¸ªDWTçº§åˆ«ä»…ç›‘ç£ä½é¢‘LLå­å¸¦ï¼ŒåŒæ—¶ä»¥è‡ªæˆ‘ç›‘ç£çš„æ–¹å¼åœ¨é«˜é¢‘HHå­å¸¦ä¸Šå®æ–½ç¨€ç–æ€§ã€‚è·¨åŸºå‡†å®éªŒçš„æµ‹è¯•è¡¨æ˜ï¼ŒDWTGSåœ¨ä½é¢‘ä¸ºä¸­å¿ƒçš„ç­–ç•¥æé«˜äº†æ³›åŒ–èƒ½åŠ›å¹¶å‡å°‘äº†é«˜é¢‘å¹»è§‰ï¼Œå› æ­¤å®ƒæŒç»­ä¼˜äºåŸºäºå‚…ç«‹å¶çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¨€ç–è§†è§’çš„3Dé«˜æ–¯å–·ç»˜ï¼ˆ3DGSï¼‰åœ¨é‡å»ºé«˜è´¨é‡æ–°è§†è§’æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œæ˜“è¿‡æ‹Ÿåˆäºé«˜é¢‘ç»†èŠ‚ã€‚</li>
<li>é¢‘ç‡æ­£åˆ™åŒ–æ˜¯ä¸€ç§è§£å†³æ­¤é—®é¢˜çš„æœ‰å‰é€”çš„æ–¹æ³•ï¼Œä½†ä¼ ç»Ÿçš„é¢‘ç‡æ­£åˆ™åŒ–ä¾èµ–äºå‚…ç«‹å¶å˜æ¢ï¼Œå­˜åœ¨å‚æ•°è°ƒæ•´å›°éš¾å’Œåå‘é«˜é¢‘å­¦ä¹ çš„ç¼ºé™·ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºDWTGSæ¡†æ¶ï¼Œåˆ©ç”¨å°æ³¢ç©ºé—´æŸå¤±è¿›è¡Œé¢‘ç‡æ­£åˆ™åŒ–ï¼Œæä¾›é¢å¤–çš„ç©ºé—´ç›‘ç£ã€‚</li>
<li>DWTGSé€šè¿‡ç›‘ç£å¤šä¸ªDWTçº§åˆ«çš„ä½é¢‘LLå­å¸¦å¹¶è‡ªæˆ‘ç›‘ç£é«˜é¢‘HHå­å¸¦çš„ç¨€ç–æ€§ï¼Œå®ç°äº†ä¸€ç§ä½é¢‘ä¸ºä¸­å¿ƒçš„ç­–ç•¥ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒDWTGSæ¡†æ¶èƒ½æé«˜æ³›åŒ–èƒ½åŠ›å¹¶å‡å°‘é«˜é¢‘å¹»è§‰ã€‚</li>
<li>DWTGSæŒç»­ä¼˜äºåŸºäºå‚…ç«‹å¶çš„æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.15690">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-17bcd51353ace54d0ad8aa6013b26d01" align="middle">
<img src="https://picx.zhimg.com/v2-42a4ac4053caf53d9a7c69e25b318e86" align="middle">
<img src="https://picx.zhimg.com/v2-9600037a6ceef4a4de66bec7a707a6b3" align="middle">
<img src="https://picx.zhimg.com/v2-cf85e5e2208e523b23a2da8f534b0dd1" align="middle">
<img src="https://picx.zhimg.com/v2-311626e83c079f165d31c8bea52da013" align="middle">
<img src="https://picx.zhimg.com/v2-7c6719b56ee6eb16d31a8041b8a50774" align="middle">
<img src="https://picx.zhimg.com/v2-22bece77c37640fe4be82de922674dff" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="GAF-Gaussian-Action-Field-as-a-4D-Representation-for-Dynamic-World-Modeling-in-Robotic-Manipulation"><a href="#GAF-Gaussian-Action-Field-as-a-4D-Representation-for-Dynamic-World-Modeling-in-Robotic-Manipulation" class="headerlink" title="GAF: Gaussian Action Field as a 4D Representation for Dynamic World   Modeling in Robotic Manipulation"></a>GAF: Gaussian Action Field as a 4D Representation for Dynamic World   Modeling in Robotic Manipulation</h2><p><strong>Authors:Ying Chai, Litao Deng, Ruizhi Shao, Jiajun Zhang, Kangchen Lv, Liangjun Xing, Xiang Li, Hongwen Zhang, Yebin Liu</strong></p>
<p>Accurate scene perception is critical for vision-based robotic manipulation. Existing approaches typically follow either a Vision-to-Action (V-A) paradigm, predicting actions directly from visual inputs, or a Vision-to-3D-to-Action (V-3D-A) paradigm, leveraging intermediate 3D representations. However, these methods often struggle with action inaccuracies due to the complexity and dynamic nature of manipulation scenes. In this paper, we adopt a V-4D-A framework that enables direct action reasoning from motion-aware 4D representations via a Gaussian Action Field (GAF). GAF extends 3D Gaussian Splatting (3DGS) by incorporating learnable motion attributes, allowing 4D modeling of dynamic scenes and manipulation actions. To learn time-varying scene geometry and action-aware robot motion, GAF provides three interrelated outputs: reconstruction of the current scene, prediction of future frames, and estimation of init action via Gaussian motion. Furthermore, we employ an action-vision-aligned denoising framework, conditioned on a unified representation that combines the init action and the Gaussian perception, both generated by the GAF, to further obtain more precise actions. Extensive experiments demonstrate significant improvements, with GAF achieving +11.5385 dB PSNR, +0.3864 SSIM and -0.5574 LPIPS improvements in reconstruction quality, while boosting the average +7.3% success rate in robotic manipulation tasks over state-of-the-art methods. </p>
<blockquote>
<p>å‡†ç¡®åœºæ™¯æ„ŸçŸ¥å¯¹äºåŸºäºè§†è§‰çš„æœºå™¨äººæ“ä½œè‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éµå¾ªè§†è§‰åˆ°åŠ¨ä½œï¼ˆV-Aï¼‰èŒƒå¼ï¼Œç›´æ¥ä»è§†è§‰è¾“å…¥é¢„æµ‹åŠ¨ä½œï¼Œæˆ–è€…éµå¾ªè§†è§‰åˆ°ä¸‰ç»´åˆ°åŠ¨ä½œï¼ˆV-3D-Aï¼‰èŒƒå¼ï¼Œåˆ©ç”¨ä¸­é—´ä¸‰ç»´è¡¨ç¤ºã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸ç”±äºæ“ä½œåœºæ™¯çš„å¤æ‚æ€§å’ŒåŠ¨æ€æ€§è€Œé¢ä¸´åŠ¨ä½œä¸å‡†ç¡®çš„é—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§V-4D-Aæ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿé€šè¿‡é«˜æ–¯åŠ¨ä½œåœºï¼ˆGAFï¼‰ä»æ„ŸçŸ¥è¿åŠ¨çš„4Dè¡¨ç¤ºä¸­è¿›è¡Œç›´æ¥åŠ¨ä½œæ¨ç†ã€‚GAFé€šè¿‡ç»“åˆå¯å­¦ä¹ çš„è¿åŠ¨å±æ€§æ‰©å±•äº†ä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰ï¼Œå…è®¸å¯¹åŠ¨æ€åœºæ™¯å’Œæ“çºµåŠ¨ä½œè¿›è¡Œ4Då»ºæ¨¡ã€‚ä¸ºäº†å­¦ä¹ éšæ—¶é—´å˜åŒ–çš„åœºæ™¯å‡ ä½•å’Œæ„ŸçŸ¥åŠ¨ä½œçš„æœºå™¨äººè¿åŠ¨ï¼ŒGAFæä¾›äº†ä¸‰ä¸ªç›¸äº’å…³è”çš„è¾“å‡ºï¼šå½“å‰åœºæ™¯çš„é‡å»ºã€æœªæ¥å¸§çš„é¢„æµ‹ä»¥åŠé€šè¿‡é«˜æ–¯è¿åŠ¨ä¼°è®¡çš„åˆå§‹åŠ¨ä½œã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§ä¸è¡ŒåŠ¨è§†è§‰å¯¹é½çš„å»å™ªæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä»¥ç”±GAFç”Ÿæˆçš„åˆå§‹åŠ¨ä½œå’Œé«˜æ–¯æ„ŸçŸ¥çš„ç»“åˆçš„ç»Ÿä¸€è¡¨ç¤ºä¸ºæ¡ä»¶ï¼Œè¿›ä¸€æ­¥è·å¾—æ›´ç²¾ç¡®çš„åŠ¨ä½œã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒGAFåœ¨é‡å»ºè´¨é‡æ–¹é¢å®ç°äº†+11.5385åˆ†è´å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ã€+0.3864ç»“æ„ç›¸ä¼¼æ€§ï¼ˆSSIMï¼‰å’Œ-0.5574å­¦ä¹ æ„ŸçŸ¥æŸå¤±ï¼ˆLPIPSï¼‰çš„æ˜¾è‘—æ”¹å–„ï¼ŒåŒæ—¶åœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸Šçš„æˆåŠŸç‡å¹³å‡æé«˜äº†+7.3%ï¼Œè¶…è¿‡äº†æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.14135v4">PDF</a> <a target="_blank" rel="noopener" href="http://chaiying1.github.io/GAF.github.io/project_page/">http://chaiying1.github.io/GAF.github.io/project_page/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ä¸ªåŸºäºåŠ¨æ€åœºæ™¯çš„V-4D-Aæ¡†æ¶ï¼Œåˆ©ç”¨é«˜æ–¯åŠ¨ä½œåœºï¼ˆGAFï¼‰å®ç°ç›´æ¥ä»è¿åŠ¨æ„ŸçŸ¥çš„4Dè¡¨ç¤ºä¸­è¿›è¡ŒåŠ¨ä½œæ¨ç†ã€‚GAFæ‰©å±•äº†3Dé«˜æ–¯æ‹¼è´´æŠ€æœ¯ï¼Œé€šè¿‡å¼•å…¥å¯å­¦ä¹ çš„è¿åŠ¨å±æ€§ï¼Œå®ç°å¯¹åŠ¨æ€åœºæ™¯å’Œæ“æ§åŠ¨ä½œçš„4Då»ºæ¨¡ã€‚æ­¤å¤–ï¼ŒGAFè¿˜æä¾›ä¸‰ç§ç›¸å…³è¾“å‡ºï¼Œç”¨äºå­¦ä¹ éšæ—¶é—´å˜åŒ–çš„åœºæ™¯å‡ ä½•å’Œæœºå™¨äººåŠ¨ä½œæ„ŸçŸ¥ã€‚é‡‡ç”¨ä¸åŠ¨ä½œè§†è§‰å¯¹é½çš„é™å™ªæ¡†æ¶ï¼Œè¿›ä¸€æ­¥æé«˜åŠ¨ä½œçš„ç²¾ç¡®åº¦ã€‚å®éªŒè¡¨æ˜ï¼ŒGAFåœ¨é‡å»ºè´¨é‡å’Œæœºå™¨äººæ“ä½œä»»åŠ¡ä¸Šçš„æˆåŠŸç‡å‡æ˜¾è‘—æé«˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥V-4D-Aæ¡†æ¶ï¼Œç»“åˆåŠ¨æ€åœºæ™¯ä¸ç›´æ¥åŠ¨ä½œæ¨ç†ã€‚</li>
<li>æå‡ºé«˜æ–¯åŠ¨ä½œåœºï¼ˆGAFï¼‰ï¼Œæ‰©å±•3Dé«˜æ–¯æ‹¼è´´æŠ€æœ¯ï¼Œå®ç°4Då»ºæ¨¡ã€‚</li>
<li>GAFæä¾›ä¸‰ç§è¾“å‡ºï¼šé‡å»ºå½“å‰åœºæ™¯ã€é¢„æµ‹æœªæ¥å¸§ã€ä¼°è®¡åˆå§‹åŠ¨ä½œã€‚</li>
<li>ç»“åˆåˆå§‹åŠ¨ä½œå’Œé«˜æ–¯æ„ŸçŸ¥çš„ç»Ÿè¡¨ç¤ºï¼Œé‡‡ç”¨åŠ¨ä½œè§†è§‰å¯¹é½çš„é™å™ªæ¡†æ¶ã€‚</li>
<li>GAFåœ¨é‡å»ºè´¨é‡ä¸Šè¾ƒç°æœ‰æŠ€æœ¯æœ‰æ˜¾è‘—æ”¹è¿›ï¼Œå¦‚PSNRã€SSIMå’ŒLPIPSæŒ‡æ ‡ã€‚</li>
<li>åœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸Šï¼ŒGAFè¾ƒç°æœ‰æ–¹æ³•çš„æˆåŠŸç‡å¹³å‡æå‡7.3%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.14135">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c6812e81b452e29955a55087c433dbc6" align="middle">
<img src="https://picx.zhimg.com/v2-042bea39661132dbdcb052ff0d4f262b" align="middle">
<img src="https://picx.zhimg.com/v2-fb997de45b43dc0fa97d6d526e494854" align="middle">
<img src="https://picx.zhimg.com/v2-76dca6175577a6d9597638e9077b03e1" align="middle">
<img src="https://picx.zhimg.com/v2-53d4db65bf8aa9868d7cd9ea9b93f06b" align="middle">
<img src="https://picx.zhimg.com/v2-1be85e39b75845a5968e813bf94a1213" align="middle">
<img src="https://picx.zhimg.com/v2-5a7cb15becb54bd26b2584ba6ea6663f" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-28/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-28/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-28/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-cdc7ffdf5f932180a83612b9c0ec803a" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-28  Integrating Object Interaction Self-Attention and GAN-Based Debiasing   for Visual Question Answering
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-28/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-4c5d37a29b968f296b28266d27044f27" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-28  Audio-Driven Universal Gaussian Head Avatars
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32562k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
