<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Interactive">
    <meta name="description" content="Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-28  Thinking While Listening Simple Test Time Scaling For Audio   Classification">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Interactive | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-21fd2027d8af8a8b6e81953d4f2a5c54~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687685&auth_key=1760687685-0-0-6a28417080bca9b2c3092463978ce82b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Interactive</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Interactive/">
                                <span class="chip bg-color">Interactive</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                Interactive
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-28
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-08
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    27 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-28-æ›´æ–°"><a href="#2025-09-28-æ›´æ–°" class="headerlink" title="2025-09-28 æ›´æ–°"></a>2025-09-28 æ›´æ–°</h1><h2 id="Thinking-While-Listening-Simple-Test-Time-Scaling-For-Audio-Classification"><a href="#Thinking-While-Listening-Simple-Test-Time-Scaling-For-Audio-Classification" class="headerlink" title="Thinking While Listening: Simple Test Time Scaling For Audio   Classification"></a>Thinking While Listening: Simple Test Time Scaling For Audio   Classification</h2><p><strong>Authors:Prateek Verma, Mert Pilanci</strong></p>
<p>We propose a framework that enables neural models to â€œthink while listeningâ€ to everyday sounds, thereby enhancing audio classification performance. Motivated by recent advances in the reasoning capabilities of large language models, we address two central questions: (i) how can thinking be incorporated into existing audio classification pipelines to enable reasoning in the category space and improve performance, and (ii) can a new architecture be designed from the ground up to support both thinking and test-time scaling? We demonstrate that in both settings, our models exhibit improved classification accuracy. Leveraging test-time scaling, we observe consistent gains as the number of sampled traces increases. Furthermore, we evaluate two open-source reasoning models, GPT-OSS-20B and Qwen3-14B, showing that while such models are capable of zero-shot reasoning, a lightweight approachâ€“retraining only the embedding matrix of a frozen, smaller model like GPT-2â€“can surpass the performance of billion-parameter text-based reasoning models. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œä½¿ç¥ç»ç½‘ç»œæ¨¡å‹èƒ½å¤Ÿåœ¨è†å¬æ—¥å¸¸å£°éŸ³æ—¶â€œæ€è€ƒâ€ï¼Œä»è€Œæé«˜éŸ³é¢‘åˆ†ç±»çš„æ€§èƒ½ã€‚å—å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›æœ€æ–°è¿›å±•çš„å¯å‘ï¼Œæˆ‘ä»¬è§£å†³äº†ä¸¤ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š(i) å¦‚ä½•å°†æ€è€ƒèå…¥ç°æœ‰çš„éŸ³é¢‘åˆ†ç±»ç®¡é“ï¼Œä»¥åœ¨ç±»åˆ«ç©ºé—´ä¸­å®ç°æ¨ç†å¹¶æé«˜æ€§èƒ½ï¼Œä»¥åŠ(ii) æ˜¯å¦å¯ä»¥ä»å¤´å¼€å§‹è®¾è®¡ä¸€ç§æ–°çš„æ¶æ„ï¼Œä»¥æ”¯æŒæ€è€ƒå’Œæµ‹è¯•æ—¶çš„æ‰©å±•ï¼Ÿæˆ‘ä»¬è¯æ˜ï¼Œåœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„æ¨¡å‹éƒ½è¡¨ç°å‡ºæ›´é«˜çš„åˆ†ç±»ç²¾åº¦ã€‚åˆ©ç”¨æµ‹è¯•æ—¶çš„æ‰©å±•æ€§ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°éšç€é‡‡æ ·è½¨è¿¹æ•°é‡çš„å¢åŠ ï¼Œæ”¶ç›ŠæŒç»­ç¨³å®šã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯„ä¼°äº†ä¸¤ä¸ªå¼€æºæ¨ç†æ¨¡å‹GPT-OSS-20Bå’ŒQwen3-14Bï¼Œç»“æœè¡¨æ˜ï¼Œè™½ç„¶è¿™äº›æ¨¡å‹å…·å¤‡é›¶å¯åŠ¨æ¨ç†èƒ½åŠ›ï¼Œä½†é‡‡ç”¨ä¸€ç§è½»å‹æ–¹æ³•â€”â€”ä»…å¯¹å†»ç»“å°å‹æ¨¡å‹ï¼ˆå¦‚GPT-2ï¼‰çš„åµŒå…¥çŸ©é˜µè¿›è¡Œå†è®­ç»ƒâ€”â€”å¯ä»¥è¶…è¶Šåäº¿å‚æ•°æ–‡æœ¬æ¨ç†æ¨¡å‹çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.19676v1">PDF</a> 6 pages, 3 figures, 2 Tables, ICASSP 2026</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§æ¡†æ¶ï¼Œä½¿ç¥ç»ç½‘ç»œæ¨¡å‹èƒ½å¤Ÿåœ¨è†å¬æ—¥å¸¸å£°éŸ³æ—¶è¿›è¡Œâ€œæ€è€ƒâ€ï¼Œä»è€Œæé«˜éŸ³é¢‘åˆ†ç±»æ€§èƒ½ã€‚è¯¥æ¡†æ¶å—åˆ°å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›è¿›æ­¥çš„å¯å‘ï¼Œè§£å†³äº†ä¸¤ä¸ªæ ¸å¿ƒé—®é¢˜ï¼šä¸€æ˜¯å¦‚ä½•å°†æ€è€ƒèå…¥ç°æœ‰éŸ³é¢‘åˆ†ç±»ç®¡é“ï¼Œä»¥æ”¯æŒç±»åˆ«ç©ºé—´ä¸­çš„æ¨ç†å¹¶æå‡æ€§èƒ½ï¼›äºŒæ˜¯èƒ½å¦è®¾è®¡å…¨æ–°æ¶æ„ä»¥æ”¯æŒæ€è€ƒå’Œæµ‹è¯•æ—¶çš„æ‰©å±•æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½æé«˜åˆ†ç±»å‡†ç¡®æ€§ï¼Œå¹¶ä¸”åœ¨æµ‹è¯•æ—¶éšç€é‡‡æ ·è½¨è¿¹æ•°é‡çš„å¢åŠ ï¼Œæ€§èƒ½æå‡æ›´åŠ æ˜æ˜¾ã€‚æ­¤å¤–ï¼Œè¯„ä¼°äº†ä¸¤ç§å¼€æºæ¨ç†æ¨¡å‹GPT-OSS-20Bå’ŒQwen3-14Bï¼Œå‘ç°è™½ç„¶è¿™äº›æ¨¡å‹å…·å¤‡é›¶æ ·æœ¬æ¨ç†èƒ½åŠ›ï¼Œä½†é€šè¿‡ä»…å¯¹GPT-2ç­‰è¾ƒå°æ¨¡å‹çš„åµŒå…¥çŸ©é˜µè¿›è¡Œå¾®è°ƒï¼Œå…¶æ€§èƒ½å¯è¶…è¶Šäº¿çº§å‚æ•°æ–‡æœ¬æ¨ç†æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºçš„æ¡†æ¶ä½¿ç¥ç»ç½‘ç»œæ¨¡å‹èƒ½å¤Ÿåœ¨éŸ³é¢‘åˆ†ç±»è¿‡ç¨‹ä¸­è¿›è¡Œâ€œæ€è€ƒâ€ï¼Œä»è€Œæé«˜æ€§èƒ½ã€‚</li>
<li>æ¡†æ¶è§£å†³äº†å¦‚ä½•èå…¥æ€è€ƒå’Œè®¾è®¡æ”¯æŒæ€è€ƒçš„å…¨æ–°æ¶æ„è¿™ä¸¤ä¸ªæ ¸å¿ƒé—®é¢˜ã€‚</li>
<li>åœ¨å®éªŒç¯å¢ƒä¸­ï¼Œè¯¥æ¡†æ¶è¡¨ç°å‡ºæé«˜åˆ†ç±»å‡†ç¡®æ€§çš„èƒ½åŠ›ã€‚</li>
<li>æµ‹è¯•æ—¶éšç€é‡‡æ ·è½¨è¿¹æ•°é‡çš„å¢åŠ ï¼Œæ€§èƒ½æå‡æ˜¾è‘—ã€‚</li>
<li>è¯„ä¼°äº†ä¸¤ç§å¼€æºæ¨ç†æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>è¿™äº›å¼€æºæ¨¡å‹å…·å¤‡é›¶æ ·æœ¬æ¨ç†èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.19676">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-21fd2027d8af8a8b6e81953d4f2a5c54~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687693&auth_key=1760687693-0-0-e9705bd748b3fdf6fa9149e0641fb18b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-40d4a9c15fb3847df055f8c5050d970d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687701&auth_key=1760687701-0-0-f50a2612a42741da5b633c20bd1994bd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cedffa71301af48febae5fa68eb3dadb~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687708&auth_key=1760687708-0-0-99695265b86c77757cf3ad41a420e600&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Listening-to-the-long-ringdown-A-novel-way-to-pinpoint-the-EOS-in-neutron-star-cores"><a href="#Listening-to-the-long-ringdown-A-novel-way-to-pinpoint-the-EOS-in-neutron-star-cores" class="headerlink" title="Listening to the long ringdown: A novel way to pinpoint the EOS in   neutron-star cores"></a>Listening to the long ringdown: A novel way to pinpoint the EOS in   neutron-star cores</h2><p><strong>Authors:Christian Ecker, Tyler Gorda, Aleksi Kurkela, Luciano Rezzolla</strong></p>
<p>Gravitational waves (GWs) from binary neutron star (BNS) merger remnants complement constraints from the inspiral phase, mass-radius measurements, and microscopic theory by providing information about the neutron-star equation of state (EOS) at extreme densities. We perform general-relativistic simulations of BNS mergers using EOS models that span the uncertain high-density regime. We find a robust correlation between the ratio of energy and angular momentum lost during the late-time post-merger GW signal - the long ringdown - and the EOS at the highest densities in neutron star cores. Applying this correlation to post-merger GW signals reduces EOS uncertainty at several times saturation density, where no direct constraints currently exist. </p>
<blockquote>
<p>æ¥è‡ªåŒä¸­å­æ˜Ÿåˆå¹¶æ®‹ç•™ç‰©çš„å¼•åŠ›æ³¢ï¼ˆGWsï¼‰è¡¥å……äº†èºæ—‹æ¡¨é˜¶æ®µã€è´¨é‡åŠå¾„æµ‹é‡å’Œå¾®è§‚ç†è®ºæ‰€æ–½åŠ çš„çº¦æŸï¼Œæä¾›äº†æœ‰å…³æç«¯å¯†åº¦ä¸‹ä¸­å­æ˜ŸçŠ¶æ€æ–¹ç¨‹ï¼ˆEOSï¼‰çš„ä¿¡æ¯ã€‚æˆ‘ä»¬ä½¿ç”¨è·¨è¶Šä¸ç¡®å®šé«˜å¯†åº¦åŒºåŸŸçš„EOSæ¨¡å‹ï¼Œå¯¹åŒä¸­å­æ˜Ÿåˆå¹¶è¿›è¡Œå¹¿ä¹‰ç›¸å¯¹è®ºæ¨¡æ‹Ÿã€‚æˆ‘ä»¬å‘ç°åæœŸåˆå¹¶åå¼•åŠ›æ³¢ä¿¡å·ä¸­èƒ½é‡å’Œè§’åŠ¨é‡ä¸¢å¤±çš„æ¯”ç‡ï¼ˆå³é•¿ç¯å½¢æŒ¯è¡ï¼‰ä¸ä¸­å­æ˜Ÿæ ¸å¿ƒæœ€é«˜å¯†åº¦å¤„çš„EOSä¹‹é—´å­˜åœ¨ç¨³å¥çš„ç›¸å…³æ€§ã€‚å°†æ­¤ç›¸å…³æ€§åº”ç”¨äºåˆå¹¶åçš„å¼•åŠ›æ³¢ä¿¡å·ï¼Œå¯ä»¥å‡å°‘é¥±å’Œå¯†åº¦å‡ å€å¤„çš„EOSä¸ç¡®å®šæ€§ï¼Œç›®å‰å°šæ— ç›´æ¥çº¦æŸå­˜åœ¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18665v1">PDF</a> 4 pages, 2 figures, Quark Matter 2025 Proceedings</p>
<p><strong>Summary</strong></p>
<p>æ–‡ä¸­å…³äºäºŒå…ƒä¸­å­æ˜Ÿåˆå¹¶æ®‹ä½™äº§ç”Ÿçš„å¼•åŠ›æ³¢å¯¹ä¸­å­æ˜Ÿç‰©è´¨çŠ¶æ€æ–¹ç¨‹ï¼ˆEOSï¼‰åœ¨æé«˜å¯†åº¦ä¸‹çš„çº¦æŸè¿›è¡Œäº†ç ”ç©¶ã€‚é€šè¿‡æ¨¡æ‹Ÿä½¿ç”¨æ¶µç›–ä¸ç¡®å®šé«˜å¯†åº¦åŒºåŸŸçš„å„ç§EOSæ¨¡å‹ï¼Œå‘ç°æ™šæœŸååˆå¹¶å¼•åŠ›æ³¢ä¿¡å·é‡Šæ”¾çš„èƒ½é‡ä¸è§’åŠ¨é‡ä¹‹æ¯”ï¼ˆå³é•¿æœŸç¯éœ‡ï¼‰ä¸æ˜Ÿæ ¸ä¸­æœ€é«˜å¯†åº¦ä¸‹çš„EOSä¹‹é—´å­˜åœ¨ç¨³å¥ç›¸å…³æ€§ã€‚æ­¤ç›¸å…³æ€§å¯ç”¨äºé™ä½æ²¡æœ‰ç›´æ¥çº¦æŸä¸‹çš„å‡ å€é¥±å’Œå¯†åº¦çš„EOSä¸ç¡®å®šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äºŒå…ƒä¸­å­æ˜Ÿåˆå¹¶æ®‹ä½™äº§ç”Ÿçš„å¼•åŠ›æ³¢å¯ä»¥æä¾›å…³äºä¸­å­æ˜Ÿç‰©è´¨çŠ¶æ€æ–¹ç¨‹ï¼ˆEOSï¼‰åœ¨æç«¯å¯†åº¦ä¸‹çš„ä¿¡æ¯ã€‚</li>
<li>é«˜å¯†åº¦ä¸‹çš„EOSæ¨¡å‹å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œéœ€è¦è¿›è¡Œæ¨¡æ‹Ÿç ”ç©¶ã€‚</li>
<li>å‘ç°æ™šæœŸååˆå¹¶å¼•åŠ›æ³¢ä¿¡å·çš„èƒ½é‡ä¸è§’åŠ¨é‡ä¹‹æ¯”ä¸EOSä¹‹é—´å­˜åœ¨ç¨³å¥ç›¸å…³æ€§ã€‚</li>
<li>è¿™ç§ç›¸å…³æ€§å¯ä»¥ç”¨äºé™ä½å½“å‰æ²¡æœ‰ç›´æ¥çº¦æŸçš„å‡ å€é¥±å’Œå¯†åº¦çš„EOSä¸ç¡®å®šæ€§ã€‚</li>
<li>é€šè¿‡å¼•åŠ›æ³¢ä¿¡å·ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°äº†è§£ä¸­å­æ˜Ÿå†…éƒ¨ç»“æ„å’Œç‰©ç†ç‰¹æ€§ã€‚</li>
<li>æ­¤ç ”ç©¶å¯¹äºç†è§£æç«¯ç‰©ç†æ¡ä»¶ä¸‹çš„ç‰©è´¨çŠ¶æ€æ–¹ç¨‹å…·æœ‰é‡è¦ä»·å€¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18665">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-ac0b1067ccb23953603e5930801d0535~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687715&auth_key=1760687715-0-0-9173505408076a46f97a49310b177a6f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-431a9394050576f6cea17eba04581be0~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687722&auth_key=1760687722-0-0-2b14b632aaf765c1361eecab6124710d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7c852f35a87751307b609a0fb5b5d7e6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687729&auth_key=1760687729-0-0-8ca895d6fd1c0efab407fca6ceabcb14&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-83000d8f09811ceab35b5d5f3ae268f8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687736&auth_key=1760687736-0-0-a41f91d68dd1cbd81fb50719993665f9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="NormGenesis-Multicultural-Dialogue-Generation-via-Exemplar-Guided-Social-Norm-Modeling-and-Violation-Recovery"><a href="#NormGenesis-Multicultural-Dialogue-Generation-via-Exemplar-Guided-Social-Norm-Modeling-and-Violation-Recovery" class="headerlink" title="NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided   Social Norm Modeling and Violation Recovery"></a>NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided   Social Norm Modeling and Violation Recovery</h2><p><strong>Authors:Minki Hong, Jangho Choi, Jihie Kim</strong></p>
<p>Social norms govern culturally appropriate behavior in communication, enabling dialogue systems to produce responses that are not only coherent but also socially acceptable. We present NormGenesis, a multicultural framework for generating and annotating socially grounded dialogues across English, Chinese, and Korean. To model the dynamics of social interaction beyond static norm classification, we propose a novel dialogue type, Violation-to-Resolution (V2R), which models the progression of conversations following norm violations through recognition and socially appropriate repair. To improve pragmatic consistency in underrepresented languages, we implement an exemplar-based iterative refinement early in the dialogue synthesis process. This design introduces alignment with linguistic, emotional, and sociocultural expectations before full dialogue generation begins. Using this framework, we construct a dataset of 10,800 multi-turn dialogues annotated at the turn level for norm adherence, speaker intent, and emotional response. Human and LLM-based evaluations demonstrate that NormGenesis significantly outperforms existing datasets in refinement quality, dialogue naturalness, and generalization performance. We show that models trained on our V2R-augmented data exhibit improved pragmatic competence in ethically sensitive contexts. Our work establishes a new benchmark for culturally adaptive dialogue modeling and provides a scalable methodology for norm-aware generation across linguistically and culturally diverse languages. </p>
<blockquote>
<p>ç¤¾ä¼šè§„èŒƒåœ¨æ²Ÿé€šä¸­ä¸»å¯¼ç€æ°å½“çš„æ–‡åŒ–è¡Œä¸ºï¼Œä½¿å¾—å¯¹è¯ç³»ç»Ÿèƒ½å¤Ÿäº§ç”Ÿä¸ä»…è¿è´¯è€Œä¸”ç¤¾ä¼šå¯æ¥å—çš„å›åº”ã€‚æˆ‘ä»¬æå‡ºäº†NormGenesisï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šæ–‡åŒ–çš„æ¡†æ¶ï¼Œç”¨äºç”Ÿæˆå’Œæ³¨é‡Šè‹±è¯­ã€ä¸­æ–‡å’ŒéŸ©è¯­çš„ç¤¾ä¼šåŒ–å¯¹è¯ã€‚ä¸ºäº†æ¨¡æ‹Ÿç¤¾ä¼šäº’åŠ¨çš„åŠ¨æ€è€Œä¸ä»…ä»…æ˜¯é™æ€è§„èŒƒçš„åˆ†ç±»ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„å¯¹è¯ç±»å‹â€”â€”ä»è¿è§„åˆ°è§£å†³ï¼ˆV2Rï¼‰ï¼Œè¯¥æ¨¡å‹æ¨¡æ‹Ÿäº†è§„èŒƒè¿è§„åå¯¹è¯çš„è¿›å±•ï¼Œé€šè¿‡è¯†åˆ«å’Œé€‚å½“çš„ç¤¾ä¼šä¿®å¤æ¥è¿›è¡Œã€‚ä¸ºäº†æé«˜æ¬ ä»£è¡¨è¯­è¨€çš„å®ç”¨æ€§ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬åœ¨å¯¹è¯åˆæˆè¿‡ç¨‹çš„æ—©æœŸå®ç°äº†åŸºäºèŒƒä¾‹çš„è¿­ä»£ç»†åŒ–ã€‚è¿™ç§è®¾è®¡åœ¨å®Œæ•´çš„å¯¹è¯ç”Ÿæˆå¼€å§‹ä¹‹å‰ï¼Œå¼•å…¥äº†ä¸è¯­è¨€ã€æƒ…æ„Ÿå’Œç¤¾ä¼šæ–‡åŒ–æœŸæœ›çš„å¯¹é½ã€‚ä½¿ç”¨è¿™ä¸ªæ¡†æ¶ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«10800ä¸ªå¤šè½®å¯¹è¯çš„æ•°æ®é›†ï¼Œåœ¨è½®æ¬¡çº§åˆ«è¿›è¡Œè§„èŒƒéµå®ˆã€è¯´è¯è€…æ„å›¾å’Œæƒ…ç»ªååº”çš„æ³¨é‡Šã€‚äººç±»å’ŒLLMï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰ä¸ºåŸºç¡€çš„è¯„ä»·è¡¨æ˜ï¼ŒNormGenesisåœ¨æ”¹è¿›è´¨é‡ã€å¯¹è¯è‡ªç„¶æ€§å’Œæ³›åŒ–æ€§èƒ½æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ•°æ®é›†ã€‚æˆ‘ä»¬å±•ç¤ºï¼Œåœ¨V2Rå¢å¼ºæ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹åœ¨é“å¾·æ•æ„Ÿç¯å¢ƒä¸‹è¡¨ç°å‡ºæ›´å¼ºçš„å®ç”¨æŠ€èƒ½ã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ºæ–‡åŒ–é€‚åº”çš„å¯¹è¯å»ºæ¨¡å»ºç«‹äº†æ–°çš„åŸºå‡†ï¼Œå¹¶ä¸ºè·¨è¯­è¨€å’Œè·¨æ–‡åŒ–å¤šæ ·åŒ–çš„è§„èŒƒæ„ŸçŸ¥ç”Ÿæˆæä¾›äº†å¯æ‰©å±•çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18395v1">PDF</a> 39 pages, 17 figures, EMNLP 2025 Main Conference</p>
<p><strong>Summary</strong></p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18395">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-13ac459ff419d275983b318302147fa7~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687743&auth_key=1760687743-0-0-30a02e93b55cee738304ae116ed0d417&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c85ec5e15a1a16dcb54b596c9fe960e4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687750&auth_key=1760687750-0-0-f67d1eff9eefb49d21b175f6856e59cc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1a641942283e1c432ea47fc5c39d1844~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687757&auth_key=1760687757-0-0-987b21a31bcdf74b64ebaae5841cdd69&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a5645182ac8bb9eae462abc3a9f7f862~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687764&auth_key=1760687764-0-0-47ef5fc6f413d8e8fe4244c4e3de9442&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="WavReward-Spoken-Dialogue-Models-With-Generalist-Reward-Evaluators"><a href="#WavReward-Spoken-Dialogue-Models-With-Generalist-Reward-Evaluators" class="headerlink" title="WavReward: Spoken Dialogue Models With Generalist Reward Evaluators"></a>WavReward: Spoken Dialogue Models With Generalist Reward Evaluators</h2><p><strong>Authors:Shengpeng Ji, Tianle Liang, Yangzhuo Li, Jialong Zuo, Minghui Fang, Jinzheng He, Yifu Chen, Zhengqing Liu, Ziyue Jiang, Xize Cheng, Siqi Zheng, Jin Xu, Junyang Lin, Zhou Zhao</strong></p>
<p>End-to-end spoken dialogue models such as GPT-4o-audio have recently garnered significant attention in the speech domain. However, the evaluation of spoken dialogue modelsâ€™ conversational performance has largely been overlooked. This is primarily due to the intelligent chatbots convey a wealth of non-textual information which cannot be easily measured using text-based language models like ChatGPT. To address this gap, we propose WavReward, a reward feedback model based on audio language models that can evaluate both the IQ and EQ of spoken dialogue systems with speech input. Specifically, 1) based on audio language models, WavReward incorporates the deep reasoning process and the nonlinear reward mechanism for post-training. By utilizing multi-sample feedback via the reinforcement learning algorithm, we construct a specialized evaluator tailored to spoken dialogue models. 2) We introduce ChatReward-30K, a preference dataset used to train WavReward. ChatReward-30K includes both comprehension and generation aspects of spoken dialogue models. These scenarios span various tasks, such as text-based chats, nine acoustic attributes of instruction chats, and implicit chats. WavReward outperforms previous state-of-the-art evaluation models across multiple spoken dialogue scenarios, achieving a substantial improvement about Qwen2.5-Omni in objective accuracy from 53.4$%$ to 91.5$%$. In subjective A&#x2F;B testing, WavReward also leads by a margin of 83$%$. Comprehensive ablation studies confirm the necessity of each component of WavReward. All data and code will be publicly at <a target="_blank" rel="noopener" href="https://github.com/jishengpeng/WavReward">https://github.com/jishengpeng/WavReward</a> after the paper is accepted. </p>
<blockquote>
<p>ç«¯åˆ°ç«¯å£è¯­å¯¹è¯æ¨¡å‹ï¼Œå¦‚GPT-4o-audioï¼Œæœ€è¿‘åœ¨è¯­éŸ³é¢†åŸŸå¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œå£è¯­å¯¹è¯æ¨¡å‹çš„ä¼šè¯æ€§èƒ½è¯„ä¼°å´è¢«å¤§å¤§å¿½è§†äº†ã€‚è¿™ä¸»è¦æ˜¯å› ä¸ºæ™ºèƒ½èŠå¤©æœºå™¨äººä¼ è¾¾äº†å¤§é‡çš„éæ–‡æœ¬ä¿¡æ¯ï¼Œè¿™äº›éæ–‡æœ¬ä¿¡æ¯æ— æ³•è½»æ¾åœ°ä½¿ç”¨åŸºäºæ–‡æœ¬çš„æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†WavRewardï¼Œä¸€ä¸ªåŸºäºéŸ³é¢‘è¯­è¨€æ¨¡å‹çš„å¥–åŠ±åé¦ˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥æ ¹æ®è¯­éŸ³è¾“å…¥è¯„ä¼°å£è¯­å¯¹è¯ç³»ç»Ÿçš„æ™ºå•†å’Œæƒ…å•†ã€‚å…·ä½“æ¥è¯´ï¼Œ1ï¼‰WavRewardåŸºäºéŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼Œèå…¥äº†æ·±åº¦æ¨ç†è¿‡ç¨‹å’Œç”¨äºè®­ç»ƒåçš„éçº¿æ€§å¥–åŠ±æœºåˆ¶ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„å¤šæ ·æœ¬åé¦ˆï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªä¸“ä¸ºå£è¯­å¯¹è¯æ¨¡å‹é‡èº«å®šåˆ¶çš„è¯„ä¼°å™¨ã€‚2ï¼‰æˆ‘ä»¬å¼•å…¥äº†ç”¨äºè®­ç»ƒWavRewardçš„åå¥½æ•°æ®é›†ChatReward-30Kã€‚ChatReward-30Kæ¶µç›–äº†å£è¯­å¯¹è¯æ¨¡å‹çš„ç†è§£å’Œç”Ÿæˆæ–¹é¢ã€‚è¿™äº›åœºæ™¯æ¶µç›–äº†å„ç§ä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬èŠå¤©ã€æŒ‡ä»¤èŠå¤©çš„ä¹ä¸ªå£°éŸ³ç‰¹å¾å’Œéšå¼èŠå¤©ã€‚WavRewardåœ¨å¤šä¸ªå£è¯­å¯¹è¯åœºæ™¯ä¸­è¶…è¶Šäº†å…ˆå‰çš„æœ€å…ˆè¿›çš„è¯„ä¼°æ¨¡å‹ï¼Œåœ¨å®¢è§‚å‡†ç¡®åº¦ä¸Šå®ç°äº†æ˜¾è‘—çš„æå‡ï¼Œå°†Qwen2.5-Omniä»53.4%æé«˜åˆ°91.5%ã€‚åœ¨ä¸»è§‚çš„A&#x2F;Bæµ‹è¯•ä¸­ï¼ŒWavRewardçš„é¢†å…ˆå¹…åº¦ä¹Ÿè¾¾åˆ°äº†83%ã€‚å…¨é¢çš„æ¶ˆèç ”ç©¶è¯å®äº†WavRewardæ¯ä¸ªç»„ä»¶çš„å¿…è¦æ€§ã€‚è®ºæ–‡è¢«æ¥å—åï¼Œæ‰€æœ‰æ•°æ®å’Œä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/jishengpeng/WavReward%E4%B8%8A%E5%85%AC%E5%BC%80%E3%80%82">https://github.com/jishengpeng/WavRewardä¸Šå…¬å¼€ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.09558v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¿‘æœŸè¯­éŸ³é¢†åŸŸå‡ºç°äº†ç«¯åˆ°ç«¯çš„å¯¹è¯æ¨¡å‹ï¼Œå¦‚GPT-4o-audioç­‰ï¼Œä½†å¯¹è¯æ¨¡å‹çš„è¯„ä»·å¸¸å¸¸å¿½è§†å…¶äº¤äº’æ€§èƒ½ã€‚é’ˆå¯¹æ™ºèƒ½èŠå¤©æœºå™¨äººæ‰€ä¼ è¾¾çš„ä¸°å¯Œéæ–‡æœ¬ä¿¡æ¯ï¼Œæˆ‘ä»¬æå‡ºåŸºäºéŸ³é¢‘è¯­è¨€æ¨¡å‹çš„åé¦ˆå¥–åŠ±æ¨¡å‹WavRewardï¼Œç”¨ä»¥è¯„ä»·å¯¹è¯ç³»ç»Ÿçš„æ™ºå•†å’Œæƒ…å•†ã€‚æ­¤æ¨¡å‹èå…¥æ·±åº¦å­¦ä¹ è¿‡ç¨‹ä¸­çš„æ¨ç†è¿‡ç¨‹å’Œéçº¿æ€§å¥–åŠ±æœºåˆ¶è¿›è¡Œåè®­ç»ƒã€‚åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„å¤šæ ·æœ¬åé¦ˆæ„å»ºä¸“ç”¨äºå¯¹è¯æ¨¡å‹çš„è¯„ä»·å™¨ã€‚å¼•å…¥ChatReward-30Kåå¥½æ•°æ®é›†ç”¨äºè®­ç»ƒWavRewardï¼Œæ¶µç›–æ–‡æœ¬èŠå¤©ã€æŒ‡ä»¤èŠå¤©çš„ä¹ç§å£°éŸ³ç‰¹å¾ä»¥åŠéšå«èŠå¤©ç­‰åœºæ™¯ã€‚ç›¸è¾ƒäºä¹‹å‰çš„æœ€ä½³è¯„ä»·æ¨¡å‹ï¼ŒWavRewardåœ¨å¤šåœºæ™¯å¯¹è¯ä¸­è¡¨ç°å‡ºæ›´é«˜çš„å®¢è§‚å‡†ç¡®ç‡ï¼Œä»53.4%æå‡è‡³91.5%ã€‚ä¸»è§‚æµ‹è¯•ä¸­ï¼ŒWavRewardä¹Ÿå æ®æ˜æ˜¾ä¼˜åŠ¿ï¼Œé«˜å‡ºçº¦83%ã€‚å…¨é¢çš„æ¶ˆèç ”ç©¶è¯å®äº†WavRewardæ¯ä¸ªç»„ä»¶çš„å¿…è¦æ€§ã€‚æ‰€æœ‰æ•°æ®å’Œç›¸å…³ä»£ç å°†åœ¨è®ºæ–‡è¢«æ¥å—åå…¬å¼€äº<a target="_blank" rel="noopener" href="https://github.com/jishengpeng/WavReward%E3%80%82">https://github.com/jishengpeng/WavRewardã€‚</a></p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç«¯åˆ°ç«¯å¯¹è¯æ¨¡å‹å¦‚GPT-4o-audioå—åˆ°å…³æ³¨ï¼Œä½†å¯¹è¯æ¨¡å‹çš„è¯„ä»·å¤šä¾§é‡äºæ–‡æœ¬ä¿¡æ¯è€Œå¿½è§†äº¤äº’æ€§èƒ½ã€‚</li>
<li>WavRewardåŸºäºéŸ³é¢‘è¯­è¨€æ¨¡å‹æ„å»ºï¼Œå¯è¯„ä¼°å¯¹è¯ç³»ç»Ÿçš„æ™ºå•†å’Œæƒ…å•†ã€‚</li>
<li>WavRewardé‡‡ç”¨æ·±åº¦å­¦ä¹ è¿‡ç¨‹ä¸­çš„æ¨ç†è¿‡ç¨‹å’Œéçº¿æ€§å¥–åŠ±æœºåˆ¶è¿›è¡Œåè®­ç»ƒã€‚</li>
<li>ChatReward-30Kæ•°æ®é›†çš„å¼•å…¥ç”¨äºè®­ç»ƒWavRewardï¼ŒåŒ…æ‹¬å¤šæ–¹é¢çš„å¯¹è¯åœºæ™¯ã€‚</li>
<li>WavRewardåœ¨å®¢è§‚å’Œä¸»è§‚æµ‹è¯•ä¸­å‡è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œæ˜¾è‘—æé«˜è¯„ä»·å‡†ç¡®ç‡ã€‚</li>
<li>WavRewardçš„æ¯ä¸ªç»„ä»¶éƒ½ç»è¿‡æ¶ˆèç ”ç©¶éªŒè¯å…¶å¿…è¦æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.09558">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-f4b55a175bfb5f77df61458d8f8c0a3d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687771&auth_key=1760687771-0-0-6d81ffac3526bd4b15a5214982b38009&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ac266c9227db009e57d624d1983fb69e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687779&auth_key=1760687779-0-0-f5506df2486c933680f550a597448d59&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c41d7e228bcb2a9b2ecf4fe62cc5dffe~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687786&auth_key=1760687786-0-0-5b7460924123d8b968b27bea9b9520d6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="BAP-v2-An-Enhanced-Task-Framework-for-Instruction-Following-in-Minecraft-Dialogues"><a href="#BAP-v2-An-Enhanced-Task-Framework-for-Instruction-Following-in-Minecraft-Dialogues" class="headerlink" title="BAP v2: An Enhanced Task Framework for Instruction Following in   Minecraft Dialogues"></a>BAP v2: An Enhanced Task Framework for Instruction Following in   Minecraft Dialogues</h2><p><strong>Authors:Prashant Jayannavar, Liliang Ren, Marisa Hudspeth, Risham Sidhu, Charlotte Lambert, Ariel Cordes, Elizabeth Kaplan, Anjali Narayan-Chen, Julia Hockenmaier</strong></p>
<p>Developing interactive agents that can understand language, perceive their surroundings, and act within the physical world is a long-standing goal of AI research. The Minecraft Collaborative Building Task (MCBT) (Narayan-Chen, Jayannavar, and Hockenmaier 2019), a two-player game in which an Architect (A) instructs a Builder (B) to construct a target structure in a simulated 3D Blocks World environment, offers a rich platform to work towards this goal. In this work, we focus on the Builder Action Prediction (BAP) subtask: predicting Bâ€™s actions in a multimodal game context (Jayannavar, Narayan-Chen, and Hockenmaier 2020) - a challenging testbed for grounded instruction following, with limited training data. We holistically re-examine this task and introduce BAP v2 to address key challenges in evaluation, training data, and modeling. Specifically, we define an enhanced evaluation benchmark, featuring a cleaner test set and fairer, more insightful metrics that also reveal spatial reasoning as the primary performance bottleneck. To address data scarcity and to teach models basic spatial skills, we generate different types of synthetic MCBT data. We observe that current, LLM-based SOTA models trained on the human BAP dialogues fail on these simpler, synthetic BAP ones, but show that training models on this synthetic data improves their performance across the board. We also introduce a new SOTA model, Llama-CRAFTS, which leverages richer input representations, and achieves an F1 score of 53.0 on the BAP v2 task and strong performance on the synthetic data. While this result marks a notable 6 points improvement over previous work, it also underscores the taskâ€™s remaining difficulty, establishing BAP v2 as a fertile ground for future research, and providing a useful measure of the spatial capabilities of current text-only LLMs in such embodied tasks. </p>
<blockquote>
<p>å¼€å‘èƒ½å¤Ÿç†è§£è¯­è¨€ã€æ„ŸçŸ¥å‘¨å›´ç¯å¢ƒå¹¶åœ¨ç‰©ç†ä¸–ç•Œä¸­è¡ŒåŠ¨çš„äº¤äº’æ™ºèƒ½ä½“æ˜¯äººå·¥æ™ºèƒ½ç ”ç©¶çš„é•¿è¿œç›®æ ‡ã€‚MinecraftååŒå»ºé€ ä»»åŠ¡ï¼ˆMCBTï¼‰ï¼ˆNarayan-Chenã€Jayannavarå’ŒHockenmaier 2019ï¼‰æ˜¯ä¸€ä¸ªä¸¤äººæ¸¸æˆï¼Œå»ºç­‘å¸ˆï¼ˆAï¼‰æŒ‡å¯¼å»ºé€ è€…ï¼ˆBï¼‰åœ¨ä¸€ä¸ªæ¨¡æ‹Ÿçš„3Dæ–¹å—ä¸–ç•Œç¯å¢ƒä¸­å»ºé€ ç›®æ ‡ç»“æ„ï¼Œè¿™ä¸ºå®ç°è¿™ä¸€ç›®æ ‡æä¾›äº†ä¸€ä¸ªä¸°å¯Œçš„å¹³å°ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é‡ç‚¹å…³æ³¨å»ºé€ è€…è¡ŒåŠ¨é¢„æµ‹ï¼ˆBAPï¼‰å­ä»»åŠ¡ï¼šåœ¨å¤šåª’ä½“æ¸¸æˆä¸­é¢„æµ‹Bçš„è¡ŒåŠ¨ï¼ˆJayannavarã€Narayan-Chenå’ŒHockenmaier 2020ï¼‰â€”â€”è¿™æ˜¯ä¸€ä¸ªå¯¹éµå¾ªæŒ‡ä»¤å…·æœ‰æŒ‘æˆ˜æ€§çš„æµ‹è¯•å¹³å°ï¼Œä¸”è®­ç»ƒæ•°æ®æœ‰é™ã€‚æˆ‘ä»¬å…¨é¢é‡æ–°å®¡è§†äº†è¿™é¡¹ä»»åŠ¡ï¼Œå¹¶å¼•å…¥äº†BAP v2æ¥è§£å†³è¯„ä¼°ã€è®­ç»ƒæ•°æ®å’Œå»ºæ¨¡æ–¹é¢çš„å…³é”®æŒ‘æˆ˜ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªå¢å¼ºçš„è¯„ä¼°åŸºå‡†ï¼ŒåŒ…æ‹¬ä¸€ä¸ªæ›´å¹²å‡€çš„æµ‹è¯•é›†å’Œæ›´å…¬å¹³ã€æ›´æ·±å…¥çš„æŒ‡æ ‡ï¼Œè¿™äº›æŒ‡æ ‡è¿˜æ­ç¤ºäº†ç©ºé—´æ¨ç†æ˜¯ä¸»è¦çš„æ€§èƒ½ç“¶é¢ˆã€‚ä¸ºäº†è§£å†³æ•°æ®ç¨€ç¼ºçš„é—®é¢˜å¹¶æ•™æˆæ¨¡å‹åŸºæœ¬ç©ºé—´æŠ€èƒ½ï¼Œæˆ‘ä»¬ç”Ÿæˆäº†ä¸åŒç±»å‹çš„åˆæˆMCBTæ•°æ®ã€‚æˆ‘ä»¬å‘ç°ï¼Œå½“å‰åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æœ€æ–°æ¨¡å‹åœ¨äººç±»BAPå¯¹è¯ä¸Šçš„è®­ç»ƒæ•ˆæœåœ¨è¿™äº›æ›´ç®€å•ã€åˆæˆçš„BAPæ•°æ®ä¸Šè¡¨ç°ä¸ä½³ï¼Œä½†è®­ç»ƒæ¨¡å‹ä½¿ç”¨è¿™ç§åˆæˆæ•°æ®å¯ä»¥æé«˜å…¶æ•´ä½“è¡¨ç°ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§æ–°å‹SOTAæ¨¡å‹Llama-CRAFTSï¼Œå®ƒåˆ©ç”¨æ›´ä¸°å¯Œçš„è¾“å…¥è¡¨ç¤ºå½¢å¼ï¼Œåœ¨BAP v2ä»»åŠ¡ä¸Šå®ç°äº†53.0çš„F1åˆ†æ•°ï¼Œå¹¶åœ¨åˆæˆæ•°æ®ä¸Šè¡¨ç°å‡ºå¼ºåŠ²çš„æ€§èƒ½ã€‚è™½ç„¶è¿™ä¸€ç»“æœæ¯”å‰äººçš„å·¥ä½œæé«˜äº†6ä¸ªç™¾åˆ†ç‚¹ï¼Œä½†ä¹Ÿè¡¨æ˜äº†ä»»åŠ¡ä»å­˜åœ¨éš¾åº¦ï¼Œç¡®ç«‹äº†BAP v2ä½œä¸ºæœªæ¥ç ”ç©¶çš„è‚¥æ²ƒåœŸå£¤ï¼Œå¹¶ä¸ºå½“å‰æ–‡æœ¬å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¿™ç§å®ä½“ä»»åŠ¡ä¸­çš„ç©ºé—´èƒ½åŠ›æä¾›äº†æœ‰ç”¨çš„è¡¡é‡æ ‡å‡†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10836v3">PDF</a> major revision; few examples of changes: added contemporary LLMs and   new SOTA model, improved readability, expanded related work, etc</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†äººå·¥æ™ºèƒ½é¢†åŸŸé•¿æœŸçš„ç›®æ ‡ï¼šå¼€å‘èƒ½å¤Ÿç†è§£è¯­è¨€ã€æ„ŸçŸ¥å‘¨å›´ç¯å¢ƒå¹¶åœ¨ç‰©ç†ä¸–ç•Œä¸­è¡ŒåŠ¨çš„äº¤äº’ä»£ç†ã€‚æ–‡ç« ä»¥Minecraftåä½œå»ºé€ ä»»åŠ¡ï¼ˆMCBTï¼‰ä¸ºä¾‹ï¼Œé‡ç‚¹ä»‹ç»äº†å»ºé€ è€…è¡ŒåŠ¨é¢„æµ‹ï¼ˆBAPï¼‰å­ä»»åŠ¡ï¼Œè¿™æ˜¯ä¸€ä¸ªå¯¹éµå¾ªæŒ‡ä»¤æœ‰ç°å®æ„ä¹‰çš„æµ‹è¯•å¹³å°ï¼Œå¹¶å­˜åœ¨å…³é”®æŒ‘æˆ˜ã€‚ç ”ç©¶å›¢é˜Ÿæå‡ºäº†BAP v2æ¥å®Œå–„è¯„ä»·åŸºå‡†ã€è®­ç»ƒæ•°æ®å’Œå»ºæ¨¡æ–¹æ³•ã€‚é€šè¿‡å¼•å…¥åˆæˆMCBTæ•°æ®æ¥è§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œå¹¶æ•™æˆæ¨¡å‹åŸºæœ¬ç©ºé—´æŠ€èƒ½ã€‚æ–‡ç« è¿˜ä»‹ç»äº†ä¸€ç§æ–°å‹æ¨¡å‹Llama-CRAFTSï¼Œå®ƒåœ¨BAP v2ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—æˆç»©ï¼Œå¹¶å¼ºè°ƒæœªæ¥ç ”ç©¶çš„æ½œåŠ›ã€‚æ­¤æˆæœå±•ç°äº†å½“å‰çº¯æ–‡æœ¬å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æ­¤ç±»åµŒå…¥å¼ä»»åŠ¡æ—¶çš„ç©ºé—´èƒ½åŠ›æŒ‘æˆ˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIç ”ç©¶çš„ä¸€ä¸ªé‡è¦ç›®æ ‡æ˜¯å¼€å‘èƒ½å¤Ÿç†è§£è¯­è¨€ã€æ„ŸçŸ¥ç¯å¢ƒå¹¶åœ¨ç‰©ç†ä¸–ç•Œè¡ŒåŠ¨çš„äº¤äº’ä»£ç†ã€‚</li>
<li>Minecraftåä½œå»ºé€ ä»»åŠ¡ï¼ˆMCBTï¼‰ä¸ºè¿™ä¸€ç›®æ ‡çš„å®ç°æä¾›äº†ä¸°å¯Œçš„å¹³å°ã€‚</li>
<li>å»ºé€ è€…è¡ŒåŠ¨é¢„æµ‹ï¼ˆBAPï¼‰å­ä»»åŠ¡æ˜¯ä¸€ä¸ªå¯¹éµå¾ªæŒ‡ä»¤æœ‰ç°å®æ„ä¹‰çš„æµ‹è¯•å¹³å°ï¼Œä½†å­˜åœ¨å…³é”®æŒ‘æˆ˜ã€‚</li>
<li>BAP v2çš„æ¨å‡ºè§£å†³äº†è¯„ä»·åŸºå‡†ã€è®­ç»ƒæ•°æ®å’Œå»ºæ¨¡æ–¹æ³•ä¸Šçš„å…³é”®æŒ‘æˆ˜ã€‚</li>
<li>é€šè¿‡å¼•å…¥åˆæˆMCBTæ•°æ®æ¥è§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œå¹¶æ•™æˆæ¨¡å‹åŸºæœ¬ç©ºé—´æŠ€èƒ½ã€‚</li>
<li>å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤„ç†ç®€å•åˆæˆBAPæ•°æ®æ—¶è¡¨ç°ä¸ä½³ï¼Œä½†è®­ç»ƒåœ¨è¿™äº›æ•°æ®ä¸Šå¯ä»¥æé«˜å…¶æ•´ä½“æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10836">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-8274a597010b41e9fbc922f71e1075cd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687793&auth_key=1760687793-0-0-51cef810ce37879d025068c43db4529f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-16dced13be35c38a644e62a9d274ac00~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687801&auth_key=1760687801-0-0-c0d7f1526873c7c23a8f62174fe98bf5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ee10b1d11e9f303f5ec4ef8f87c1ee70~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687807&auth_key=1760687807-0-0-289128f44f79b4ae6deb18b81f0ecf63&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Text-Augmented-Multimodal-LLMs-for-Chemical-Reaction-Condition-Recommendation"><a href="#Text-Augmented-Multimodal-LLMs-for-Chemical-Reaction-Condition-Recommendation" class="headerlink" title="Text-Augmented Multimodal LLMs for Chemical Reaction Condition   Recommendation"></a>Text-Augmented Multimodal LLMs for Chemical Reaction Condition   Recommendation</h2><p><strong>Authors:Yu Zhang, Ruijie Yu, Kaipeng Zeng, Ding Li, Feng Zhu, Xiaokang Yang, Yaohui Jin, Yanyan Xu</strong></p>
<p>Identifying reaction conditions that are broadly applicable across diverse substrates is a longstanding challenge in chemical and pharmaceutical research. While many methods are available to generate conditions with acceptable performance, a universal approach for reliably discovering effective conditions during reaction exploration is rare. Consequently, current reaction optimization processes are often labor-intensive, time-consuming, and costly, relying heavily on trial-and-error experimentation. Nowadays, large language models (LLMs) are capable of tackling chemistry-related problems, such as molecule design and chemical reasoning tasks. Here, we report the design, implementation and application of Chemma-RC, a text-augmented multimodal LLM to identify effective conditions through task-specific dialogue and condition generation. Chemma-RC learns a unified representation of chemical reactions by aligning multiple modalities-including text corpus, reaction SMILES, and reaction graphs-within a shared embedding module. Performance benchmarking on datasets showed high precision in identifying optimal conditions, with up to 17% improvement over the current state-of-the-art methods. A palladium-catalysed imidazole C-H arylation reaction was investigated experimentally to evaluate the functionalities of the Chemma-RC in practice. Our findings suggest that Chemma-RC holds significant potential to accelerate high-throughput condition screening in chemical synthesis. </p>
<blockquote>
<p>è¯†åˆ«å¹¿æ³›åº”ç”¨äºå„ç§åº•ç‰©çš„ååº”æ¡ä»¶ä¸€ç›´æ˜¯åŒ–å­¦å’Œåˆ¶è¯ç ”ç©¶ä¸­çš„ä¸€é¡¹é•¿æœŸæŒ‘æˆ˜ã€‚è™½ç„¶æœ‰è®¸å¤šæ–¹æ³•èƒ½å¤Ÿäº§ç”Ÿå¯æ¥å—çš„æ€§èƒ½æ¡ä»¶ï¼Œä½†åœ¨ååº”æ¢ç´¢è¿‡ç¨‹ä¸­å¯é åœ°å‘ç°æœ‰æ•ˆæ¡ä»¶çš„é€šç”¨æ–¹æ³•å´å¾ˆå°‘è§ã€‚å› æ­¤ï¼Œå½“å‰çš„ååº”ä¼˜åŒ–è¿‡ç¨‹å¾€å¾€åŠ³åŠ¨å¼ºåº¦é«˜ã€è€—æ—¶ä¸”æˆæœ¬é«˜æ˜‚ï¼Œä¸¥é‡ä¾èµ–äºè¯•é”™å®éªŒã€‚å¦‚ä»Šï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰èƒ½å¤Ÿè§£å†³åŒ–å­¦ç›¸å…³é—®é¢˜ï¼Œä¾‹å¦‚åˆ†å­è®¾è®¡å’ŒåŒ–å­¦æ¨ç†ä»»åŠ¡ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æŠ¥å‘Šäº†Chemma-RCçš„è®¾è®¡ã€å®ç°å’Œåº”ç”¨ã€‚Chemma-RCæ˜¯ä¸€ç§æ–‡æœ¬å¢å¼ºå¤šæ¨¡å¼LLMï¼Œé€šè¿‡ç‰¹å®šä»»åŠ¡å¯¹è¯å’Œæ¡ä»¶ç”Ÿæˆæ¥è¯†åˆ«æœ‰æ•ˆæ¡ä»¶ã€‚Chemma-RCé€šè¿‡å…±äº«åµŒå…¥æ¨¡å—å¯¹é½å¤šä¸ªæ¨¡å¼ï¼ŒåŒ…æ‹¬æ–‡æœ¬è¯­æ–™åº“ã€ååº”SMILESå’Œååº”å›¾ï¼Œå­¦ä¹ åŒ–å­¦ååº”çš„ç»Ÿä¸€è¡¨ç¤ºã€‚åœ¨æ•°æ®é›†ä¸Šçš„æ€§èƒ½åŸºå‡†æµ‹è¯•æ˜¾ç¤ºï¼Œåœ¨è¯†åˆ«æœ€ä½³æ¡ä»¶æ–¹é¢å…·æœ‰è¾ƒé«˜çš„ç²¾åº¦ï¼Œæ¯”å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•é«˜å‡ºé«˜è¾¾17%ã€‚é€šè¿‡å®éªŒè°ƒæŸ¥é’¯å‚¬åŒ–çš„å’ªå”‘C-HèŠ³åŸºåŒ–ååº”ï¼Œä»¥è¯„ä¼°Chemma-RCåœ¨å®é™…æ“ä½œä¸­çš„åŠŸèƒ½ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒChemma-RCåœ¨é«˜é€šé‡æ¡ä»¶ç­›é€‰æ–¹é¢å…·æœ‰å·¨å¤§çš„æ½œåŠ›ï¼Œå¯åŠ é€ŸåŒ–å­¦åˆæˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.15141v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŒ–å­¦ä¸åˆ¶è¯ç ”ç©¶ä¸­ï¼Œç¡®å®šå¯å¹¿æ³›åº”ç”¨äºä¸åŒåº•ç‰©çš„ååº”æ¡ä»¶æ˜¯ä¸€é¡¹é•¿æœŸæŒ‘æˆ˜ã€‚å½“å‰ååº”ä¼˜åŒ–æµç¨‹åŠ³åŠ¨å¯†é›†å‹ï¼Œè€—æ—¶è€—èµ„ï¼Œå¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºè¯•éªŒæ€§é”™è¯¯æ¢ç´¢ã€‚æœ¬ç ”ç©¶æŠ¥å‘Šæ¨å‡ºChemma-RCï¼Œä¸€ç§æ–‡æœ¬å¢å¼ºå¤šæ¨¡å¼å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡ç‰¹å®šä»»åŠ¡å¯¹è¯å’Œæ¡ä»¶ç”Ÿæˆæ¥è¯†åˆ«æœ‰æ•ˆæ¡ä»¶ã€‚Chemma-RCé€šè¿‡å…±äº«åµŒå…¥æ¨¡å—å¯¹é½æ–‡æœ¬è¯­æ–™åº“ã€ååº”SMILESå’Œååº”å›¾è°±ç­‰å¤šç§æ¨¡å¼ï¼Œå­¦ä¹ åŒ–å­¦ååº”çš„ç»Ÿä¸€è¡¨ç¤ºã€‚æ•°æ®é›†ä¸Šçš„æ€§èƒ½è¯„ä¼°æ˜¾ç¤ºï¼Œå…¶åœ¨ç¡®å®šæœ€ä½³æ¡ä»¶æ–¹é¢å…·æœ‰é«˜ç²¾åº¦ï¼Œè¾ƒå½“å‰å‰æ²¿æ–¹æ³•æœ€é«˜æå‡äº†17%ã€‚é€šè¿‡å®éªŒéªŒè¯çš„é’¯å‚¬åŒ–å’ªå”‘C-HèŠ³åŸºåŒ–ååº”ï¼Œè¯æ˜äº†Chemma-RCåœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰æ˜¾è‘—æ½œåŠ›ï¼Œå¯åŠ é€ŸåŒ–å­¦åˆæˆä¸­çš„é«˜é€šé‡æ¡ä»¶ç­›é€‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¡®å®šå¯å¹¿æ³›åº”ç”¨äºä¸åŒåº•ç‰©çš„ååº”æ¡ä»¶æ˜¯ä¸€é¡¹æŒ‘æˆ˜ã€‚</li>
<li>å½“å‰ååº”ä¼˜åŒ–æµç¨‹åŠ³åŠ¨å¯†é›†å‹ä¸”è€—æ—¶è€—èµ„ã€‚</li>
<li>Chemma-RCæ˜¯ä¸€ç§æ–‡æœ¬å¢å¼ºå¤šæ¨¡å¼å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³åŒ–å­¦ååº”æ¡ä»¶è¯†åˆ«é—®é¢˜ã€‚</li>
<li>Chemma-RCé€šè¿‡å¯¹é½å¤šç§æ¨¡å¼å­¦ä¹ åŒ–å­¦ååº”çš„ç»Ÿä¸€è¡¨ç¤ºã€‚</li>
<li>æ€§èƒ½è¯„ä¼°æ˜¾ç¤ºChemma-RCåœ¨ç¡®å®šæœ€ä½³æ¡ä»¶æ–¹é¢å…·æœ‰è¾ƒé«˜çš„ç²¾åº¦ï¼Œè¾ƒå½“å‰å‰æ²¿æ–¹æ³•æœ‰æ‰€æå‡ã€‚</li>
<li>å®éªŒéªŒè¯çš„é’¯å‚¬åŒ–å’ªå”‘C-HèŠ³åŸºåŒ–ååº”è¯æ˜äº†Chemma-RCçš„å®é™…åº”ç”¨æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.15141">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-524328574b8f79ae3832bd9f699b0886~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687815&auth_key=1760687815-0-0-be514a9bbd3b8f22f66e41fa622c5a3d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d14a1d524a2453dd40faacb577dc077e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687822&auth_key=1760687822-0-0-63b222090ed0030dfb9ca4402798ff5f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f07e8622b3a66543d9b93ec21f5d2b94~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687829&auth_key=1760687829-0-0-bdba305fc8d602e12a43d50cd34b10f3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5b09077073a1556af3ba309b29f3117b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687836&auth_key=1760687836-0-0-28eb7e5e7364b8ea2c256c34dd7a41dc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="REACT-Real-time-Efficiency-and-Accuracy-Compromise-for-Tradeoffs-in-Scene-Graph-Generation"><a href="#REACT-Real-time-Efficiency-and-Accuracy-Compromise-for-Tradeoffs-in-Scene-Graph-Generation" class="headerlink" title="REACT: Real-time Efficiency and Accuracy Compromise for Tradeoffs in   Scene Graph Generation"></a>REACT: Real-time Efficiency and Accuracy Compromise for Tradeoffs in   Scene Graph Generation</h2><p><strong>Authors:MaÃ«lic Neau, Paulo E. Santos, Anne-Gwenn Bosser, CÃ©dric Buche, Akihiro Sugimoto</strong></p>
<p>Scene Graph Generation (SGG) is a task that encodes visual relationships between objects in images as graph structures. SGG shows significant promise as a foundational component for downstream tasks, such as reasoning for embodied agents. To enable real-time applications, SGG must address the trade-off between performance and inference speed. However, current methods tend to focus on one of the following: (1) improving relation prediction accuracy, (2) enhancing object detection accuracy, or (3) reducing latency, without aiming to balance all three objectives simultaneously. To address this limitation, we propose the Real-time Efficiency and Accuracy Compromise for Tradeoffs in Scene Graph Generation (REACT) architecture, which achieves the highest inference speed among existing SGG models, improving object detection accuracy without sacrificing relation prediction performance. Compared to state-of-the-art approaches, REACT is 2.7 times faster and improves object detection accuracy by 58%. Furthermore, our proposal significantly reduces model size, with an average of 5.5x fewer parameters. The code is available at <a target="_blank" rel="noopener" href="https://github.com/Maelic/SGG-Benchmark">https://github.com/Maelic/SGG-Benchmark</a> </p>
<blockquote>
<p>åœºæ™¯å›¾ç”Ÿæˆï¼ˆSGGï¼‰æ˜¯ä¸€é¡¹å°†å›¾åƒä¸­å¯¹è±¡ä¹‹é—´çš„è§†è§‰å…³ç³»ç¼–ç ä¸ºå›¾ç»“æ„çš„ä»»åŠ¡ã€‚SGGä½œä¸ºä¸‹æ¸¸ä»»åŠ¡çš„åŸºç¡€ç»„ä»¶ï¼Œå¦‚åœ¨å®ä½“ä»£ç†ä¸­è¿›è¡Œæ¨ç†ï¼Œæ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ã€‚ä¸ºäº†å®ç°å®æ—¶åº”ç”¨ï¼ŒSGGå¿…é¡»è§£å†³æ€§èƒ½ä¸æ¨ç†é€Ÿåº¦ä¹‹é—´çš„æƒè¡¡ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ–¹æ³•å¾€å¾€ä¾§é‡äºä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼šï¼ˆ1ï¼‰æé«˜å…³ç³»é¢„æµ‹ç²¾åº¦ï¼Œï¼ˆ2ï¼‰æé«˜å¯¹è±¡æ£€æµ‹ç²¾åº¦ï¼Œæˆ–ï¼ˆ3ï¼‰é™ä½å»¶è¿Ÿï¼Œè€Œæ²¡æœ‰åŒæ—¶ç„å‡†å¹³è¡¡è¿™ä¸‰ä¸ªç›®æ ‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†åœºæ™¯å›¾ç”Ÿæˆä¸­çš„å®æ—¶æ•ˆç‡ä¸ç²¾åº¦æƒè¡¡ï¼ˆREACTï¼‰æ¶æ„ã€‚è¯¥æ¶æ„å®ç°äº†ç°æœ‰SGGæ¨¡å‹ä¸­æœ€é«˜çš„æ¨ç†é€Ÿåº¦ï¼Œæé«˜äº†å¯¹è±¡æ£€æµ‹ç²¾åº¦ï¼ŒåŒæ—¶ä¸ç‰ºç‰²å…³ç³»é¢„æµ‹æ€§èƒ½ã€‚ä¸æœ€æ–°æ–¹æ³•ç›¸æ¯”ï¼ŒREACTçš„é€Ÿåº¦æé«˜äº†2.7å€ï¼Œå¯¹è±¡æ£€æµ‹ç²¾åº¦æé«˜äº†58%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ææ¡ˆè¿˜æ˜¾è‘—å‡å°‘äº†æ¨¡å‹å¤§å°ï¼Œå‚æ•°å¹³å‡å‡å°‘äº†5.5å€ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Maelic/SGG-Benchmark%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Maelic/SGG-Benchmarkæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.16116v3">PDF</a> Accepted at the 2025 British Machine Vision Conference (BMVC)</p>
<p><strong>Summary</strong><br>     åœºæ™¯å›¾ç”Ÿæˆï¼ˆSGGï¼‰æ˜¯ç¼–ç å›¾åƒä¸­å¯¹è±¡ä¹‹é—´è§†è§‰å…³ç³»ä½œä¸ºå›¾ç»“æ„çš„ä»»åŠ¡ã€‚å®ƒä½œä¸ºä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚æ™ºèƒ½ä½“æ¨ç†ï¼‰çš„åŸºç¡€ç»„ä»¶ï¼Œå…·æœ‰å·¨å¤§æ½œåŠ›ã€‚ä¸ºäº†å®æ—¶åº”ç”¨ï¼ŒSGGå¿…é¡»åœ¨æ€§èƒ½ä¸æ¨ç†é€Ÿåº¦ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚å½“å‰æ–¹æ³•å¾€å¾€ä¾§é‡äºæ”¹è¿›å…³ç³»é¢„æµ‹å‡†ç¡®æ€§ã€æé«˜å¯¹è±¡æ£€æµ‹å‡†ç¡®æ€§æˆ–é™ä½å»¶è¿Ÿï¼Œè€Œæ²¡æœ‰åŒæ—¶å¹³è¡¡è¿™ä¸‰ä¸ªç›®æ ‡ã€‚ä¸ºè§£å†³æ­¤å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†å®æ—¶æ•ˆç‡å’Œå‡†ç¡®æ€§å¦¥åçš„åœºæ™¯å›¾ç”Ÿæˆï¼ˆREACTï¼‰æ¶æ„ï¼Œå®ƒåœ¨ç°æœ‰SGGæ¨¡å‹ä¸­å®ç°äº†æœ€é«˜çš„æ¨ç†é€Ÿåº¦ï¼Œæé«˜äº†å¯¹è±¡æ£€æµ‹å‡†ç¡®æ€§ï¼Œä¸ç‰ºç‰²å…³ç³»é¢„æµ‹æ€§èƒ½ã€‚ä¸æœ€æ–°æ–¹æ³•ç›¸æ¯”ï¼ŒREACTé€Ÿåº¦æ›´å¿«ï¼ˆå¿«2.7å€ï¼‰ï¼Œå¯¹è±¡æ£€æµ‹å‡†ç¡®æ€§æé«˜äº†58%ï¼Œä¸”æ˜¾è‘—å‡å°‘äº†æ¨¡å‹å¤§å°ï¼ˆå¹³å‡å‡å°‘5.5å€å‚æ•°ï¼‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åœºæ™¯å›¾ç”Ÿæˆï¼ˆSGGï¼‰æ˜¯ç¼–ç å›¾åƒä¸­å¯¹è±¡é—´è§†è§‰å…³ç³»çš„ä»»åŠ¡ï¼Œå¯¹ä¸‹æ¸¸ä»»åŠ¡å¦‚æ™ºèƒ½ä½“æ¨ç†æœ‰é‡è¦ä½œç”¨ã€‚</li>
<li>SGGé¢ä¸´å®æ—¶åº”ç”¨ä¸­æ€§èƒ½ä¸æ¨ç†é€Ÿåº¦çš„æƒè¡¡é—®é¢˜ã€‚</li>
<li>å½“å‰SGGæ–¹æ³•å¾€å¾€åªå…³æ³¨å…³ç³»é¢„æµ‹å‡†ç¡®æ€§ã€å¯¹è±¡æ£€æµ‹å‡†ç¡®æ€§æˆ–é™ä½å»¶è¿Ÿä¸­çš„ä¸€ä¸ªæ–¹é¢ï¼Œæœªèƒ½å…¨é¢å¹³è¡¡ã€‚</li>
<li>æå‡ºREACTæ¶æ„ï¼Œå®ç°äº†é«˜æ¨ç†é€Ÿåº¦ï¼Œæé«˜äº†å¯¹è±¡æ£€æµ‹å‡†ç¡®æ€§ï¼Œä¸”ä¸ç‰ºç‰²å…³ç³»é¢„æµ‹æ€§èƒ½ã€‚</li>
<li>REACTç›¸æ¯”ç°æœ‰SGGæ¨¡å‹ï¼Œé€Ÿåº¦æ›´å¿«ï¼ˆå¿«2.7å€ï¼‰ï¼Œå¯¹è±¡æ£€æµ‹å‡†ç¡®æ€§æ›´é«˜ï¼ˆæé«˜58%ï¼‰ã€‚</li>
<li>REACTæ˜¾è‘—å‡å°‘äº†æ¨¡å‹å¤§å°ï¼ˆå¹³å‡å‡å°‘5.5å€å‚æ•°ï¼‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.16116">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-f2c589b8ad67f655e6dd339bd4511607~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687843&auth_key=1760687843-0-0-57f9bd1ba513be2ea5b17f7cd9db701a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8abe53e1f7aa118053768ca8f6d64be9~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687850&auth_key=1760687850-0-0-487e66c624abbc14487c6b15d8ed8cd3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1bbdff50e5089cc81f22d7a59febb084~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687857&auth_key=1760687857-0-0-5dc29dc52bc4aa52fb1256e2fe305118&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2b0fa315de3367763f69cad184303b98~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687864&auth_key=1760687864-0-0-96f0c88517f4b7c9f6ac4cb4794f8c42&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-28/Interactive/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-28/Interactive/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Interactive/">
                                    <span class="chip bg-color">Interactive</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-28/Text-to-Motion/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-de546a7ff7271e54e5b757ded3773989~resize:0:q75.jpg?source=1f5c5e47&expiration=1760687870&auth_key=1760687870-0-0-d233a056a19109227fd587c7845cb09b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Text-to-Motion">
                        
                        <span class="card-title">Text-to-Motion</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Text-to-Motion æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-28  Lagrangian Motion Fields for Long-term Motion Generation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Text-to-Motion/" class="post-category">
                                    Text-to-Motion
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Text-to-Motion/">
                        <span class="chip bg-color">Text-to-Motion</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-28/TTS/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-e607b8f83468f4baea55d969f7d47e58~resize:0:q75.jpg?source=1f5c5e47&expiration=1760040003&auth_key=1760040003-0-0-59d9c6317775f1e319e369f811dc9bd4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-28  UniSS Unified Expressive Speech-to-Speech Translation with Your Voice
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32102k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
