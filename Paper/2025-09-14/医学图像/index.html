<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-14  On the Encapsulation of Medical Imaging AI Algorithms">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2504.07134v2/page_0_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-14
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-07
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    11.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    47 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-14-æ›´æ–°"><a href="#2025-09-14-æ›´æ–°" class="headerlink" title="2025-09-14 æ›´æ–°"></a>2025-09-14 æ›´æ–°</h1><h2 id="On-the-Encapsulation-of-Medical-Imaging-AI-Algorithms"><a href="#On-the-Encapsulation-of-Medical-Imaging-AI-Algorithms" class="headerlink" title="On the Encapsulation of Medical Imaging AI Algorithms"></a>On the Encapsulation of Medical Imaging AI Algorithms</h2><p><strong>Authors:Hans Meine, Yongli Mou, Guido Prause, Horst Hahn</strong></p>
<p>In the context of collaborative AI research and development projects, it would be ideal to have self-contained encapsulated algorithms that can be easily shared between different parties, executed and validated on data at different sites, or trained in a federated manner. In practice, all of this is possible but greatly complicated, because human supervision and expert knowledge is needed to set up the execution of algorithms based on their documentation, possibly implicit assumptions, and knowledge about the execution environment and data involved.   We derive and formulate a range of detailed requirements from the above goal and from specific use cases, focusing on medical imaging AI algorithms. Furthermore, we refer to a number of existing APIs and implementations and review which aspects each of them addresses, which problems are still open, and which public standards and ontologies may be relevant. Our contribution is a comprehensive collection of aspects that have not yet been addressed in their entirety by any single solution.   Working towards the formulated goals should lead to more sustainable algorithm ecosystems and relates to the FAIR principles for research data, where this paper focuses on interoperability and (re)usability of medical imaging AI algorithms. </p>
<blockquote>
<p>åœ¨åä½œå¼äººå·¥æ™ºèƒ½ç ”ç©¶å’Œå‘å±•é¡¹ç›®çš„èƒŒæ™¯ä¸‹ï¼Œæ‹¥æœ‰èƒ½å¤Ÿç‹¬ç«‹äºä¸åŒæ–¹å…±äº«ã€åœ¨ä¸åŒç«™ç‚¹æ•°æ®ä¸Šæ‰§è¡Œå’ŒéªŒè¯ï¼Œæˆ–ä»¥è”é‚¦æ–¹å¼è®­ç»ƒçš„è‡ªä¸»å°è£…ç®—æ³•å°†æ˜¯æœ€ç†æƒ³çš„ã€‚åœ¨å®è·µä¸­ï¼Œæ‰€æœ‰è¿™äº›éƒ½æ˜¯å¯èƒ½çš„ï¼Œä½†éå¸¸å¤æ‚ï¼Œå› ä¸ºéœ€è¦æ ¹æ®ç®—æ³•æ–‡æ¡£ã€å¯èƒ½çš„éšå«å‡è®¾ä»¥åŠæ‰§è¡Œç¯å¢ƒå’Œæ¶‰åŠæ•°æ®çš„äº†è§£æ¥è®¾ç½®ç®—æ³•çš„æ‰§è¡Œï¼Œè¿™éœ€è¦äººå·¥ç›‘ç£å’Œä¸“ä¸šçŸ¥è¯†ã€‚æˆ‘ä»¬ä»ä¸Šè¿°ç›®æ ‡å’Œå…·ä½“ç”¨ä¾‹ä¸­å¾—å‡ºå¹¶åˆ¶å®šäº†è¯¦ç»†çš„è¦æ±‚ï¼Œé‡ç‚¹å…³æ³¨åŒ»å­¦å½±åƒAIç®—æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‚è€ƒäº†è®¸å¤šç°æœ‰çš„APIå’Œå®ç°ï¼Œå¹¶å›é¡¾äº†å®ƒä»¬å„è‡ªè§£å†³çš„æ–¹é¢ã€ä»ç„¶å­˜åœ¨çš„é—®é¢˜ä»¥åŠå¯èƒ½çš„å…¬å…±æ ‡å‡†å’Œæœ¬ä½“ã€‚æˆ‘ä»¬çš„è´¡çŒ®æ˜¯å…¨é¢æ”¶é›†äº†å°šæœªè¢«ä»»ä½•å•ä¸€è§£å†³æ–¹æ¡ˆå®Œå…¨è§£å†³çš„æ–¹é¢ã€‚æœç€æ—¢å®šç›®æ ‡åŠªåŠ›åº”è¯¥ä¼šå¯¼è‡´æ›´å¯æŒç»­çš„ç®—æ³•ç”Ÿæ€ç³»ç»Ÿï¼Œå¹¶ä¸ç ”ç©¶æ•°æ®çš„FAIRåŸåˆ™ç›¸å…³ï¼Œæœ¬è®ºæ–‡çš„é‡ç‚¹æ˜¯åŒ»å­¦å½±åƒAIç®—æ³•çš„äº’æ“ä½œæ€§å’Œï¼ˆé‡æ–°ï¼‰ä½¿ç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21412v2">PDF</a> v2: mention FAIR4ML, MLentory, some minor elaboration and spelling   fixes</p>
<p><strong>Summary</strong></p>
<p>åœ¨åä½œå¼äººå·¥æ™ºèƒ½ç ”ç©¶ä¸å‘å±•é¡¹ç›®ä¸­ï¼Œç†æƒ³çŠ¶æ€æ˜¯æ‹¥æœ‰å¯è‡ªæˆ‘å°è£…çš„ç®—æ³•ï¼Œæ˜“äºåœ¨ä¸åŒå›¢é˜Ÿé—´å…±äº«ã€æ‰§è¡Œå’ŒéªŒè¯æ•°æ®ï¼Œæˆ–è¿›è¡Œè”é‚¦å¼è®­ç»ƒã€‚ä½†åœ¨å®è·µä¸­ï¼Œå®ç°è¿™ä¸€åˆ‡æä¸ºå¤æ‚ï¼Œéœ€è¦äººå·¥ç›‘ç£ä¸ä¸“ä¸šçŸ¥è¯†æ¥æ ¹æ®æ–‡æ¡£ã€éšå«å‡è®¾ã€æ‰§è¡Œç¯å¢ƒä¸ç›¸å…³æ•°æ®è®¾ç½®ç®—æ³•æ‰§è¡Œã€‚æœ¬æ–‡ç”±æ­¤ç›®æ ‡åŠå…·ä½“ç”¨ä¾‹å‡ºå‘ï¼Œæ¨å¯¼å‡ºè¯¦å°½çš„éœ€æ±‚ï¼Œå¹¶é’ˆå¯¹åŒ»å­¦æˆåƒäººå·¥æ™ºèƒ½ç®—æ³•è¿›è¡Œæ·±å…¥æ¢è®¨ã€‚åŒæ—¶ï¼Œæœ¬æ–‡å›é¡¾äº†ç°æœ‰APIå’Œå®æ–½æ–¹æ¡ˆçš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶æŒ‡å‡ºäº†å°šæœªè§£å†³çš„é—®é¢˜å’Œå¯èƒ½çš„å…¬å…±æ ‡å‡†åŠæœ¬ä½“è®ºå…³è”ã€‚æœ¬æ–‡çš„è´¡çŒ®åœ¨äºå…¨é¢æ€»ç»“äº†ç›®å‰å°šæœªè¢«å•ä¸€è§£å†³æ–¹æ¡ˆå®Œå…¨è§£å†³çš„é—®é¢˜ã€‚æœç€æ—¢å®šç›®æ ‡åŠªåŠ›å°†ä¿ƒè¿›ç®—æ³•ç”Ÿæ€çš„å¯æŒç»­å‘å±•ï¼Œå¹¶ç¬¦åˆç ”ç©¶æ•°æ®çš„FAIRåŸåˆ™ï¼Œé‡ç‚¹æå‡åŒ»å­¦æˆåƒAIç®—æ³•çš„äº’é€šæ€§å’Œå¯å¤ç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç†æƒ³çŠ¶æ€æ˜¯æ‹¥æœ‰å¯è‡ªæˆ‘å°è£…çš„ç®—æ³•ï¼Œä¾¿äºåœ¨åä½œå¼AIé¡¹ç›®ä¸­çš„å…±äº«ã€æ‰§è¡Œå’ŒéªŒè¯ã€‚</li>
<li>å®ç°è¿™ä¸€ç†æƒ³çŠ¶æ€éœ€è¦äººå·¥ç›‘ç£ä¸ä¸“ä¸šçŸ¥è¯†æ¥æ­£ç¡®è®¾ç½®ç®—æ³•æ‰§è¡Œã€‚</li>
<li>æœ¬æ–‡ä»å…·ä½“ç”¨ä¾‹å‡ºå‘ï¼Œæ¨å¯¼å‡ºå…³äºåŒ»å­¦æˆåƒAIç®—æ³•çš„è¯¦å°½éœ€æ±‚ã€‚</li>
<li>ç°æœ‰APIå’Œå®æ–½æ–¹æ¡ˆçš„ä¼˜ç¼ºç‚¹å¾—åˆ°äº†å›é¡¾ã€‚</li>
<li>å°šæœªè§£å†³çš„é—®é¢˜å’Œå¯èƒ½çš„å…¬å…±æ ‡å‡†åŠæœ¬ä½“è®ºå…³è”è¢«æŒ‡å‡ºã€‚</li>
<li>æœ¬æ–‡ä¸ºåŒ»å­¦æˆåƒAIç®—æ³•é¢†åŸŸå…¨é¢æ€»ç»“äº†å°šæœªè¢«è§£å†³çš„é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21412">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2504.21412v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2504.21412v2/page_1_0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Bringing-Attention-to-CAD-Boundary-Representation-Learning-via-Transformer"><a href="#Bringing-Attention-to-CAD-Boundary-Representation-Learning-via-Transformer" class="headerlink" title="Bringing Attention to CAD: Boundary Representation Learning via   Transformer"></a>Bringing Attention to CAD: Boundary Representation Learning via   Transformer</h2><p><strong>Authors:Qiang Zou, Lizhen Zhu</strong></p>
<p>The recent rise of generative artificial intelligence (AI), powered by Transformer networks, has achieved remarkable success in natural language processing, computer vision, and graphics. However, the application of Transformers in computer-aided design (CAD), particularly for processing boundary representation (B-rep) models, remains largely unexplored. To bridge this gap, we propose a novel approach for adapting Transformers to B-rep learning, called the Boundary Representation Transformer (BRT). B-rep models pose unique challenges due to their irregular topology and continuous geometric definitions, which are fundamentally different from the structured and discrete data Transformers are designed for. To address this, BRT proposes a continuous geometric embedding method that encodes B-rep surfaces (trimmed and untrimmed) into Bezier triangles, preserving their shape and continuity without discretization. Additionally, BRT employs a topology-aware embedding method that organizes these geometric embeddings into a sequence of discrete tokens suitable for Transformers, capturing both geometric and topological characteristics within B-rep models. This enables the Transformerâ€™s attention mechanism to effectively learn shape patterns and contextual semantics of boundary elements in a B-rep model. Extensive experiments demonstrate that BRT achieves state-of-the-art performance in part classification and feature recognition tasks. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œä»¥Transformerç½‘ç»œä¸ºé©±åŠ¨çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦é¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚ç„¶è€Œï¼ŒTransformeråœ¨è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰ä¸­çš„åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†è¾¹ç•Œè¡¨ç¤ºï¼ˆB-repï¼‰æ¨¡å‹æ–¹é¢ï¼Œä»è¢«å¤§å¤§å¿½è§†ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„é€‚åº”Transformerç”¨äºB-repå­¦ä¹ çš„æ–¹æ³•ï¼Œç§°ä¸ºè¾¹ç•Œè¡¨ç¤ºè½¬æ¢å™¨ï¼ˆBRTï¼‰ã€‚ç”±äºB-repæ¨¡å‹å…·æœ‰ä¸è§„åˆ™æ‹“æ‰‘å’Œè¿ç»­å‡ ä½•å®šä¹‰çš„ç‰¹ç‚¹ï¼Œä¸ä¼ ç»Ÿçš„ä¸ºç»“æ„åŒ–ç¦»æ•£æ•°æ®è®¾è®¡çš„Transformerå­˜åœ¨æ ¹æœ¬å·®å¼‚ï¼Œå› æ­¤æ„æˆäº†ç‹¬ç‰¹çš„æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼ŒBRTæå‡ºäº†ä¸€ç§è¿ç»­å‡ ä½•åµŒå…¥æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†B-repè¡¨é¢ï¼ˆä¿®å‰ªå’Œæœªä¿®å‰ªï¼‰ç¼–ç ä¸ºBezierä¸‰è§’å½¢ï¼Œåœ¨ä¿æŒå…¶å½¢çŠ¶å’Œè¿ç»­æ€§çš„åŒæ—¶æ— éœ€ç¦»æ•£åŒ–ã€‚æ­¤å¤–ï¼ŒBRTè¿˜é‡‡ç”¨äº†ä¸€ç§æ‹“æ‰‘æ„ŸçŸ¥åµŒå…¥æ–¹æ³•ï¼Œå°†è¿™äº›å‡ ä½•åµŒå…¥ç»„ç»‡æˆé€‚åˆTransformerçš„ç¦»æ•£ä»¤ç‰Œåºåˆ—ï¼Œæ•è·B-repæ¨¡å‹ä¸­çš„å‡ ä½•å’Œæ‹“æ‰‘ç‰¹å¾ã€‚è¿™ä½¿å¾—Transformerçš„æ³¨æ„åŠ›æœºåˆ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ B-repæ¨¡å‹ä¸­è¾¹ç•Œå…ƒç´ çš„å½¢çŠ¶æ¨¡å¼å’Œä¸Šä¸‹æ–‡è¯­ä¹‰ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒBRTåœ¨é›¶ä»¶åˆ†ç±»å’Œç‰¹å¾è¯†åˆ«ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.07134v2">PDF</a> </p>
<p><strong>Summary</strong><br>     åŸºäºTransformerç½‘ç»œçš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦ç­‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†åœ¨è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰ä¸­çš„åº”ç”¨ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†è¾¹ç•Œè¡¨ç¤ºï¼ˆB-repï¼‰æ¨¡å‹æ–¹é¢ä»é²œæœ‰æ¢ç´¢ã€‚ä¸ºå¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæå‡ºäº†é€‚åº”B-repå­¦ä¹ çš„å…¨æ–°æ–¹æ³•â€”â€”è¾¹ç•Œè¡¨ç¤ºè½¬æ¢å™¨ï¼ˆBRTï¼‰ã€‚BRTé€šè¿‡è¿ç»­å‡ ä½•åµŒå…¥æ–¹æ³•ï¼Œå°†B-repæ¨¡å‹ï¼ˆæ— è®ºæ˜¯ä¿®å‰ªçš„è¿˜æ˜¯æœªä¿®å‰ªçš„ï¼‰ç¼–ç ä¸ºBezierä¸‰è§’å½¢ï¼Œä¿æŒå…¶å½¢çŠ¶å’Œè¿ç»­æ€§ï¼Œä¸”ä¸è¿›è¡Œç¦»æ•£åŒ–ã€‚æ­¤å¤–ï¼ŒBRTé‡‡ç”¨æ‹“æ‰‘æ„ŸçŸ¥åµŒå…¥æ–¹æ³•ï¼Œå°†è¿™äº›å‡ ä½•åµŒå…¥ç»„ç»‡æˆé€‚åˆTransformerçš„ç¦»æ•£ä»¤ç‰Œåºåˆ—ï¼ŒåŒæ—¶æ•æ‰B-repæ¨¡å‹ä¸­çš„å‡ ä½•å’Œæ‹“æ‰‘ç‰¹å¾ã€‚è¿™ä½¿å¾—Transformerçš„æ³¨æ„åŠ›æœºåˆ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ B-repæ¨¡å‹ä¸­è¾¹ç•Œå…ƒç´ çš„å½¢çŠ¶æ¨¡å¼å’Œä¸Šä¸‹æ–‡è¯­ä¹‰ã€‚å®éªŒè¡¨æ˜ï¼ŒBRTåœ¨é›¶ä»¶åˆ†ç±»å’Œç‰¹å¾è¯†åˆ«ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åœ¨å¤šä¸ªé¢†åŸŸå–å¾—æ˜¾è‘—æˆåŠŸï¼Œä½†åœ¨è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰ä¸­çš„B-repæ¨¡å‹å¤„ç†æ–¹é¢å­˜åœ¨ç©ºç™½ã€‚</li>
<li>è¾¹ç•Œè¡¨ç¤ºè½¬æ¢å™¨ï¼ˆBRTï¼‰æ˜¯é€‚åº”B-repå­¦ä¹ çš„å…¨æ–°æ–¹æ³•ã€‚</li>
<li>BRTé€šè¿‡è¿ç»­å‡ ä½•åµŒå…¥æ–¹æ³•å¤„ç†B-repæ¨¡å‹ï¼Œä¿æŒå…¶å½¢çŠ¶å’Œè¿ç»­æ€§ï¼Œä¸è¿›è¡Œç¦»æ•£åŒ–ã€‚</li>
<li>BRTé‡‡ç”¨æ‹“æ‰‘æ„ŸçŸ¥åµŒå…¥æ–¹æ³•ï¼Œå°†å‡ ä½•åµŒå…¥è½¬åŒ–ä¸ºé€‚åˆTransformerçš„ç¦»æ•£ä»¤ç‰Œåºåˆ—ã€‚</li>
<li>BRTèƒ½å¤Ÿæ•æ‰B-repæ¨¡å‹ä¸­çš„å‡ ä½•å’Œæ‹“æ‰‘ç‰¹å¾ã€‚</li>
<li>Transformerçš„æ³¨æ„åŠ›æœºåˆ¶èƒ½æœ‰æ•ˆå­¦ä¹ B-repæ¨¡å‹ä¸­è¾¹ç•Œå…ƒç´ çš„å½¢çŠ¶æ¨¡å¼å’Œä¸Šä¸‹æ–‡è¯­ä¹‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.07134">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2504.07134v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2504.07134v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2504.07134v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2504.07134v2/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2504.07134v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Core-Excited-States-of-Linear-and-Bent-Uranyl-Complexes-Insights-from-High-Energy-Resolution-X-ray-Spectroscopy-and-Relativistic-Quantum-Chemistry"><a href="#Core-Excited-States-of-Linear-and-Bent-Uranyl-Complexes-Insights-from-High-Energy-Resolution-X-ray-Spectroscopy-and-Relativistic-Quantum-Chemistry" class="headerlink" title="Core-Excited States of Linear and Bent Uranyl Complexes: Insights from   High-Energy Resolution X-ray Spectroscopy and Relativistic Quantum Chemistry"></a>Core-Excited States of Linear and Bent Uranyl Complexes: Insights from   High-Energy Resolution X-ray Spectroscopy and Relativistic Quantum Chemistry</h2><p><strong>Authors:Wilken Aldair Misael, Lucia Amidani, Juliane MÃ¤rz, Elena F. Bazarkina, Kristina O. Kvashnina, ValÃ©rie Vallet, AndrÃ© Severo Pereira Gomes</strong></p>
<p>Advanced X-ray spectroscopic techniques are widely recognized as state-of-the-art tools for probing the electronic structure, bonding, and chemical environments of the heaviest elements in the periodic table. In this study, we employ X-ray absorption near-edge structure measurements in high-energy resolution fluorescence detection (HERFD-XANES) mode to investigate the core states arising from excitations out of the U 3d${_{3&#x2F;2}}$ (M$_4$ edge) levels for molecular complexes in which the uranyl moiety deviates from linearity to varying degrees, and in particular systems containing the UO$_2$Cl$_2$ group such as UO$_2$Cl$_2$.n(H$_2$O) and UO$_2$Cl$_2$(phen)$_2$, which in the latter case exhibits a pronounced O-U-O bending angle. These U M$_4$ edge HERFD-XANES spectra are compared to those of other uranyl complexes reported in the literature. This evaluation is complemented by \textit{ab initio} relativistic quantum chemistry simulations on the [UO$_2$(NO$_3$)$_2$.n(H$_2$O)], UO$_2$Cl$_2$.n(H$_2$O) and UO$_2$Cl$_2$(phen)$_2$ systems, using 2-component Time-Dependent Density Functional Theory (TD-DFT) with the CAM-B3LYP functional, employing the Tamm-Dancoff approximation (2c-TDA). Our 2c-TDA simulations show modest deviations from the HERFD-XANES data, with peak splittings differing by less than 1 eV from experimental values. These core-excited states were further characterized by Natural Transition Orbital (NTO) analysis. Overall, our results highlight the influence of equatorial ligands on the spectroscopic signatures, particularly pronounced in UO$_2$Cl$_2$(phen)$<em>2$, where the U 3d$</em>{3&#x2F;2}$ $\rightarrow$ 5f$\sigma_u^*$ satellite transition appears at lower energies compared to the other systems studied. </p>
<blockquote>
<p>å…ˆè¿›çš„Xå°„çº¿å…‰è°±æŠ€æœ¯è¢«å¹¿æ³›è®¤ä¸ºæ˜¯æ¢ç´¢å‘¨æœŸè¡¨ä¸­é‡å…ƒç´ çš„ç”µå­ç»“æ„ã€é”®åˆå’ŒåŒ–å­¦ç¯å¢ƒçš„æœ€å‰æ²¿å·¥å…·ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨é«˜èƒ½é‡åˆ†è¾¨ç‡è§å…‰æ£€æµ‹ï¼ˆHERFDï¼‰æ¨¡å¼ä¸‹çš„Xå°„çº¿å¸æ”¶è¿‘è¾¹ç¼˜ç»“æ„æµ‹é‡æ³•ï¼Œç ”ç©¶åç¦»çº¿æ€§çš„é“€é…°åˆ†å­å¤åˆç‰©çš„æ ¸å¿ƒçŠ¶æ€ï¼Œç‰¹åˆ«æ˜¯å«æœ‰UO2Cl2åŸºå›¢çš„ç³»ç»Ÿï¼Œå¦‚UO2Cl2.nï¼ˆH2Oï¼‰å’ŒUO2Cl2ï¼ˆphenï¼‰2ã€‚åœ¨åä¸€ç§æƒ…å†µä¸‹ï¼Œè¡¨ç°å‡ºæ˜æ˜¾çš„O-U-Oå¼¯æ›²è§’ã€‚å°†è¿™äº›UM4è¾¹ç¼˜çš„HERFD-XANESå…‰è°±ä¸æ–‡çŒ®ä¸­æŠ¥é“çš„å…¶ä»–é“€é…°å¤åˆç‰©çš„å…‰è°±è¿›è¡Œæ¯”è¾ƒã€‚æ­¤æ¬¡è¯„ä¼°è¾…ä»¥é’ˆå¯¹[UO2ï¼ˆNO3ï¼‰2.nï¼ˆH2Oï¼‰]ã€UO2Cl2.nï¼ˆH2Oï¼‰å’ŒUO2Cl2ï¼ˆphenï¼‰2ç³»ç»Ÿçš„ä»å¤´å¼€å§‹ç›¸å¯¹è®ºé‡å­åŒ–å­¦æ¨¡æ‹Ÿï¼Œä½¿ç”¨é‡‡ç”¨CAM-B3LYPåŠŸèƒ½çš„ä¸¤åˆ†é‡å«æ—¶å¯†åº¦æ³›å‡½ç†è®ºï¼ˆTD-DFTï¼‰ï¼Œå¹¶é‡‡ç”¨å¡”å§†-ä¸¹ç§‘å¤«è¿‘ä¼¼ï¼ˆ2c-TDAï¼‰ã€‚æˆ‘ä»¬çš„ä¸¤åˆ†é‡TDAæ¨¡æ‹Ÿä¸HERFD-XANESæ•°æ®å­˜åœ¨é€‚åº¦åå·®ï¼Œå³°å€¼åˆ†è£‚ä¸å®éªŒå€¼ç›¸å·®å°äº1ç”µå­ä¼ç‰¹ã€‚è¿™äº›æ ¸å¿ƒæ¿€å‘æ€è¿›ä¸€æ­¥é€šè¿‡è‡ªç„¶è¿‡æ¸¡è½¨é“ï¼ˆNTOï¼‰åˆ†æè¿›è¡Œè¡¨å¾ã€‚æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„ç»“æœçªå‡ºäº†èµ¤é“é…ä½“å¯¹å…‰è°±ç‰¹å¾çš„å½±å“ï¼Œç‰¹åˆ«æ˜¯åœ¨UO2Cl2ï¼ˆphenï¼‰2ä¸­å°¤ä¸ºæ˜æ˜¾ï¼Œå…¶ä¸­U 3d_{3&#x2F;2} â†’ 5fÏƒu*å«æ˜Ÿè·ƒè¿å‡ºç°åœ¨æ¯”å…¶ä»–ç³»ç»Ÿæ›´ä½çš„èƒ½é‡å¤„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.05542v3">PDF</a> 55 pages, 10 figures, 5 tables</p>
<p><strong>æ‘˜è¦</strong><br>     æœ¬ç ”ç©¶é‡‡ç”¨é«˜èƒ½é‡åˆ†è¾¨ç‡è§å…‰æ£€æµ‹ï¼ˆHERFD-XANESï¼‰æ¨¡å¼çš„Xå°„çº¿å¸æ”¶è¿‘è¾¹ç»“æ„æµ‹é‡æŠ€æœ¯ï¼Œé’ˆå¯¹ä¸åŒç¨‹åº¦åç¦»çº¿æ€§çš„é“€é…°åŸºå›¢åˆ†å­å¤åˆç‰©ï¼Œç‰¹åˆ«æ˜¯å«æœ‰UO2Cl2åŸºå›¢çš„ä½“ç³»ï¼Œå¦‚UO2Cl2Â·n(H2O)å’ŒUO2Cl2(phen)2ï¼Œè¿›è¡Œäº†æ ¸å¿ƒçŠ¶æ€çš„ç ”ç©¶ã€‚é€šè¿‡ä¸æ–‡çŒ®æŠ¥é“çš„å…¶ä»–é“€é…°å¤åˆç‰©è¿›è¡Œæ¯”è¾ƒï¼Œæœ¬ç ”ç©¶è¯„ä¼°äº†è¿™äº›ä½“ç³»çš„UM4è¾¹ç¼˜HERFD-XANESå…‰è°±ã€‚åŒæ—¶ï¼Œç»“åˆåŸºäºTD-DFTçš„ä»å¤´ç®—ç›¸å¯¹è®ºé‡å­åŒ–å­¦æ¨¡æ‹Ÿï¼Œå¯¹[UO2(NO3)2Â·n(H2O)]ã€UO2Cl2Â·n(H2O)å’ŒUO2Cl2(phen)2ä½“ç³»è¿›è¡Œäº†ç ”ç©¶ã€‚æ¨¡æ‹Ÿç»“æœä¸å®éªŒæ•°æ®ç•¥æœ‰åå·®ï¼Œå³°å€¼åˆ†è£‚ä¸å®éªŒå€¼ç›¸å·®ä¸åˆ°1 eVã€‚é€šè¿‡è‡ªç„¶è·ƒè¿è½¨é“ï¼ˆNTOï¼‰åˆ†æè¿›ä¸€æ­¥è¡¨å¾äº†è¿™äº›æ ¸å¿ƒæ¿€å‘æ€ã€‚ç»“æœè¡¨æ˜ï¼Œèµ¤é“é…ä½“å¯¹å…‰è°±ç‰¹å¾çš„å½±å“æ˜¾è‘—ï¼Œç‰¹åˆ«æ˜¯åœ¨UO2Cl2(phen)2ä½“ç³»ä¸­ï¼ŒU 3d_{3&#x2F;2} â†’ 5fÏƒu*å«æ˜Ÿè·ƒè¿å‡ºç°åœ¨è¾ƒä½èƒ½é‡å¤„ã€‚</p>
<p><strong>è¦ç‚¹å½’çº³</strong></p>
<ol>
<li>æœ¬ç ”ç©¶ä½¿ç”¨HERFD-XANESæŠ€æœ¯æ¢ç©¶äº†ä¸åŒç¨‹åº¦åç¦»çº¿æ€§çš„é“€é…°åŸºå›¢åˆ†å­å¤åˆç‰©çš„æ ¸å¿ƒçŠ¶æ€ã€‚</li>
<li>ç ”ç©¶å¯¹è±¡åŒ…æ‹¬å«æœ‰UO2Cl2åŸºå›¢çš„ä½“ç³»ï¼Œå¦‚UO2Cl2Â·n(H2O)å’ŒUO2Cl2(phen)2ã€‚</li>
<li>é€šè¿‡ä¸æ–‡çŒ®å¯¹æ¯”ï¼Œè¯„ä¼°äº†è¿™äº›ä½“ç³»çš„UM4è¾¹ç¼˜HERFD-XANESå…‰è°±ã€‚</li>
<li>ç»“åˆä»å¤´ç®—ç›¸å¯¹è®ºé‡å­åŒ–å­¦æ¨¡æ‹Ÿè¿›è¡Œç ”ç©¶ï¼Œä½¿ç”¨äº†TD-DFTæ–¹æ³•å’ŒCAM-B3LYPåŠŸèƒ½ã€‚</li>
<li>æ¨¡æ‹Ÿç»“æœä¸å®éªŒæ•°æ®ç•¥æœ‰åå·®ï¼Œä½†æ•´ä½“è¶‹åŠ¿ä¸€è‡´ã€‚</li>
<li>èµ¤é“é…ä½“å¯¹å…‰è°±ç‰¹å¾çš„å½±å“æ˜¾è‘—ï¼Œç‰¹åˆ«æ˜¯åœ¨UO2Cl2(phen)2ä½“ç³»ä¸­ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.05542">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2504.05542v3/page_0_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="In-Context-Reverse-Classification-Accuracy-Efficient-Estimation-of-Segmentation-Quality-without-Ground-Truth"><a href="#In-Context-Reverse-Classification-Accuracy-Efficient-Estimation-of-Segmentation-Quality-without-Ground-Truth" class="headerlink" title="In-Context Reverse Classification Accuracy: Efficient Estimation of   Segmentation Quality without Ground-Truth"></a>In-Context Reverse Classification Accuracy: Efficient Estimation of   Segmentation Quality without Ground-Truth</h2><p><strong>Authors:Matias Cosarinsky, Ramiro Billot, Lucas Mansilla, Gabriel Jimenez, Nicolas GaggiÃ³n, Guanghui Fu, Enzo Ferrante</strong></p>
<p>Assessing the quality of automatic image segmentation is crucial in clinical practice, but often very challenging due to the limited availability of ground truth annotations. In this paper, we introduce In-Context Reverse Classification Accuracy (In-Context RCA), a novel framework for automatically estimating segmentation quality in the absence of ground-truth annotations. By leveraging recent in-context learning segmentation models and incorporating retrieval-augmentation techniques to select the most relevant reference images, our approach enables efficient quality estimation with minimal reference data. Validated across diverse medical imaging modalities, our method demonstrates robust performance and computational efficiency, offering a promising solution for automated quality control in clinical workflows, where fast and reliable segmentation assessment is essential. The code is available at <a target="_blank" rel="noopener" href="https://github.com/mcosarinsky/In-Context-RCA">https://github.com/mcosarinsky/In-Context-RCA</a>. </p>
<blockquote>
<p>åœ¨ä¸´åºŠå®è·µä¸­ï¼Œè¯„ä¼°è‡ªåŠ¨å›¾åƒåˆ†å‰²çš„è´¨é‡è‡³å…³é‡è¦ï¼Œä½†ç”±äºçœŸå®æ ‡æ³¨æ•°æ®çš„æœ‰é™æ€§ï¼Œè¿™å¸¸å¸¸æ˜¯ä¸€é¡¹éå¸¸å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†æ— çœŸå®æ ‡æ³¨æƒ…å†µä¸‹çš„è‡ªåŠ¨ä¼°è®¡åˆ†å‰²è´¨é‡çš„æ–°å‹æ¡†æ¶â€”â€”ä¸Šä¸‹æ–‡åå‘åˆ†ç±»å‡†ç¡®ç‡ï¼ˆIn-Context RCAï¼‰ã€‚æˆ‘ä»¬é€šè¿‡åˆ©ç”¨æœ€æ–°çš„ä¸Šä¸‹æ–‡å­¦ä¹ åˆ†å‰²æ¨¡å‹å’Œç»“åˆæ£€ç´¢å¢å¼ºæŠ€æœ¯æ¥é€‰æ‹©æœ€ç›¸å…³çš„å‚è€ƒå›¾åƒï¼Œä½¿å¾—åœ¨æå°‘å‚è€ƒæ•°æ®çš„æƒ…å†µä¸‹ä¹Ÿèƒ½å®ç°é«˜æ•ˆçš„è´¨é‡è¯„ä¼°ã€‚æˆ‘ä»¬çš„æ–¹æ³•å·²ç»é€šè¿‡ä¸åŒåŒ»å­¦å½±åƒæ¨¡æ€çš„éªŒè¯ï¼Œè¡¨ç°å‡ºäº†ç¨³å¥çš„æ€§èƒ½å’Œè®¡ç®—æ•ˆç‡ï¼Œä¸ºä¸´åºŠå·¥ä½œæµç¨‹ä¸­çš„è‡ªåŠ¨åŒ–è´¨é‡æ§åˆ¶æä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆï¼Œç‰¹åˆ«æ˜¯åœ¨å¿«é€Ÿå¯é çš„åˆ†å‰²è¯„ä¼°æ–¹é¢ã€‚ç›¸å…³ä»£ç å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/mcosarinsky/In-Context-RCA%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/mcosarinsky/In-Context-RCAè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.04522v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>åŒ»å­¦å›¾åƒè‡ªåŠ¨åˆ†å‰²è´¨é‡è¯„ä¼°åœ¨ä¸´åºŠå®è·µä¸­è‡³å…³é‡è¦ï¼Œä½†å—é™äºçœŸå®æ ‡æ³¨æ•°æ®çš„ç¨€ç¼ºæ€§ï¼Œè¯„ä¼°å·¥ä½œé¢‡å…·æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ— éœ€çœŸå®æ ‡æ³¨çš„è‡ªåŠ¨åˆ†å‰²è´¨é‡è¯„ä¼°æ–°æ¡†æ¶â€”â€”åŸºäºè¯­å¢ƒåå‘åˆ†ç±»å‡†ç¡®åº¦ï¼ˆIn-Context RCAï¼‰ã€‚é€šè¿‡é‡‡ç”¨æœ€æ–°çš„è¯­å¢ƒå­¦ä¹ åˆ†å‰²æ¨¡å‹å’Œæ£€ç´¢å¢å¼ºæŠ€æœ¯é€‰æ‹©æœ€ç›¸å…³çš„å‚è€ƒå›¾åƒï¼Œè¯¥æ–¹æ³•å¯åœ¨å°‘é‡å‚è€ƒæ•°æ®çš„æƒ…å†µä¸‹å®ç°é«˜æ•ˆçš„è´¨é‡è¯„ä¼°ã€‚åœ¨ä¸åŒåŒ»å­¦æˆåƒæ¨¡å¼ä¸‹è¿›è¡Œçš„éªŒè¯æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•å…·æœ‰ç¨³å¥çš„æ€§èƒ½å’Œè®¡ç®—æ•ˆç‡ï¼Œä¸ºä¸´åºŠå·¥ä½œæµç¨‹ä¸­çš„è‡ªåŠ¨åŒ–è´¨é‡æ§åˆ¶æä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¿«é€Ÿå¯é åˆ†å‰²è¯„ä¼°çš„æƒ…å†µä¸‹ã€‚ç›¸å…³ä»£ç å¯è®¿é—®<a target="_blank" rel="noopener" href="https://github.com/mcosarinsky/In-Context-RCA%E3%80%82">https://github.com/mcosarinsky/In-Context-RCAã€‚</a></p>
<p><strong>è¦ç‚¹æ‘˜è¦</strong></p>
<ul>
<li>è‡ªåŠ¨åˆ†å‰²è´¨é‡è¯„ä¼°åœ¨åŒ»å­¦å›¾åƒåˆ†æä¸­å…·æœ‰é‡è¦åœ°ä½ï¼Œä½†ç”±äºçœŸå®æ ‡æ³¨æ•°æ®çš„ç¨€ç¼ºæ€§è€Œé¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹è¯„ä¼°æ¡†æ¶In-Context RCAï¼Œæ— éœ€çœŸå®æ ‡æ³¨æ•°æ®ã€‚</li>
<li>èåˆæœ€æ–°çš„è¯­å¢ƒå­¦ä¹ åˆ†å‰²æ¨¡å‹å’Œæ£€ç´¢å¢å¼ºæŠ€æœ¯æ¥æå‡è´¨é‡è¯„ä¼°çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</li>
<li>æ–¹æ³•åœ¨å¤šç§åŒ»å­¦æˆåƒæ¨¡å¼ä¸‹è¡¨ç°ç¨³å¥ï¼Œå…·å¤‡é«˜æ•ˆè®¡ç®—æ•ˆç‡ã€‚</li>
<li>ä¸ºä¸´åºŠå®è·µä¸­è‡ªåŠ¨åŒ–è´¨é‡æ§åˆ¶æä¾›äº†åˆ‡å®å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.04522">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2503.04522v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2503.04522v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2503.04522v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Optimizing-normal-tissue-sparing-via-spatiotemporal-optimization-under-equivalent-tumor-radical-efficacy"><a href="#Optimizing-normal-tissue-sparing-via-spatiotemporal-optimization-under-equivalent-tumor-radical-efficacy" class="headerlink" title="Optimizing normal tissue sparing via spatiotemporal optimization under   equivalent tumor-radical efficacy"></a>Optimizing normal tissue sparing via spatiotemporal optimization under   equivalent tumor-radical efficacy</h2><p><strong>Authors:Nimita Shinde, Wangyao Li, Ronald C Chen, Hao Gao</strong></p>
<p>Objective: Spatiotemporal optimization in radiation therapy involves determining the optimal number of dose delivery fractions (temporal) and the optimal dose per fraction (spatial). Traditional approaches focus on maximizing the biologically effective dose (BED) to the target while constraining BED to organs-at-risk (OAR), which may lead to insufficient BED for complete tumor cell kill. This work proposes a formulation that ensures adequate BED delivery to the target while minimizing BED to the OAR. Approach: A spatiotemporal optimization model is developed that incorporates an inequality constraint to guarantee sufficient BED for tumor cell kill while minimizing BED to the OAR. The model accounts for tumor proliferation dynamics, including lag time (delay before proliferation begins) and doubling time (time for tumor volume to double), to optimize dose fractionation. Results: The performance of our formulation is evaluated for varying lag and doubling times. The results show that mean BED to the target consistently meets the minimum requirement for tumor cell kill. Additionally, the mean BED to OAR varies based on tumor proliferation dynamics. In the prostate case with lag time of 7 days and doubling time of 2 days, it is observed that mean BED delivered to femoral head is lowest at around 20 fractions, making this an optimal choice. While in the head-and-neck case, mean BED to OAR decreases as the number of fractions increases, suggesting that a higher number of fractions is optimal. Significance: A spatiotemporal optimization model is presented that minimizes BED to the OAR while ensuring sufficient BED for tumor cell kill. By incorporating tumor lag and doubling time, the approach identifies optimal number of fractions. This model can be extended to support hyperfractionation or accelerated fractionation strategies, offering a versatile tool for clinical treatment planning. </p>
<blockquote>
<p>ç›®æ ‡ï¼šæ”¾å°„æ²»ç–—ä¸­çš„æ—¶ç©ºä¼˜åŒ–æ¶‰åŠç¡®å®šæœ€ä½³ç»™è¯åˆ†æ•°ï¼ˆæ—¶é—´ï¼‰å’Œæ¯åˆ†æ•°çš„æœ€ä½³å‰‚é‡ï¼ˆç©ºé—´ï¼‰ã€‚ä¼ ç»Ÿæ–¹æ³•ä¾§é‡äºæœ€å¤§åŒ–ç›®æ ‡éƒ¨ä½çš„ç”Ÿç‰©æœ‰æ•ˆå‰‚é‡ï¼ˆBEDï¼‰ï¼ŒåŒæ—¶é™åˆ¶é£é™©å™¨å®˜ï¼ˆOARï¼‰çš„BEDï¼Œè¿™å¯èƒ½å¯¼è‡´å¯¹ç›®æ ‡éƒ¨ä½çš„BEDä¸è¶³ï¼Œæ— æ³•å®Œå…¨æ€æ­»è‚¿ç˜¤ç»†èƒã€‚è¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ç§å…¬å¼ï¼Œå¯ç¡®ä¿ç›®æ ‡éƒ¨ä½è·å¾—è¶³å¤Ÿçš„BEDï¼ŒåŒæ—¶æœ€å°åŒ–OARçš„BEDã€‚æ–¹æ³•ï¼šå¼€å‘äº†ä¸€ä¸ªæ—¶ç©ºä¼˜åŒ–æ¨¡å‹ï¼Œé€šè¿‡ä¸ç­‰å¼çº¦æŸç¡®ä¿è‚¿ç˜¤ç»†èƒæ€æ­»çš„BEDå……è¶³ï¼ŒåŒæ—¶æœ€å°åŒ–OARçš„BEDã€‚è¯¥æ¨¡å‹è€ƒè™‘äº†è‚¿ç˜¤å¢æ®–åŠ¨åŠ›å­¦ï¼ŒåŒ…æ‹¬æ½œä¼æœŸï¼ˆå¢æ®–å¼€å§‹å‰çš„å»¶è¿Ÿæ—¶é—´ï¼‰å’Œå€å¢æ—¶é—´ï¼ˆè‚¿ç˜¤ä½“ç§¯ç¿»å€æ‰€éœ€çš„æ—¶é—´ï¼‰ï¼Œä»¥ä¼˜åŒ–å‰‚é‡åˆ†å‰²ã€‚ç»“æœï¼šæˆ‘ä»¬çš„å…¬å¼é’ˆå¯¹ä¸åŒçš„æ½œä¼æœŸå’Œå€å¢æ—¶é—´è¿›è¡Œäº†æ€§èƒ½è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼Œç›®æ ‡éƒ¨ä½çš„å¹³å‡BEDå§‹ç»ˆè¾¾åˆ°è‚¿ç˜¤ç»†èƒæ€æ­»çš„æœ€ä½è¦æ±‚ã€‚æ­¤å¤–ï¼ŒOARçš„å¹³å‡BEDä¼šæ ¹æ®è‚¿ç˜¤å¢æ®–åŠ¨åŠ›å­¦è€Œå˜åŒ–ã€‚åœ¨å‰åˆ—è…ºæ¡ˆä¾‹ä¸­ï¼Œæ½œä¼æœŸä¸º7å¤©ï¼Œå€å¢æ—¶é—´ä¸º2å¤©çš„æƒ…å†µä¸‹ï¼Œè§‚å¯Ÿåˆ°è‚¡éª¨å¤´çš„å¹³å‡BEDåœ¨å¤§çº¦20ä¸ªåˆ†æ•°æ—¶æœ€ä½ï¼Œè¿™ä½¿å¾—å®ƒæˆä¸ºæœ€ä½³é€‰æ‹©ã€‚è€Œåœ¨å¤´é¢ˆæ¡ˆä¾‹ä¸­ï¼Œéšç€åˆ†æ•°çš„å¢åŠ ï¼ŒOARçš„å¹³å‡BEDä¸‹é™ï¼Œè¡¨æ˜åˆ†æ•°è¶Šå¤šè¶Šç†æƒ³ã€‚æ„ä¹‰ï¼šæå‡ºäº†ä¸€ç§æ—¶ç©ºä¼˜åŒ–æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ç¡®ä¿ç›®æ ‡éƒ¨ä½è·å¾—è¶³å¤Ÿçš„BEDï¼ŒåŒæ—¶æœ€å°åŒ–OARçš„BEDã€‚é€šè¿‡ç»“åˆè‚¿ç˜¤çš„æ½œä¼æœŸå’Œå€å¢æ—¶é—´ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç¡®å®šæœ€ä½³åˆ†æ•°ã€‚è¯¥æ¨¡å‹å¯æ‰©å±•åˆ°æ”¯æŒè¶…åˆ†å‰²æˆ–åŠ é€Ÿåˆ†å‰²ç­–ç•¥ï¼Œæˆä¸ºä¸´åºŠæ²»ç–—æ–¹æ¡ˆåˆ¶å®šçš„çµæ´»å·¥å…·ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.16333v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†æ”¾å°„æ²»ç–—ä¸­çš„æ—¶ç©ºä¼˜åŒ–é—®é¢˜ï¼Œæ—¨åœ¨ç¡®å®šæœ€ä½³å‰‚é‡äº¤ä»˜åˆ†æ•°ï¼ˆæ—¶é—´ï¼‰å’Œæ¯ä¸ªåˆ†æ•°çš„æœ€ä½³å‰‚é‡ï¼ˆç©ºé—´ï¼‰ã€‚ä¼ ç»Ÿæ–¹æ³•ä¾§é‡äºæœ€å¤§åŒ–ç›®æ ‡ç”Ÿç‰©æœ‰æ•ˆå‰‚é‡ï¼ˆBEDï¼‰ï¼ŒåŒæ—¶é™åˆ¶å±é™©å™¨å®˜ï¼ˆOARï¼‰çš„BEDï¼Œå¯èƒ½å¯¼è‡´ä¸è¶³ä»¥å®Œå…¨æ€æ­»è‚¿ç˜¤ç»†èƒã€‚æœ¬æ–‡æå‡ºä¸€ç§ç¡®ä¿ç›®æ ‡BEDå……è¶³å¹¶æœ€å°åŒ–OARçš„BEDçš„æ—¶ç©ºä¼˜åŒ–æ¨¡å‹ã€‚è¯¥æ¨¡å‹è€ƒè™‘äº†è‚¿ç˜¤å¢æ®–åŠ¨åŠ›å­¦ï¼ŒåŒ…æ‹¬æ½œä¼æœŸï¼ˆå¢æ®–å¼€å§‹å‰çš„å»¶è¿Ÿæ—¶é—´ï¼‰å’Œå€å¢æ—¶é—´ï¼ˆè‚¿ç˜¤ä½“ç§¯ç¿»å€çš„æ—¶é—´ï¼‰ï¼Œä»¥ä¼˜åŒ–å‰‚é‡åˆ†å‰²ã€‚è¯„ä»·æ¨¡å‹åœ¨ä¸åŒæ½œä¼æœŸå’Œå€å¢æ—¶é—´ä¸‹çš„è¡¨ç°ï¼Œç»“æœæ˜¾ç¤ºç›®æ ‡å¹³å‡BEDå§‹ç»ˆæ»¡è¶³è‚¿ç˜¤ç»†èƒæ€ç­çš„æœ€ä½è¦æ±‚ã€‚æ­¤å¤–ï¼ŒOARçš„å¹³å‡BEDä¼šæ ¹æ®è‚¿ç˜¤å¢æ®–åŠ¨åŠ›å­¦è€Œå˜åŒ–ã€‚åœ¨å‰åˆ—è…ºæ¡ˆä¾‹ä¸­ï¼Œå½“æ½œä¼æœŸä¸º7å¤©ï¼Œå€å¢æ—¶é—´ä¸º2å¤©æ—¶ï¼Œè‚¡éª¨å¤´çš„å¹³å‡BEDåœ¨å¤§çº¦20ä¸ªåˆ†æ•°æ—¶æœ€ä½ï¼Œè¿™æ˜¯æœ€ä½³é€‰æ‹©ã€‚åœ¨å¤´é¢ˆæ¡ˆä¾‹ä¸­ï¼Œéšç€åˆ†æ•°çš„å¢åŠ ï¼ŒOARçš„å¹³å‡BEDé™ä½ï¼Œè¡¨æ˜åˆ†æ•°æ›´é«˜æ˜¯æœ€ä½³çš„ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ—¶ç©ºä¼˜åŒ–æ¨¡å‹ï¼Œé€šè¿‡ç»“åˆè‚¿ç˜¤æ½œå‰æœŸå’Œå€å¢æ—¶é—´ç¡®å®šæœ€ä½³åˆ†å‰²æ¬¡æ•°ã€‚å®ƒèƒ½å¤Ÿå»¶é•¿å¯¹OARçš„BEDçš„åŒæ—¶ç¡®ä¿è‚¿ç˜¤ç»†èƒæ€ç­çš„å……è¶³BEDã€‚æ­¤æ¨¡å‹å¯æ”¯æŒè¶…åˆ†å‰²æˆ–åŠ é€Ÿåˆ†å‰²ç­–ç•¥ï¼Œä¸ºä¸´åºŠæ²»ç–—æ–¹æ¡ˆè®¾è®¡æä¾›çµæ´»å·¥å…·ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æ”¾å°„æ²»ç–—ä¸­çš„æ—¶ç©ºä¼˜åŒ–æ¶‰åŠç¡®å®šæœ€ä½³å‰‚é‡äº¤ä»˜åˆ†æ•°å’Œæ¯ä¸ªåˆ†æ•°çš„æœ€ä½³å‰‚é‡ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•å¯èƒ½ä¸è¶³ä»¥ä¿è¯å®Œå…¨æ€æ­»è‚¿ç˜¤ç»†èƒçš„BEDã€‚</li>
<li>æå‡ºçš„æ¨¡å‹ç¡®ä¿ç›®æ ‡çš„BEDå……è¶³å¹¶æœ€å°åŒ–å±é™©å™¨å®˜çš„BEDã€‚</li>
<li>æ¨¡å‹è€ƒè™‘äº†è‚¿ç˜¤å¢æ®–åŠ¨åŠ›å­¦ï¼ŒåŒ…æ‹¬æ½œä¼æœŸå’Œå€å¢æ—¶é—´ã€‚</li>
<li>åœ¨ä¸åŒçš„è‚¿ç˜¤æ¡ˆä¾‹ä¸­ï¼Œæœ€ä½³å‰‚é‡åˆ†å‰²ç­–ç•¥æœ‰æ‰€ä¸åŒã€‚</li>
<li>æ¨¡å‹å¯æ”¯æŒä¸åŒçš„å‰‚é‡åˆ†å‰²ç­–ç•¥ï¼Œä¸ºä¸´åºŠæ²»ç–—æ–¹æ¡ˆæä¾›çµæ´»æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.16333">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2502.16333v2/page_0_0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Frequency-Domain-Enhanced-U-Net-for-Low-Frequency-Information-Rich-Image-Segmentation-in-Surgical-and-Deep-Sea-Exploration-Robots"><a href="#Frequency-Domain-Enhanced-U-Net-for-Low-Frequency-Information-Rich-Image-Segmentation-in-Surgical-and-Deep-Sea-Exploration-Robots" class="headerlink" title="Frequency Domain Enhanced U-Net for Low-Frequency Information-Rich Image   Segmentation in Surgical and Deep-Sea Exploration Robots"></a>Frequency Domain Enhanced U-Net for Low-Frequency Information-Rich Image   Segmentation in Surgical and Deep-Sea Exploration Robots</h2><p><strong>Authors:Guohao Huo, Ruiting Dai, Jinliang Liu, Ling Shao, Hao Tang</strong></p>
<p>In deep-sea exploration and surgical robotics scenarios, environmental lighting and device resolution limitations often cause high-frequency feature attenuation. Addressing the differences in frequency band sensitivity between CNNs and the human visual system (mid-frequency sensitivity with low-frequency sensitivity surpassing high-frequency), we experimentally quantified the CNN contrast sensitivity function and proposed a wavelet adaptive spectrum fusion (WASF) method inspired by biological vision mechanisms to balance cross-frequency image features. Furthermore, we designed a perception frequency block (PFB) that integrates WASF to enhance frequency-domain feature extraction. Based on this, we developed the FE-UNet model, which employs a SAM2 backbone network and incorporates fine-tuned Hiera-Large modules to ensure segmentation accuracy while improving generalization capability. Experiments demonstrate that FE-UNet achieves state-of-the-art performance in cross-domain tasks such as marine organism segmentation and polyp segmentation, showcasing robust adaptability and significant application potential. The code will be released soon. </p>
<blockquote>
<p>åœ¨æ·±æµ·æ¢ç´¢å’Œæ‰‹æœ¯æœºå™¨äººåœºæ™¯ä¸­ï¼Œç¯å¢ƒç…§æ˜å’Œè®¾å¤‡åˆ†è¾¨ç‡çš„é™åˆ¶é€šå¸¸ä¼šå¯¼è‡´é«˜é¢‘ç‰¹å¾è¡°å‡ã€‚ä¸ºäº†è§£å†³å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’Œäººç±»è§†è§‰ç³»ç»Ÿä¹‹é—´åœ¨é¢‘ç‡å¸¦å®½æ•æ„Ÿæ€§ä¸Šçš„å·®å¼‚ï¼ˆä¸­é¢‘æ•æ„Ÿæ€§ä½äºä½é¢‘æ•æ„Ÿæ€§è€Œé«˜äºé«˜é¢‘ï¼‰ï¼Œæˆ‘ä»¬é€šè¿‡å®éªŒé‡åŒ–äº†CNNçš„å¯¹æ¯”æ•æ„Ÿåº¦å‡½æ•°ï¼Œå¹¶åŸºäºç”Ÿç‰©è§†è§‰æœºåˆ¶æå‡ºäº†ä¸€ç§å°æ³¢è‡ªé€‚åº”é¢‘è°±èåˆï¼ˆWASFï¼‰æ–¹æ³•æ¥å¹³è¡¡è·¨é¢‘ç‡çš„å›¾åƒç‰¹å¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæ„ŸçŸ¥é¢‘ç‡å—ï¼ˆPFBï¼‰ï¼Œå°†WASFé›†æˆå…¶ä¸­ï¼Œä»¥å¢å¼ºé¢‘ç‡åŸŸçš„ç‰¹å¾æå–ã€‚åŸºäºæ­¤ï¼Œæˆ‘ä»¬å¼€å‘äº†FE-UNetæ¨¡å‹ï¼Œè¯¥æ¨¡å‹é‡‡ç”¨SAM2ä¸»å¹²ç½‘ç»œï¼Œå¹¶èå…¥äº†ç²¾ç»†è°ƒæ•´è¿‡çš„Hiera-Largeæ¨¡å—ï¼Œä»¥ç¡®ä¿åˆ†å‰²ç²¾åº¦çš„åŒæ—¶æé«˜æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒFE-UNetåœ¨è·¨åŸŸä»»åŠ¡ï¼ˆå¦‚æµ·æ´‹ç”Ÿç‰©åˆ†å‰²å’Œæ¯è‚‰åˆ†å‰²ï¼‰ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½è¡¨ç°ï¼Œå±•ç°äº†å¼ºå¤§çš„é€‚åº”æ€§å’Œæ˜¾è‘—çš„åº”ç”¨æ½œåŠ›ã€‚ä»£ç å°†å¾ˆå¿«å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.03829v3">PDF</a> </p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒç ”ç©¶ä¸­ï¼Œé’ˆå¯¹æ·±æµ·æ¢ç´¢å’Œæ‰‹æœ¯æœºå™¨äººåœºæ™¯ä¸‹çš„ç¯å¢ƒç…§æ˜å’Œè®¾å¤‡åˆ†è¾¨ç‡é™åˆ¶å¯¼è‡´é«˜é¢‘ç‰¹å¾è¡°å‡é—®é¢˜ï¼Œé€šè¿‡å¯¹æ¯”CNNä¸äººç±»è§†è§‰ç³»ç»Ÿçš„é¢‘ç‡æ•æ„Ÿåº¦å·®å¼‚ï¼Œæå‡ºäº†åŸºäºç”Ÿç‰©è§†è§‰æœºåˆ¶çš„å°æ³¢è‡ªé€‚åº”é¢‘è°±èåˆï¼ˆWASFï¼‰æ–¹æ³•ï¼Œå¹¶è®¾è®¡äº†æ„ŸçŸ¥é¢‘ç‡å—ï¼ˆPFBï¼‰æ¥å¢å¼ºé¢‘ç‡åŸŸç‰¹å¾æå–ã€‚åœ¨æ­¤åŸºç¡€ä¸Šå¼€å‘çš„FE-UNetæ¨¡å‹ï¼Œç»“åˆäº†SAM2éª¨å¹²ç½‘ç»œå’Œç»è¿‡è°ƒä¼˜çš„Hiera-Largeæ¨¡å—ï¼Œæå‡äº†åˆ†å‰²å‡†ç¡®æ€§ä¸æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶åœ¨è·¨åŸŸä»»åŠ¡å¦‚æµ·æ´‹ç”Ÿç‰©åˆ†å‰²å’Œæ¯è‚‰åˆ†å‰²ä¸­å–å¾—æœ€ä½³æ€§èƒ½ï¼Œå±•ç°å‡ºå¼ºå¤§çš„é€‚åº”æ€§å’Œåº”ç”¨æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±æµ·æ¢ç´¢å’Œæ‰‹æœ¯æœºå™¨äººåœºæ™¯ä¸­ï¼Œç¯å¢ƒç…§æ˜å’Œè®¾å¤‡åˆ†è¾¨ç‡é™åˆ¶å¯¼è‡´é«˜é¢‘ç‰¹å¾è¡°å‡é—®é¢˜ã€‚</li>
<li>å¯¹æ¯”äº†CNNä¸äººç±»è§†è§‰ç³»ç»Ÿçš„é¢‘ç‡æ•æ„Ÿåº¦å·®å¼‚ï¼Œå‘ç°CNNå¯¹ä¸­é—´é¢‘ç‡çš„æ•æ„Ÿåº¦è¾ƒä½ã€‚</li>
<li>æå‡ºäº†åŸºäºç”Ÿç‰©è§†è§‰æœºåˆ¶çš„å°æ³¢è‡ªé€‚åº”é¢‘è°±èåˆï¼ˆWASFï¼‰æ–¹æ³•ï¼Œä»¥å¹³è¡¡è·¨é¢‘ç‡å›¾åƒç‰¹å¾ã€‚</li>
<li>è®¾è®¡äº†æ„ŸçŸ¥é¢‘ç‡å—ï¼ˆPFBï¼‰ä»¥å¢å¼ºé¢‘ç‡åŸŸç‰¹å¾æå–ã€‚</li>
<li>å¼€å‘FE-UNetæ¨¡å‹ï¼Œç»“åˆSAM2éª¨å¹²ç½‘ç»œå’Œç»è¿‡è°ƒä¼˜çš„Hiera-Largeæ¨¡å—ï¼Œæé«˜åˆ†å‰²å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>FE-UNetæ¨¡å‹åœ¨è·¨åŸŸä»»åŠ¡å¦‚æµ·æ´‹ç”Ÿç‰©åˆ†å‰²å’Œæ¯è‚‰åˆ†å‰²ä¸­å–å¾—æœ€ä½³æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.03829">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2502.03829v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2502.03829v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2502.03829v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2502.03829v3/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2502.03829v3/page_5_1.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Efficient-Deep-Learning-based-Forward-Solvers-for-Brain-Tumor-Growth-Models"><a href="#Efficient-Deep-Learning-based-Forward-Solvers-for-Brain-Tumor-Growth-Models" class="headerlink" title="Efficient Deep Learning-based Forward Solvers for Brain Tumor Growth   Models"></a>Efficient Deep Learning-based Forward Solvers for Brain Tumor Growth   Models</h2><p><strong>Authors:Zeineb Haouari, Jonas Weidner, Yeray Martin-Ruisanchez, Ivan Ezhov, Aswathi Varma, Daniel Rueckert, Bjoern Menze, Benedikt Wiestler</strong></p>
<p>Glioblastoma, a highly aggressive brain tumor, poses major challenges due to its poor prognosis and high morbidity rates. Partial differential equation-based models offer promising potential to enhance therapeutic outcomes by simulating patient-specific tumor behavior for improved radiotherapy planning. However, model calibration remains a bottleneck due to the high computational demands of optimization methods like Monte Carlo sampling and evolutionary algorithms. To address this, we recently introduced an approach leveraging a neural forward solver with gradient-based optimization to significantly reduce calibration time. This approach requires a highly accurate and fully differentiable forward model. We investigate multiple architectures, including (i) an enhanced TumorSurrogate, (ii) a modified nnU-Net, and (iii) a 3D Vision Transformer (ViT). The nnU-Net achieved the best overall results, excelling in both tumor outline matching and voxel-level prediction of tumor cell concentration. It yielded the lowest MSE in tumor cell concentration compared to ground truth numerical simulation and the highest Dice score across all tumor cell concentration thresholds. Our study demonstrates significant enhancement in forward solver performance and outlines important future research directions. </p>
<blockquote>
<p>èƒ¶è´¨æ¯ç»†èƒç˜¤æ˜¯ä¸€ç§é«˜åº¦ä¾µè¢­æ€§çš„è„‘è‚¿ç˜¤ï¼Œç”±äºå…¶é¢„åä¸è‰¯å’Œå‘ç—…ç‡é«˜è€Œå¸¦æ¥é‡å¤§æŒ‘æˆ˜ã€‚åŸºäºåå¾®åˆ†æ–¹ç¨‹æ¨¡å‹çš„æ¨¡å‹åœ¨æ¨¡æ‹Ÿæ‚£è€…ç‰¹å®šè‚¿ç˜¤è¡Œä¸ºä»¥æ”¹å–„æ”¾ç–—è®¡åˆ’æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œæœ‰æœ›æé«˜æ²»ç–—æ•ˆæœã€‚ç„¶è€Œï¼Œæ¨¡å‹æ ¡å‡†ä»ç„¶æ˜¯ç“¶é¢ˆï¼Œå› ä¸ºä¼˜åŒ–æ–¹æ³•ï¼ˆå¦‚è’™ç‰¹å¡ç½—é‡‡æ ·å’Œè¿›åŒ–ç®—æ³•ï¼‰çš„è®¡ç®—éœ€æ±‚å¾ˆé«˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æœ€è¿‘å¼•å…¥äº†ä¸€ç§åˆ©ç”¨åŸºäºæ¢¯åº¦çš„ç¥ç»æ­£å‘æ±‚è§£å™¨çš„æ–¹æ³•ï¼Œå¯ä»¥å¤§å¤§ç¼©çŸ­æ ¡å‡†æ—¶é—´ã€‚è¿™ç§æ–¹æ³•éœ€è¦ä¸€ä¸ªé«˜åº¦ç²¾ç¡®å’Œå®Œå…¨å¯å¾®åˆ†çš„æ­£å‘æ¨¡å‹ã€‚æˆ‘ä»¬è°ƒæŸ¥äº†å¤šç§æ¶æ„ï¼ŒåŒ…æ‹¬ï¼ˆiï¼‰å¢å¼ºçš„TumorSurrogateï¼Œï¼ˆiiï¼‰ç»è¿‡ä¿®æ”¹çš„nnU-Netï¼Œä»¥åŠï¼ˆiiiï¼‰3D Vision Transformerï¼ˆViTï¼‰ã€‚nnU-Netå–å¾—äº†æœ€ä½³çš„æ•´ä½“ç»“æœï¼Œåœ¨è‚¿ç˜¤è½®å»“åŒ¹é…å’Œè‚¿ç˜¤ç»†èƒæµ“åº¦çš„ä½“ç´ çº§é¢„æµ‹æ–¹é¢éƒ½è¡¨ç°å‡ºè‰²ã€‚ä¸åœ°é¢çœŸå®æ•°å€¼æ¨¡æ‹Ÿç›¸æ¯”ï¼Œå®ƒåœ¨è‚¿ç˜¤ç»†èƒæµ“åº¦æ–¹é¢çš„å‡æ–¹è¯¯å·®æœ€ä½ï¼Œå¹¶ä¸”åœ¨æ‰€æœ‰è‚¿ç˜¤ç»†èƒæµ“åº¦é˜ˆå€¼ä¸­éƒ½å–å¾—äº†æœ€é«˜çš„Diceå¾—åˆ†ã€‚æˆ‘ä»¬çš„ç ”ç©¶å±•ç¤ºäº†æ­£å‘æ±‚è§£å™¨æ€§èƒ½çš„æ˜¾è‘—æé«˜ï¼Œå¹¶æ¦‚è¿°äº†æœªæ¥é‡è¦çš„ç ”ç©¶æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.08226v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>é«˜åº¦ä¾µè¢­æ€§çš„è„‘è‚¿ç˜¤èƒ¶è´¨æ¯ç»†èƒç˜¤é¢„åä¸è‰¯ã€å‘ç—…ç‡é«˜ï¼Œå¸¦æ¥å¾ˆå¤§æŒ‘æˆ˜ã€‚åŸºäºåå¾®åˆ†æ–¹ç¨‹æ¨¡å‹çš„æ¨¡æ‹Ÿåœ¨ä¼˜åŒ–æ”¾å°„æ²»ç–—è®¡åˆ’æ–¹é¢æ˜¾ç¤ºå‡ºæ½œåŠ›ã€‚ä½†æ¨¡å‹æ ¡å‡†å› è®¡ç®—éœ€æ±‚å¤§è€Œæˆä¸ºç“¶é¢ˆã€‚æœ€æ–°ç ”ç©¶åˆ©ç”¨ç¥ç»ç½‘ç»œå‰å‘æ±‚è§£å™¨å’ŒåŸºäºæ¢¯åº¦çš„ä¼˜åŒ–æ–¹æ³•å¤§å¹…å‡å°‘æ ¡å‡†æ—¶é—´ã€‚ç ”ç©¶ä¸­è°ƒæŸ¥äº†å¤šç§æ¶æ„ï¼Œæœ€ç»ˆå‘ç°nnU-Netæ•ˆæœæœ€ä½³ï¼Œåœ¨è‚¿ç˜¤è½®å»“åŒ¹é…å’Œè‚¿ç˜¤ç»†èƒæµ“åº¦ä½“ç´ çº§é¢„æµ‹æ–¹é¢éƒ½è¡¨ç°å‡ºè‰²ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>èƒ¶è´¨æ¯ç»†èƒç˜¤æ˜¯ä¸€ç§é«˜åº¦ä¾µè¢­æ€§çš„è„‘è‚¿ç˜¤ï¼Œé¢„åä¸è‰¯ã€å‘ç—…ç‡é«˜ï¼Œå¯¹æ²»ç–—å¸¦æ¥å¾ˆå¤§æŒ‘æˆ˜ã€‚</li>
<li>åŸºäºåå¾®åˆ†æ–¹ç¨‹æ¨¡å‹çš„æ¨¡æ‹Ÿåœ¨ä¼˜åŒ–æ”¾å°„æ²»ç–—è®¡åˆ’æ–¹é¢æ˜¾ç¤ºå‡ºæ½œåŠ›ã€‚</li>
<li>æ¨¡å‹æ ¡å‡†æ˜¯ç“¶é¢ˆï¼Œå› ä¸ºéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚</li>
<li>åˆ©ç”¨ç¥ç»ç½‘ç»œå‰å‘æ±‚è§£å™¨å’ŒåŸºäºæ¢¯åº¦çš„ä¼˜åŒ–æ–¹æ³•å¤§å¹…å‡å°‘æ ¡å‡†æ—¶é—´ã€‚</li>
<li>ç ”ç©¶ä¸­è°ƒæŸ¥äº†å¤šç§ç¥ç»ç½‘ç»œæ¶æ„ï¼ŒåŒ…æ‹¬å¢å¼ºç‰ˆTumorSurrogateã€æ”¹è‰¯ç‰ˆnnU-Netå’Œ3D Vision Transformerã€‚</li>
<li>nnU-Netåœ¨è‚¿ç˜¤è½®å»“åŒ¹é…å’Œè‚¿ç˜¤ç»†èƒæµ“åº¦ä½“ç´ çº§é¢„æµ‹æ–¹é¢éƒ½è¡¨ç°å‡ºæœ€ä½³æ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.08226">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2501.08226v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2501.08226v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2501.08226v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2501.08226v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2501.08226v2/page_4_1.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="CAD-Assistant-Tool-Augmented-VLLMs-as-Generic-CAD-Task-Solvers"><a href="#CAD-Assistant-Tool-Augmented-VLLMs-as-Generic-CAD-Task-Solvers" class="headerlink" title="CAD-Assistant: Tool-Augmented VLLMs as Generic CAD Task Solvers"></a>CAD-Assistant: Tool-Augmented VLLMs as Generic CAD Task Solvers</h2><p><strong>Authors:Dimitrios Mallis, Ahmet Serdar Karadeniz, Sebastian Cavada, Danila Rukhovich, Niki Foteinopoulou, Kseniya Cherenkova, Anis Kacem, Djamila Aouada</strong></p>
<p>We propose CAD-Assistant, a general-purpose CAD agent for AI-assisted design. Our approach is based on a powerful Vision and Large Language Model (VLLM) as a planner and a tool-augmentation paradigm using CAD-specific tools. CAD-Assistant addresses multimodal user queries by generating actions that are iteratively executed on a Python interpreter equipped with the FreeCAD software, accessed via its Python API. Our framework is able to assess the impact of generated CAD commands on geometry and adapts subsequent actions based on the evolving state of the CAD design. We consider a wide range of CAD-specific tools including a sketch image parameterizer, rendering modules, a 2D cross-section generator, and other specialized routines. CAD-Assistant is evaluated on multiple CAD benchmarks, where it outperforms VLLM baselines and supervised task-specific methods. Beyond existing benchmarks, we qualitatively demonstrate the potential of tool-augmented VLLMs as general-purpose CAD solvers across diverse workflows. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†CADåŠ©æ‰‹ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºäººå·¥æ™ºèƒ½è¾…åŠ©è®¾è®¡çš„é€šç”¨CADä»£ç†ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŸºäºå¼ºå¤§çš„è§†è§‰å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆVLLMï¼‰ä½œä¸ºè§„åˆ’å™¨ï¼Œå¹¶ä½¿ç”¨CADä¸“ç”¨å·¥å…·è¿›è¡Œå·¥å…·å¢å¼ºèŒƒå¼ã€‚CADåŠ©æ‰‹é€šè¿‡ç”ŸæˆåŠ¨ä½œæ¥è§£å†³å¤šæ¨¡æ€ç”¨æˆ·æŸ¥è¯¢ï¼Œè¿™äº›åŠ¨ä½œåœ¨é…å¤‡FreeCADè½¯ä»¶çš„Pythonè§£é‡Šå™¨ä¸Šè¿­ä»£æ‰§è¡Œï¼Œé€šè¿‡å…¶Python APIè¿›è¡Œè®¿é—®ã€‚æˆ‘ä»¬çš„æ¡†æ¶èƒ½å¤Ÿè¯„ä¼°ç”Ÿæˆçš„CADå‘½ä»¤å¯¹å‡ ä½•ç»“æ„çš„å½±å“ï¼Œå¹¶æ ¹æ®CADè®¾è®¡çš„ä¸æ–­å˜åŒ–çŠ¶æ€è°ƒæ•´åç»­åŠ¨ä½œã€‚æˆ‘ä»¬è€ƒè™‘äº†å¹¿æ³›çš„CADä¸“ç”¨å·¥å…·ï¼ŒåŒ…æ‹¬è‰å›¾å›¾åƒå‚æ•°åŒ–å™¨ã€æ¸²æŸ“æ¨¡å—ã€2Dæ¨ªæˆªé¢ç”Ÿæˆå™¨å’Œå…¶ä»–ä¸“ä¸šä¾‹è¡Œç¨‹åºã€‚CADåŠ©æ‰‹åœ¨å¤šä¸ªCADåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œè¡¨ç°å‡ºä¼˜äºVLLMåŸºå‡†çº¿å’Œæœ‰ç›‘ç£çš„ç‰¹å®šä»»åŠ¡æ–¹æ³•ã€‚é™¤äº†ç°æœ‰çš„åŸºå‡†æµ‹è¯•å¤–ï¼Œæˆ‘ä»¬è¿˜ä»å®šæ€§è§’åº¦å±•ç¤ºäº†å·¥å…·å¢å¼ºå‹VLLMåœ¨å¤šæ ·åŒ–å·¥ä½œæµç¨‹ä¸­çš„é€šç”¨CADæ±‚è§£å™¨çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.13810v3">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æå‡ºäº†åŸºäºå¼ºå¤§çš„è§†è§‰å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆVLLMï¼‰çš„CADåŠ©æ‰‹ã€‚é€šè¿‡é‡‡ç”¨å·¥å…·å¢å¼ºæ¨¡å¼å¹¶ä½¿ç”¨CADç‰¹å®šå·¥å…·ï¼Œå®ƒèƒ½å¤Ÿå¤„ç†å¤šç§æ¨¡æ€çš„ç”¨æˆ·æŸ¥è¯¢ï¼Œå¹¶ç”ŸæˆåŠ¨ä½œåœ¨Pythonè§£é‡Šå™¨ä¸Šæ‰§è¡Œï¼ŒåŒæ—¶é…å¤‡FreeCADè½¯ä»¶é€šè¿‡å…¶Python APIè¿›è¡Œè®¿é—®ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿè¯„ä¼°ç”Ÿæˆçš„CADå‘½ä»¤å¯¹å‡ ä½•ç»“æ„çš„å½±å“ï¼Œå¹¶æ ¹æ®CADè®¾è®¡çš„ä¸æ–­å˜åŒ–çŠ¶æ€è°ƒæ•´åç»­åŠ¨ä½œã€‚è€ƒè™‘åˆ°äº†å¹¿æ³›çš„CADç‰¹å®šå·¥å…·ï¼ŒåŒ…æ‹¬è‰å›¾å›¾åƒå‚æ•°åŒ–å™¨ã€æ¸²æŸ“æ¨¡å—ã€äºŒç»´æ¨ªæˆªé¢ç”Ÿæˆå™¨å’Œå…¶ä»–ä¸“ä¸šä¾‹è¡Œç¨‹åºã€‚åœ¨å¤šä¸ªCADåŸºå‡†æµ‹è¯•ä¸­è¯„ä¼°äº†CADåŠ©æ‰‹çš„è¡¨ç°ï¼Œè¯æ˜å…¶ä¼˜äºVLLMåŸºå‡†å’Œå—ç›‘ç£çš„ç‰¹å®šä»»åŠ¡æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é€šè¿‡å®šæ€§æ¼”ç¤ºäº†å·¥å…·å¢å¼ºå‹VLLMåœ¨å¤šæ ·åŒ–å·¥ä½œæµç¨‹ä¸­çš„é€šç”¨CADæ±‚è§£æ½œåŠ›ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>CAD-Assistantæ˜¯åŸºäºå¼ºå¤§çš„è§†è§‰å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆVLLMï¼‰æ„å»ºçš„é€šç”¨CADä»£ç†ï¼Œç”¨äºAIè¾…åŠ©è®¾è®¡ã€‚</li>
<li>CAD-Assistanté‡‡ç”¨å·¥å…·å¢å¼ºæ¨¡å¼ï¼Œä½¿ç”¨CADç‰¹å®šå·¥å…·å¤„ç†å¤šç§æ¨¡æ€çš„ç”¨æˆ·æŸ¥è¯¢ã€‚</li>
<li>å®ƒé€šè¿‡Python APIä¸FreeCADè½¯ä»¶é›†æˆï¼Œèƒ½å¤Ÿæ‰§è¡ŒCADå‘½ä»¤å¹¶è¿­ä»£ç”ŸæˆåŠ¨ä½œã€‚</li>
<li>CAD-Assistantèƒ½å¤Ÿè¯„ä¼°å‘½ä»¤å¯¹å‡ ä½•ç»“æ„çš„å½±å“ï¼Œå¹¶æ ¹æ®è®¾è®¡çŠ¶æ€çš„æ¼”å˜è°ƒæ•´åç»­åŠ¨ä½œã€‚</li>
<li>è¯¥æ¡†æ¶æ”¯æŒå¤šç§CADç‰¹å®šå·¥å…·ï¼ŒåŒ…æ‹¬è‰å›¾å›¾åƒå‚æ•°åŒ–å™¨ã€æ¸²æŸ“æ¨¡å—ç­‰ã€‚</li>
<li>åœ¨å¤šä¸ªCADåŸºå‡†æµ‹è¯•ä¸­ï¼ŒCAD-Assistantè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œä¼˜äºä¼ ç»Ÿçš„VLLMæ–¹æ³•å’Œå—ç›‘ç£çš„ç‰¹å®šä»»åŠ¡æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.13810">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2412.13810v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2412.13810v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2412.13810v3/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2412.13810v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="PadChest-GR-A-Bilingual-Chest-X-ray-Dataset-for-Grounded-Radiology-Report-Generation"><a href="#PadChest-GR-A-Bilingual-Chest-X-ray-Dataset-for-Grounded-Radiology-Report-Generation" class="headerlink" title="PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology   Report Generation"></a>PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology   Report Generation</h2><p><strong>Authors:Daniel C. Castro, Aurelia Bustos, Shruthi Bannur, Stephanie L. Hyland, Kenza Bouzid, Maria Teodora Wetscherek, Maria Dolores SÃ¡nchez-Valverde, Lara Jaques-PÃ©rez, Lourdes PÃ©rez-RodrÃ­guez, Kenji Takeda, JosÃ© MarÃ­a Salinas, Javier Alvarez-Valle, JoaquÃ­n Galant Herrero, Antonio Pertusa</strong></p>
<p>Radiology report generation (RRG) aims to create free-text radiology reports from clinical imaging. Grounded radiology report generation (GRRG) extends RRG by including the localisation of individual findings on the image. Currently, there are no manually annotated chest X-ray (CXR) datasets to train GRRG models. In this work, we present a dataset called PadChest-GR (Grounded-Reporting) derived from PadChest aimed at training GRRG models for CXR images. We curate a public bi-lingual dataset of 4,555 CXR studies with grounded reports (3,099 abnormal and 1,456 normal), each containing complete lists of sentences describing individual present (positive) and absent (negative) findings in English and Spanish. In total, PadChest-GR contains 7,037 positive and 3,422 negative finding sentences. Every positive finding sentence is associated with up to two independent sets of bounding boxes labelled by different readers and has categorical labels for finding type, locations, and progression. To the best of our knowledge, PadChest-GR is the first manually curated dataset designed to train GRRG models for understanding and interpreting radiological images and generated text. By including detailed localization and comprehensive annotations of all clinically relevant findings, it provides a valuable resource for developing and evaluating GRRG models from CXR images. PadChest-GR can be downloaded under request from <a target="_blank" rel="noopener" href="https://bimcv.cipf.es/bimcv-projects/padchest-gr/">https://bimcv.cipf.es/bimcv-projects/padchest-gr/</a> </p>
<blockquote>
<p>æ”¾å°„æŠ¥å‘Šç”Ÿæˆï¼ˆRRGï¼‰æ—¨åœ¨ä»ä¸´åºŠå½±åƒä¸­ç”Ÿæˆè‡ªç”±æ–‡æœ¬æ”¾å°„æŠ¥å‘Šã€‚åŸºäºæƒ…å¢ƒçš„æ”¾å°„æŠ¥å‘Šç”Ÿæˆï¼ˆGRRGï¼‰æ‰©å±•äº†RRGï¼Œé€šè¿‡åœ¨å›¾åƒä¸Šå®šä½ä¸ªåˆ«å‘ç°ç‰©ã€‚ç›®å‰ï¼Œæ²¡æœ‰æ‰‹åŠ¨æ ‡æ³¨çš„èƒ¸éƒ¨Xå°„çº¿ï¼ˆCXRï¼‰æ•°æ®é›†æ¥è®­ç»ƒGRRGæ¨¡å‹ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºPadChest-GRï¼ˆåŸºäºæƒ…å¢ƒçš„æŠ¥å‘Šï¼‰çš„æ•°æ®é›†ï¼Œå®ƒæ¥æºäºPadChestï¼Œæ—¨åœ¨é’ˆå¯¹CXRå›¾åƒè®­ç»ƒGRRGæ¨¡å‹ã€‚æˆ‘ä»¬æ•´ç†äº†ä¸€ä¸ªå…¬å…±åŒè¯­æ•°æ®é›†ï¼ŒåŒ…å«4555é¡¹CXRç ”ç©¶ï¼Œå¸¦æœ‰åŸºäºæƒ…å¢ƒçš„æŠ¥å‘Šï¼ˆ3099é¡¹å¼‚å¸¸å’Œ1456é¡¹æ­£å¸¸ï¼‰ï¼Œæ¯é¡¹ç ”ç©¶éƒ½åŒ…å«ç”¨è‹±è¯­å’Œè¥¿ç­ç‰™è¯­æè¿°çš„ä¸ªåˆ«å½“å‰å­˜åœ¨ï¼ˆé˜³æ€§ï¼‰å’Œä¸å­˜åœ¨ï¼ˆé˜´æ€§ï¼‰çš„å‘ç°ç‰©çš„å®Œæ•´å¥å­åˆ—è¡¨ã€‚æ€»å…±ï¼ŒPadChest-GRåŒ…å«7037ä¸ªé˜³æ€§å‘ç°ç‰©å¥å­å’Œ3422ä¸ªé˜´æ€§å‘ç°ç‰©å¥å­ã€‚æ¯ä¸ªé˜³æ€§å‘ç°ç‰©å¥å­éƒ½ä¸ç”±ä¸åŒè¯»è€…æ ‡è®°çš„ä¸¤å¥—ç‹¬ç«‹è¾¹ç•Œæ¡†ç›¸å…³è”ï¼Œå¹¶å…·æœ‰å‘ç°ç‰©ç±»å‹ã€ä½ç½®å’Œè¿›å±•çš„ç±»åˆ«æ ‡ç­¾ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒPadChest-GRæ˜¯ç¬¬ä¸€ä¸ªæ‰‹åŠ¨æ•´ç†çš„æ•°æ®é›†ï¼Œæ—¨åœ¨é’ˆå¯¹ç†è§£å’Œè§£é‡Šæ”¾å°„å½±åƒå›¾åƒå’Œç”Ÿæˆæ–‡æœ¬è®­ç»ƒGRRGæ¨¡å‹ã€‚é€šè¿‡åŒ…å«æ‰€æœ‰ä¸´åºŠç›¸å…³å‘ç°ç‰©çš„è¯¦ç»†å®šä½å’Œå…¨é¢æ³¨é‡Šï¼Œå®ƒä¸ºå¼€å‘å’Œè¯„ä¼°ä»CXRå›¾åƒç”Ÿæˆçš„GRRGæ¨¡å‹æä¾›äº†å®è´µçš„èµ„æºã€‚å¯ä»¥é€šè¿‡<a target="_blank" rel="noopener" href="https://bimcv.cipf.es/bimcv-projects/padchest-gr/%E7%9A%84%E8%A6%81%E6%B1%82%E4%B8%8B%E8%BD%BDPadChest-GR%E3%80%82">https://bimcv.cipf.es/bimcv-projects/padchest-gr/çš„è¦æ±‚ä¸‹è½½PadChest-GRã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.05085v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†PadChest-GRæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æ˜¯ä»PadChestè¡ç”Ÿè€Œæ¥ï¼Œæ—¨åœ¨è®­ç»ƒç”¨äºèƒ¸éƒ¨Xå°„çº¿å›¾åƒï¼ˆCXRï¼‰çš„GRRGæ¨¡å‹ã€‚è¯¥æ•°æ®é›†åŒ…å«å¸¦æœ‰æ¥åœ°æŠ¥å‘Šï¼ˆå³æœ‰å’Œæ­£å¸¸æƒ…å†µä¸‹çš„è§‚å¯Ÿç»“æœï¼‰çš„4,555ä¸ªCXRç ”ç©¶ï¼ŒåŒ…æ‹¬ç”¨è‹±è¯­å’Œè¥¿ç­ç‰™è¯­æè¿°çš„ä¸ªåˆ«è§‚å¯Ÿç»“æœçš„å¥å­åˆ—è¡¨ã€‚è¯¥æ•°æ®é›†æä¾›äº†è¯¦ç»†çš„å®šä½å’Œæ‰€æœ‰ç›¸å…³ä¸´åºŠå‘ç°çš„å…¨é¢æ³¨é‡Šï¼Œæ˜¯ç†è§£å’Œè§£é‡Šæ”¾å°„å›¾åƒå’Œç”Ÿæˆæ–‡æœ¬çš„ç¬¬ä¸€ä¸ªæ‰‹åŠ¨æ•´ç†çš„æ•°æ®é›†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RRGæ—¨åœ¨ä»ä¸´åºŠæˆåƒä¸­ç”Ÿæˆè‡ªç”±æ–‡æœ¬æ”¾å°„å­¦æŠ¥å‘Šã€‚GRRGè¿›ä¸€æ­¥é€šè¿‡åŒ…å«å›¾åƒä¸Šä¸ªåˆ«å‘ç°çš„å®šä½æ¥æ‰©å±•RRGã€‚</li>
<li>ç›®å‰æ²¡æœ‰ç”¨äºè®­ç»ƒGRRGæ¨¡å‹çš„èƒ¸éƒ¨Xå°„çº¿ï¼ˆCXRï¼‰æ‰‹åŠ¨æ³¨é‡Šæ•°æ®é›†ã€‚</li>
<li>PadChest-GRæ•°æ®é›†æ˜¯ä»PadChestè¡ç”Ÿè€Œæ¥çš„åŒè¯­æ•°æ®é›†ï¼ŒåŒ…å«4,555ä¸ªCXRç ”ç©¶ï¼Œå¸¦æœ‰æ¥åœ°æŠ¥å‘Šã€‚å…¶ä¸­æ—¢æœ‰3,099ä¸ªå¼‚å¸¸æƒ…å†µå’Œ1,456ä¸ªæ­£å¸¸æƒ…å†µã€‚</li>
<li>PadChest-GRåŒ…å«ä¸é«˜è¾¾ä¸¤ä¸ªç‹¬ç«‹è§‚å¯Ÿè€…æ ‡è®°çš„è¾¹ç•Œæ¡†ç›¸å…³è”çš„é˜³æ€§å‘ç°å¥å­ï¼Œå¹¶ä¸ºå‘ç°ç±»å‹ã€ä½ç½®å’Œè¿›å±•æä¾›ç±»åˆ«æ ‡ç­¾ã€‚</li>
<li>PadChest-GRæ˜¯ç¬¬ä¸€ä¸ªè®¾è®¡ç”¨äºè®­ç»ƒå’Œè§£é‡Šæ”¾å°„å›¾åƒç”Ÿæˆæ–‡æœ¬ï¼ˆGRRGæ¨¡å‹ï¼‰çš„æ‰‹åŠ¨æ•´ç†æ•°æ®é›†ã€‚</li>
<li>PadChest-GRåŒ…å«æ‰€æœ‰ç›¸å…³ä¸´åºŠå‘ç°çš„è¯¦ç»†å®šä½å’Œå…¨é¢æ³¨é‡Šï¼Œå¯¹äºå¼€å‘å’Œè¯„ä¼°GRRGæ¨¡å‹å…·æœ‰å®è´µä»·å€¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.05085">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2411.05085v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2411.05085v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2411.05085v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2411.05085v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Deep-Learning-based-Cross-modal-Reconstruction-of-Vehicle-Target-from-Sparse-3D-SAR-Image"><a href="#Deep-Learning-based-Cross-modal-Reconstruction-of-Vehicle-Target-from-Sparse-3D-SAR-Image" class="headerlink" title="Deep Learning-based Cross-modal Reconstruction of Vehicle Target from   Sparse 3D SAR Image"></a>Deep Learning-based Cross-modal Reconstruction of Vehicle Target from   Sparse 3D SAR Image</h2><p><strong>Authors:Da Li, Guoqiang Zhao, Chen Yao, Kaiqiang Zhu, Houjun Sun, Jiacheng Bao, Maokun Li</strong></p>
<p>Three-dimensional synthetic aperture radar (3D SAR) is an advanced active microwave imaging technology widely utilized in remote sensing area. To achieve high-resolution 3D imaging,3D SAR requires observations from multiple aspects and altitude baselines surrounding the target. However, constrained flight trajectories often lead to sparse observations, which degrade imaging quality, particularly for anisotropic man-made small targets, such as vehicles and aircraft. In the past, compressive sensing (CS) was the mainstream approach for sparse 3D SAR image reconstruction. More recently, deep learning (DL) has emerged as a powerful alternative, markedly boosting reconstruction quality and efficiency. However, existing DL-based methods typically rely solely on high-quality 3D SAR images as supervisory signals to train deep neural networks (DNNs). This unimodal learning paradigm prevents the integration of complementary information from other data modalities, which limits reconstruction performance and reduces target discriminability due to the inherent constraints of electromagnetic scattering. In this paper, we introduce cross-modal learning and propose a Cross-Modal 3D-SAR Reconstruction Network (CMAR-Net) for enhancing sparse 3D SAR images of vehicle targets by fusing optical information. Leveraging cross-modal supervision from 2D optical images and error propagation guaranteed by differentiable rendering, CMAR-Net achieves efficient training and reconstructs sparse 3D SAR images, which are derived from highly sparse-aspect observations, into visually structured 3D vehicle images. Trained exclusively on simulated data, CMAR-Net exhibits robust generalization to real-world data, outperforming state-of-the-art CS and DL methods in structural accuracy within a large-scale parking lot experiment involving numerous civilian vehicles, thereby demonstrating its strong practical applicability. </p>
<blockquote>
<p>ä¸‰ç»´åˆæˆå­”å¾„é›·è¾¾ï¼ˆ3D SARï¼‰æ˜¯ä¸€ç§å…ˆè¿›çš„ä¸»åŠ¨å¾®æ³¢æˆåƒæŠ€æœ¯ï¼Œå¹¿æ³›åº”ç”¨äºé¥æ„Ÿé¢†åŸŸã€‚ä¸ºäº†å®ç°é«˜åˆ†è¾¨ç‡çš„3Dæˆåƒï¼Œéœ€è¦æ¥è‡ªç›®æ ‡å‘¨å›´å¤šä¸ªæ–¹ä½å’Œé«˜åº¦åŸºçº¿çš„è§‚æµ‹æ•°æ®ã€‚ç„¶è€Œï¼Œå—çº¦æŸçš„é£è¡Œè½¨è¿¹å¾€å¾€å¯¼è‡´è§‚æµ‹æ•°æ®ç¨€ç–ï¼Œä»è€Œé™ä½äº†æˆåƒè´¨é‡ï¼Œç‰¹åˆ«æ˜¯å¯¹äºè½¦è¾†å’Œé£æœºç­‰å¼‚å‘çš„äººé€ å°ç›®æ ‡æ›´æ˜¯å¦‚æ­¤ã€‚è¿‡å»ï¼Œå‹ç¼©æ„ŸçŸ¥ï¼ˆCSï¼‰æ˜¯ç¨€ç–ä¸‰ç»´SARå›¾åƒé‡å»ºçš„ä¸»æµæ–¹æ³•ã€‚æœ€è¿‘ï¼Œæ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰ä½œä¸ºä¸€ç§å¼ºå¤§çš„æ›¿ä»£æ–¹æ³•å´­éœ²å¤´è§’ï¼Œæ˜¾è‘—æé«˜äº†é‡å»ºè´¨é‡å’Œæ•ˆç‡ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•é€šå¸¸ä»…ä¾èµ–é«˜è´¨é‡çš„ä¸‰ç»´SARå›¾åƒä½œä¸ºç›‘ç£ä¿¡å·æ¥è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNsï¼‰ã€‚è¿™ç§å•ä¸€æ¨¡æ€çš„å­¦ä¹ æ¨¡å¼æ— æ³•æ•´åˆæ¥è‡ªå…¶ä»–æ•°æ®æ¨¡æ€çš„äº’è¡¥ä¿¡æ¯ï¼Œä»è€Œé™åˆ¶äº†é‡å»ºæ€§èƒ½å¹¶é™ä½äº†ç›®æ ‡è¾¨è¯†åº¦ï¼Œè¿™æºäºç”µç£æ•£å°„çš„å›ºæœ‰çº¦æŸã€‚æœ¬æ–‡ä»‹ç»äº†è·¨æ¨¡æ€å­¦ä¹ ï¼Œå¹¶æå‡ºäº†ä¸€ç§åŸºäºå…‰å­¦ä¿¡æ¯èåˆçš„ä¸‰ç»´SARè·¨æ¨¡æ€é‡å»ºç½‘ç»œï¼ˆCMAR-Netï¼‰ï¼Œæ—¨åœ¨æé«˜è½¦è¾†ç›®æ ‡çš„ç¨€ç–ä¸‰ç»´SARå›¾åƒè´¨é‡ã€‚é€šè¿‡åˆ©ç”¨äºŒç»´å…‰å­¦å›¾åƒçš„è·¨æ¨¡æ€ç›‘ç£ä¿¡æ¯å’Œå¯å¾®åˆ†æ¸²æŸ“ä¿è¯çš„é”™è¯¯ä¼ æ’­æœºåˆ¶ï¼ŒCMAR-Netå®ç°äº†é«˜æ•ˆçš„è®­ç»ƒï¼Œå¹¶å°†ä»é«˜åº¦ç¨€ç–æ–¹ä½è§‚æµ‹ä¸­å¾—åˆ°çš„ä¸‰ç»´SARå›¾åƒé‡å»ºä¸ºè§†è§‰ä¸Šç»“æ„åŒ–çš„ä¸‰ç»´è½¦è¾†å›¾åƒã€‚ä»…åœ¨æ¨¡æ‹Ÿæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒçš„CMAR-Netå¯¹çœŸå®æ•°æ®å…·æœ‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨å¤§è§„æ¨¡åœè½¦åœºå®éªŒä¸­å¯¹å¤§é‡æ°‘ç”¨è½¦è¾†çš„é‡å»ºåœ¨ç»“æ„ç²¾åº¦ä¸Šè¶…è¿‡äº†ç°æœ‰çš„å‹ç¼©æ„ŸçŸ¥å’Œæ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œä»è€Œè¯æ˜äº†å…¶å¼ºå¤§çš„å®é™…åº”ç”¨ä»·å€¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.04158v7">PDF</a> This work has been submitted to the IEEE for possible publication</p>
<p><strong>Summary</strong><br>    æœ¬æ–‡ä»‹ç»äº†åŸºäºè·¨æ¨¡æ€å­¦ä¹ çš„ä¸‰ç»´åˆæˆå­”å¾„é›·è¾¾ï¼ˆ3D SARï¼‰å›¾åƒé‡å»ºæŠ€æœ¯ã€‚é€šè¿‡èåˆå…‰å­¦ä¿¡æ¯ï¼Œæå‡ºäº†ä¸€ç§åä¸ºCMAR-Netçš„è·¨æ¨¡æ€3D-SARé‡å»ºç½‘ç»œï¼Œå¯æé«˜ç¨€ç–3D SARå›¾åƒçš„è½¦è¾†ç›®æ ‡è´¨é‡ã€‚åˆ©ç”¨æ¥è‡ªäºŒç»´å…‰å­¦å›¾åƒçš„è·¨æ¨¡æ€ç›‘ç£ä¿¡æ¯å’Œå¯å¾®åˆ†æ¸²æŸ“ä¿è¯è¯¯å·®ä¼ æ’­ï¼ŒCMAR-Netèƒ½å¤Ÿé«˜æ•ˆè®­ç»ƒï¼Œå°†é«˜åº¦ç¨€ç–è§‚æµ‹çš„ç¨€ç–3D SARå›¾åƒé‡å»ºä¸ºè§†è§‰ç»“æ„åŒ–çš„3Dè½¦è¾†å›¾åƒã€‚åœ¨å¤§å‹åœè½¦åœºå®éªŒä¸­ï¼Œä»…é€šè¿‡æ¨¡æ‹Ÿæ•°æ®è®­ç»ƒçš„CMAR-Netå¯¹çœŸå®æ•°æ®å…·æœ‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨ç»“æ„å‡†ç¡®æ€§æ–¹é¢ä¼˜äºç°æœ‰çš„å‹ç¼©æ„ŸçŸ¥å’Œæ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œæ˜¾ç¤ºå‡ºå…¶å¼ºå¤§çš„å®é™…åº”ç”¨ä»·å€¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸‰ç»´åˆæˆå­”å¾„é›·è¾¾ï¼ˆ3D SARï¼‰æ˜¯ä¸€ç§å…ˆè¿›çš„ä¸»åŠ¨å¾®æ³¢æˆåƒæŠ€æœ¯ï¼Œå¹¿æ³›åº”ç”¨äºé¥æ„Ÿé¢†åŸŸã€‚</li>
<li>3D SARéœ€è¦æ¥è‡ªç›®æ ‡å‘¨å›´å¤šä¸ªæ–¹é¢å’Œé«˜åº¦çš„è§‚å¯Ÿæ¥å®ç°é«˜åˆ†è¾¨ç‡æˆåƒï¼Œä½†çº¦æŸé£è¡Œè½¨è¿¹ä¼šå¯¼è‡´è§‚æµ‹ç¨€ç–ï¼Œé™ä½æˆåƒè´¨é‡ã€‚</li>
<li>ä»¥å¾€çš„å‹ç¼©æ„ŸçŸ¥ï¼ˆCSï¼‰æ˜¯ç¨€ç–3D SARå›¾åƒé‡å»ºçš„ä¸»æµæ–¹æ³•ï¼Œè€Œæ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰æœ€è¿‘æˆä¸ºäº†ä¸€ç§å¼ºå¤§çš„æ›¿ä»£æ–¹æ³•ï¼Œæ˜¾è‘—æé«˜äº†é‡å»ºè´¨é‡å’Œæ•ˆç‡ã€‚</li>
<li>ç°æœ‰çš„åŸºäºDLçš„æ–¹æ³•é€šå¸¸ä»…ä¾èµ–é«˜è´¨é‡çš„3D SARå›¾åƒä½œä¸ºç›‘ç£ä¿¡å·æ¥è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNsï¼‰ï¼Œè¿™é™åˆ¶äº†äº’è¡¥ä¿¡æ¯çš„é›†æˆå’Œå…¶ä»–æ•°æ®æ¨¡æ€çš„ä½¿ç”¨ï¼Œä»è€Œé™ä½äº†é‡å»ºæ€§èƒ½å’Œç›®æ ‡è¾¨åˆ«èƒ½åŠ›ã€‚</li>
<li>æœ¬æ–‡å¼•å…¥è·¨æ¨¡æ€å­¦ä¹ ï¼Œå¹¶æå‡ºäº†ä¸€ç§åä¸ºCMAR-Netçš„è·¨æ¨¡æ€3D-SARé‡å»ºç½‘ç»œï¼Œé€šè¿‡èåˆå…‰å­¦ä¿¡æ¯æ¥æé«˜ç¨€ç–3D SARå›¾åƒçš„è½¦è¾†ç›®æ ‡è´¨é‡ã€‚</li>
<li>CMAR-Netåˆ©ç”¨æ¥è‡ªäºŒç»´å…‰å­¦å›¾åƒçš„è·¨æ¨¡æ€ç›‘ç£ä¿¡æ¯å’Œå¯å¾®åˆ†æ¸²æŸ“ä¿è¯è¯¯å·®ä¼ æ’­ï¼Œå®ç°é«˜æ•ˆè®­ç»ƒå’Œç¨€ç–3D SARå›¾åƒçš„é‡å»ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.04158">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2406.04158v7/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2406.04158v7/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2406.04158v7/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2406.04158v7/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2406.04158v7/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2406.04158v7/page_5_0.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Automatic-segmentation-of-Organs-at-Risk-in-Head-and-Neck-cancer-patients-from-CT-and-MRI-scans"><a href="#Automatic-segmentation-of-Organs-at-Risk-in-Head-and-Neck-cancer-patients-from-CT-and-MRI-scans" class="headerlink" title="Automatic segmentation of Organs at Risk in Head and Neck cancer   patients from CT and MRI scans"></a>Automatic segmentation of Organs at Risk in Head and Neck cancer   patients from CT and MRI scans</h2><p><strong>Authors:SÃ©bastien Quetin, Andrew Heschl, Mauricio Murillo, Rohit Murali, Piotr Pater, George Shenouda, Shirin A. Enger, Farhad Maleki</strong></p>
<p>Purpose: To present a high-performing, robust, and flexible deep learning pipeline for automatic segmentation of 30 organs-at-risk (OARs) in head and neck (H&amp;N) cancer patients, using MRI, CT, or both. Method: We trained a segmentation pipeline on paired CT and MRI-T1 scans from 296 patients. We combined data from the H&amp;N OARs CT and MR segmentation (HaN-Seg) challenge and the Burdenko and GLIS-RT datasets from the Cancer Imaging Archive (TCIA). MRI was rigidly registered to CT, and both were stacked as input to an nnU-Net pipeline. Left and right OARs were merged into single classes during training and separated at inference time based on anatomical position. Modality Dropout was applied during the training, ensuring the model would learn from both modalities and robustly handle missing modalities during inference. The trained model was evaluated on the HaN-Seg test set and three TCIA datasets. Predictions were also compared with Limbus AI software. Dice Score (DS) and Hausdorff Distance (HD) were used as evaluation metrics. Results: The pipeline achieved state-of-the-art performance on the HaN-Seg challenge with a mean DS of 78.12% and HD of 3.42 mm. On TCIA datasets, the model maintained strong agreement with Limbus AI software (DS: 77.43% , HD: 3.27 mm), while also flagging low-quality contours. The pipeline can segment seamlessly from the CT, the MRI scan, or both. Conclusion: The proposed pipeline achieved the best DS and HD scores among all HaN-Seg challenge participants and establishes a new state-of-the-art for fully automated, multi-modal segmentation of H&amp;N OARs. </p>
<blockquote>
<p>ç›®çš„ï¼šæœ¬ç ”ç©¶çš„ç›®çš„æ˜¯åˆ©ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œæ„å»ºä¸€ä¸ªé«˜æ€§èƒ½ã€ç¨³å¥ä¸”çµæ´»çš„ç®¡é“ï¼Œå®ç°å¯¹å¤´é¢ˆç™Œæ‚£è€…30ä¸ªé£é™©å™¨å®˜ï¼ˆOARï¼‰çš„è‡ªåŠ¨åˆ†å‰²ã€‚è¯¥æ–¹æ³•ä½¿ç”¨MRIã€CTæˆ–ä¸¤è€…ç»“åˆçš„æ•°æ®ã€‚æ–¹æ³•ï¼šæˆ‘ä»¬åœ¨æ¥è‡ª296åæ‚£è€…çš„é…å¯¹CTå’ŒMRI-T1æ‰«æä¸Šè®­ç»ƒäº†åˆ†å‰²ç®¡é“ã€‚æˆ‘ä»¬ç»“åˆäº†å¤´é¢ˆé£é™©å™¨å®˜CTå’ŒMRåˆ†å‰²ï¼ˆHaN-Segï¼‰æŒ‘æˆ˜çš„æ•°æ®ä»¥åŠTCIAçš„Burdenkoå’ŒGLIS-RTæ•°æ®é›†ã€‚MRIè¢«åˆšæ€§é…å‡†åˆ°CTï¼Œä¸¤è€…éƒ½è¢«å †å ä¸ºè¾“å…¥åˆ°nnU-Netç®¡é“ä¸­ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå·¦å³OARè¢«åˆå¹¶ä¸ºå•ä¸€ç±»åˆ«ï¼Œå¹¶åœ¨æ¨ç†æ—¶æ ¹æ®è§£å‰–ä½ç½®è¿›è¡Œåˆ†ç¦»ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åº”ç”¨äº†æ¨¡æ€ä¸¢å¼ƒæ³•ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿä»ä¸¤ç§æ¨¡æ€ä¸­å­¦ä¹ ï¼Œå¹¶åœ¨æ¨ç†æ—¶ç¨³å¥åœ°å¤„ç†ç¼ºå¤±çš„æ¨¡æ€ã€‚è¯¥è®­ç»ƒæ¨¡å‹åœ¨HaN-Segæµ‹è¯•é›†å’Œä¸‰ä¸ªTCIAæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚é¢„æµ‹ç»“æœè¿˜ä¸Limbus AIè½¯ä»¶è¿›è¡Œäº†æ¯”è¾ƒã€‚ä½¿ç”¨Diceç³»æ•°ï¼ˆDSï¼‰å’ŒHausdorffè·ç¦»ï¼ˆHDï¼‰ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ã€‚ç»“æœï¼šè¯¥ç®¡é“åœ¨HaN-SegæŒ‘æˆ˜ä¸­å–å¾—äº†æœ€æ–°æŠ€æœ¯æ€§èƒ½ï¼Œå¹³å‡Diceç³»æ•°ä¸º78.12%ï¼ŒHausdorffè·ç¦»ä¸º3.42æ¯«ç±³ã€‚åœ¨TCIAæ•°æ®é›†ä¸­ï¼Œè¯¥æ¨¡å‹ä¸Limbus AIè½¯ä»¶ä¿æŒé«˜åº¦ä¸€è‡´ï¼ˆDiceç³»æ•°ï¼š77.43%ï¼ŒHausdorffè·ç¦»ï¼š3.27æ¯«ç±³ï¼‰ï¼ŒåŒæ—¶æ ‡è®°äº†ä½è´¨é‡çš„è½®å»“ã€‚è¯¥ç®¡é“å¯ä»¥æ— ç¼åœ°ä»CTæˆ–MRIæ‰«ææˆ–ä¸¤è€…ä¸­è¿›è¡Œåˆ†å‰²ã€‚ç»“è®ºï¼šæ‰€æå‡ºçš„ç®¡é“åœ¨HaN-SegæŒ‘æˆ˜ä¸­å–å¾—äº†æœ€ä½³çš„Diceç³»æ•°å’ŒHausdorffè·ç¦»å¾—åˆ†ï¼Œä¸ºå…¨è‡ªåŠ¨å¤šæ¨¡æ€å¤´é¢ˆé£é™©å™¨å®˜çš„åˆ†å‰²å»ºç«‹äº†æ–°çš„å…ˆè¿›æŠ€æœ¯æ ‡å‡†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.10833v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é«˜æ€§èƒ½ã€ç¨³å¥ã€çµæ´»çš„æ·±åº¦å­¦ä¹ ç®¡é“ï¼Œå¯è‡ªåŠ¨å¯¹å¤´éƒ¨å’Œé¢ˆéƒ¨ï¼ˆH&amp;Nï¼‰ç™Œç—‡æ‚£è€…çš„30ä¸ªå±é™©å™¨å®˜ï¼ˆOARï¼‰è¿›è¡ŒMRIã€CTæˆ–ä¸¤è€…çš„åˆ†å‰²ã€‚è¯¥ç®¡é“åœ¨HaN-SegæŒ‘æˆ˜å’ŒTCIAæ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒä¸è¯„ä¼°ï¼Œå®ç°äº†åœ¨HN-SegæŒ‘æˆ˜ä¸­çš„æœ€ä½³è¡¨ç°ï¼Œå»ºç«‹äº†å…¨è‡ªåŠ¨å¤šæ¨¡æ€åˆ†å‰²HN OARsçš„æ–°é‡Œç¨‹ç¢‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ ç®¡é“ç”¨äºè‡ªåŠ¨åˆ†å‰²å¤´éƒ¨å’Œé¢ˆéƒ¨ç™Œç—‡æ‚£è€…çš„å±é™©å™¨å®˜ã€‚</li>
<li>ç®¡é“ç»“åˆäº†MRIå’ŒCTæ‰«ææ•°æ®ï¼Œä½¿ç”¨nnU-Netç®¡é“è¿›è¡Œè®­ç»ƒã€‚</li>
<li>å·¦å³å±é™©å™¨å®˜åœ¨è®­ç»ƒæœŸé—´åˆå¹¶æˆå•ä¸ªç±»åˆ«ï¼Œåœ¨æ¨ç†æ—¶é—´æ ¹æ®è§£å‰–ä½ç½®è¿›è¡Œåˆ†ç¦»ã€‚</li>
<li>è®­ç»ƒè¿‡ç¨‹ä¸­åº”ç”¨äº†æ¨¡æ€ä¸¢å¼ƒæŠ€æœ¯ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå¤„ç†ç¼ºå¤±çš„æ¨¡æ€ã€‚</li>
<li>åœ¨HaN-SegæŒ‘æˆ˜å’ŒTCIAæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®ç°äº†æœ€ä½³æ€§èƒ½ã€‚</li>
<li>ä¸Limbus AIè½¯ä»¶ç›¸æ¯”ï¼Œè¯¥æ¨¡å‹ä¿æŒäº†å¼ºå¤§çš„åè®®ï¼Œå¹¶å¯ä»¥æ ‡è®°ä½è´¨é‡çš„è½®å»“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.10833">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2405.10833v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_åŒ»å­¦å›¾åƒ/2405.10833v3/page_3_0.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-14/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-14/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-16/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_R1_Reasoning/2509.06806v4/page_1_0.jpg" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-16  DeepDive Advancing Deep Search Agents with Knowledge Graphs and   Multi-Turn RL
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-14/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-14\./crop_Diffusion Models/2411.00827v5/page_2_0.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-14  A novel method and dataset for depth-guided image deblurring from   smartphone Lidar
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32298.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
