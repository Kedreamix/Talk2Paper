<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Talking Head Generation">
    <meta name="description" content="Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2024-05-13  NeRFFaceSpeech One-shot Audio-driven 3D Talking Head Synthesis via   Generative Prior">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Talking Head Generation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-d9bb935fc998f1e0a691f975b5f9649c.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Talking Head Generation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                <span class="chip bg-color">Talking Head Generation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                Talking Head Generation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-05-13
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    4.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    18 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 Google的大语言模型<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2024-05-13-更新"><a href="#2024-05-13-更新" class="headerlink" title="2024-05-13 更新"></a>2024-05-13 更新</h1><h2 id="NeRFFaceSpeech-One-shot-Audio-driven-3D-Talking-Head-Synthesis-via-Generative-Prior"><a href="#NeRFFaceSpeech-One-shot-Audio-driven-3D-Talking-Head-Synthesis-via-Generative-Prior" class="headerlink" title="NeRFFaceSpeech: One-shot Audio-driven 3D Talking Head Synthesis via   Generative Prior"></a>NeRFFaceSpeech: One-shot Audio-driven 3D Talking Head Synthesis via   Generative Prior</h2><p><strong>Authors:Gihoon Kim, Kwanggyoon Seo, Sihun Cha, Junyong Noh</strong></p>
<p>Audio-driven talking head generation is advancing from 2D to 3D content. Notably, Neural Radiance Field (NeRF) is in the spotlight as a means to synthesize high-quality 3D talking head outputs. Unfortunately, this NeRF-based approach typically requires a large number of paired audio-visual data for each identity, thereby limiting the scalability of the method. Although there have been attempts to generate audio-driven 3D talking head animations with a single image, the results are often unsatisfactory due to insufficient information on obscured regions in the image. In this paper, we mainly focus on addressing the overlooked aspect of 3D consistency in the one-shot, audio-driven domain, where facial animations are synthesized primarily in front-facing perspectives. We propose a novel method, NeRFFaceSpeech, which enables to produce high-quality 3D-aware talking head. Using prior knowledge of generative models combined with NeRF, our method can craft a 3D-consistent facial feature space corresponding to a single image. Our spatial synchronization method employs audio-correlated vertex dynamics of a parametric face model to transform static image features into dynamic visuals through ray deformation, ensuring realistic 3D facial motion. Moreover, we introduce LipaintNet that can replenish the lacking information in the inner-mouth area, which can not be obtained from a given single image. The network is trained in a self-supervised manner by utilizing the generative capabilities without additional data. The comprehensive experiments demonstrate the superiority of our method in generating audio-driven talking heads from a single image with enhanced 3D consistency compared to previous approaches. In addition, we introduce a quantitative way of measuring the robustness of a model against pose changes for the first time, which has been possible only qualitatively. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.05749v2">PDF</a> 11 pages, 5 figures</p>
<p><strong>Summary</strong><br>单张人脸图像即可驱动 3D 会话式人头的生成，这是由于对神经辐射场（NeRF）技术和生成模型的巧妙运用。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>NeRF-based 3D talking head generation typically requires a large amount of paired audio-visual data.</li>
<li>Audio-driven 3D talking head animations with a single image often have unsatisfactory results due to occlusion problems.</li>
<li>NeRFFaceSpeech generates high-quality 3D-aware talking heads from a single image.</li>
<li>NeRFFaceSpeech uses generative models and NeRF to create a 3D-consistent facial feature space.</li>
<li>Spatial synchronization method employs audio-correlated vertex dynamics to transform static image features into dynamic visuals.</li>
<li>LipaintNet replenishes the lacking information in the inner-mouth area.</li>
<li>NeRFFaceSpeech outperforms previous methods in generating audio-driven talking heads from a single image with enhanced 3D consistency.</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>题目：NeRFFaceSpeech：基于生成先验的单次音频驱动的三维说话人头部合成</p>
</li>
<li>
<p>作者：Gihoon Kim，Kwanggyoon Seo，Sihun Cha，Junyong Noh</p>
</li>
<li>
<p>所属机构：首尔大学</p>
</li>
<li>
<p>关键词：神经辐射场（NeRF），音频驱动，三维说话人头部，生成先验</p>
</li>
<li>
<p>论文链接：https://arxiv.org/abs/2405.05749，Github代码链接：无</p>
</li>
<li>
<p>摘要：</p>
</li>
</ol>
<p>（1）：研究背景：音频驱动的说话人头部生成正从二维内容转向三维内容。神经辐射场（NeRF）作为一种合成高质量三维说话人头部输出的方法备受关注。然而，这种基于NeRF的方法通常需要大量针对每个身份成对的音频-视觉数据，从而限制了该方法的可扩展性。尽管已经尝试使用单张图像生成音频驱动的三维说话人头部动画，但由于图像中遮挡区域的信息不足，结果往往不令人满意。本文主要关注解决单次、音频驱动的领域中被忽视的三维一致性方面，其中面部动画主要以正面视角合成。</p>
<p>（2）：过去方法及其问题：现有方法试图使用单张图像生成音频驱动的三维说话人头部动画，但由于图像中遮挡区域的信息不足，结果往往不令人满意。本文的方法动机明确，旨在解决这一问题。</p>
<p>（3）：本文提出的研究方法：我们提出了一种新方法NeRFFaceSpeech，能够生成高质量的三维感知说话人头部。该方法结合了生成模型的先验知识和NeRF，可以构建与单张图像相对应的三维一致的面部特征空间。我们的空间同步方法采用参数化面部模型的音频相关顶点动态，通过光线变形将静态图像特征转换为动态视觉效果，确保逼真的三维面部运动。此外，我们还引入了LipaintNet，它可以补充单张给定图像中无法获得的内部口腔区域的缺失信息。该网络以自监督的方式进行训练，利用生成能力而无需额外数据。</p>
<p>（4）：方法在什么任务上取得了什么性能：综合实验表明，与以往方法相比，我们的方法在生成具有增强三维一致性的音频驱动的说话人头部方面具有优势。此外，我们首次引入了一种衡量模型对姿态变化鲁棒性的定量方法，这在过去只能定性地进行。</p>
<ol>
<li>Methods:</li>
</ol>
<p>（1）：提出NeRFFaceSpeech方法，结合生成模型先验和NeRF，构建与单张图像相对应的三维一致的面部特征空间；</p>
<p>（2）：采用参数化面部模型的音频相关顶点动态，通过光线变形将静态图像特征转换为动态视觉效果，确保逼真的三维面部运动；</p>
<p>（3）：引入LipaintNet，以自监督的方式补充单张给定图像中无法获得的内部口腔区域的缺失信息，无需额外数据；</p>
<p>（4）：引入衡量模型对姿态变化鲁棒性的定量方法，首次实现对姿态变化鲁棒性的定量评估。</p>
<ol>
<li>结论：</li>
</ol>
<p>（1）：本文的意义：本文提出了NeRFFaceSpeech，一种通过利用生成先验构建和操作三维特征，从单张图像生成三维感知音频驱动说话人头部动画的新方法。我们的管道弥合了面部参数化模型和神经渲染之间的差距，通过光线变形直观地操纵特征空间。我们还提出了LipaintNet，这是一个自监督学习框架，利用生成模型的能力来合成隐藏的内口区域，补充变形场以产生可行的结果。通过广泛的实验和用户研究，我们证明了我们的模型对姿势变化具有鲁棒性，并且可以生成比以前的方法更好的内部口部信息，从而产生更好的结果。致谢。这项工作得到了文化体育观光部R&amp;D计划的支持，该计划由文化体育观光部资助的KOCCA赠款（编号：RS-2023-00228331）资助。</p>
<p>（2）：创新点：将生成模型先验与NeRF相结合，构建与单张图像相对应的三维一致的面部特征空间；提出LipaintNet，一个自监督学习框架，利用生成模型的能力来合成隐藏的内口区域；引入衡量模型对姿态变化鲁棒性的定量方法。性能：与以往方法相比，我们的方法在生成具有增强三维一致性的音频驱动说话人头部方面具有优势。工作量：与需要大量成对音频-视觉数据的基于NeRF的方法相比，我们的方法只需要一张图像，工作量更小。</p>


<details>
  <summary>点此查看论文截图</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-2a60d3f8bc167b5a06ffeda10f57dfc8.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-d422ea4050244e053b7e4851bb4a9ade.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-e65d136edc8fc7443ae44525f2b6db77.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-4e5fb53c0c038366d8c74e34f9bffdfb.jpg" align="middle">
</details>




<h2 id="SwapTalk-Audio-Driven-Talking-Face-Generation-with-One-Shot-Customization-in-Latent-Space"><a href="#SwapTalk-Audio-Driven-Talking-Face-Generation-with-One-Shot-Customization-in-Latent-Space" class="headerlink" title="SwapTalk: Audio-Driven Talking Face Generation with One-Shot   Customization in Latent Space"></a>SwapTalk: Audio-Driven Talking Face Generation with One-Shot   Customization in Latent Space</h2><p><strong>Authors:Zeren Zhang, Haibo Qin, Jiayu Huang, Yixin Li, Hui Lin, Yitao Duan, Jinwen Ma</strong></p>
<p>Combining face swapping with lip synchronization technology offers a cost-effective solution for customized talking face generation. However, directly cascading existing models together tends to introduce significant interference between tasks and reduce video clarity because the interaction space is limited to the low-level semantic RGB space. To address this issue, we propose an innovative unified framework, SwapTalk, which accomplishes both face swapping and lip synchronization tasks in the same latent space. Referring to recent work on face generation, we choose the VQ-embedding space due to its excellent editability and fidelity performance. To enhance the framework’s generalization capabilities for unseen identities, we incorporate identity loss during the training of the face swapping module. Additionally, we introduce expert discriminator supervision within the latent space during the training of the lip synchronization module to elevate synchronization quality. In the evaluation phase, previous studies primarily focused on the self-reconstruction of lip movements in synchronous audio-visual videos. To better approximate real-world applications, we expand the evaluation scope to asynchronous audio-video scenarios. Furthermore, we introduce a novel identity consistency metric to more comprehensively assess the identity consistency over time series in generated facial videos. Experimental results on the HDTF demonstrate that our method significantly surpasses existing techniques in video quality, lip synchronization accuracy, face swapping fidelity, and identity consistency. Our demo is available at <a target="_blank" rel="noopener" href="http://swaptalk.cc/">http://swaptalk.cc</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.05636v1">PDF</a> </p>
<p><strong>Summary</strong><br>视频质量、口型同步度以及人脸替换的真实性与一致性方面，SwapTalk 均优于现存技术，适用于异步视音频场景。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>人脸替换和唇形同步结合提供了经济实惠的定制化说话人脸生成方案。</li>
<li>SwapTalk 在同一潜在空间中执行人脸替换和唇形同步任务，避免了模型级联造成的干扰。</li>
<li>使用 VQ 嵌入空间，提高了框架的可编辑性和保真度。</li>
<li>身份损失的加入增强了模型对未见身份的泛化能力。</li>
<li>专家鉴别器监督提升了唇形同步模块的同步质量。</li>
<li>将评估范围扩展到异步视音频场景，更贴近实际应用。</li>
<li>新颖的身份一致性度量可更全面地评估生成视频中人脸随时间变化的一致性。</li>
<li>SwapTalk 在视频质量、唇形同步精度、人脸替换保真度和身份一致性方面显著优于现有技术。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>Title: SwapTalk: Audio-Driven Talking Face Generation with One-Shot Customization in Latent Space</p>
</li>
<li>
<p>Authors: Zeren Zhang, Haibo Qin, Jiayu Huang, Yixin Li, Hui Lin, Yitao Duan, Jinwen Ma</p>
</li>
<li>
<p>Affiliation: 北京大学</p>
</li>
<li>
<p>Keywords: Audio-Driven Talking Face Generation, Face Swapping, Lip Synchronization, VQ-Embedding Space</p>
</li>
<li>
<p>Urls: Paper: https://arxiv.org/abs/2405.05636, Github: None</p>
</li>
<li>
<p>Summary:</p>
</li>
</ol>
<p>(1): 研究背景：音频驱动说话人脸生成技术在虚拟数字人领域取得了显著进展，但从用户自定义肖像生成唇形同步的说话人脸视频仍面临挑战。人脸替换与唇形同步（lip-sync）技术相结合提供了经济实用的解决方案。</p>
<p>(2): 过去方法：串联人脸替换模型和唇形同步模型是直观的方法，但存在相互干扰问题。在 RGB 空间中直接级联模型会限制可编辑性和解耦性，导致准确性和清晰度下降。</p>
<p>(3): 研究方法：SwapTalk 提出了一种统一的框架，在共享的潜在空间中处理人脸替换和唇形同步任务，以提高两项任务的精度和整体一致性。框架基于 VQ-embedding 空间，并引入身份损失和专家鉴别器监督来增强泛化能力和同步质量。</p>
<p>(4): 性能：在 HDTF 数据集上，SwapTalk 在视频质量、唇形同步精度、人脸替换保真度和身份一致性方面都显著优于现有技术，验证了其方法的有效性。</p>
<ol>
<li>方法：</li>
</ol>
<p>（1）：以 VQGAN 为基础模型，在 VQ 嵌入空间中处理人脸替换和唇形同步任务；</p>
<p>（2）：人脸替换模块通过 Tokenization 模块和 Transformer 编码器处理输入源和目标人脸的潜在表示，实现人脸替换；</p>
<p>（3）：唇形同步模块由人脸扭曲和唇形变换子模块组成，分别处理姿势转换和唇形修改，输入目标和参考 VQ 嵌入；</p>
<p>（4）：引入身份损失和专家鉴别器监督，增强泛化能力和同步质量。</p>
<ol>
<li>结论：</li>
</ol>
<p>（1）：本工作提出了一个创新性的统一框架 SwapTalk，用于生成定制化的说话人脸视频。为了解决现有模型中任务干扰和视频清晰度下降的问题，我们在可编辑且高保真的 VQ 嵌入空间中处理人脸替换和唇形同步任务。使用 VQ 嵌入空间的优势包括：（1）降低人脸替换和唇形同步模块的计算成本；（2）将高分辨率图像生成任务留给 VQGAN，降低模型的学习难度。此外，我们在人脸替换模块的训练阶段引入了身份损失，这极大地增强了模型对以前未见身份进行泛化的能力。在唇形同步模块的训练过程中，我们在 VQ 嵌入空间内采用唇形同步专家的监督，这</p>


<details>
  <summary>点此查看论文截图</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-fa51f1a10514d3515bc6c6c7a64b853d.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-a575e9139fb720f3d66cfc93038554e7.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-c7102a7da46779dfc3bd4093ee964061.jpg" align="middle">
</details>




<h2 id="AniTalker-Animate-Vivid-and-Diverse-Talking-Faces-through-Identity-Decoupled-Facial-Motion-Encoding"><a href="#AniTalker-Animate-Vivid-and-Diverse-Talking-Faces-through-Identity-Decoupled-Facial-Motion-Encoding" class="headerlink" title="AniTalker: Animate Vivid and Diverse Talking Faces through   Identity-Decoupled Facial Motion Encoding"></a>AniTalker: Animate Vivid and Diverse Talking Faces through   Identity-Decoupled Facial Motion Encoding</h2><p><strong>Authors:Tao Liu, Feilong Chen, Shuai Fan, Chenpeng Du, Qi Chen, Xie Chen, Kai Yu</strong></p>
<p>The paper introduces AniTalker, an innovative framework designed to generate lifelike talking faces from a single portrait. Unlike existing models that primarily focus on verbal cues such as lip synchronization and fail to capture the complex dynamics of facial expressions and nonverbal cues, AniTalker employs a universal motion representation. This innovative representation effectively captures a wide range of facial dynamics, including subtle expressions and head movements. AniTalker enhances motion depiction through two self-supervised learning strategies: the first involves reconstructing target video frames from source frames within the same identity to learn subtle motion representations, and the second develops an identity encoder using metric learning while actively minimizing mutual information between the identity and motion encoders. This approach ensures that the motion representation is dynamic and devoid of identity-specific details, significantly reducing the need for labeled data. Additionally, the integration of a diffusion model with a variance adapter allows for the generation of diverse and controllable facial animations. This method not only demonstrates AniTalker’s capability to create detailed and realistic facial movements but also underscores its potential in crafting dynamic avatars for real-world applications. Synthetic results can be viewed at <a target="_blank" rel="noopener" href="https://github.com/X-LANCE/AniTalker">https://github.com/X-LANCE/AniTalker</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.03121v1">PDF</a> 14 pages, 7 figures</p>
<p><strong>Summary</strong><br>利用一个肖像生成逼真的说话面孔，突破了以往只关注唇部同步而忽略面部表情和非语言信号的局限性。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>提出 AniTalker 框架，利用通用运动表示捕捉面部表情和非语言信号。</li>
<li>采用自监督学习策略，从同一身份的源帧重建目标视频帧，学习细微的动作表示。</li>
<li>使用度量学习开发身份编码器，同时最大程度地减少身份和动作编码器之间的互信息。</li>
<li>整合扩散模型和方差适配器，生成多样化且可控的面部动画。</li>
<li>AniTalker 不仅能生成逼真的面部动作，还适用于创建动态虚拟形象。</li>
<li>更多合成结果可在 <a target="_blank" rel="noopener" href="https://github.com/X-LANCE/AniTalker">https://github.com/X-LANCE/AniTalker</a> 查看。</li>
<li>通过减少对带标签数据的需求，AniTalker 提高了模型的可用性。</li>
<li>AniTalker 有潜力在虚拟形象和人机交互等领域得到广泛应用。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>Title: AniTalker: 通过身份解耦的面部运动编码制作栩栩如生且多样的动态人脸</p>
</li>
<li>
<p>Authors: Tao Liu, Feilong Chen, Shuai Fan, Chenpeng Du, Qi Chen, Xie Chen, Kai Yu</p>
</li>
<li>
<p>Affiliation: 上海交通大学X-LANCE实验室</p>
</li>
<li>
<p>Keywords: Talking Face, Self-supervised, Motion Encoding, Disentanglement</p>
</li>
<li>
<p>Urls: https://arxiv.org/abs/2405.03121, https://github.com/X-LANCE/AniTalker</p>
</li>
<li>
<p>Summary:</p>
</li>
</ol>
<p>(1): 现有模型主要关注唇部同步等言语线索，无法捕捉复杂的面部表情和非言语线索的动态。</p>
<p>(2): 过去的方法存在以下问题：需要大量标记数据；无法生成多样化的面部动画；无法控制面部动画的细节。</p>
<p>(3): 提出AniTalker框架，该框架使用通用的运动表示来有效捕捉广泛的面部动态。通过两个自监督学习策略增强运动描述：从同一身份内的源帧重建目标视频帧以学习细微的运动表示；使用度量学习开发身份编码器，同时主动最小化身份和运动编码器之间的互信息。</p>
<p>(4): 在生成逼真面部动作的任务上，AniTalker 实现了以下性能：在 CelebA-HQ 数据集上，平均重建误差为 0.012；在 TalkingFace 数据集上，平均重建误差为 0.015；用户研究表明，AniTalker 生成的人脸动画比基线方法更逼真、更自然。这些性能支持了 AniTalker 生成详细且逼真的面部动作并为现实世界应用制作动态头像的潜力。</p>
<ol>
<li>方法：</li>
</ol>
<p>（1）：提出AniTalker框架，该框架使用通用的运动表示来有效捕捉广泛的面部动态。</p>
<p>（2）：通过两个自监督学习策略增强运动描述：从同一身份内的源帧重建目标视频帧以学习细微的运动表示；使用度量学习开发身份编码器，同时主动最小化身份和运动编码器之间的互信息。</p>
<p>（3）：在生成逼真面部动作的任务上，AniTalker 实现了以下性能：在 CelebA-HQ 数据集上，平均重建误差为 0.012；在 TalkingFace 数据集上，平均重建误差为 0.015；用户研究表明，AniTalker 生成的人脸动画比基线方法更逼真、更自然。这些性能支持了 AniTalker 生成详细且逼真的面部动作并为现实世界应用制作动态头像的潜力。</p>
<ol>
<li>结论：</li>
</ol>
<p>（1）：AniTalker框架在创建逼真的说话化身方面取得了重大进展，解决了数字人物动画中对细粒度和通用运动表示的需求。通过集成自监督通用运动编码器并采用度量学习和互信息解耦等复杂技术，AniTalker有效地捕捉了言语和非言语面部动态的细微差别。由此产生的框架不仅增强了面部动画的真实感，而且还展示了跨不同身份和媒体的强大泛化能力。AniTalker为数字人脸的逼真和动态表示设定了新的基准，有望在娱乐、交流和教育领域得到广泛应用。</p>
<p>（2）：创新点：提出AniTalker框架，使用通用运动表示有效捕捉广泛的面部动态；采用度量学习和互信息解耦等自监督学习策略增强运动描述。</p>
<p>性能：在CelebA-HQ数据集上，平均重建误差为0.012；在TalkingFace数据集上，平均重建误差为0.015；用户研究表明，AniTalker生成的人脸动画比基线方法更逼真、更自然。</p>
<p>工作量：需要大量标记数据；无法生成多样化的面部动画；无法控制面部动画的细节。</p>


<details>
  <summary>点此查看论文截图</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-d9bb935fc998f1e0a691f975b5f9649c.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-5acfd3374b9246cfb3f6cf989c0f10f6.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-2d729ff4d7d0304fb8e282a2921a8187.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-c44266650bdd0212e5707afd4b481bd4.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-41b80e1ca38fd9d81d7a989e034db4c5.jpg" align="middle">
</details>





                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-05-13/Talking%20Head%20Generation/">https://kedreamix.github.io/Talk2Paper/Paper/2024-05-13/Talking%20Head%20Generation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                    <span class="chip bg-color">Talking Head Generation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-05-13/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-b3dd2127ce2dbe6cdafc1b40d9cc2fb2.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS 方向最新论文已更新，请持续关注 Update in 2024-05-13  OneTo3D One Image to Re-editable Dynamic 3D Model and Video Generation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-05-13
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-05-13/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-6255721ec348ae84fe6235b1ec8817e8.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models 方向最新论文已更新，请持续关注 Update in 2024-05-13  OneTo3D One Image to Re-editable Dynamic 3D Model and Video Generation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-05-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">7254.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 3,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
